{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "270fec5d-2428-4d80-890c-3304162fd8ad",
   "metadata": {},
   "source": [
    "# Finding the Lyapunov Function using Counterexamples Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7f0ba27-b991-407f-9b0f-724141d0120b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from scipy.linalg import solve_continuous_lyapunov\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from dreal import *\n",
    "\n",
    "import timeit \n",
    "\n",
    "import tqdm\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307e8551-93e3-406b-abdc-967af866f9d2",
   "metadata": {},
   "source": [
    "## Obtaining the Trajectories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f33ac833-122b-4879-a529-80449992bd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "# Training Data\n",
    "mat = scipy.io.loadmat('../LASA_Dataset/lasahandwritingdataset/Angle_train.mat')\n",
    "datat = mat['Data']\n",
    "datat = np.transpose(datat)\n",
    "# Getting the Position and Velocity Seperately\n",
    "X_train = datat[:,:2]\n",
    "y_train = datat[:,2:]\n",
    "# Testing Data\n",
    "mat = scipy.io.loadmat('../LASA_Dataset/lasahandwritingdataset/Angle_test.mat')\n",
    "data = mat['Data']\n",
    "data = np.transpose(data)\n",
    "# Getting the Position and Velocity Seperately\n",
    "X_test = data[:,:2]\n",
    "y_test = data[:,2:]\n",
    "# Validation Data\n",
    "mat = scipy.io.loadmat('../LASA_Dataset/lasahandwritingdataset/Angle_val.mat')\n",
    "data = mat['Data']\n",
    "data = np.transpose(data)\n",
    "# Getting the Position and Velocity Seperately\n",
    "X_val = data[:,:2]\n",
    "y_val = data[:,2:]\n",
    "# dt\n",
    "dt = 0.0030\n",
    "\n",
    "\n",
    "### NORMALISE THE TRAJECTORIES\n",
    "X_train /= 40\n",
    "X_test /= 40\n",
    "X_val /= 40\n",
    "y_train /= 40\n",
    "y_test /= 40\n",
    "y_val /= 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "062d3c8b-acc8-4694-86dd-ac326749ec89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the Training Data\n",
    "fig, ax = plt.subplots()\n",
    "n = int(X_train.shape[0]/1000)\n",
    "for i in range(5):\n",
    "    ax.plot(X_train[(i-1)*1000+1:i*1000,0], X_train[(i-1)*1000+1:i*1000,1],\"b\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1565cf-0888-488c-9bc1-7539e9179153",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af90cd8b-3833-4abe-911e-b48fb7f4d505",
   "metadata": {},
   "outputs": [],
   "source": [
    "## NN for learning the Lyapunov Function\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self,n_input,n_hidden,n_output):\n",
    "        super(Net, self).__init__()\n",
    "        self.layer1 = torch.nn.Linear(n_input, n_hidden)\n",
    "        self.layer2 = torch.nn.Linear(n_hidden,n_output)\n",
    "        # Xavier Initialisation\n",
    "        nn.init.xavier_uniform_(self.layer1.weight)\n",
    "        nn.init.xavier_uniform_(self.layer2.weight)\n",
    "    def forward(self,x):\n",
    "        sigmoid = torch.nn.Tanh()\n",
    "        h_1 = sigmoid(self.layer1(x))\n",
    "        out = sigmoid(self.layer2(h_1))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9a51c0b-a163-4c12-a42b-3f4786fab718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NN for learning dynamics\n",
    "class fNet(torch.nn.Module):\n",
    "    def __init__(self,n_input, n_hidden1,  n_output):\n",
    "        super().__init__()\n",
    "        self.layer1 = torch.nn.Linear(n_input, n_hidden1)\n",
    "        self.layer2 = torch.nn.Linear(n_hidden1,n_output)  \n",
    "        # Xavier Initialisation\n",
    "        nn.init.xavier_uniform_(self.layer1.weight)\n",
    "        nn.init.xavier_uniform_(self.layer2.weight)\n",
    "    def forward(self,x):\n",
    "        sigmoid = torch.nn.Tanh()\n",
    "        h_1 = sigmoid(self.layer1(x))\n",
    "        out = self.layer2(h_1) \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44be2dde-998f-4ee4-9507-46f4acaeb906",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5a780a8-ab8f-4892-b90c-ab9e0179b118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a dynamical system dx/dt = f(x,u) and candidate Lyapunov function V\n",
    "# Check the Lyapunov conditions within a domain around the origin (ball_lb ≤ sqrt(∑xᵢ²) ≤ ball_ub). \n",
    "# If it return unsat, then there is no state violating the conditions. \n",
    "def CheckLyapunov(x, f, V, ball_lb, ball_ub, config, epsilon):    \n",
    "    ball= Expression(0)\n",
    "    lie_derivative_of_V = Expression(0)\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        ball += x[i]*x[i]\n",
    "        lie_derivative_of_V += f[i]*V.Differentiate(x[i])  \n",
    "    ball_in_bound = logical_and(ball_lb*ball_lb <= ball, ball <= ball_ub*ball_ub)\n",
    "    \n",
    "    # Constraint: x ∈ Ball → (V(c, x) > 0 ∧ Lie derivative of V <= 0)     \n",
    "    condition = logical_and(logical_imply(ball_in_bound, V >= 0),\n",
    "                           logical_imply(ball_in_bound, lie_derivative_of_V <= epsilon))\n",
    "    # Constraint: x^2 < lb → (V(x) = 0)\n",
    "    V_epsi = 1e-1\n",
    "    ball_in_bound_internal = logical_and(0 <= ball, ball <= ball_lb*ball_lb)\n",
    "    condition_y = logical_and(logical_imply(ball_in_bound_internal, V <= V_epsi), condition)\n",
    "    return CheckSatisfiability(logical_not(condition_y),config)\n",
    "\n",
    "# Given a candidate Lyapunov function V, check the Lipschitz constant within a domain around the origin (sqrt(∑xᵢ²) ≤ ball_ub). \n",
    "# If it return unsat, then there is no state violating the conditions. \n",
    "def CheckdVdx(x, V, ball_ub, config, M):        \n",
    "    ball= Expression(0)\n",
    "    derivative_of_V = Expression(0)\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        ball += x[i]*x[i]\n",
    "        derivative_of_V += V.Differentiate(x[i])*V.Differentiate(x[i])\n",
    "    ball_in_bound = logical_and(ball <= ball_ub*ball_ub)\n",
    "    \n",
    "    # Constraint: x ∈ Ball → partial derivative of V <= M     \n",
    "    condition = logical_imply(ball_in_bound, derivative_of_V <= M)\n",
    "    return CheckSatisfiability(logical_not(condition),config)\n",
    "\n",
    "# Adding Counter-Examples back to sample set\n",
    "def AddCounterexamples(x,CE,N): \n",
    "    c = []\n",
    "    nearby= []\n",
    "    for i in range(CE.size()):\n",
    "        c.append(CE[i].mid())\n",
    "        lb = CE[i].lb()\n",
    "        ub = CE[i].ub()\n",
    "        nearby_ = np.random.uniform(lb,ub,N)\n",
    "        nearby.append(nearby_)\n",
    "    for i in range(N):\n",
    "        n_pt = []\n",
    "        for j in range(x.shape[1]):\n",
    "            n_pt.append(nearby[j][i])             \n",
    "        x = torch.cat((x, torch.tensor([n_pt])), 0)\n",
    "    return x\n",
    "\n",
    "# Derivative of activation\n",
    "def dtanh(s):\n",
    "    return 1.0 - s**2\n",
    "\n",
    "# Circle function values\n",
    "def Tune(x):\n",
    "    y = []\n",
    "    for r in range(0,len(x)):\n",
    "        v = 0 \n",
    "        for j in range(x.shape[1]):\n",
    "            v += x[r][j]**2\n",
    "        f = [torch.sqrt(v)]\n",
    "        y.append(f)\n",
    "    y = torch.tensor(y)\n",
    "    return y\n",
    "\n",
    "# Loss Function for Warmstarting\n",
    "def lossfunction_warm(x, y, model_v, model_f):\n",
    "    # V_candidate = model_v(x)\n",
    "    y_pred = model_f(x)\n",
    "    # Circle_Tuning = Tune(x)\n",
    "    # Circle_Tuning = Circle_Tuning\n",
    "    loss_fn = nn.MSELoss()  # mean square error\n",
    "    L1 = loss_fn(y_pred, y)\n",
    "    #loss = ((Circle_Tuning-V_candidate).pow(2)).mean() + 10 * L1\n",
    "    loss = L1\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ef2d8ea5-e761-4e45-aaae-4f6d39e52592",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4825/3558207232.py:15: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_train = torch.tensor(X_train, dtype=torch.float32)\n",
      "/tmp/ipykernel_4825/3558207232.py:16: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train = torch.tensor(y_train, dtype=torch.float32)\n",
      "/tmp/ipykernel_4825/3558207232.py:17: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_test = torch.tensor(X_test, dtype=torch.float32)\n",
      "/tmp/ipykernel_4825/3558207232.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test = torch.tensor(y_test, dtype=torch.float32)\n",
      "/tmp/ipykernel_4825/3558207232.py:19: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X_val = torch.tensor(X_val, dtype=torch.float32)\n",
      "/tmp/ipykernel_4825/3558207232.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_val = torch.tensor(y_val, dtype=torch.float32)\n"
     ]
    }
   ],
   "source": [
    "################ WARM STARTING #############\n",
    "# Neural Network Structure\n",
    "nn_h_f = 50\n",
    "# Dimensions\n",
    "nn_x = 2\n",
    "# Weights for the LOSS\n",
    "DECAY_MSE = 1\n",
    "DECAY_LY = 1\n",
    "DECAY_LYG = 1\n",
    "# Epochs\n",
    "n_epochs = 100\n",
    "lr_warm = 0.005\n",
    "########################### TRAINING SET ############################################################\n",
    "# Convert to 2D PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "y_val = torch.tensor(y_val, dtype=torch.float32)\n",
    "\n",
    "########################## Improving V ################################################\n",
    "'''\n",
    "For learning the Lyapunov Function and Dynamics Function together\n",
    "'''\n",
    "N = 1000            # sample size\n",
    "D_in = 2           # input dimension\n",
    "H1 = 6            # hidden dimension\n",
    "D_out = 1          # output dimension\n",
    "region = [-1.5,1.5]\n",
    "x = torch.Tensor(N, D_in).uniform_(region[0],region[1])           \n",
    "x_0 = torch.zeros([1, 2])\n",
    "'''\n",
    "For verifying \n",
    "'''\n",
    "x1 = Variable(\"x1\")\n",
    "x2 = Variable(\"x2\")\n",
    "vars_ = [x1,x2]\n",
    "config = Config()\n",
    "config.use_polytope_in_forall = True\n",
    "config.use_local_optimization = True\n",
    "config.precision = 1e-2\n",
    "\n",
    "learning_rate = 0.0001\n",
    "# For Verification\n",
    "beta = -0.0002 # initial guess of beta\n",
    "# Checking candidate V within a ball around the origin (ball_lb ≤ sqrt(∑xᵢ²) ≤ ball_ub)\n",
    "ball_lb = 1e-4\n",
    "ball_ub = 2\n",
    "\n",
    "# parameters for beta\n",
    "Kf = 3.4599\n",
    "KF = 5.452\n",
    "d = 5e-4\n",
    "loss = 0.0085 # equals alpha above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "88207b7a-e1c4-466c-abd5-9018bef9182d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0973\n",
      "RMSE: 0.3119\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "fNet(\n",
       "  (layer1): Linear(in_features=2, out_features=50, bias=True)\n",
       "  (layer2): Linear(in_features=50, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hold the best model\n",
    "best_mse = np.inf   # init to infinity\n",
    "best_weights = None\n",
    "history = []\n",
    "\n",
    "# Model\n",
    "model_f = fNet(nn_x, nn_h_f, nn_x)\n",
    "model_v = Net(D_in,H1, D_out)\n",
    "\n",
    "loss_fn = nn.MSELoss()  # mean square error\n",
    "optimizer_f = torch.optim.Adam(model_f.parameters(), lr = lr_warm)\n",
    "optimizer_v = torch.optim.Adam(model_v.parameters(), lr = lr_warm)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model_f.train()\n",
    "    model_v.train()\n",
    "    # Calculate the loss\n",
    "    loss = lossfunction_warm(X_train, y_train, model_v, model_f)\n",
    "    # backward pass\n",
    "    optimizer_f.zero_grad()\n",
    "    optimizer_v.zero_grad()\n",
    "    loss.backward() \n",
    "    optimizer_f.step()\n",
    "    optimizer_v.step()\n",
    "    #evaluate accuracy at end of each epoch\n",
    "    model_f.eval()\n",
    "    model_v.eval()\n",
    "    y_pred = model_f(X_test)\n",
    "    mse = lossfunction_warm(X_test, y_test, model_v, model_f)\n",
    "    mse = float(mse)\n",
    "    history.append(mse)\n",
    "    if loss < best_mse:\n",
    "        best_mse = mse\n",
    "        best_weights = copy.deepcopy(model_f.state_dict())\n",
    "    with torch.no_grad():\n",
    "        torch.cuda.empty_cache()\n",
    "# restore model and return best accuracy\n",
    "model_f.load_state_dict(best_weights)\n",
    "print(\"MSE: %.4f\" % best_mse)\n",
    "print(\"RMSE: %.4f\" % np.sqrt(best_mse))\n",
    "plt.plot(history)\n",
    "plt.show()\n",
    "model_f.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5f2373-9a35-4afa-bd54-d1d67d5eb7de",
   "metadata": {},
   "source": [
    "## Taking Train Dataset Whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3822ca79-904b-42e5-9b2d-e1d6227666c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0) Lyapunov Risk = 2.0600757598876953, MSE = 0.09029114991426468, V_0_loss = tensor([[0.0065]], grad_fn=<PowBackward0>), V_pos_loss = 0.21220408380031586, Lv_loss = 0.25860708951950073, Circular Tuning Loss = 1.8393646478652954\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.00010000000000000002, 0.00010000000000000002]\n",
      "x2 : [-0.00010000000000000002, 0.00010000000000000002]\n",
      "==============================\n",
      "1) Lyapunov Risk = 2.032743453979492, MSE = 0.09097481518983841, V_0_loss = tensor([[0.0064]], grad_fn=<PowBackward0>), V_pos_loss = 0.2106582522392273, Lv_loss = 0.24444378912448883, Circular Tuning Loss = 1.8203381299972534\n",
      "2) Lyapunov Risk = 2.010293960571289, MSE = 0.09406661242246628, V_0_loss = tensor([[0.0064]], grad_fn=<PowBackward0>), V_pos_loss = 0.2104136049747467, Lv_loss = 0.22317993640899658, Circular Tuning Loss = 1.8194581270217896\n",
      "3) Lyapunov Risk = 1.9892088174819946, MSE = 0.09878548979759216, V_0_loss = tensor([[0.0063]], grad_fn=<PowBackward0>), V_pos_loss = 0.21016918122768402, Lv_loss = 0.1999502331018448, Circular Tuning Loss = 1.818578839302063\n",
      "4) Lyapunov Risk = 1.9670333862304688, MSE = 0.10255389660596848, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.2099253237247467, Lv_loss = 0.17845115065574646, Circular Tuning Loss = 1.8177002668380737\n",
      "5) Lyapunov Risk = 1.9431066513061523, MSE = 0.10444078594446182, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.20968273282051086, Lv_loss = 0.1602410078048706, Circular Tuning Loss = 1.8168226480484009\n",
      "6) Lyapunov Risk = 1.9223378896713257, MSE = 0.10606568306684494, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.2094418853521347, Lv_loss = 0.1449652910232544, Circular Tuning Loss = 1.8159462213516235\n",
      "7) Lyapunov Risk = 1.9092118740081787, MSE = 0.10930683463811874, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.20920252799987793, Lv_loss = 0.13164140284061432, Circular Tuning Loss = 1.8150713443756104\n",
      "8) Lyapunov Risk = 1.9030978679656982, MSE = 0.11459090560674667, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.20896483957767487, Lv_loss = 0.118814617395401, Circular Tuning Loss = 1.8141977787017822\n",
      "9) Lyapunov Risk = 1.900214433670044, MSE = 0.12098945677280426, V_0_loss = tensor([[0.0058]], grad_fn=<PowBackward0>), V_pos_loss = 0.20872853696346283, Lv_loss = 0.10603109747171402, Circular Tuning Loss = 1.8133258819580078\n",
      "10) Lyapunov Risk = 1.898801326751709, MSE = 0.12780089676380157, V_0_loss = tensor([[0.0057]], grad_fn=<PowBackward0>), V_pos_loss = 0.20849351584911346, Lv_loss = 0.09386447817087173, Circular Tuning Loss = 1.812455177307129\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.00010000000000000002, 0.00010000000000000002]\n",
      "x2 : [-0.00010000000000000002, 0.00010000000000000002]\n",
      "==============================\n",
      "11) Lyapunov Risk = 1.8888994455337524, MSE = 0.13453277945518494, V_0_loss = tensor([[0.0056]], grad_fn=<PowBackward0>), V_pos_loss = 0.20695260167121887, Lv_loss = 0.08195007592439651, Circular Tuning Loss = 1.7938798666000366\n",
      "12) Lyapunov Risk = 1.8901076316833496, MSE = 0.14051245152950287, V_0_loss = tensor([[0.0055]], grad_fn=<PowBackward0>), V_pos_loss = 0.20671692490577698, Lv_loss = 0.07297507673501968, Circular Tuning Loss = 1.79301917552948\n",
      "13) Lyapunov Risk = 1.8906376361846924, MSE = 0.14472363889217377, V_0_loss = tensor([[0.0055]], grad_fn=<PowBackward0>), V_pos_loss = 0.2064821571111679, Lv_loss = 0.06645788252353668, Circular Tuning Loss = 1.7921596765518188\n",
      "14) Lyapunov Risk = 1.88895845413208, MSE = 0.14650355279445648, V_0_loss = tensor([[0.0054]], grad_fn=<PowBackward0>), V_pos_loss = 0.20624804496765137, Lv_loss = 0.0625084787607193, Circular Tuning Loss = 1.7913004159927368\n",
      "15) Lyapunov Risk = 1.8854256868362427, MSE = 0.14635145664215088, V_0_loss = tensor([[0.0053]], grad_fn=<PowBackward0>), V_pos_loss = 0.20601452887058258, Lv_loss = 0.060520075261592865, Circular Tuning Loss = 1.7904419898986816\n",
      "16) Lyapunov Risk = 1.8814246654510498, MSE = 0.14528511464595795, V_0_loss = tensor([[0.0052]], grad_fn=<PowBackward0>), V_pos_loss = 0.20578235387802124, Lv_loss = 0.059553150087594986, Circular Tuning Loss = 1.7895846366882324\n",
      "17) Lyapunov Risk = 1.8768272399902344, MSE = 0.14375105500221252, V_0_loss = tensor([[0.0051]], grad_fn=<PowBackward0>), V_pos_loss = 0.20555081963539124, Lv_loss = 0.0589657761156559, Circular Tuning Loss = 1.7887282371520996\n",
      "18) Lyapunov Risk = 1.8714592456817627, MSE = 0.14198598265647888, V_0_loss = tensor([[0.0051]], grad_fn=<PowBackward0>), V_pos_loss = 0.2053198367357254, Lv_loss = 0.05835176259279251, Circular Tuning Loss = 1.7878726720809937\n",
      "19) Lyapunov Risk = 1.8656961917877197, MSE = 0.14016681909561157, V_0_loss = tensor([[0.0050]], grad_fn=<PowBackward0>), V_pos_loss = 0.2050892561674118, Lv_loss = 0.05771884322166443, Circular Tuning Loss = 1.7870179414749146\n",
      "20) Lyapunov Risk = 1.8603761196136475, MSE = 0.13837629556655884, V_0_loss = tensor([[0.0049]], grad_fn=<PowBackward0>), V_pos_loss = 0.2048591524362564, Lv_loss = 0.05741860717535019, Circular Tuning Loss = 1.7861641645431519\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.00010000000000000002, 0.00010000000000000002]\n",
      "x2 : [-0.00010000000000000002, 0.00010000000000000002]\n",
      "==============================\n",
      "21) Lyapunov Risk = 1.8465166091918945, MSE = 0.1364840269088745, V_0_loss = tensor([[0.0048]], grad_fn=<PowBackward0>), V_pos_loss = 0.20331858098506927, Lv_loss = 0.05727044865489006, Circular Tuning Loss = 1.768025517463684\n",
      "22) Lyapunov Risk = 1.8431389331817627, MSE = 0.1342952698469162, V_0_loss = tensor([[0.0048]], grad_fn=<PowBackward0>), V_pos_loss = 0.2030867338180542, Lv_loss = 0.058591119945049286, Circular Tuning Loss = 1.767181158065796\n",
      "23) Lyapunov Risk = 1.8402081727981567, MSE = 0.13166625797748566, V_0_loss = tensor([[0.0047]], grad_fn=<PowBackward0>), V_pos_loss = 0.2028554230928421, Lv_loss = 0.060903873294591904, Circular Tuning Loss = 1.7663379907608032\n",
      "24) Lyapunov Risk = 1.8375755548477173, MSE = 0.12873132526874542, V_0_loss = tensor([[0.0046]], grad_fn=<PowBackward0>), V_pos_loss = 0.2026243954896927, Lv_loss = 0.06393493711948395, Circular Tuning Loss = 1.765496015548706\n",
      "25) Lyapunov Risk = 1.8350776433944702, MSE = 0.12582340836524963, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.20239365100860596, Lv_loss = 0.06716416776180267, Circular Tuning Loss = 1.764655590057373\n",
      "26) Lyapunov Risk = 1.8323276042938232, MSE = 0.12332218885421753, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.2021632194519043, Lv_loss = 0.0700182095170021, Circular Tuning Loss = 1.7638165950775146\n",
      "27) Lyapunov Risk = 1.8289473056793213, MSE = 0.12142254412174225, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.2019331306219101, Lv_loss = 0.07216034829616547, Circular Tuning Loss = 1.762979507446289\n",
      "28) Lyapunov Risk = 1.8250234127044678, MSE = 0.12015342712402344, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.20170378684997559, Lv_loss = 0.07354938238859177, Circular Tuning Loss = 1.762143850326538\n",
      "29) Lyapunov Risk = 1.8209381103515625, MSE = 0.11936141550540924, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.20147483050823212, Lv_loss = 0.0744035392999649, Circular Tuning Loss = 1.76131010055542\n",
      "30) Lyapunov Risk = 1.8168894052505493, MSE = 0.11873265355825424, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.20124612748622894, Lv_loss = 0.07509521394968033, Circular Tuning Loss = 1.7604776620864868\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.00010000000000000002, 0.00010000000000000002]\n",
      "x2 : [-0.00010000000000000002, 0.00010000000000000002]\n",
      "==============================\n",
      "31) Lyapunov Risk = 1.8039933443069458, MSE = 0.1180417612195015, V_0_loss = tensor([[0.0041]], grad_fn=<PowBackward0>), V_pos_loss = 0.19970305263996124, Lv_loss = 0.0751318633556366, Circular Tuning Loss = 1.7427674531936646\n",
      "32) Lyapunov Risk = 1.8001668453216553, MSE = 0.11732393503189087, V_0_loss = tensor([[0.0041]], grad_fn=<PowBackward0>), V_pos_loss = 0.1994723379611969, Lv_loss = 0.07593700289726257, Circular Tuning Loss = 1.7419459819793701\n",
      "33) Lyapunov Risk = 1.7966680526733398, MSE = 0.11665043979883194, V_0_loss = tensor([[0.0040]], grad_fn=<PowBackward0>), V_pos_loss = 0.19924190640449524, Lv_loss = 0.076718769967556, Circular Tuning Loss = 1.7411264181137085\n",
      "34) Lyapunov Risk = 1.7934789657592773, MSE = 0.11615294218063354, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.19901177287101746, Lv_loss = 0.07723291963338852, Circular Tuning Loss = 1.7403085231781006\n",
      "35) Lyapunov Risk = 1.790467619895935, MSE = 0.11587679386138916, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.19878223538398743, Lv_loss = 0.0773378238081932, Circular Tuning Loss = 1.7394927740097046\n",
      "36) Lyapunov Risk = 1.7876126766204834, MSE = 0.11582615971565247, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.1985531896352768, Lv_loss = 0.07700589299201965, Circular Tuning Loss = 1.7386789321899414\n",
      "37) Lyapunov Risk = 1.7848259210586548, MSE = 0.11592549830675125, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.19832447171211243, Lv_loss = 0.07634886354207993, Circular Tuning Loss = 1.737866759300232\n",
      "38) Lyapunov Risk = 1.7820014953613281, MSE = 0.1160426139831543, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.19809603691101074, Lv_loss = 0.07552587240934372, Circular Tuning Loss = 1.7370566129684448\n",
      "39) Lyapunov Risk = 1.7790220975875854, MSE = 0.11602085083723068, V_0_loss = tensor([[0.0036]], grad_fn=<PowBackward0>), V_pos_loss = 0.19786782562732697, Lv_loss = 0.0747029110789299, Circular Tuning Loss = 1.7362480163574219\n",
      "40) Lyapunov Risk = 1.7758235931396484, MSE = 0.11576694250106812, V_0_loss = tensor([[0.0035]], grad_fn=<PowBackward0>), V_pos_loss = 0.19763991236686707, Lv_loss = 0.07399548590183258, Circular Tuning Loss = 1.735440969467163\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.00010000000000000002, 0.00010000000000000002]\n",
      "x2 : [-0.00010000000000000002, 0.00010000000000000002]\n",
      "==============================\n",
      "41) Lyapunov Risk = 1.7637183666229248, MSE = 0.11530468612909317, V_0_loss = tensor([[0.0035]], grad_fn=<PowBackward0>), V_pos_loss = 0.19609452784061432, Lv_loss = 0.07269441336393356, Circular Tuning Loss = 1.7181485891342163\n",
      "42) Lyapunov Risk = 1.7603111267089844, MSE = 0.11477100849151611, V_0_loss = tensor([[0.0034]], grad_fn=<PowBackward0>), V_pos_loss = 0.1958645135164261, Lv_loss = 0.07206778228282928, Circular Tuning Loss = 1.7173521518707275\n",
      "43) Lyapunov Risk = 1.7568302154541016, MSE = 0.11423641443252563, V_0_loss = tensor([[0.0034]], grad_fn=<PowBackward0>), V_pos_loss = 0.19563519954681396, Lv_loss = 0.07130341231822968, Circular Tuning Loss = 1.7165573835372925\n",
      "44) Lyapunov Risk = 1.7532750368118286, MSE = 0.11376767605543137, V_0_loss = tensor([[0.0033]], grad_fn=<PowBackward0>), V_pos_loss = 0.19540703296661377, Lv_loss = 0.07032801955938339, Circular Tuning Loss = 1.7157646417617798\n",
      "45) Lyapunov Risk = 1.749732255935669, MSE = 0.1133832037448883, V_0_loss = tensor([[0.0032]], grad_fn=<PowBackward0>), V_pos_loss = 0.19517935812473297, Lv_loss = 0.06917819380760193, Circular Tuning Loss = 1.7149730920791626\n",
      "46) Lyapunov Risk = 1.7462477684020996, MSE = 0.11305926740169525, V_0_loss = tensor([[0.0032]], grad_fn=<PowBackward0>), V_pos_loss = 0.19495251774787903, Lv_loss = 0.06793990731239319, Circular Tuning Loss = 1.7141836881637573\n",
      "47) Lyapunov Risk = 1.742805004119873, MSE = 0.11273086816072464, V_0_loss = tensor([[0.0031]], grad_fn=<PowBackward0>), V_pos_loss = 0.19472599029541016, Lv_loss = 0.06672193855047226, Circular Tuning Loss = 1.713395357131958\n",
      "48) Lyapunov Risk = 1.7393863201141357, MSE = 0.11236274242401123, V_0_loss = tensor([[0.0031]], grad_fn=<PowBackward0>), V_pos_loss = 0.19449983537197113, Lv_loss = 0.06558480113744736, Circular Tuning Loss = 1.7126089334487915\n",
      "49) Lyapunov Risk = 1.73601233959198, MSE = 0.1119658574461937, V_0_loss = tensor([[0.0030]], grad_fn=<PowBackward0>), V_pos_loss = 0.19427448511123657, Lv_loss = 0.06453395634889603, Circular Tuning Loss = 1.7118240594863892\n",
      "50) Lyapunov Risk = 1.7326874732971191, MSE = 0.11155422031879425, V_0_loss = tensor([[0.0030]], grad_fn=<PowBackward0>), V_pos_loss = 0.19404937326908112, Lv_loss = 0.06355418264865875, Circular Tuning Loss = 1.7110403776168823\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.00010000000000000002, 0.00010000000000000002]\n",
      "x2 : [-0.00010000000000000002, 0.00010000000000000002]\n",
      "==============================\n",
      "51) Lyapunov Risk = 1.721198558807373, MSE = 0.1111626923084259, V_0_loss = tensor([[0.0029]], grad_fn=<PowBackward0>), V_pos_loss = 0.19250470399856567, Lv_loss = 0.06200431287288666, Circular Tuning Loss = 1.6941511631011963\n",
      "52) Lyapunov Risk = 1.7179070711135864, MSE = 0.11088141798973083, V_0_loss = tensor([[0.0029]], grad_fn=<PowBackward0>), V_pos_loss = 0.19227749109268188, Lv_loss = 0.060959525406360626, Circular Tuning Loss = 1.6933773756027222\n",
      "53) Lyapunov Risk = 1.714582920074463, MSE = 0.11069836467504501, V_0_loss = tensor([[0.0028]], grad_fn=<PowBackward0>), V_pos_loss = 0.19205090403556824, Lv_loss = 0.05984332412481308, Circular Tuning Loss = 1.6926050186157227\n",
      "54) Lyapunov Risk = 1.7112289667129517, MSE = 0.11057399958372116, V_0_loss = tensor([[0.0027]], grad_fn=<PowBackward0>), V_pos_loss = 0.1918247640132904, Lv_loss = 0.05871610343456268, Circular Tuning Loss = 1.6918339729309082\n",
      "55) Lyapunov Risk = 1.7078500986099243, MSE = 0.11042944341897964, V_0_loss = tensor([[0.0027]], grad_fn=<PowBackward0>), V_pos_loss = 0.19159889221191406, Lv_loss = 0.05767695978283882, Circular Tuning Loss = 1.6910645961761475\n",
      "56) Lyapunov Risk = 1.7044458389282227, MSE = 0.11018538475036621, V_0_loss = tensor([[0.0026]], grad_fn=<PowBackward0>), V_pos_loss = 0.1913733333349228, Lv_loss = 0.056802403181791306, Circular Tuning Loss = 1.6902960538864136\n",
      "57) Lyapunov Risk = 1.7010036706924438, MSE = 0.10983482748270035, V_0_loss = tensor([[0.0026]], grad_fn=<PowBackward0>), V_pos_loss = 0.1911488026380539, Lv_loss = 0.05611158907413483, Circular Tuning Loss = 1.6895290613174438\n",
      "58) Lyapunov Risk = 1.6975587606430054, MSE = 0.10943525284528732, V_0_loss = tensor([[0.0025]], grad_fn=<PowBackward0>), V_pos_loss = 0.19092461466789246, Lv_loss = 0.055527374148368835, Circular Tuning Loss = 1.68876314163208\n",
      "59) Lyapunov Risk = 1.6941474676132202, MSE = 0.10901010781526566, V_0_loss = tensor([[0.0025]], grad_fn=<PowBackward0>), V_pos_loss = 0.19070053100585938, Lv_loss = 0.05502436310052872, Circular Tuning Loss = 1.6879981756210327\n",
      "60) Lyapunov Risk = 1.690735101699829, MSE = 0.10858938097953796, V_0_loss = tensor([[0.0024]], grad_fn=<PowBackward0>), V_pos_loss = 0.19047656655311584, Lv_loss = 0.054533783346414566, Circular Tuning Loss = 1.6872342824935913\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.00010000000000000002, 0.00010000000000000002]\n",
      "x2 : [-0.00010000000000000002, 0.00010000000000000002]\n",
      "==============================\n",
      "61) Lyapunov Risk = 1.6794357299804688, MSE = 0.10817951709032059, V_0_loss = tensor([[0.0024]], grad_fn=<PowBackward0>), V_pos_loss = 0.1889316439628601, Lv_loss = 0.05352357402443886, Circular Tuning Loss = 1.6707327365875244\n",
      "62) Lyapunov Risk = 1.6760473251342773, MSE = 0.10781699419021606, V_0_loss = tensor([[0.0023]], grad_fn=<PowBackward0>), V_pos_loss = 0.18870528042316437, Lv_loss = 0.05299011990427971, Circular Tuning Loss = 1.669978141784668\n",
      "63) Lyapunov Risk = 1.672681450843811, MSE = 0.10741699486970901, V_0_loss = tensor([[0.0023]], grad_fn=<PowBackward0>), V_pos_loss = 0.1884790062904358, Lv_loss = 0.052506860345602036, Circular Tuning Loss = 1.669224500656128\n",
      "64) Lyapunov Risk = 1.669321060180664, MSE = 0.10690829157829285, V_0_loss = tensor([[0.0022]], grad_fn=<PowBackward0>), V_pos_loss = 0.1882527619600296, Lv_loss = 0.052144765853881836, Circular Tuning Loss = 1.6684719324111938\n",
      "65) Lyapunov Risk = 1.6659605503082275, MSE = 0.10627226531505585, V_0_loss = tensor([[0.0022]], grad_fn=<PowBackward0>), V_pos_loss = 0.18802686035633087, Lv_loss = 0.05190858244895935, Circular Tuning Loss = 1.6677204370498657\n",
      "66) Lyapunov Risk = 1.6626112461090088, MSE = 0.105525441467762, V_0_loss = tensor([[0.0022]], grad_fn=<PowBackward0>), V_pos_loss = 0.18780116736888885, Lv_loss = 0.051772456616163254, Circular Tuning Loss = 1.666970133781433\n",
      "67) Lyapunov Risk = 1.659273386001587, MSE = 0.10474258661270142, V_0_loss = tensor([[0.0021]], grad_fn=<PowBackward0>), V_pos_loss = 0.18757566809654236, Lv_loss = 0.05166678875684738, Circular Tuning Loss = 1.666221022605896\n",
      "68) Lyapunov Risk = 1.6559348106384277, MSE = 0.10398027300834656, V_0_loss = tensor([[0.0021]], grad_fn=<PowBackward0>), V_pos_loss = 0.1873502880334854, Lv_loss = 0.05152059718966484, Circular Tuning Loss = 1.6654729843139648\n",
      "69) Lyapunov Risk = 1.6526070833206177, MSE = 0.1032676175236702, V_0_loss = tensor([[0.0020]], grad_fn=<PowBackward0>), V_pos_loss = 0.18712499737739563, Lv_loss = 0.0512879379093647, Circular Tuning Loss = 1.6647260189056396\n",
      "70) Lyapunov Risk = 1.649304986000061, MSE = 0.1026102751493454, V_0_loss = tensor([[0.0020]], grad_fn=<PowBackward0>), V_pos_loss = 0.18689973652362823, Lv_loss = 0.05096961930394173, Circular Tuning Loss = 1.6639808416366577\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.00010000000000000002, 0.00010000000000000002]\n",
      "x2 : [-0.00010000000000000002, 0.00010000000000000002]\n",
      "==============================\n",
      "71) Lyapunov Risk = 1.6384989023208618, MSE = 0.1019585058093071, V_0_loss = tensor([[0.0019]], grad_fn=<PowBackward0>), V_pos_loss = 0.18535278737545013, Lv_loss = 0.05016076937317848, Circular Tuning Loss = 1.6478538513183594\n",
      "72) Lyapunov Risk = 1.6352664232254028, MSE = 0.10134676843881607, V_0_loss = tensor([[0.0019]], grad_fn=<PowBackward0>), V_pos_loss = 0.1851254552602768, Lv_loss = 0.049777064472436905, Circular Tuning Loss = 1.6471173763275146\n",
      "73) Lyapunov Risk = 1.6320505142211914, MSE = 0.10072901099920273, V_0_loss = tensor([[0.0018]], grad_fn=<PowBackward0>), V_pos_loss = 0.18489877879619598, Lv_loss = 0.049399424344301224, Circular Tuning Loss = 1.6463819742202759\n",
      "74) Lyapunov Risk = 1.62885320186615, MSE = 0.10009534657001495, V_0_loss = tensor([[0.0018]], grad_fn=<PowBackward0>), V_pos_loss = 0.1846722960472107, Lv_loss = 0.04904311150312424, Circular Tuning Loss = 1.6456477642059326\n",
      "75) Lyapunov Risk = 1.6256680488586426, MSE = 0.09946257621049881, V_0_loss = tensor([[0.0018]], grad_fn=<PowBackward0>), V_pos_loss = 0.18444587290287018, Lv_loss = 0.04868161678314209, Circular Tuning Loss = 1.644915223121643\n",
      "76) Lyapunov Risk = 1.6224775314331055, MSE = 0.09887801110744476, V_0_loss = tensor([[0.0017]], grad_fn=<PowBackward0>), V_pos_loss = 0.1842196136713028, Lv_loss = 0.04826609417796135, Circular Tuning Loss = 1.644183874130249\n",
      "77) Lyapunov Risk = 1.619284987449646, MSE = 0.09838918596506119, V_0_loss = tensor([[0.0017]], grad_fn=<PowBackward0>), V_pos_loss = 0.18399380147457123, Lv_loss = 0.04772389680147171, Circular Tuning Loss = 1.643453598022461\n",
      "78) Lyapunov Risk = 1.6160887479782104, MSE = 0.09800593554973602, V_0_loss = tensor([[0.0016]], grad_fn=<PowBackward0>), V_pos_loss = 0.18376818299293518, Lv_loss = 0.04706120118498802, Circular Tuning Loss = 1.6427247524261475\n",
      "79) Lyapunov Risk = 1.6128841638565063, MSE = 0.09770118445158005, V_0_loss = tensor([[0.0016]], grad_fn=<PowBackward0>), V_pos_loss = 0.18354296684265137, Lv_loss = 0.046318419277668, Circular Tuning Loss = 1.641997218132019\n",
      "80) Lyapunov Risk = 1.609666109085083, MSE = 0.09743703901767731, V_0_loss = tensor([[0.0016]], grad_fn=<PowBackward0>), V_pos_loss = 0.1833181232213974, Lv_loss = 0.045535609126091, Circular Tuning Loss = 1.6412705183029175\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.00010000000000000002, 0.00010000000000000002]\n",
      "x2 : [-0.00010000000000000002, 0.00010000000000000002]\n",
      "==============================\n",
      "81) Lyapunov Risk = 1.599215030670166, MSE = 0.09717848151922226, V_0_loss = tensor([[0.0015]], grad_fn=<PowBackward0>), V_pos_loss = 0.18177229166030884, Lv_loss = 0.04435458779335022, Circular Tuning Loss = 1.625508189201355\n",
      "82) Lyapunov Risk = 1.5959863662719727, MSE = 0.09698719531297684, V_0_loss = tensor([[0.0015]], grad_fn=<PowBackward0>), V_pos_loss = 0.18154582381248474, Lv_loss = 0.04354444891214371, Circular Tuning Loss = 1.6247905492782593\n",
      "83) Lyapunov Risk = 1.5927948951721191, MSE = 0.09681965410709381, V_0_loss = tensor([[0.0015]], grad_fn=<PowBackward0>), V_pos_loss = 0.1813194453716278, Lv_loss = 0.0427219532430172, Circular Tuning Loss = 1.6240735054016113\n",
      "84) Lyapunov Risk = 1.5896375179290771, MSE = 0.0966043546795845, V_0_loss = tensor([[0.0014]], grad_fn=<PowBackward0>), V_pos_loss = 0.18109311163425446, Lv_loss = 0.04196350276470184, Circular Tuning Loss = 1.6233577728271484\n",
      "85) Lyapunov Risk = 1.5865230560302734, MSE = 0.0963401198387146, V_0_loss = tensor([[0.0014]], grad_fn=<PowBackward0>), V_pos_loss = 0.1808667778968811, Lv_loss = 0.041256554424762726, Circular Tuning Loss = 1.6226427555084229\n",
      "86) Lyapunov Risk = 1.5834364891052246, MSE = 0.09604448080062866, V_0_loss = tensor([[0.0013]], grad_fn=<PowBackward0>), V_pos_loss = 0.1806408315896988, Lv_loss = 0.040581706911325455, Circular Tuning Loss = 1.6219284534454346\n",
      "87) Lyapunov Risk = 1.580350399017334, MSE = 0.09574887901544571, V_0_loss = tensor([[0.0013]], grad_fn=<PowBackward0>), V_pos_loss = 0.18041494488716125, Lv_loss = 0.03991449251770973, Circular Tuning Loss = 1.6212148666381836\n",
      "88) Lyapunov Risk = 1.5772793292999268, MSE = 0.09547342360019684, V_0_loss = tensor([[0.0013]], grad_fn=<PowBackward0>), V_pos_loss = 0.18018920719623566, Lv_loss = 0.03924659639596939, Circular Tuning Loss = 1.6205021142959595\n",
      "89) Lyapunov Risk = 1.5742309093475342, MSE = 0.095177561044693, V_0_loss = tensor([[0.0012]], grad_fn=<PowBackward0>), V_pos_loss = 0.1799638867378235, Lv_loss = 0.03862029314041138, Circular Tuning Loss = 1.6197898387908936\n",
      "90) Lyapunov Risk = 1.5711804628372192, MSE = 0.09482268244028091, V_0_loss = tensor([[0.0012]], grad_fn=<PowBackward0>), V_pos_loss = 0.17973846197128296, Lv_loss = 0.038061924278736115, Circular Tuning Loss = 1.6190781593322754\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.00010000000000000002, 0.00010000000000000002]\n",
      "x2 : [-0.00010000000000000002, 0.00010000000000000002]\n",
      "==============================\n",
      "91) Lyapunov Risk = 1.5610215663909912, MSE = 0.09439251571893692, V_0_loss = tensor([[0.0012]], grad_fn=<PowBackward0>), V_pos_loss = 0.17819315195083618, Lv_loss = 0.03723651170730591, Circular Tuning Loss = 1.6036654710769653\n",
      "92) Lyapunov Risk = 1.5580182075500488, MSE = 0.09396083652973175, V_0_loss = tensor([[0.0011]], grad_fn=<PowBackward0>), V_pos_loss = 0.17796525359153748, Lv_loss = 0.03677508607506752, Circular Tuning Loss = 1.6029609441757202\n",
      "93) Lyapunov Risk = 1.555053472518921, MSE = 0.09350623935461044, V_0_loss = tensor([[0.0011]], grad_fn=<PowBackward0>), V_pos_loss = 0.17773720622062683, Lv_loss = 0.03635706007480621, Circular Tuning Loss = 1.6022570133209229\n",
      "94) Lyapunov Risk = 1.5521184206008911, MSE = 0.09303469955921173, V_0_loss = tensor([[0.0011]], grad_fn=<PowBackward0>), V_pos_loss = 0.17750920355319977, Lv_loss = 0.03596405312418938, Circular Tuning Loss = 1.6015537977218628\n",
      "95) Lyapunov Risk = 1.5492031574249268, MSE = 0.09254509210586548, V_0_loss = tensor([[0.0011]], grad_fn=<PowBackward0>), V_pos_loss = 0.17728130519390106, Lv_loss = 0.035603996366262436, Circular Tuning Loss = 1.6008508205413818\n",
      "96) Lyapunov Risk = 1.5463013648986816, MSE = 0.09204770624637604, V_0_loss = tensor([[0.0010]], grad_fn=<PowBackward0>), V_pos_loss = 0.17705322802066803, Lv_loss = 0.035263240337371826, Circular Tuning Loss = 1.600148320198059\n",
      "97) Lyapunov Risk = 1.5434108972549438, MSE = 0.09154956042766571, V_0_loss = tensor([[0.0010]], grad_fn=<PowBackward0>), V_pos_loss = 0.17682494223117828, Lv_loss = 0.0349523201584816, Circular Tuning Loss = 1.599446177482605\n",
      "98) Lyapunov Risk = 1.5405397415161133, MSE = 0.09105519950389862, V_0_loss = tensor([[0.0010]], grad_fn=<PowBackward0>), V_pos_loss = 0.1765965223312378, Lv_loss = 0.03465210273861885, Circular Tuning Loss = 1.5987443923950195\n",
      "99) Lyapunov Risk = 1.5376726388931274, MSE = 0.09059692174196243, V_0_loss = tensor([[0.0009]], grad_fn=<PowBackward0>), V_pos_loss = 0.1763681173324585, Lv_loss = 0.03433912992477417, Circular Tuning Loss = 1.5980430841445923\n",
      "100) Lyapunov Risk = 1.53481125831604, MSE = 0.0901796743273735, V_0_loss = tensor([[0.0009]], grad_fn=<PowBackward0>), V_pos_loss = 0.17613954842090607, Lv_loss = 0.034025199711322784, Circular Tuning Loss = 1.5973422527313232\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.00010000000000000002, 0.00010000000000000002]\n",
      "x2 : [-0.00010000000000000002, 0.00010000000000000002]\n",
      "==============================\n",
      "101) Lyapunov Risk = 1.5250571966171265, MSE = 0.08978676795959473, V_0_loss = tensor([[0.0009]], grad_fn=<PowBackward0>), V_pos_loss = 0.17459392547607422, Lv_loss = 0.03338940441608429, Circular Tuning Loss = 1.5822656154632568\n",
      "102) Lyapunov Risk = 1.5222301483154297, MSE = 0.08947937935590744, V_0_loss = tensor([[0.0009]], grad_fn=<PowBackward0>), V_pos_loss = 0.1743631213903427, Lv_loss = 0.032996565103530884, Circular Tuning Loss = 1.5815718173980713\n",
      "103) Lyapunov Risk = 1.5194514989852905, MSE = 0.08919041603803635, V_0_loss = tensor([[0.0008]], grad_fn=<PowBackward0>), V_pos_loss = 0.17413264513015747, Lv_loss = 0.032593198120594025, Circular Tuning Loss = 1.580878734588623\n",
      "104) Lyapunov Risk = 1.516687035560608, MSE = 0.08887564390897751, V_0_loss = tensor([[0.0008]], grad_fn=<PowBackward0>), V_pos_loss = 0.17390233278274536, Lv_loss = 0.03225250914692879, Circular Tuning Loss = 1.5801860094070435\n",
      "105) Lyapunov Risk = 1.5139367580413818, MSE = 0.08855079114437103, V_0_loss = tensor([[0.0008]], grad_fn=<PowBackward0>), V_pos_loss = 0.1736719161272049, Lv_loss = 0.03193502128124237, Circular Tuning Loss = 1.5794939994812012\n",
      "106) Lyapunov Risk = 1.5112106800079346, MSE = 0.08823525905609131, V_0_loss = tensor([[0.0008]], grad_fn=<PowBackward0>), V_pos_loss = 0.17344187200069427, Lv_loss = 0.031612444669008255, Circular Tuning Loss = 1.5788019895553589\n",
      "107) Lyapunov Risk = 1.5084950923919678, MSE = 0.08795279264450073, V_0_loss = tensor([[0.0007]], grad_fn=<PowBackward0>), V_pos_loss = 0.17321188747882843, Lv_loss = 0.03126656636595726, Circular Tuning Loss = 1.5781108140945435\n",
      "108) Lyapunov Risk = 1.5058064460754395, MSE = 0.08770925551652908, V_0_loss = tensor([[0.0007]], grad_fn=<PowBackward0>), V_pos_loss = 0.17298181354999542, Lv_loss = 0.030894676223397255, Circular Tuning Loss = 1.5774202346801758\n",
      "109) Lyapunov Risk = 1.5031321048736572, MSE = 0.08750263601541519, V_0_loss = tensor([[0.0007]], grad_fn=<PowBackward0>), V_pos_loss = 0.17275162041187286, Lv_loss = 0.03050057962536812, Circular Tuning Loss = 1.576729655265808\n",
      "110) Lyapunov Risk = 1.500482201576233, MSE = 0.08729147911071777, V_0_loss = tensor([[0.0007]], grad_fn=<PowBackward0>), V_pos_loss = 0.17252135276794434, Lv_loss = 0.030130671337246895, Circular Tuning Loss = 1.5760397911071777\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.00010000000000000002, 0.00010000000000000002]\n",
      "x2 : [-0.00010000000000000002, 0.00010000000000000002]\n",
      "==============================\n",
      "111) Lyapunov Risk = 1.4909875392913818, MSE = 0.08703932911157608, V_0_loss = tensor([[0.0006]], grad_fn=<PowBackward0>), V_pos_loss = 0.170977383852005, Lv_loss = 0.029539966955780983, Circular Tuning Loss = 1.5612903833389282\n",
      "112) Lyapunov Risk = 1.488379955291748, MSE = 0.08678890019655228, V_0_loss = tensor([[0.0006]], grad_fn=<PowBackward0>), V_pos_loss = 0.17074507474899292, Lv_loss = 0.02922469936311245, Circular Tuning Loss = 1.5606073141098022\n",
      "113) Lyapunov Risk = 1.4857995510101318, MSE = 0.086508609354496, V_0_loss = tensor([[0.0006]], grad_fn=<PowBackward0>), V_pos_loss = 0.1705133318901062, Lv_loss = 0.028946444392204285, Circular Tuning Loss = 1.5599247217178345\n",
      "114) Lyapunov Risk = 1.4832392930984497, MSE = 0.08619233220815659, V_0_loss = tensor([[0.0006]], grad_fn=<PowBackward0>), V_pos_loss = 0.17028167843818665, Lv_loss = 0.028706135228276253, Circular Tuning Loss = 1.559242844581604\n",
      "115) Lyapunov Risk = 1.4807031154632568, MSE = 0.08585887402296066, V_0_loss = tensor([[0.0005]], grad_fn=<PowBackward0>), V_pos_loss = 0.17004993557929993, Lv_loss = 0.028475549072027206, Circular Tuning Loss = 1.5585612058639526\n",
      "116) Lyapunov Risk = 1.4781899452209473, MSE = 0.08552255481481552, V_0_loss = tensor([[0.0005]], grad_fn=<PowBackward0>), V_pos_loss = 0.16981811821460724, Lv_loss = 0.02824716456234455, Circular Tuning Loss = 1.5578796863555908\n",
      "117) Lyapunov Risk = 1.4757041931152344, MSE = 0.08518416434526443, V_0_loss = tensor([[0.0005]], grad_fn=<PowBackward0>), V_pos_loss = 0.16958624124526978, Lv_loss = 0.028015851974487305, Circular Tuning Loss = 1.5571988821029663\n",
      "118) Lyapunov Risk = 1.4732290506362915, MSE = 0.08484359085559845, V_0_loss = tensor([[0.0005]], grad_fn=<PowBackward0>), V_pos_loss = 0.16935428977012634, Lv_loss = 0.027783488854765892, Circular Tuning Loss = 1.5565184354782104\n",
      "119) Lyapunov Risk = 1.4707698822021484, MSE = 0.08450224250555038, V_0_loss = tensor([[0.0005]], grad_fn=<PowBackward0>), V_pos_loss = 0.16912247240543365, Lv_loss = 0.02754569798707962, Circular Tuning Loss = 1.5558383464813232\n",
      "120) Lyapunov Risk = 1.4683387279510498, MSE = 0.0841558426618576, V_0_loss = tensor([[0.0004]], grad_fn=<PowBackward0>), V_pos_loss = 0.16889061033725739, Lv_loss = 0.0273129865527153, Circular Tuning Loss = 1.5551587343215942\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.00010000000000000002, 0.00010000000000000002]\n",
      "x2 : [-0.00010000000000000002, 0.00010000000000000002]\n",
      "==============================\n",
      "121) Lyapunov Risk = 1.459132194519043, MSE = 0.08377765119075775, V_0_loss = tensor([[0.0004]], grad_fn=<PowBackward0>), V_pos_loss = 0.16734997928142548, Lv_loss = 0.026865193620324135, Circular Tuning Loss = 1.540727138519287\n",
      "122) Lyapunov Risk = 1.456752061843872, MSE = 0.0834760069847107, V_0_loss = tensor([[0.0004]], grad_fn=<PowBackward0>), V_pos_loss = 0.16711628437042236, Lv_loss = 0.02661665342748165, Circular Tuning Loss = 1.5400545597076416\n",
      "123) Lyapunov Risk = 1.4544308185577393, MSE = 0.08316706866025925, V_0_loss = tensor([[0.0004]], grad_fn=<PowBackward0>), V_pos_loss = 0.16688261926174164, Lv_loss = 0.026399532333016396, Circular Tuning Loss = 1.5393822193145752\n",
      "124) Lyapunov Risk = 1.4521520137786865, MSE = 0.08281812816858292, V_0_loss = tensor([[0.0004]], grad_fn=<PowBackward0>), V_pos_loss = 0.16664943099021912, Lv_loss = 0.026240065693855286, Circular Tuning Loss = 1.538710594177246\n",
      "125) Lyapunov Risk = 1.449906826019287, MSE = 0.08242595195770264, V_0_loss = tensor([[0.0004]], grad_fn=<PowBackward0>), V_pos_loss = 0.1664162278175354, Lv_loss = 0.026134176179766655, Circular Tuning Loss = 1.5380390882492065\n",
      "126) Lyapunov Risk = 1.447681188583374, MSE = 0.08204823732376099, V_0_loss = tensor([[0.0003]], grad_fn=<PowBackward0>), V_pos_loss = 0.16618295013904572, Lv_loss = 0.026038385927677155, Circular Tuning Loss = 1.5373681783676147\n",
      "127) Lyapunov Risk = 1.4454749822616577, MSE = 0.08171458542346954, V_0_loss = tensor([[0.0003]], grad_fn=<PowBackward0>), V_pos_loss = 0.16594964265823364, Lv_loss = 0.025921642780303955, Circular Tuning Loss = 1.5366977453231812\n",
      "128) Lyapunov Risk = 1.4432995319366455, MSE = 0.0814158171415329, V_0_loss = tensor([[0.0003]], grad_fn=<PowBackward0>), V_pos_loss = 0.16571630537509918, Lv_loss = 0.025786934420466423, Circular Tuning Loss = 1.5360279083251953\n",
      "129) Lyapunov Risk = 1.4411516189575195, MSE = 0.08114001154899597, V_0_loss = tensor([[0.0003]], grad_fn=<PowBackward0>), V_pos_loss = 0.16548298299312592, Lv_loss = 0.02564365416765213, Circular Tuning Loss = 1.5353587865829468\n",
      "130) Lyapunov Risk = 1.439034342765808, MSE = 0.08083926141262054, V_0_loss = tensor([[0.0003]], grad_fn=<PowBackward0>), V_pos_loss = 0.16524963080883026, Lv_loss = 0.02552400529384613, Circular Tuning Loss = 1.5346901416778564\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.00010000000000000002, 0.00010000000000000002]\n",
      "x2 : [-0.00010000000000000002, 0.00010000000000000002]\n",
      "==============================\n",
      "131) Lyapunov Risk = 1.4302197694778442, MSE = 0.0805022343993187, V_0_loss = tensor([[0.0003]], grad_fn=<PowBackward0>), V_pos_loss = 0.16371303796768188, Lv_loss = 0.025202572345733643, Circular Tuning Loss = 1.5205681324005127\n",
      "132) Lyapunov Risk = 1.4281489849090576, MSE = 0.08021104335784912, V_0_loss = tensor([[0.0003]], grad_fn=<PowBackward0>), V_pos_loss = 0.163478285074234, Lv_loss = 0.025070618838071823, Circular Tuning Loss = 1.5199062824249268\n",
      "133) Lyapunov Risk = 1.4260910749435425, MSE = 0.07996007055044174, V_0_loss = tensor([[0.0002]], grad_fn=<PowBackward0>), V_pos_loss = 0.1632438451051712, Lv_loss = 0.024906089529395103, Circular Tuning Loss = 1.5192455053329468\n",
      "134) Lyapunov Risk = 1.4240421056747437, MSE = 0.07973667234182358, V_0_loss = tensor([[0.0002]], grad_fn=<PowBackward0>), V_pos_loss = 0.16300971806049347, Lv_loss = 0.024713119491934776, Circular Tuning Loss = 1.518585205078125\n",
      "135) Lyapunov Risk = 1.4220116138458252, MSE = 0.0795234888792038, V_0_loss = tensor([[0.0002]], grad_fn=<PowBackward0>), V_pos_loss = 0.16277572512626648, Lv_loss = 0.02450290508568287, Circular Tuning Loss = 1.5179259777069092\n",
      "136) Lyapunov Risk = 1.4200001955032349, MSE = 0.07928181439638138, V_0_loss = tensor([[0.0002]], grad_fn=<PowBackward0>), V_pos_loss = 0.16254208981990814, Lv_loss = 0.024312550202012062, Circular Tuning Loss = 1.5172677040100098\n",
      "137) Lyapunov Risk = 1.418010950088501, MSE = 0.07903090119361877, V_0_loss = tensor([[0.0002]], grad_fn=<PowBackward0>), V_pos_loss = 0.16230861842632294, Lv_loss = 0.024122051894664764, Circular Tuning Loss = 1.5166103839874268\n",
      "138) Lyapunov Risk = 1.4160367250442505, MSE = 0.07880251109600067, V_0_loss = tensor([[0.0002]], grad_fn=<PowBackward0>), V_pos_loss = 0.16207577288150787, Lv_loss = 0.02391115576028824, Circular Tuning Loss = 1.515953540802002\n",
      "139) Lyapunov Risk = 1.4140856266021729, MSE = 0.0785842165350914, V_0_loss = tensor([[0.0002]], grad_fn=<PowBackward0>), V_pos_loss = 0.1618431955575943, Lv_loss = 0.023691559210419655, Circular Tuning Loss = 1.5152978897094727\n",
      "140) Lyapunov Risk = 1.4121513366699219, MSE = 0.07834936678409576, V_0_loss = tensor([[0.0002]], grad_fn=<PowBackward0>), V_pos_loss = 0.16161081194877625, Lv_loss = 0.023482469841837883, Circular Tuning Loss = 1.5146428346633911\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.00010000000000000002, 0.00010000000000000002]\n",
      "x2 : [-0.00010000000000000002, 0.00010000000000000002]\n",
      "==============================\n",
      "141) Lyapunov Risk = 1.4035141468048096, MSE = 0.07808741182088852, V_0_loss = tensor([[0.0001]], grad_fn=<PowBackward0>), V_pos_loss = 0.16008180379867554, Lv_loss = 0.023087410256266594, Circular Tuning Loss = 1.500825047492981\n",
      "142) Lyapunov Risk = 1.401598334312439, MSE = 0.07788518071174622, V_0_loss = tensor([[0.0001]], grad_fn=<PowBackward0>), V_pos_loss = 0.159848153591156, Lv_loss = 0.02285732515156269, Circular Tuning Loss = 1.5001777410507202\n",
      "143) Lyapunov Risk = 1.3996959924697876, MSE = 0.07768873125314713, V_0_loss = tensor([[0.0001]], grad_fn=<PowBackward0>), V_pos_loss = 0.15961475670337677, Lv_loss = 0.02263014391064644, Circular Tuning Loss = 1.4995312690734863\n",
      "144) Lyapunov Risk = 1.3978086709976196, MSE = 0.0774417445063591, V_0_loss = tensor([[0.0001]], grad_fn=<PowBackward0>), V_pos_loss = 0.15938152372837067, Lv_loss = 0.02244473062455654, Circular Tuning Loss = 1.4988858699798584\n",
      "145) Lyapunov Risk = 1.3959403038024902, MSE = 0.07716121524572372, V_0_loss = tensor([[0.0001]], grad_fn=<PowBackward0>), V_pos_loss = 0.15914876759052277, Lv_loss = 0.02229349873960018, Circular Tuning Loss = 1.4982411861419678\n",
      "146) Lyapunov Risk = 1.394092082977295, MSE = 0.07687323540449142, V_0_loss = tensor([[0.0001]], grad_fn=<PowBackward0>), V_pos_loss = 0.15891626477241516, Lv_loss = 0.022160107269883156, Circular Tuning Loss = 1.4975976943969727\n",
      "147) Lyapunov Risk = 1.3922582864761353, MSE = 0.07660181075334549, V_0_loss = tensor([[9.5480e-05]], grad_fn=<PowBackward0>), V_pos_loss = 0.15868395566940308, Lv_loss = 0.022025523707270622, Circular Tuning Loss = 1.4969549179077148\n",
      "148) Lyapunov Risk = 1.3904330730438232, MSE = 0.07634937763214111, V_0_loss = tensor([[8.7673e-05]], grad_fn=<PowBackward0>), V_pos_loss = 0.15845181047916412, Lv_loss = 0.02188349887728691, Circular Tuning Loss = 1.496313214302063\n",
      "149) Lyapunov Risk = 1.3886218070983887, MSE = 0.07610680907964706, V_0_loss = tensor([[8.0219e-05]], grad_fn=<PowBackward0>), V_pos_loss = 0.15822015702724457, Lv_loss = 0.021745238453149796, Circular Tuning Loss = 1.495672583580017\n",
      "150) Lyapunov Risk = 1.3868212699890137, MSE = 0.07586698979139328, V_0_loss = tensor([[7.3114e-05]], grad_fn=<PowBackward0>), V_pos_loss = 0.15798908472061157, Lv_loss = 0.021618729457259178, Circular Tuning Loss = 1.4950329065322876\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.00010000000000000002, 0.00010000000000000002]\n",
      "x2 : [-0.00010000000000000002, 0.00010000000000000002]\n",
      "==============================\n",
      "151) Lyapunov Risk = 1.3783564567565918, MSE = 0.07561323046684265, V_0_loss = tensor([[6.6356e-05]], grad_fn=<PowBackward0>), V_pos_loss = 0.15646864473819733, Lv_loss = 0.021328624337911606, Circular Tuning Loss = 1.4815120697021484\n",
      "152) Lyapunov Risk = 1.3765597343444824, MSE = 0.07543035596609116, V_0_loss = tensor([[5.9942e-05]], grad_fn=<PowBackward0>), V_pos_loss = 0.15623681247234344, Lv_loss = 0.021191954612731934, Circular Tuning Loss = 1.4808800220489502\n",
      "153) Lyapunov Risk = 1.3747742176055908, MSE = 0.07527957111597061, V_0_loss = tensor([[5.3871e-05]], grad_fn=<PowBackward0>), V_pos_loss = 0.15600557625293732, Lv_loss = 0.02104160375893116, Circular Tuning Loss = 1.480249285697937\n",
      "154) Lyapunov Risk = 1.3729971647262573, MSE = 0.0751158818602562, V_0_loss = tensor([[4.8138e-05]], grad_fn=<PowBackward0>), V_pos_loss = 0.155774787068367, Lv_loss = 0.020907772704958916, Circular Tuning Loss = 1.4796197414398193\n",
      "155) Lyapunov Risk = 1.3712272644042969, MSE = 0.0749296247959137, V_0_loss = tensor([[4.2742e-05]], grad_fn=<PowBackward0>), V_pos_loss = 0.15554438531398773, Lv_loss = 0.02079741470515728, Circular Tuning Loss = 1.4789913892745972\n",
      "156) Lyapunov Risk = 1.369471549987793, MSE = 0.07474563270807266, V_0_loss = tensor([[3.7679e-05]], grad_fn=<PowBackward0>), V_pos_loss = 0.1553143411874771, Lv_loss = 0.02068566530942917, Circular Tuning Loss = 1.47836434841156\n",
      "157) Lyapunov Risk = 1.3677351474761963, MSE = 0.07456966489553452, V_0_loss = tensor([[3.2947e-05]], grad_fn=<PowBackward0>), V_pos_loss = 0.1550845503807068, Lv_loss = 0.02057035081088543, Circular Tuning Loss = 1.4777382612228394\n",
      "158) Lyapunov Risk = 1.3660056591033936, MSE = 0.0744166225194931, V_0_loss = tensor([[2.8545e-05]], grad_fn=<PowBackward0>), V_pos_loss = 0.15485522150993347, Lv_loss = 0.0204321201890707, Circular Tuning Loss = 1.4771134853363037\n",
      "159) Lyapunov Risk = 1.364282488822937, MSE = 0.07427402585744858, V_0_loss = tensor([[2.4469e-05]], grad_fn=<PowBackward0>), V_pos_loss = 0.15462642908096313, Lv_loss = 0.020276173949241638, Circular Tuning Loss = 1.4764899015426636\n",
      "160) Lyapunov Risk = 1.3625683784484863, MSE = 0.07412019371986389, V_0_loss = tensor([[2.0716e-05]], grad_fn=<PowBackward0>), V_pos_loss = 0.15439791977405548, Lv_loss = 0.020122574642300606, Circular Tuning Loss = 1.475867509841919\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.00010000000000000002, 0.00010000000000000002]\n",
      "x2 : [-0.00010000000000000002, 0.00010000000000000002]\n",
      "==============================\n",
      "161) Lyapunov Risk = 1.3541831970214844, MSE = 0.07391029596328735, V_0_loss = tensor([[1.7283e-05]], grad_fn=<PowBackward0>), V_pos_loss = 0.15288753807544708, Lv_loss = 0.019829094409942627, Circular Tuning Loss = 1.4626374244689941\n",
      "162) Lyapunov Risk = 1.3524831533432007, MSE = 0.07374505698680878, V_0_loss = tensor([[1.4169e-05]], grad_fn=<PowBackward0>), V_pos_loss = 0.15265831351280212, Lv_loss = 0.019683243706822395, Circular Tuning Loss = 1.4620225429534912\n",
      "163) Lyapunov Risk = 1.3507936000823975, MSE = 0.07359503209590912, V_0_loss = tensor([[1.1371e-05]], grad_fn=<PowBackward0>), V_pos_loss = 0.15242956578731537, Lv_loss = 0.019529638811945915, Circular Tuning Loss = 1.461409091949463\n",
      "164) Lyapunov Risk = 1.3491123914718628, MSE = 0.07342123240232468, V_0_loss = tensor([[8.8862e-06]], grad_fn=<PowBackward0>), V_pos_loss = 0.15220125019550323, Lv_loss = 0.019393598660826683, Circular Tuning Loss = 1.46079683303833\n",
      "165) Lyapunov Risk = 1.3474390506744385, MSE = 0.07319626957178116, V_0_loss = tensor([[6.7124e-06]], grad_fn=<PowBackward0>), V_pos_loss = 0.15197327733039856, Lv_loss = 0.01929618790745735, Circular Tuning Loss = 1.4601856470108032\n",
      "166) Lyapunov Risk = 1.3457757234573364, MSE = 0.07295571267604828, V_0_loss = tensor([[4.8475e-06]], grad_fn=<PowBackward0>), V_pos_loss = 0.15174563229084015, Lv_loss = 0.019210034981369972, Circular Tuning Loss = 1.4595757722854614\n",
      "167) Lyapunov Risk = 1.3441251516342163, MSE = 0.07272965461015701, V_0_loss = tensor([[3.2892e-06]], grad_fn=<PowBackward0>), V_pos_loss = 0.15151838958263397, Lv_loss = 0.019112389534711838, Circular Tuning Loss = 1.4589669704437256\n",
      "168) Lyapunov Risk = 1.3424811363220215, MSE = 0.07255694270133972, V_0_loss = tensor([[2.0348e-06]], grad_fn=<PowBackward0>), V_pos_loss = 0.1512918621301651, Lv_loss = 0.018974609673023224, Circular Tuning Loss = 1.4583593606948853\n",
      "169) Lyapunov Risk = 1.3408468961715698, MSE = 0.07240381836891174, V_0_loss = tensor([[1.0824e-06]], grad_fn=<PowBackward0>), V_pos_loss = 0.15106602013111115, Lv_loss = 0.018822096288204193, Circular Tuning Loss = 1.4577529430389404\n",
      "170) Lyapunov Risk = 1.3392212390899658, MSE = 0.0722222551703453, V_0_loss = tensor([[4.2949e-07]], grad_fn=<PowBackward0>), V_pos_loss = 0.150840625166893, Lv_loss = 0.01869044452905655, Circular Tuning Loss = 1.4571478366851807\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.00010000000000000002, 0.00010000000000000002]\n",
      "x2 : [-0.00010000000000000002, 0.00010000000000000002]\n",
      "==============================\n",
      "171) Lyapunov Risk = 1.330957293510437, MSE = 0.07198239117860794, V_0_loss = tensor([[7.3696e-08]], grad_fn=<PowBackward0>), V_pos_loss = 0.1493418663740158, Lv_loss = 0.01844051107764244, Circular Tuning Loss = 1.4442001581192017\n",
      "172) Lyapunov Risk = 1.3293578624725342, MSE = 0.07179494947195053, V_0_loss = tensor([[1.2417e-08]], grad_fn=<PowBackward0>), V_pos_loss = 0.1491333544254303, Lv_loss = 0.018320003524422646, Circular Tuning Loss = 1.4436025619506836\n",
      "173) Lyapunov Risk = 1.327808141708374, MSE = 0.07164778560400009, V_0_loss = tensor([[2.3679e-07]], grad_fn=<PowBackward0>), V_pos_loss = 0.14896804094314575, Lv_loss = 0.018177755177021027, Circular Tuning Loss = 1.4430140256881714\n",
      "174) Lyapunov Risk = 1.3262711763381958, MSE = 0.07151465117931366, V_0_loss = tensor([[7.3087e-07]], grad_fn=<PowBackward0>), V_pos_loss = 0.14880456030368805, Lv_loss = 0.01802876591682434, Circular Tuning Loss = 1.4424335956573486\n",
      "175) Lyapunov Risk = 1.3247439861297607, MSE = 0.07136709988117218, V_0_loss = tensor([[1.4805e-06]], grad_fn=<PowBackward0>), V_pos_loss = 0.14864259958267212, Lv_loss = 0.017893506214022636, Circular Tuning Loss = 1.441860556602478\n",
      "176) Lyapunov Risk = 1.323225736618042, MSE = 0.07120814174413681, V_0_loss = tensor([[2.4737e-06]], grad_fn=<PowBackward0>), V_pos_loss = 0.14848197996616364, Lv_loss = 0.01776852272450924, Circular Tuning Loss = 1.441294550895691\n",
      "177) Lyapunov Risk = 1.3217157125473022, MSE = 0.07105430215597153, V_0_loss = tensor([[3.6995e-06]], grad_fn=<PowBackward0>), V_pos_loss = 0.14832261204719543, Lv_loss = 0.017640510573983192, Circular Tuning Loss = 1.440734624862671\n",
      "178) Lyapunov Risk = 1.3202229738235474, MSE = 0.0709013044834137, V_0_loss = tensor([[5.1492e-06]], grad_fn=<PowBackward0>), V_pos_loss = 0.14816434681415558, Lv_loss = 0.017506929114460945, Circular Tuning Loss = 1.4401806592941284\n",
      "179) Lyapunov Risk = 1.3187425136566162, MSE = 0.07073386013507843, V_0_loss = tensor([[6.8141e-06]], grad_fn=<PowBackward0>), V_pos_loss = 0.14800706505775452, Lv_loss = 0.017376992851495743, Circular Tuning Loss = 1.439631700515747\n",
      "180) Lyapunov Risk = 1.3172721862792969, MSE = 0.07053883373737335, V_0_loss = tensor([[8.6876e-06]], grad_fn=<PowBackward0>), V_pos_loss = 0.1478506475687027, Lv_loss = 0.017264358699321747, Circular Tuning Loss = 1.4390875101089478\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.50097656250000022, -0.50000000000000011]\n",
      "x2 : [0.26171875000000011, 0.26367187500000011]\n",
      "==============================\n",
      "181) Lyapunov Risk = 1.3121415376663208, MSE = 0.07031509280204773, V_0_loss = tensor([[1.0763e-05]], grad_fn=<PowBackward0>), V_pos_loss = 0.1464540809392929, Lv_loss = 0.01702365092933178, Circular Tuning Loss = 1.428208351135254\n",
      "182) Lyapunov Risk = 1.3107047080993652, MSE = 0.07016687095165253, V_0_loss = tensor([[1.3033e-05]], grad_fn=<PowBackward0>), V_pos_loss = 0.14630083739757538, Lv_loss = 0.016875505447387695, Circular Tuning Loss = 1.4276751279830933\n",
      "183) Lyapunov Risk = 1.3092870712280273, MSE = 0.0699944794178009, V_0_loss = tensor([[1.5493e-05]], grad_fn=<PowBackward0>), V_pos_loss = 0.14614835381507874, Lv_loss = 0.016750214621424675, Circular Tuning Loss = 1.4271459579467773\n",
      "184) Lyapunov Risk = 1.3078752756118774, MSE = 0.06973063945770264, V_0_loss = tensor([[1.8139e-05]], grad_fn=<PowBackward0>), V_pos_loss = 0.14599651098251343, Lv_loss = 0.01669267565011978, Circular Tuning Loss = 1.4266204833984375\n",
      "185) Lyapunov Risk = 1.306469202041626, MSE = 0.06938982009887695, V_0_loss = tensor([[2.0965e-05]], grad_fn=<PowBackward0>), V_pos_loss = 0.14584532380104065, Lv_loss = 0.016704535111784935, Circular Tuning Loss = 1.4260982275009155\n",
      "186) Lyapunov Risk = 1.3050763607025146, MSE = 0.06905490905046463, V_0_loss = tensor([[2.3970e-05]], grad_fn=<PowBackward0>), V_pos_loss = 0.14569489657878876, Lv_loss = 0.016719302162528038, Circular Tuning Loss = 1.4255791902542114\n",
      "187) Lyapunov Risk = 1.3036894798278809, MSE = 0.06879684329032898, V_0_loss = tensor([[2.7148e-05]], grad_fn=<PowBackward0>), V_pos_loss = 0.14554491639137268, Lv_loss = 0.01667533814907074, Circular Tuning Loss = 1.425063133239746\n",
      "188) Lyapunov Risk = 1.3023067712783813, MSE = 0.06862669438123703, V_0_loss = tensor([[3.0498e-05]], grad_fn=<PowBackward0>), V_pos_loss = 0.1453954428434372, Lv_loss = 0.016563845798373222, Circular Tuning Loss = 1.4245498180389404\n",
      "189) Lyapunov Risk = 1.3009326457977295, MSE = 0.06848359107971191, V_0_loss = tensor([[3.4016e-05]], grad_fn=<PowBackward0>), V_pos_loss = 0.14524637162685394, Lv_loss = 0.016433261334896088, Circular Tuning Loss = 1.4240388870239258\n",
      "190) Lyapunov Risk = 1.2995610237121582, MSE = 0.06831452995538712, V_0_loss = tensor([[3.7700e-05]], grad_fn=<PowBackward0>), V_pos_loss = 0.14509767293930054, Lv_loss = 0.016325587406754494, Circular Tuning Loss = 1.4235302209854126\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.50097656250000022, -0.50000000000000011]\n",
      "x2 : [0.13085937500000006, 0.13281250000000006]\n",
      "==============================\n",
      "191) Lyapunov Risk = 1.2941503524780273, MSE = 0.06811278313398361, V_0_loss = tensor([[4.1548e-05]], grad_fn=<PowBackward0>), V_pos_loss = 0.14374148845672607, Lv_loss = 0.01611010544002056, Circular Tuning Loss = 1.4121522903442383\n",
      "192) Lyapunov Risk = 1.2927987575531006, MSE = 0.06800844520330429, V_0_loss = tensor([[4.5555e-05]], grad_fn=<PowBackward0>), V_pos_loss = 0.14359501004219055, Lv_loss = 0.01596219465136528, Circular Tuning Loss = 1.4116512537002563\n",
      "193) Lyapunov Risk = 1.291455626487732, MSE = 0.06794733554124832, V_0_loss = tensor([[4.9720e-05]], grad_fn=<PowBackward0>), V_pos_loss = 0.14344891905784607, Lv_loss = 0.015781335532665253, Circular Tuning Loss = 1.4111521244049072\n",
      "194) Lyapunov Risk = 1.2901166677474976, MSE = 0.06784768402576447, V_0_loss = tensor([[5.4042e-05]], grad_fn=<PowBackward0>), V_pos_loss = 0.1433033049106598, Lv_loss = 0.01563325710594654, Circular Tuning Loss = 1.4106552600860596\n",
      "195) Lyapunov Risk = 1.2887790203094482, MSE = 0.06767585128545761, V_0_loss = tensor([[5.8517e-05]], grad_fn=<PowBackward0>), V_pos_loss = 0.14315809309482574, Lv_loss = 0.015540536493062973, Circular Tuning Loss = 1.4101601839065552\n",
      "196) Lyapunov Risk = 1.2874469757080078, MSE = 0.06746283918619156, V_0_loss = tensor([[6.3145e-05]], grad_fn=<PowBackward0>), V_pos_loss = 0.14301323890686035, Lv_loss = 0.015479094348847866, Circular Tuning Loss = 1.4096670150756836\n",
      "197) Lyapunov Risk = 1.2861175537109375, MSE = 0.0672670379281044, V_0_loss = tensor([[6.7924e-05]], grad_fn=<PowBackward0>), V_pos_loss = 0.14286859333515167, Lv_loss = 0.015406920574605465, Circular Tuning Loss = 1.4091752767562866\n",
      "198) Lyapunov Risk = 1.2847925424575806, MSE = 0.06710575520992279, V_0_loss = tensor([[7.2852e-05]], grad_fn=<PowBackward0>), V_pos_loss = 0.14272423088550568, Lv_loss = 0.0152939697727561, Circular Tuning Loss = 1.408685564994812\n",
      "199) Lyapunov Risk = 1.2834686040878296, MSE = 0.06694312393665314, V_0_loss = tensor([[7.7929e-05]], grad_fn=<PowBackward0>), V_pos_loss = 0.1425800621509552, Lv_loss = 0.015167385339736938, Circular Tuning Loss = 1.4081971645355225\n",
      "200) Lyapunov Risk = 1.282144546508789, MSE = 0.06674475222826004, V_0_loss = tensor([[8.3154e-05]], grad_fn=<PowBackward0>), V_pos_loss = 0.14243607223033905, Lv_loss = 0.015059811063110828, Circular Tuning Loss = 1.4077099561691284\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.12500000000000003, -0.12304687500000003]\n",
      "x2 : [0.12304687500000003, 0.12500000000000003]\n",
      "==============================\n",
      "201) Lyapunov Risk = 1.2766865491867065, MSE = 0.06649164110422134, V_0_loss = tensor([[8.8525e-05]], grad_fn=<PowBackward0>), V_pos_loss = 0.14111630618572235, Lv_loss = 0.014924820512533188, Circular Tuning Loss = 1.3958238363265991\n",
      "202) Lyapunov Risk = 1.2753734588623047, MSE = 0.06631876528263092, V_0_loss = tensor([[9.4036e-05]], grad_fn=<PowBackward0>), V_pos_loss = 0.1409740000963211, Lv_loss = 0.014796091243624687, Circular Tuning Loss = 1.3953429460525513\n",
      "203) Lyapunov Risk = 1.274061918258667, MSE = 0.06618183851242065, V_0_loss = tensor([[9.9685e-05]], grad_fn=<PowBackward0>), V_pos_loss = 0.1408320814371109, Lv_loss = 0.014639929868280888, Circular Tuning Loss = 1.3948636054992676\n",
      "204) Lyapunov Risk = 1.272754192352295, MSE = 0.06603129208087921, V_0_loss = tensor([[0.0001]], grad_fn=<PowBackward0>), V_pos_loss = 0.14069058001041412, Lv_loss = 0.014501366764307022, Circular Tuning Loss = 1.3943859338760376\n",
      "205) Lyapunov Risk = 1.271450400352478, MSE = 0.06583897769451141, V_0_loss = tensor([[0.0001]], grad_fn=<PowBackward0>), V_pos_loss = 0.14054924249649048, Lv_loss = 0.014403688721358776, Circular Tuning Loss = 1.3939096927642822\n",
      "206) Lyapunov Risk = 1.2701468467712402, MSE = 0.06564105302095413, V_0_loss = tensor([[0.0001]], grad_fn=<PowBackward0>), V_pos_loss = 0.14040815830230713, Lv_loss = 0.014313324354588985, Circular Tuning Loss = 1.3934348821640015\n",
      "207) Lyapunov Risk = 1.2688482999801636, MSE = 0.06547326594591141, V_0_loss = tensor([[0.0001]], grad_fn=<PowBackward0>), V_pos_loss = 0.140267476439476, Lv_loss = 0.014194290153682232, Circular Tuning Loss = 1.3929613828659058\n",
      "208) Lyapunov Risk = 1.2675540447235107, MSE = 0.06532135605812073, V_0_loss = tensor([[0.0001]], grad_fn=<PowBackward0>), V_pos_loss = 0.14012713730335236, Lv_loss = 0.014054673723876476, Circular Tuning Loss = 1.3924891948699951\n",
      "209) Lyapunov Risk = 1.266260027885437, MSE = 0.06516608595848083, V_0_loss = tensor([[0.0001]], grad_fn=<PowBackward0>), V_pos_loss = 0.13998691737651825, Lv_loss = 0.013911797665059566, Circular Tuning Loss = 1.3920183181762695\n",
      "210) Lyapunov Risk = 1.2649668455123901, MSE = 0.06498286128044128, V_0_loss = tensor([[0.0001]], grad_fn=<PowBackward0>), V_pos_loss = 0.13984684646129608, Lv_loss = 0.01378901582211256, Circular Tuning Loss = 1.391548752784729\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.50683593750000022, -0.50585937500000022]\n",
      "x2 : [0.50000000000000011, 0.50175040084150746]\n",
      "==============================\n",
      "211) Lyapunov Risk = 1.2618374824523926, MSE = 0.06476765871047974, V_0_loss = tensor([[0.0001]], grad_fn=<PowBackward0>), V_pos_loss = 0.1385650634765625, Lv_loss = 0.013593689538538456, Circular Tuning Loss = 1.3838410377502441\n",
      "212) Lyapunov Risk = 1.2605469226837158, MSE = 0.06461793929338455, V_0_loss = tensor([[0.0002]], grad_fn=<PowBackward0>), V_pos_loss = 0.1384245753288269, Lv_loss = 0.013425256125628948, Circular Tuning Loss = 1.3833740949630737\n",
      "213) Lyapunov Risk = 1.2592614889144897, MSE = 0.06444476544857025, V_0_loss = tensor([[0.0002]], grad_fn=<PowBackward0>), V_pos_loss = 0.13828495144844055, Lv_loss = 0.013266310095787048, Circular Tuning Loss = 1.3829081058502197\n",
      "214) Lyapunov Risk = 1.2579755783081055, MSE = 0.0641607865691185, V_0_loss = tensor([[0.0002]], grad_fn=<PowBackward0>), V_pos_loss = 0.13814614713191986, Lv_loss = 0.013196149840950966, Circular Tuning Loss = 1.3824430704116821\n",
      "215) Lyapunov Risk = 1.2566895484924316, MSE = 0.0637880340218544, V_0_loss = tensor([[0.0002]], grad_fn=<PowBackward0>), V_pos_loss = 0.13800784945487976, Lv_loss = 0.013201707042753696, Circular Tuning Loss = 1.3819794654846191\n",
      "216) Lyapunov Risk = 1.2554068565368652, MSE = 0.06343424320220947, V_0_loss = tensor([[0.0002]], grad_fn=<PowBackward0>), V_pos_loss = 0.13786974549293518, Lv_loss = 0.01318709272891283, Circular Tuning Loss = 1.3815170526504517\n",
      "217) Lyapunov Risk = 1.254122018814087, MSE = 0.06317494809627533, V_0_loss = tensor([[0.0002]], grad_fn=<PowBackward0>), V_pos_loss = 0.13773173093795776, Lv_loss = 0.013082624413073063, Circular Tuning Loss = 1.3810555934906006\n",
      "218) Lyapunov Risk = 1.2528377771377563, MSE = 0.06301694363355637, V_0_loss = tensor([[0.0002]], grad_fn=<PowBackward0>), V_pos_loss = 0.13759379088878632, Lv_loss = 0.012888657860457897, Circular Tuning Loss = 1.380595326423645\n",
      "219) Lyapunov Risk = 1.25155508518219, MSE = 0.06284703314304352, V_0_loss = tensor([[0.0002]], grad_fn=<PowBackward0>), V_pos_loss = 0.13745592534542084, Lv_loss = 0.012713702395558357, Circular Tuning Loss = 1.3801358938217163\n",
      "220) Lyapunov Risk = 1.2502670288085938, MSE = 0.06260886788368225, V_0_loss = tensor([[0.0002]], grad_fn=<PowBackward0>), V_pos_loss = 0.13731813430786133, Lv_loss = 0.012601567432284355, Circular Tuning Loss = 1.3796775341033936\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.50195312500000022, -0.50000000000000011]\n",
      "x2 : [0.50000000000000011, 0.50390625000000022]\n",
      "==============================\n",
      "221) Lyapunov Risk = 1.2472788095474243, MSE = 0.06234366446733475, V_0_loss = tensor([[0.0002]], grad_fn=<PowBackward0>), V_pos_loss = 0.1360693722963333, Lv_loss = 0.012494091875851154, Circular Tuning Loss = 1.3720989227294922\n",
      "222) Lyapunov Risk = 1.2459806203842163, MSE = 0.06223353371024132, V_0_loss = tensor([[0.0002]], grad_fn=<PowBackward0>), V_pos_loss = 0.13593170046806335, Lv_loss = 0.012253153137862682, Circular Tuning Loss = 1.371642827987671\n",
      "223) Lyapunov Risk = 1.2446882724761963, MSE = 0.06217708811163902, V_0_loss = tensor([[0.0002]], grad_fn=<PowBackward0>), V_pos_loss = 0.13579432666301727, Lv_loss = 0.011954148299992085, Circular Tuning Loss = 1.371187686920166\n",
      "224) Lyapunov Risk = 1.2433977127075195, MSE = 0.06201551482081413, V_0_loss = tensor([[0.0002]], grad_fn=<PowBackward0>), V_pos_loss = 0.13565708696842194, Lv_loss = 0.011758212000131607, Circular Tuning Loss = 1.3707334995269775\n",
      "225) Lyapunov Risk = 1.2421021461486816, MSE = 0.06171289086341858, V_0_loss = tensor([[0.0003]], grad_fn=<PowBackward0>), V_pos_loss = 0.13552038371562958, Lv_loss = 0.011699158698320389, Circular Tuning Loss = 1.370280385017395\n",
      "226) Lyapunov Risk = 1.2408117055892944, MSE = 0.06138765439391136, V_0_loss = tensor([[0.0003]], grad_fn=<PowBackward0>), V_pos_loss = 0.13538414239883423, Lv_loss = 0.011669994331896305, Circular Tuning Loss = 1.3698277473449707\n",
      "227) Lyapunov Risk = 1.2395169734954834, MSE = 0.061157118529081345, V_0_loss = tensor([[0.0003]], grad_fn=<PowBackward0>), V_pos_loss = 0.13524818420410156, Lv_loss = 0.011551467701792717, Circular Tuning Loss = 1.3693766593933105\n",
      "228) Lyapunov Risk = 1.2382181882858276, MSE = 0.06100669503211975, V_0_loss = tensor([[0.0003]], grad_fn=<PowBackward0>), V_pos_loss = 0.13511233031749725, Lv_loss = 0.01135658286511898, Circular Tuning Loss = 1.3689260482788086\n",
      "229) Lyapunov Risk = 1.2369236946105957, MSE = 0.06083236262202263, V_0_loss = tensor([[0.0003]], grad_fn=<PowBackward0>), V_pos_loss = 0.1349765509366989, Lv_loss = 0.011181705631315708, Circular Tuning Loss = 1.3684766292572021\n",
      "230) Lyapunov Risk = 1.235629916191101, MSE = 0.06058045104146004, V_0_loss = tensor([[0.0003]], grad_fn=<PowBackward0>), V_pos_loss = 0.13484078645706177, Lv_loss = 0.011073734611272812, Circular Tuning Loss = 1.368027925491333\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.50195312500000022, -0.50000000000000011]\n",
      "x2 : [0.50000000000000011, 0.50195312500000022]\n",
      "==============================\n",
      "231) Lyapunov Risk = 1.23268461227417, MSE = 0.06025774031877518, V_0_loss = tensor([[0.0003]], grad_fn=<PowBackward0>), V_pos_loss = 0.13361874222755432, Lv_loss = 0.010999321937561035, Circular Tuning Loss = 1.360568881034851\n",
      "232) Lyapunov Risk = 1.2313965559005737, MSE = 0.06006769463419914, V_0_loss = tensor([[0.0003]], grad_fn=<PowBackward0>), V_pos_loss = 0.13348419964313507, Lv_loss = 0.010817218571901321, Circular Tuning Loss = 1.3601224422454834\n",
      "233) Lyapunov Risk = 1.2301114797592163, MSE = 0.05989820510149002, V_0_loss = tensor([[0.0003]], grad_fn=<PowBackward0>), V_pos_loss = 0.1333497315645218, Lv_loss = 0.010604023933410645, Circular Tuning Loss = 1.3596770763397217\n",
      "234) Lyapunov Risk = 1.228824496269226, MSE = 0.05963922664523125, V_0_loss = tensor([[0.0003]], grad_fn=<PowBackward0>), V_pos_loss = 0.1332152783870697, Lv_loss = 0.01046675257384777, Circular Tuning Loss = 1.3592323064804077\n",
      "235) Lyapunov Risk = 1.2275311946868896, MSE = 0.059271711856126785, V_0_loss = tensor([[0.0003]], grad_fn=<PowBackward0>), V_pos_loss = 0.13308092951774597, Lv_loss = 0.010430146008729935, Circular Tuning Loss = 1.3587884902954102\n",
      "236) Lyapunov Risk = 1.2262394428253174, MSE = 0.058897871524095535, V_0_loss = tensor([[0.0004]], grad_fn=<PowBackward0>), V_pos_loss = 0.13294658064842224, Lv_loss = 0.010402197018265724, Circular Tuning Loss = 1.358345627784729\n",
      "237) Lyapunov Risk = 1.2249433994293213, MSE = 0.05862095206975937, V_0_loss = tensor([[0.0004]], grad_fn=<PowBackward0>), V_pos_loss = 0.1328122764825821, Lv_loss = 0.010286767967045307, Circular Tuning Loss = 1.3579035997390747\n",
      "238) Lyapunov Risk = 1.2236416339874268, MSE = 0.05844102054834366, V_0_loss = tensor([[0.0004]], grad_fn=<PowBackward0>), V_pos_loss = 0.13267798721790314, Lv_loss = 0.010086932219564915, Circular Tuning Loss = 1.3574622869491577\n",
      "239) Lyapunov Risk = 1.2223405838012695, MSE = 0.05830112472176552, V_0_loss = tensor([[0.0004]], grad_fn=<PowBackward0>), V_pos_loss = 0.13254374265670776, Lv_loss = 0.009861736558377743, Circular Tuning Loss = 1.357021689414978\n",
      "240) Lyapunov Risk = 1.2210407257080078, MSE = 0.05810012295842171, V_0_loss = tensor([[0.0004]], grad_fn=<PowBackward0>), V_pos_loss = 0.13240952789783478, Lv_loss = 0.009709740057587624, Circular Tuning Loss = 1.3565819263458252\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.50097656250000022, -0.50000000000000011]\n",
      "x2 : [0.50000000000000011, 0.50195312500000022]\n",
      "==============================\n",
      "241) Lyapunov Risk = 1.2180825471878052, MSE = 0.05780267342925072, V_0_loss = tensor([[0.0004]], grad_fn=<PowBackward0>), V_pos_loss = 0.13121715188026428, Lv_loss = 0.009589560329914093, Circular Tuning Loss = 1.349244475364685\n",
      "242) Lyapunov Risk = 1.2167741060256958, MSE = 0.05761782079935074, V_0_loss = tensor([[0.0004]], grad_fn=<PowBackward0>), V_pos_loss = 0.1310841292142868, Lv_loss = 0.009426241740584373, Circular Tuning Loss = 1.3488069772720337\n",
      "243) Lyapunov Risk = 1.2154728174209595, MSE = 0.057482171803712845, V_0_loss = tensor([[0.0004]], grad_fn=<PowBackward0>), V_pos_loss = 0.1309511661529541, Lv_loss = 0.009236637502908707, Circular Tuning Loss = 1.34837007522583\n",
      "244) Lyapunov Risk = 1.2141780853271484, MSE = 0.057266294956207275, V_0_loss = tensor([[0.0004]], grad_fn=<PowBackward0>), V_pos_loss = 0.13081827759742737, Lv_loss = 0.009127874858677387, Circular Tuning Loss = 1.3479341268539429\n",
      "245) Lyapunov Risk = 1.2128793001174927, MSE = 0.05693305656313896, V_0_loss = tensor([[0.0004]], grad_fn=<PowBackward0>), V_pos_loss = 0.1306854486465454, Lv_loss = 0.009096663445234299, Circular Tuning Loss = 1.347499132156372\n",
      "246) Lyapunov Risk = 1.2115867137908936, MSE = 0.05655577406287193, V_0_loss = tensor([[0.0005]], grad_fn=<PowBackward0>), V_pos_loss = 0.13055266439914703, Lv_loss = 0.00909921433776617, Circular Tuning Loss = 1.3470649719238281\n",
      "247) Lyapunov Risk = 1.2103049755096436, MSE = 0.056229811161756516, V_0_loss = tensor([[0.0005]], grad_fn=<PowBackward0>), V_pos_loss = 0.13041990995407104, Lv_loss = 0.00907499622553587, Circular Tuning Loss = 1.346631646156311\n",
      "248) Lyapunov Risk = 1.209023118019104, MSE = 0.05599932745099068, V_0_loss = tensor([[0.0005]], grad_fn=<PowBackward0>), V_pos_loss = 0.13028724491596222, Lv_loss = 0.008995802141726017, Circular Tuning Loss = 1.3461993932724\n",
      "249) Lyapunov Risk = 1.2077494859695435, MSE = 0.05578489229083061, V_0_loss = tensor([[0.0005]], grad_fn=<PowBackward0>), V_pos_loss = 0.13015490770339966, Lv_loss = 0.008914295583963394, Circular Tuning Loss = 1.3457677364349365\n",
      "250) Lyapunov Risk = 1.2064807415008545, MSE = 0.05549221113324165, V_0_loss = tensor([[0.0005]], grad_fn=<PowBackward0>), V_pos_loss = 0.13002289831638336, Lv_loss = 0.00888801645487547, Circular Tuning Loss = 1.345337152481079\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.50097656250000022, -0.50000000000000011]\n",
      "x2 : [0.17187500000000006, 0.17382812500000006]\n",
      "==============================\n",
      "251) Lyapunov Risk = 1.2018928527832031, MSE = 0.055142052471637726, V_0_loss = tensor([[0.0005]], grad_fn=<PowBackward0>), V_pos_loss = 0.12886005640029907, Lv_loss = 0.00883172731846571, Circular Tuning Loss = 1.3352738618850708\n",
      "252) Lyapunov Risk = 1.2006200551986694, MSE = 0.054910846054553986, V_0_loss = tensor([[0.0005]], grad_fn=<PowBackward0>), V_pos_loss = 0.1287292242050171, Lv_loss = 0.008772386237978935, Circular Tuning Loss = 1.3348478078842163\n",
      "253) Lyapunov Risk = 1.1993484497070312, MSE = 0.05476149916648865, V_0_loss = tensor([[0.0005]], grad_fn=<PowBackward0>), V_pos_loss = 0.12859851121902466, Lv_loss = 0.008660527877509594, Circular Tuning Loss = 1.3344229459762573\n",
      "254) Lyapunov Risk = 1.1980799436569214, MSE = 0.054554533213377, V_0_loss = tensor([[0.0005]], grad_fn=<PowBackward0>), V_pos_loss = 0.128467857837677, Lv_loss = 0.008588423952460289, Circular Tuning Loss = 1.3339990377426147\n",
      "255) Lyapunov Risk = 1.1968075037002563, MSE = 0.05427749454975128, V_0_loss = tensor([[0.0006]], grad_fn=<PowBackward0>), V_pos_loss = 0.12833726406097412, Lv_loss = 0.008557196706533432, Circular Tuning Loss = 1.3335763216018677\n",
      "256) Lyapunov Risk = 1.195543885231018, MSE = 0.05400407686829567, V_0_loss = tensor([[0.0006]], grad_fn=<PowBackward0>), V_pos_loss = 0.1282067894935608, Lv_loss = 0.008520633913576603, Circular Tuning Loss = 1.333154559135437\n",
      "257) Lyapunov Risk = 1.194289207458496, MSE = 0.053777050226926804, V_0_loss = tensor([[0.0006]], grad_fn=<PowBackward0>), V_pos_loss = 0.12807635962963104, Lv_loss = 0.008457615040242672, Circular Tuning Loss = 1.3327338695526123\n",
      "258) Lyapunov Risk = 1.1930348873138428, MSE = 0.053588397800922394, V_0_loss = tensor([[0.0006]], grad_fn=<PowBackward0>), V_pos_loss = 0.12794603407382965, Lv_loss = 0.008370959199965, Circular Tuning Loss = 1.332314133644104\n",
      "259) Lyapunov Risk = 1.1917881965637207, MSE = 0.05338706821203232, V_0_loss = tensor([[0.0006]], grad_fn=<PowBackward0>), V_pos_loss = 0.1278158277273178, Lv_loss = 0.008293929509818554, Circular Tuning Loss = 1.331895351409912\n",
      "260) Lyapunov Risk = 1.1905421018600464, MSE = 0.05311724916100502, V_0_loss = tensor([[0.0006]], grad_fn=<PowBackward0>), V_pos_loss = 0.12768585979938507, Lv_loss = 0.008256873115897179, Circular Tuning Loss = 1.3314776420593262\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.078125000000000028, -0.077148437500000028]\n",
      "x2 : [0.12402343750000003, 0.12500000000000003]\n",
      "==============================\n",
      "261) Lyapunov Risk = 1.1856324672698975, MSE = 0.05279316380620003, V_0_loss = tensor([[0.0006]], grad_fn=<PowBackward0>), V_pos_loss = 0.1265515685081482, Lv_loss = 0.008186009712517262, Circular Tuning Loss = 1.3207404613494873\n",
      "262) Lyapunov Risk = 1.1843944787979126, MSE = 0.052590660750865936, V_0_loss = tensor([[0.0006]], grad_fn=<PowBackward0>), V_pos_loss = 0.12642282247543335, Lv_loss = 0.008124075829982758, Circular Tuning Loss = 1.3203277587890625\n",
      "263) Lyapunov Risk = 1.18315851688385, MSE = 0.05245470628142357, V_0_loss = tensor([[0.0006]], grad_fn=<PowBackward0>), V_pos_loss = 0.12629424035549164, Lv_loss = 0.00803389959037304, Circular Tuning Loss = 1.3199163675308228\n",
      "264) Lyapunov Risk = 1.1819281578063965, MSE = 0.05228200554847717, V_0_loss = tensor([[0.0007]], grad_fn=<PowBackward0>), V_pos_loss = 0.12616579234600067, Lv_loss = 0.007971695624291897, Circular Tuning Loss = 1.319506287574768\n",
      "265) Lyapunov Risk = 1.1806974411010742, MSE = 0.05203163996338844, V_0_loss = tensor([[0.0007]], grad_fn=<PowBackward0>), V_pos_loss = 0.12603749334812164, Lv_loss = 0.007958297617733479, Circular Tuning Loss = 1.3190971612930298\n",
      "266) Lyapunov Risk = 1.179472804069519, MSE = 0.051766082644462585, V_0_loss = tensor([[0.0007]], grad_fn=<PowBackward0>), V_pos_loss = 0.12590929865837097, Lv_loss = 0.00796070508658886, Circular Tuning Loss = 1.3186893463134766\n",
      "267) Lyapunov Risk = 1.1782523393630981, MSE = 0.05156032741069794, V_0_loss = tensor([[0.0007]], grad_fn=<PowBackward0>), V_pos_loss = 0.12578125298023224, Lv_loss = 0.007929272949695587, Circular Tuning Loss = 1.3182823657989502\n",
      "268) Lyapunov Risk = 1.177037000656128, MSE = 0.05140234902501106, V_0_loss = tensor([[0.0007]], grad_fn=<PowBackward0>), V_pos_loss = 0.12565334141254425, Lv_loss = 0.007870693691074848, Circular Tuning Loss = 1.3178768157958984\n",
      "269) Lyapunov Risk = 1.1758252382278442, MSE = 0.05121651664376259, V_0_loss = tensor([[0.0007]], grad_fn=<PowBackward0>), V_pos_loss = 0.12552551925182343, Lv_loss = 0.00782468169927597, Circular Tuning Loss = 1.317472219467163\n",
      "270) Lyapunov Risk = 1.1746156215667725, MSE = 0.05095409229397774, V_0_loss = tensor([[0.0007]], grad_fn=<PowBackward0>), V_pos_loss = 0.12539781630039215, Lv_loss = 0.007817525416612625, Circular Tuning Loss = 1.3170684576034546\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.47407016413274589, -0.47234150840826228]\n",
      "x2 : [0.50000000000000011, 0.5011755932243942]\n",
      "==============================\n",
      "271) Lyapunov Risk = 1.1719595193862915, MSE = 0.05065608024597168, V_0_loss = tensor([[0.0007]], grad_fn=<PowBackward0>), V_pos_loss = 0.12429157644510269, Lv_loss = 0.007811608724296093, Circular Tuning Loss = 1.3100767135620117\n",
      "272) Lyapunov Risk = 1.170744776725769, MSE = 0.0504898875951767, V_0_loss = tensor([[0.0007]], grad_fn=<PowBackward0>), V_pos_loss = 0.12416515499353409, Lv_loss = 0.007726972457021475, Circular Tuning Loss = 1.3096754550933838\n",
      "273) Lyapunov Risk = 1.1695398092269897, MSE = 0.050346214324235916, V_0_loss = tensor([[0.0008]], grad_fn=<PowBackward0>), V_pos_loss = 0.12403891235589981, Lv_loss = 0.007628082297742367, Circular Tuning Loss = 1.3092752695083618\n",
      "274) Lyapunov Risk = 1.1683429479599, MSE = 0.05008917674422264, V_0_loss = tensor([[0.0008]], grad_fn=<PowBackward0>), V_pos_loss = 0.12391281127929688, Lv_loss = 0.007594880647957325, Circular Tuning Loss = 1.3088762760162354\n",
      "275) Lyapunov Risk = 1.1671499013900757, MSE = 0.04969584941864014, V_0_loss = tensor([[0.0008]], grad_fn=<PowBackward0>), V_pos_loss = 0.12378688156604767, Lv_loss = 0.007633857429027557, Circular Tuning Loss = 1.3084783554077148\n",
      "276) Lyapunov Risk = 1.1659772396087646, MSE = 0.04930240660905838, V_0_loss = tensor([[0.0008]], grad_fn=<PowBackward0>), V_pos_loss = 0.12366104125976562, Lv_loss = 0.007676820270717144, Circular Tuning Loss = 1.3080813884735107\n",
      "277) Lyapunov Risk = 1.1648105382919312, MSE = 0.04902133345603943, V_0_loss = tensor([[0.0008]], grad_fn=<PowBackward0>), V_pos_loss = 0.12353532016277313, Lv_loss = 0.0076657505705952644, Circular Tuning Loss = 1.3076852560043335\n",
      "278) Lyapunov Risk = 1.1636463403701782, MSE = 0.048857782036066055, V_0_loss = tensor([[0.0008]], grad_fn=<PowBackward0>), V_pos_loss = 0.1234096884727478, Lv_loss = 0.007596047129482031, Circular Tuning Loss = 1.3072903156280518\n",
      "279) Lyapunov Risk = 1.1624903678894043, MSE = 0.04870186001062393, V_0_loss = tensor([[0.0008]], grad_fn=<PowBackward0>), V_pos_loss = 0.12328417599201202, Lv_loss = 0.00753059983253479, Circular Tuning Loss = 1.3068962097167969\n",
      "280) Lyapunov Risk = 1.1613357067108154, MSE = 0.04846453294157982, V_0_loss = tensor([[0.0008]], grad_fn=<PowBackward0>), V_pos_loss = 0.12315871566534042, Lv_loss = 0.007517100311815739, Circular Tuning Loss = 1.3065030574798584\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.46924606707847893, -0.46805014001082712]\n",
      "x2 : [0.50368640196232128, 0.5049152026164283]\n",
      "==============================\n",
      "281) Lyapunov Risk = 1.1587272882461548, MSE = 0.04817739874124527, V_0_loss = tensor([[0.0009]], grad_fn=<PowBackward0>), V_pos_loss = 0.12208425998687744, Lv_loss = 0.00747898081317544, Circular Tuning Loss = 1.2996647357940674\n",
      "282) Lyapunov Risk = 1.157569169998169, MSE = 0.048067592084407806, V_0_loss = tensor([[0.0009]], grad_fn=<PowBackward0>), V_pos_loss = 0.12195806950330734, Lv_loss = 0.007411828730255365, Circular Tuning Loss = 1.2992734909057617\n",
      "283) Lyapunov Risk = 1.1564265489578247, MSE = 0.04798823222517967, V_0_loss = tensor([[0.0009]], grad_fn=<PowBackward0>), V_pos_loss = 0.12183229625225067, Lv_loss = 0.007335651200264692, Circular Tuning Loss = 1.2988827228546143\n",
      "284) Lyapunov Risk = 1.155292272567749, MSE = 0.04777614772319794, V_0_loss = tensor([[0.0009]], grad_fn=<PowBackward0>), V_pos_loss = 0.12170732766389847, Lv_loss = 0.007329188287258148, Circular Tuning Loss = 1.2984932661056519\n",
      "285) Lyapunov Risk = 1.1541682481765747, MSE = 0.04744177684187889, V_0_loss = tensor([[0.0009]], grad_fn=<PowBackward0>), V_pos_loss = 0.12158359587192535, Lv_loss = 0.0073881009593605995, Circular Tuning Loss = 1.2981044054031372\n",
      "286) Lyapunov Risk = 1.1530590057373047, MSE = 0.047180116176605225, V_0_loss = tensor([[0.0009]], grad_fn=<PowBackward0>), V_pos_loss = 0.12146014720201492, Lv_loss = 0.007414450403302908, Circular Tuning Loss = 1.2977168560028076\n",
      "287) Lyapunov Risk = 1.1519534587860107, MSE = 0.04703620448708534, V_0_loss = tensor([[0.0009]], grad_fn=<PowBackward0>), V_pos_loss = 0.1213369071483612, Lv_loss = 0.007378411013633013, Circular Tuning Loss = 1.2973304986953735\n",
      "288) Lyapunov Risk = 1.1508610248565674, MSE = 0.046893034130334854, V_0_loss = tensor([[0.0009]], grad_fn=<PowBackward0>), V_pos_loss = 0.12121385335922241, Lv_loss = 0.007343551144003868, Circular Tuning Loss = 1.2969449758529663\n",
      "289) Lyapunov Risk = 1.1497762203216553, MSE = 0.046671122312545776, V_0_loss = tensor([[0.0010]], grad_fn=<PowBackward0>), V_pos_loss = 0.12109091132879257, Lv_loss = 0.007349045947194099, Circular Tuning Loss = 1.2965606451034546\n",
      "290) Lyapunov Risk = 1.1487005949020386, MSE = 0.0463775135576725, V_0_loss = tensor([[0.0010]], grad_fn=<PowBackward0>), V_pos_loss = 0.12096811830997467, Lv_loss = 0.007393172476440668, Circular Tuning Loss = 1.2961775064468384\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.070312500000000028, -0.069335937500000028]\n",
      "x2 : [0.12402343750000003, 0.12500000000000003]\n",
      "==============================\n",
      "291) Lyapunov Risk = 1.1442049741744995, MSE = 0.04611629620194435, V_0_loss = tensor([[0.0010]], grad_fn=<PowBackward0>), V_pos_loss = 0.11991584300994873, Lv_loss = 0.007361944764852524, Circular Tuning Loss = 1.285967230796814\n",
      "292) Lyapunov Risk = 1.1431455612182617, MSE = 0.04606444761157036, V_0_loss = tensor([[0.0010]], grad_fn=<PowBackward0>), V_pos_loss = 0.1197943314909935, Lv_loss = 0.007280362769961357, Circular Tuning Loss = 1.2855889797210693\n",
      "293) Lyapunov Risk = 1.1421020030975342, MSE = 0.04605822637677193, V_0_loss = tensor([[0.0010]], grad_fn=<PowBackward0>), V_pos_loss = 0.119672991335392, Lv_loss = 0.007186384405940771, Circular Tuning Loss = 1.2852121591567993\n",
      "294) Lyapunov Risk = 1.1410664319992065, MSE = 0.04592732712626457, V_0_loss = tensor([[0.0010]], grad_fn=<PowBackward0>), V_pos_loss = 0.11955185979604721, Lv_loss = 0.007158979307860136, Circular Tuning Loss = 1.2848362922668457\n",
      "295) Lyapunov Risk = 1.1400399208068848, MSE = 0.04569069668650627, V_0_loss = tensor([[0.0010]], grad_fn=<PowBackward0>), V_pos_loss = 0.11943086981773376, Lv_loss = 0.007181320805102587, Circular Tuning Loss = 1.2844617366790771\n",
      "296) Lyapunov Risk = 1.1390275955200195, MSE = 0.045485954731702805, V_0_loss = tensor([[0.0010]], grad_fn=<PowBackward0>), V_pos_loss = 0.11931010335683823, Lv_loss = 0.007188485004007816, Circular Tuning Loss = 1.2840884923934937\n",
      "297) Lyapunov Risk = 1.1380195617675781, MSE = 0.0453793965280056, V_0_loss = tensor([[0.0011]], grad_fn=<PowBackward0>), V_pos_loss = 0.11918968707323074, Lv_loss = 0.007148168981075287, Circular Tuning Loss = 1.2837164402008057\n",
      "298) Lyapunov Risk = 1.137024164199829, MSE = 0.04530324786901474, V_0_loss = tensor([[0.0011]], grad_fn=<PowBackward0>), V_pos_loss = 0.11906962096691132, Lv_loss = 0.00709448242560029, Circular Tuning Loss = 1.283345341682434\n",
      "299) Lyapunov Risk = 1.1360365152359009, MSE = 0.045141614973545074, V_0_loss = tensor([[0.0011]], grad_fn=<PowBackward0>), V_pos_loss = 0.11894972622394562, Lv_loss = 0.007081512827426195, Circular Tuning Loss = 1.282975435256958\n",
      "300) Lyapunov Risk = 1.1350575685501099, MSE = 0.04487239196896553, V_0_loss = tensor([[0.0011]], grad_fn=<PowBackward0>), V_pos_loss = 0.11882998794317245, Lv_loss = 0.007117156405001879, Circular Tuning Loss = 1.282606840133667\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.12500000000000003, -0.12109375000000003]\n",
      "x2 : [0.12109375000000003, 0.12500000000000003]\n",
      "==============================\n",
      "301) Lyapunov Risk = 1.13099205493927, MSE = 0.04459584131836891, V_0_loss = tensor([[0.0011]], grad_fn=<PowBackward0>), V_pos_loss = 0.11780417710542679, Lv_loss = 0.007253268267959356, Circular Tuning Loss = 1.27260160446167\n",
      "302) Lyapunov Risk = 1.1300286054611206, MSE = 0.04451136291027069, V_0_loss = tensor([[0.0011]], grad_fn=<PowBackward0>), V_pos_loss = 0.11768568307161331, Lv_loss = 0.007199550047516823, Circular Tuning Loss = 1.2722376585006714\n",
      "303) Lyapunov Risk = 1.1290826797485352, MSE = 0.04448879137635231, V_0_loss = tensor([[0.0011]], grad_fn=<PowBackward0>), V_pos_loss = 0.11756736040115356, Lv_loss = 0.0071231708861887455, Circular Tuning Loss = 1.271875023841858\n",
      "304) Lyapunov Risk = 1.1281434297561646, MSE = 0.04431911185383797, V_0_loss = tensor([[0.0011]], grad_fn=<PowBackward0>), V_pos_loss = 0.11744921654462814, Lv_loss = 0.007121996022760868, Circular Tuning Loss = 1.27151358127594\n",
      "305) Lyapunov Risk = 1.127213716506958, MSE = 0.044044770300388336, V_0_loss = tensor([[0.0012]], grad_fn=<PowBackward0>), V_pos_loss = 0.11733123660087585, Lv_loss = 0.007174384314566851, Circular Tuning Loss = 1.271153450012207\n",
      "306) Lyapunov Risk = 1.1262985467910767, MSE = 0.0438506118953228, V_0_loss = tensor([[0.0012]], grad_fn=<PowBackward0>), V_pos_loss = 0.1172134056687355, Lv_loss = 0.00718274898827076, Circular Tuning Loss = 1.2707945108413696\n",
      "307) Lyapunov Risk = 1.1253868341445923, MSE = 0.043803974986076355, V_0_loss = tensor([[0.0012]], grad_fn=<PowBackward0>), V_pos_loss = 0.1170957162976265, Lv_loss = 0.0071096522733569145, Circular Tuning Loss = 1.2704367637634277\n",
      "308) Lyapunov Risk = 1.1244919300079346, MSE = 0.04379166290163994, V_0_loss = tensor([[0.0012]], grad_fn=<PowBackward0>), V_pos_loss = 0.11697815358638763, Lv_loss = 0.00702068954706192, Circular Tuning Loss = 1.2700799703598022\n",
      "309) Lyapunov Risk = 1.1236062049865723, MSE = 0.04366013780236244, V_0_loss = tensor([[0.0012]], grad_fn=<PowBackward0>), V_pos_loss = 0.11686071753501892, Lv_loss = 0.006998641416430473, Circular Tuning Loss = 1.2697242498397827\n",
      "310) Lyapunov Risk = 1.1227335929870605, MSE = 0.043416474014520645, V_0_loss = tensor([[0.0012]], grad_fn=<PowBackward0>), V_pos_loss = 0.11674343794584274, Lv_loss = 0.007039126008749008, Circular Tuning Loss = 1.2693692445755005\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.43847656250000011, -0.43750000000000011]\n",
      "x2 : [0.48828125000000011, 0.48925781250000011]\n",
      "==============================\n",
      "311) Lyapunov Risk = 1.120434045791626, MSE = 0.04321467876434326, V_0_loss = tensor([[0.0012]], grad_fn=<PowBackward0>), V_pos_loss = 0.11574288457632065, Lv_loss = 0.0070080324076116085, Circular Tuning Loss = 1.2626575231552124\n",
      "312) Lyapunov Risk = 1.119555950164795, MSE = 0.04324345290660858, V_0_loss = tensor([[0.0012]], grad_fn=<PowBackward0>), V_pos_loss = 0.11562695354223251, Lv_loss = 0.00691039115190506, Circular Tuning Loss = 1.2623052597045898\n",
      "313) Lyapunov Risk = 1.1187077760696411, MSE = 0.04326491430401802, V_0_loss = tensor([[0.0013]], grad_fn=<PowBackward0>), V_pos_loss = 0.11551119387149811, Lv_loss = 0.0068223485723137856, Circular Tuning Loss = 1.2619543075561523\n",
      "314) Lyapunov Risk = 1.117855191230774, MSE = 0.04305286332964897, V_0_loss = tensor([[0.0013]], grad_fn=<PowBackward0>), V_pos_loss = 0.11539562046527863, Lv_loss = 0.0068566747941076756, Circular Tuning Loss = 1.2616043090820312\n",
      "315) Lyapunov Risk = 1.1170144081115723, MSE = 0.04270331934094429, V_0_loss = tensor([[0.0013]], grad_fn=<PowBackward0>), V_pos_loss = 0.11528017371892929, Lv_loss = 0.006968817673623562, Circular Tuning Loss = 1.2612552642822266\n",
      "316) Lyapunov Risk = 1.1161878108978271, MSE = 0.04247758537530899, V_0_loss = tensor([[0.0013]], grad_fn=<PowBackward0>), V_pos_loss = 0.11516489833593369, Lv_loss = 0.007022240664809942, Circular Tuning Loss = 1.2609074115753174\n",
      "317) Lyapunov Risk = 1.1153554916381836, MSE = 0.0424659363925457, V_0_loss = tensor([[0.0013]], grad_fn=<PowBackward0>), V_pos_loss = 0.11504976451396942, Lv_loss = 0.006953547243028879, Circular Tuning Loss = 1.2605606317520142\n",
      "318) Lyapunov Risk = 1.1145429611206055, MSE = 0.042492371052503586, V_0_loss = tensor([[0.0013]], grad_fn=<PowBackward0>), V_pos_loss = 0.11493472754955292, Lv_loss = 0.0068703037686645985, Circular Tuning Loss = 1.260214924812317\n",
      "319) Lyapunov Risk = 1.1137292385101318, MSE = 0.04238394647836685, V_0_loss = tensor([[0.0013]], grad_fn=<PowBackward0>), V_pos_loss = 0.11481983214616776, Lv_loss = 0.006858050357550383, Circular Tuning Loss = 1.2598698139190674\n",
      "320) Lyapunov Risk = 1.112926959991455, MSE = 0.04217249155044556, V_0_loss = tensor([[0.0013]], grad_fn=<PowBackward0>), V_pos_loss = 0.11470507830381393, Lv_loss = 0.006901389919221401, Circular Tuning Loss = 1.2595256567001343\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.078125000000000028, -0.077148437500000028]\n",
      "x2 : [0.12402343750000003, 0.12500000000000003]\n",
      "==============================\n",
      "321) Lyapunov Risk = 1.1089863777160645, MSE = 0.042014796286821365, V_0_loss = tensor([[0.0014]], grad_fn=<PowBackward0>), V_pos_loss = 0.1137288361787796, Lv_loss = 0.006865147966891527, Circular Tuning Loss = 1.2498408555984497\n",
      "322) Lyapunov Risk = 1.1081929206848145, MSE = 0.042110443115234375, V_0_loss = tensor([[0.0014]], grad_fn=<PowBackward0>), V_pos_loss = 0.11361526697874069, Lv_loss = 0.0067558870650827885, Circular Tuning Loss = 1.2495012283325195\n",
      "323) Lyapunov Risk = 1.1074298620224, MSE = 0.04222040995955467, V_0_loss = tensor([[0.0014]], grad_fn=<PowBackward0>), V_pos_loss = 0.11350209265947342, Lv_loss = 0.006652995478361845, Circular Tuning Loss = 1.2491629123687744\n",
      "324) Lyapunov Risk = 1.1066601276397705, MSE = 0.04210420325398445, V_0_loss = tensor([[0.0014]], grad_fn=<PowBackward0>), V_pos_loss = 0.11338938027620316, Lv_loss = 0.0066681415773928165, Circular Tuning Loss = 1.2488257884979248\n",
      "325) Lyapunov Risk = 1.1059057712554932, MSE = 0.041876256465911865, V_0_loss = tensor([[0.0014]], grad_fn=<PowBackward0>), V_pos_loss = 0.11327691376209259, Lv_loss = 0.006742989178746939, Circular Tuning Loss = 1.2484898567199707\n",
      "326) Lyapunov Risk = 1.1051595211029053, MSE = 0.041766442358493805, V_0_loss = tensor([[0.0014]], grad_fn=<PowBackward0>), V_pos_loss = 0.11316464096307755, Lv_loss = 0.006754111032932997, Circular Tuning Loss = 1.248154878616333\n",
      "327) Lyapunov Risk = 1.1044137477874756, MSE = 0.041802044957876205, V_0_loss = tensor([[0.0014]], grad_fn=<PowBackward0>), V_pos_loss = 0.11305255442857742, Lv_loss = 0.006685805507004261, Circular Tuning Loss = 1.24782133102417\n",
      "328) Lyapunov Risk = 1.1036862134933472, MSE = 0.04180531203746796, V_0_loss = tensor([[0.0014]], grad_fn=<PowBackward0>), V_pos_loss = 0.11294068396091461, Lv_loss = 0.006633915472775698, Circular Tuning Loss = 1.2474888563156128\n",
      "329) Lyapunov Risk = 1.1029618978500366, MSE = 0.04164379462599754, V_0_loss = tensor([[0.0015]], grad_fn=<PowBackward0>), V_pos_loss = 0.11282896250486374, Lv_loss = 0.006663577165454626, Circular Tuning Loss = 1.2471572160720825\n",
      "330) Lyapunov Risk = 1.1022578477859497, MSE = 0.04126494750380516, V_0_loss = tensor([[0.0015]], grad_fn=<PowBackward0>), V_pos_loss = 0.11271731555461884, Lv_loss = 0.006794404704123735, Circular Tuning Loss = 1.2468267679214478\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.40820312500000011, -0.40625000000000011]\n",
      "x2 : [0.46875000000000011, 0.47070312500000011]\n",
      "==============================\n",
      "331) Lyapunov Risk = 1.1002235412597656, MSE = 0.041022587567567825, V_0_loss = tensor([[0.0015]], grad_fn=<PowBackward0>), V_pos_loss = 0.11176551878452301, Lv_loss = 0.006882748566567898, Circular Tuning Loss = 1.2400678396224976\n",
      "332) Lyapunov Risk = 1.0994977951049805, MSE = 0.041180796921253204, V_0_loss = tensor([[0.0015]], grad_fn=<PowBackward0>), V_pos_loss = 0.11165511608123779, Lv_loss = 0.006676617078483105, Circular Tuning Loss = 1.239740014076233\n",
      "333) Lyapunov Risk = 1.0988351106643677, MSE = 0.041359901428222656, V_0_loss = tensor([[0.0015]], grad_fn=<PowBackward0>), V_pos_loss = 0.11154486984014511, Lv_loss = 0.006466618739068508, Circular Tuning Loss = 1.2394130229949951\n",
      "334) Lyapunov Risk = 1.0981409549713135, MSE = 0.04111611843109131, V_0_loss = tensor([[0.0015]], grad_fn=<PowBackward0>), V_pos_loss = 0.11143475770950317, Lv_loss = 0.0064962259493768215, Circular Tuning Loss = 1.2390872240066528\n",
      "335) Lyapunov Risk = 1.0974981784820557, MSE = 0.040557555854320526, V_0_loss = tensor([[0.0015]], grad_fn=<PowBackward0>), V_pos_loss = 0.111324742436409, Lv_loss = 0.006740387063473463, Circular Tuning Loss = 1.238762378692627\n",
      "336) Lyapunov Risk = 1.0968350172042847, MSE = 0.04045501723885536, V_0_loss = tensor([[0.0015]], grad_fn=<PowBackward0>), V_pos_loss = 0.11121491342782974, Lv_loss = 0.006702058482915163, Circular Tuning Loss = 1.2384384870529175\n",
      "337) Lyapunov Risk = 1.0961946249008179, MSE = 0.0406477227807045, V_0_loss = tensor([[0.0016]], grad_fn=<PowBackward0>), V_pos_loss = 0.11110517382621765, Lv_loss = 0.0064692385494709015, Circular Tuning Loss = 1.238115668296814\n",
      "338) Lyapunov Risk = 1.0955753326416016, MSE = 0.04065756872296333, V_0_loss = tensor([[0.0016]], grad_fn=<PowBackward0>), V_pos_loss = 0.11099550873041153, Lv_loss = 0.006378960330039263, Circular Tuning Loss = 1.2377939224243164\n",
      "339) Lyapunov Risk = 1.0949323177337646, MSE = 0.04035075753927231, V_0_loss = tensor([[0.0016]], grad_fn=<PowBackward0>), V_pos_loss = 0.1108858734369278, Lv_loss = 0.006502989679574966, Circular Tuning Loss = 1.2374728918075562\n",
      "340) Lyapunov Risk = 1.0943320989608765, MSE = 0.04006744548678398, V_0_loss = tensor([[0.0016]], grad_fn=<PowBackward0>), V_pos_loss = 0.11077630519866943, Lv_loss = 0.006626337766647339, Circular Tuning Loss = 1.2371526956558228\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.062500000000000014, -0.061523437500000014]\n",
      "x2 : [0.12402343750000003, 0.12500000000000003]\n",
      "==============================\n",
      "341) Lyapunov Risk = 1.0906610488891602, MSE = 0.04005102813243866, V_0_loss = tensor([[0.0016]], grad_fn=<PowBackward0>), V_pos_loss = 0.10984701663255692, Lv_loss = 0.006502977106720209, Circular Tuning Loss = 1.2277865409851074\n",
      "342) Lyapunov Risk = 1.0900601148605347, MSE = 0.04029354453086853, V_0_loss = tensor([[0.0016]], grad_fn=<PowBackward0>), V_pos_loss = 0.10973839461803436, Lv_loss = 0.006271961145102978, Circular Tuning Loss = 1.2274706363677979\n",
      "343) Lyapunov Risk = 1.0894728899002075, MSE = 0.04035385698080063, V_0_loss = tensor([[0.0016]], grad_fn=<PowBackward0>), V_pos_loss = 0.10962992161512375, Lv_loss = 0.006179432850331068, Circular Tuning Loss = 1.2271558046340942\n",
      "344) Lyapunov Risk = 1.0888640880584717, MSE = 0.04013421759009361, V_0_loss = tensor([[0.0016]], grad_fn=<PowBackward0>), V_pos_loss = 0.1095215380191803, Lv_loss = 0.006253201514482498, Circular Tuning Loss = 1.2268420457839966\n",
      "345) Lyapunov Risk = 1.088293194770813, MSE = 0.03996078670024872, V_0_loss = tensor([[0.0017]], grad_fn=<PowBackward0>), V_pos_loss = 0.1094132736325264, Lv_loss = 0.006304255686700344, Circular Tuning Loss = 1.2265293598175049\n",
      "346) Lyapunov Risk = 1.0876975059509277, MSE = 0.040045518428087234, V_0_loss = tensor([[0.0017]], grad_fn=<PowBackward0>), V_pos_loss = 0.10930511355400085, Lv_loss = 0.006191962864249945, Circular Tuning Loss = 1.2262173891067505\n",
      "347) Lyapunov Risk = 1.0871257781982422, MSE = 0.04024925082921982, V_0_loss = tensor([[0.0017]], grad_fn=<PowBackward0>), V_pos_loss = 0.10919705778360367, Lv_loss = 0.006027471274137497, Circular Tuning Loss = 1.2259066104888916\n",
      "348) Lyapunov Risk = 1.0865566730499268, MSE = 0.0402015782892704, V_0_loss = tensor([[0.0017]], grad_fn=<PowBackward0>), V_pos_loss = 0.10908908396959305, Lv_loss = 0.005992628633975983, Circular Tuning Loss = 1.2255966663360596\n",
      "349) Lyapunov Risk = 1.0859925746917725, MSE = 0.03984794765710831, V_0_loss = tensor([[0.0017]], grad_fn=<PowBackward0>), V_pos_loss = 0.1089811623096466, Lv_loss = 0.00611500721424818, Circular Tuning Loss = 1.225287675857544\n",
      "350) Lyapunov Risk = 1.085430383682251, MSE = 0.03980961814522743, V_0_loss = tensor([[0.0017]], grad_fn=<PowBackward0>), V_pos_loss = 0.10887333750724792, Lv_loss = 0.006064876914024353, Circular Tuning Loss = 1.2249794006347656\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.078125000000000028, -0.077148437500000028]\n",
      "x2 : [0.12402343750000003, 0.12500000000000003]\n",
      "==============================\n",
      "351) Lyapunov Risk = 1.081939935684204, MSE = 0.039883989840745926, V_0_loss = tensor([[0.0017]], grad_fn=<PowBackward0>), V_pos_loss = 0.10796579718589783, Lv_loss = 0.0058984337374567986, Circular Tuning Loss = 1.2157795429229736\n",
      "352) Lyapunov Risk = 1.0814026594161987, MSE = 0.039940331131219864, V_0_loss = tensor([[0.0017]], grad_fn=<PowBackward0>), V_pos_loss = 0.10785892605781555, Lv_loss = 0.005786598194390535, Circular Tuning Loss = 1.215475082397461\n",
      "353) Lyapunov Risk = 1.0808550119400024, MSE = 0.03980880603194237, V_0_loss = tensor([[0.0017]], grad_fn=<PowBackward0>), V_pos_loss = 0.10775215923786163, Lv_loss = 0.005793084390461445, Circular Tuning Loss = 1.2151715755462646\n",
      "354) Lyapunov Risk = 1.080316185951233, MSE = 0.03961684927344322, V_0_loss = tensor([[0.0018]], grad_fn=<PowBackward0>), V_pos_loss = 0.10764550417661667, Lv_loss = 0.0058458708226680756, Circular Tuning Loss = 1.2148691415786743\n",
      "355) Lyapunov Risk = 1.0797823667526245, MSE = 0.03958549350500107, V_0_loss = tensor([[0.0018]], grad_fn=<PowBackward0>), V_pos_loss = 0.10753895342350006, Lv_loss = 0.005794854834675789, Circular Tuning Loss = 1.21456778049469\n",
      "356) Lyapunov Risk = 1.0792521238327026, MSE = 0.039673399180173874, V_0_loss = tensor([[0.0018]], grad_fn=<PowBackward0>), V_pos_loss = 0.10743258148431778, Lv_loss = 0.005668177735060453, Circular Tuning Loss = 1.2142672538757324\n",
      "357) Lyapunov Risk = 1.078731894493103, MSE = 0.039700672030448914, V_0_loss = tensor([[0.0018]], grad_fn=<PowBackward0>), V_pos_loss = 0.10732635855674744, Lv_loss = 0.005584270693361759, Circular Tuning Loss = 1.2139675617218018\n",
      "358) Lyapunov Risk = 1.0782095193862915, MSE = 0.039573993533849716, V_0_loss = tensor([[0.0018]], grad_fn=<PowBackward0>), V_pos_loss = 0.10722025483846664, Lv_loss = 0.005601172801107168, Circular Tuning Loss = 1.2136688232421875\n",
      "359) Lyapunov Risk = 1.0776965618133545, MSE = 0.039430659264326096, V_0_loss = tensor([[0.0018]], grad_fn=<PowBackward0>), V_pos_loss = 0.10711421817541122, Lv_loss = 0.005631082691252232, Circular Tuning Loss = 1.2133710384368896\n",
      "360) Lyapunov Risk = 1.0771825313568115, MSE = 0.03941884636878967, V_0_loss = tensor([[0.0018]], grad_fn=<PowBackward0>), V_pos_loss = 0.10700824111700058, Lv_loss = 0.005574680864810944, Circular Tuning Loss = 1.2130738496780396\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.062500000000000014, -0.061523437500000014]\n",
      "x2 : [0.12402343750000003, 0.12500000000000003]\n",
      "==============================\n",
      "361) Lyapunov Risk = 1.0737688541412354, MSE = 0.03948161005973816, V_0_loss = tensor([[0.0018]], grad_fn=<PowBackward0>), V_pos_loss = 0.10612204670906067, Lv_loss = 0.005431508645415306, Circular Tuning Loss = 1.2040321826934814\n",
      "362) Lyapunov Risk = 1.0732678174972534, MSE = 0.03956739977002144, V_0_loss = tensor([[0.0019]], grad_fn=<PowBackward0>), V_pos_loss = 0.10601712763309479, Lv_loss = 0.005321652628481388, Circular Tuning Loss = 1.203739047050476\n",
      "363) Lyapunov Risk = 1.0727618932724, MSE = 0.03952651470899582, V_0_loss = tensor([[0.0019]], grad_fn=<PowBackward0>), V_pos_loss = 0.10591240972280502, Lv_loss = 0.00529369805008173, Circular Tuning Loss = 1.203446865081787\n",
      "364) Lyapunov Risk = 1.0722624063491821, MSE = 0.03943853825330734, V_0_loss = tensor([[0.0019]], grad_fn=<PowBackward0>), V_pos_loss = 0.10580786317586899, Lv_loss = 0.005298712756484747, Circular Tuning Loss = 1.203155517578125\n",
      "365) Lyapunov Risk = 1.0717650651931763, MSE = 0.03945420682430267, V_0_loss = tensor([[0.0019]], grad_fn=<PowBackward0>), V_pos_loss = 0.1057034432888031, Lv_loss = 0.005240381229668856, Circular Tuning Loss = 1.2028656005859375\n",
      "366) Lyapunov Risk = 1.0712697505950928, MSE = 0.039559464901685715, V_0_loss = tensor([[0.0019]], grad_fn=<PowBackward0>), V_pos_loss = 0.10559918731451035, Lv_loss = 0.005136583000421524, Circular Tuning Loss = 1.2025765180587769\n",
      "367) Lyapunov Risk = 1.0707838535308838, MSE = 0.03961775079369545, V_0_loss = tensor([[0.0019]], grad_fn=<PowBackward0>), V_pos_loss = 0.10549503564834595, Lv_loss = 0.0050693079829216, Circular Tuning Loss = 1.202288269996643\n",
      "368) Lyapunov Risk = 1.0702955722808838, MSE = 0.03953873738646507, V_0_loss = tensor([[0.0019]], grad_fn=<PowBackward0>), V_pos_loss = 0.1053909957408905, Lv_loss = 0.005067951511591673, Circular Tuning Loss = 1.2020010948181152\n",
      "369) Lyapunov Risk = 1.0698134899139404, MSE = 0.03944249823689461, V_0_loss = tensor([[0.0019]], grad_fn=<PowBackward0>), V_pos_loss = 0.10528715699911118, Lv_loss = 0.0050740716978907585, Circular Tuning Loss = 1.2017145156860352\n",
      "370) Lyapunov Risk = 1.0693292617797852, MSE = 0.03942957520484924, V_0_loss = tensor([[0.0019]], grad_fn=<PowBackward0>), V_pos_loss = 0.105183444917202, Lv_loss = 0.00503478292375803, Circular Tuning Loss = 1.2014288902282715\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.40527343750000011, -0.40429687500000011]\n",
      "x2 : [0.48828125000000011, 0.48925781250000011]\n",
      "==============================\n",
      "371) Lyapunov Risk = 1.0676718950271606, MSE = 0.039457716047763824, V_0_loss = tensor([[0.0020]], grad_fn=<PowBackward0>), V_pos_loss = 0.10431903600692749, Lv_loss = 0.004936087876558304, Circular Tuning Loss = 1.1953567266464233\n",
      "372) Lyapunov Risk = 1.067191243171692, MSE = 0.03953429311513901, V_0_loss = tensor([[0.0020]], grad_fn=<PowBackward0>), V_pos_loss = 0.10421581566333771, Lv_loss = 0.0048487838357687, Circular Tuning Loss = 1.1950726509094238\n",
      "373) Lyapunov Risk = 1.0667099952697754, MSE = 0.039482444524765015, V_0_loss = tensor([[0.0020]], grad_fn=<PowBackward0>), V_pos_loss = 0.10411304235458374, Lv_loss = 0.004820346366614103, Circular Tuning Loss = 1.1947894096374512\n",
      "374) Lyapunov Risk = 1.06623113155365, MSE = 0.039303746074438095, V_0_loss = tensor([[0.0020]], grad_fn=<PowBackward0>), V_pos_loss = 0.10401075333356857, Lv_loss = 0.0048580411821603775, Circular Tuning Loss = 1.194507360458374\n",
      "375) Lyapunov Risk = 1.0657540559768677, MSE = 0.03920223191380501, V_0_loss = tensor([[0.0020]], grad_fn=<PowBackward0>), V_pos_loss = 0.10390856862068176, Lv_loss = 0.004864824935793877, Circular Tuning Loss = 1.194225788116455\n",
      "376) Lyapunov Risk = 1.0652774572372437, MSE = 0.03922981768846512, V_0_loss = tensor([[0.0020]], grad_fn=<PowBackward0>), V_pos_loss = 0.10380657017230988, Lv_loss = 0.004793910775333643, Circular Tuning Loss = 1.1939451694488525\n",
      "377) Lyapunov Risk = 1.0648051500320435, MSE = 0.03924606740474701, V_0_loss = tensor([[0.0020]], grad_fn=<PowBackward0>), V_pos_loss = 0.10370466858148575, Lv_loss = 0.004734290298074484, Circular Tuning Loss = 1.1936653852462769\n",
      "378) Lyapunov Risk = 1.0643310546875, MSE = 0.03916322812438011, V_0_loss = tensor([[0.0020]], grad_fn=<PowBackward0>), V_pos_loss = 0.10360287874937057, Lv_loss = 0.00473887799307704, Circular Tuning Loss = 1.1933866739273071\n",
      "379) Lyapunov Risk = 1.0638644695281982, MSE = 0.039075132459402084, V_0_loss = tensor([[0.0020]], grad_fn=<PowBackward0>), V_pos_loss = 0.10350116342306137, Lv_loss = 0.004750935826450586, Circular Tuning Loss = 1.193108081817627\n",
      "380) Lyapunov Risk = 1.063395380973816, MSE = 0.03906331956386566, V_0_loss = tensor([[0.0021]], grad_fn=<PowBackward0>), V_pos_loss = 0.10339951515197754, Lv_loss = 0.0047186133451759815, Circular Tuning Loss = 1.1928304433822632\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.093750000000000028, -0.093261718750000028]\n",
      "x2 : [0.12402343750000003, 0.12500000000000003]\n",
      "==============================\n",
      "381) Lyapunov Risk = 1.06022047996521, MSE = 0.03910234943032265, V_0_loss = tensor([[0.0021]], grad_fn=<PowBackward0>), V_pos_loss = 0.1025548130273819, Lv_loss = 0.004651891998946667, Circular Tuning Loss = 1.1840802431106567\n",
      "382) Lyapunov Risk = 1.0597565174102783, MSE = 0.039201781153678894, V_0_loss = tensor([[0.0021]], grad_fn=<PowBackward0>), V_pos_loss = 0.10245414078235626, Lv_loss = 0.004561631940305233, Circular Tuning Loss = 1.1838059425354004\n",
      "383) Lyapunov Risk = 1.0592896938323975, MSE = 0.03919845446944237, V_0_loss = tensor([[0.0021]], grad_fn=<PowBackward0>), V_pos_loss = 0.10235361009836197, Lv_loss = 0.0045438725501298904, Circular Tuning Loss = 1.1835325956344604\n",
      "384) Lyapunov Risk = 1.0588289499282837, MSE = 0.03914914280176163, V_0_loss = tensor([[0.0021]], grad_fn=<PowBackward0>), V_pos_loss = 0.10225320607423782, Lv_loss = 0.004553215578198433, Circular Tuning Loss = 1.183260440826416\n",
      "385) Lyapunov Risk = 1.0583703517913818, MSE = 0.039160288870334625, V_0_loss = tensor([[0.0021]], grad_fn=<PowBackward0>), V_pos_loss = 0.10215293616056442, Lv_loss = 0.004529474303126335, Circular Tuning Loss = 1.1829888820648193\n",
      "386) Lyapunov Risk = 1.0579171180725098, MSE = 0.03922351822257042, V_0_loss = tensor([[0.0021]], grad_fn=<PowBackward0>), V_pos_loss = 0.10205277800559998, Lv_loss = 0.004475690890103579, Circular Tuning Loss = 1.1827181577682495\n",
      "387) Lyapunov Risk = 1.0574671030044556, MSE = 0.0392606221139431, V_0_loss = tensor([[0.0021]], grad_fn=<PowBackward0>), V_pos_loss = 0.10195271670818329, Lv_loss = 0.004430755972862244, Circular Tuning Loss = 1.182448148727417\n",
      "388) Lyapunov Risk = 1.0570160150527954, MSE = 0.03923191875219345, V_0_loss = tensor([[0.0021]], grad_fn=<PowBackward0>), V_pos_loss = 0.10185276716947556, Lv_loss = 0.004412171896547079, Circular Tuning Loss = 1.1821790933609009\n",
      "389) Lyapunov Risk = 1.0565683841705322, MSE = 0.03916628286242485, V_0_loss = tensor([[0.0021]], grad_fn=<PowBackward0>), V_pos_loss = 0.10175290703773499, Lv_loss = 0.004405569285154343, Circular Tuning Loss = 1.1819102764129639\n",
      "390) Lyapunov Risk = 1.056119441986084, MSE = 0.039130985736846924, V_0_loss = tensor([[0.0022]], grad_fn=<PowBackward0>), V_pos_loss = 0.10165321081876755, Lv_loss = 0.004378031939268112, Circular Tuning Loss = 1.1816425323486328\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.093750000000000028, -0.093261718750000028]\n",
      "x2 : [0.12402343750000003, 0.12500000000000003]\n",
      "==============================\n",
      "391) Lyapunov Risk = 1.0530091524124146, MSE = 0.03909602016210556, V_0_loss = tensor([[0.0022]], grad_fn=<PowBackward0>), V_pos_loss = 0.10082833468914032, Lv_loss = 0.004323242697864771, Circular Tuning Loss = 1.1730403900146484\n",
      "392) Lyapunov Risk = 1.052567958831787, MSE = 0.039120446890592575, V_0_loss = tensor([[0.0022]], grad_fn=<PowBackward0>), V_pos_loss = 0.1007298156619072, Lv_loss = 0.004267694428563118, Circular Tuning Loss = 1.1727758646011353\n",
      "393) Lyapunov Risk = 1.0521255731582642, MSE = 0.039101965725421906, V_0_loss = tensor([[0.0022]], grad_fn=<PowBackward0>), V_pos_loss = 0.10063145309686661, Lv_loss = 0.004241079092025757, Circular Tuning Loss = 1.172512173652649\n",
      "394) Lyapunov Risk = 1.0516852140426636, MSE = 0.03904340788722038, V_0_loss = tensor([[0.0022]], grad_fn=<PowBackward0>), V_pos_loss = 0.10053320974111557, Lv_loss = 0.0042406413704156876, Circular Tuning Loss = 1.1722497940063477\n",
      "395) Lyapunov Risk = 1.0512454509735107, MSE = 0.039020732045173645, V_0_loss = tensor([[0.0022]], grad_fn=<PowBackward0>), V_pos_loss = 0.10043506324291229, Lv_loss = 0.00422630924731493, Circular Tuning Loss = 1.1719880104064941\n",
      "396) Lyapunov Risk = 1.0508073568344116, MSE = 0.0390399731695652, V_0_loss = tensor([[0.0022]], grad_fn=<PowBackward0>), V_pos_loss = 0.10033703595399857, Lv_loss = 0.004197162110358477, Circular Tuning Loss = 1.1717270612716675\n",
      "397) Lyapunov Risk = 1.0503718852996826, MSE = 0.0390574149787426, V_0_loss = tensor([[0.0022]], grad_fn=<PowBackward0>), V_pos_loss = 0.1002391055226326, Lv_loss = 0.0041737426072359085, Circular Tuning Loss = 1.1714669466018677\n",
      "398) Lyapunov Risk = 1.0499356985092163, MSE = 0.039041630923748016, V_0_loss = tensor([[0.0022]], grad_fn=<PowBackward0>), V_pos_loss = 0.10014127194881439, Lv_loss = 0.004164970945566893, Circular Tuning Loss = 1.1712076663970947\n",
      "399) Lyapunov Risk = 1.0495017766952515, MSE = 0.03901973366737366, V_0_loss = tensor([[0.0022]], grad_fn=<PowBackward0>), V_pos_loss = 0.10004352033138275, Lv_loss = 0.004156691022217274, Circular Tuning Loss = 1.17094886302948\n",
      "400) Lyapunov Risk = 1.0490680932998657, MSE = 0.03901730477809906, V_0_loss = tensor([[0.0023]], grad_fn=<PowBackward0>), V_pos_loss = 0.09994587302207947, Lv_loss = 0.004137157928198576, Circular Tuning Loss = 1.170690894126892\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.12500000000000003, -0.12451171875000003]\n",
      "x2 : [0.12402343750000003, 0.12500000000000003]\n",
      "==============================\n",
      "401) Lyapunov Risk = 1.0460262298583984, MSE = 0.0389983169734478, V_0_loss = tensor([[0.0023]], grad_fn=<PowBackward0>), V_pos_loss = 0.09914013743400574, Lv_loss = 0.004091162234544754, Circular Tuning Loss = 1.1622464656829834\n",
      "402) Lyapunov Risk = 1.0455963611602783, MSE = 0.039029791951179504, V_0_loss = tensor([[0.0023]], grad_fn=<PowBackward0>), V_pos_loss = 0.09904340654611588, Lv_loss = 0.004059421364217997, Circular Tuning Loss = 1.1619917154312134\n",
      "403) Lyapunov Risk = 1.045166254043579, MSE = 0.03904125466942787, V_0_loss = tensor([[0.0023]], grad_fn=<PowBackward0>), V_pos_loss = 0.09894681721925735, Lv_loss = 0.004037636797875166, Circular Tuning Loss = 1.1617379188537598\n",
      "404) Lyapunov Risk = 1.0447384119033813, MSE = 0.03902429714798927, V_0_loss = tensor([[0.0023]], grad_fn=<PowBackward0>), V_pos_loss = 0.09885050356388092, Lv_loss = 0.0040281848050653934, Circular Tuning Loss = 1.161484956741333\n",
      "405) Lyapunov Risk = 1.0443116426467896, MSE = 0.03903121128678322, V_0_loss = tensor([[0.0023]], grad_fn=<PowBackward0>), V_pos_loss = 0.09875433146953583, Lv_loss = 0.004011659882962704, Circular Tuning Loss = 1.1612329483032227\n",
      "406) Lyapunov Risk = 1.0438860654830933, MSE = 0.03906402736902237, V_0_loss = tensor([[0.0023]], grad_fn=<PowBackward0>), V_pos_loss = 0.09865826368331909, Lv_loss = 0.00398620730265975, Circular Tuning Loss = 1.1609817743301392\n",
      "407) Lyapunov Risk = 1.0434625148773193, MSE = 0.03908354416489601, V_0_loss = tensor([[0.0023]], grad_fn=<PowBackward0>), V_pos_loss = 0.0985623225569725, Lv_loss = 0.003965879790484905, Circular Tuning Loss = 1.160731315612793\n",
      "408) Lyapunov Risk = 1.0430386066436768, MSE = 0.039060913026332855, V_0_loss = tensor([[0.0023]], grad_fn=<PowBackward0>), V_pos_loss = 0.09846649318933487, Lv_loss = 0.00395977171137929, Circular Tuning Loss = 1.1604818105697632\n",
      "409) Lyapunov Risk = 1.0426169633865356, MSE = 0.03902755677700043, V_0_loss = tensor([[0.0023]], grad_fn=<PowBackward0>), V_pos_loss = 0.09837077558040619, Lv_loss = 0.003955597523599863, Circular Tuning Loss = 1.1602329015731812\n",
      "410) Lyapunov Risk = 1.042196273803711, MSE = 0.03900626301765442, V_0_loss = tensor([[0.0024]], grad_fn=<PowBackward0>), V_pos_loss = 0.09827516227960587, Lv_loss = 0.003945100586861372, Circular Tuning Loss = 1.1599847078323364\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.37548828125000011, -0.37500000000000011]\n",
      "x2 : [0.43750000000000011, 0.43847656250000011]\n",
      "==============================\n",
      "411) Lyapunov Risk = 1.040503740310669, MSE = 0.038989439606666565, V_0_loss = tensor([[0.0024]], grad_fn=<PowBackward0>), V_pos_loss = 0.09748820960521698, Lv_loss = 0.0039158775471150875, Circular Tuning Loss = 1.1537624597549438\n",
      "412) Lyapunov Risk = 1.040081262588501, MSE = 0.03908232972025871, V_0_loss = tensor([[0.0024]], grad_fn=<PowBackward0>), V_pos_loss = 0.09739350527524948, Lv_loss = 0.0038488763384521008, Circular Tuning Loss = 1.1535159349441528\n",
      "413) Lyapunov Risk = 1.039660930633545, MSE = 0.03908202797174454, V_0_loss = tensor([[0.0024]], grad_fn=<PowBackward0>), V_pos_loss = 0.09729891270399094, Lv_loss = 0.003820694051682949, Circular Tuning Loss = 1.1532702445983887\n",
      "414) Lyapunov Risk = 1.0392379760742188, MSE = 0.038947694003582, V_0_loss = tensor([[0.0024]], grad_fn=<PowBackward0>), V_pos_loss = 0.09720446914434433, Lv_loss = 0.0038379463367164135, Circular Tuning Loss = 1.1530251502990723\n",
      "415) Lyapunov Risk = 1.038818597793579, MSE = 0.038843292742967606, V_0_loss = tensor([[0.0024]], grad_fn=<PowBackward0>), V_pos_loss = 0.09711011499166489, Lv_loss = 0.0038432611618191004, Circular Tuning Loss = 1.1527806520462036\n",
      "416) Lyapunov Risk = 1.038396954536438, MSE = 0.03886416554450989, V_0_loss = tensor([[0.0024]], grad_fn=<PowBackward0>), V_pos_loss = 0.0970158725976944, Lv_loss = 0.0038055432960391045, Circular Tuning Loss = 1.1525367498397827\n",
      "417) Lyapunov Risk = 1.0379793643951416, MSE = 0.03891502693295479, V_0_loss = tensor([[0.0024]], grad_fn=<PowBackward0>), V_pos_loss = 0.09692171216011047, Lv_loss = 0.0037619275972247124, Circular Tuning Loss = 1.1522936820983887\n",
      "418) Lyapunov Risk = 1.0375595092773438, MSE = 0.038878750056028366, V_0_loss = tensor([[0.0024]], grad_fn=<PowBackward0>), V_pos_loss = 0.09682762622833252, Lv_loss = 0.0037512900307774544, Circular Tuning Loss = 1.1520508527755737\n",
      "419) Lyapunov Risk = 1.0371423959732056, MSE = 0.03879760578274727, V_0_loss = tensor([[0.0024]], grad_fn=<PowBackward0>), V_pos_loss = 0.09673362225294113, Lv_loss = 0.0037597469054162502, Circular Tuning Loss = 1.1518086194992065\n",
      "420) Lyapunov Risk = 1.0367236137390137, MSE = 0.03877606615424156, V_0_loss = tensor([[0.0024]], grad_fn=<PowBackward0>), V_pos_loss = 0.09663970023393631, Lv_loss = 0.0037505244836211205, Circular Tuning Loss = 1.1515668630599976\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.033203125000000014, -0.031250000000000007]\n",
      "x2 : [0.15625000000000006, 0.16015625000000006]\n",
      "==============================\n",
      "421) Lyapunov Risk = 1.0339699983596802, MSE = 0.03881039842963219, V_0_loss = tensor([[0.0025]], grad_fn=<PowBackward0>), V_pos_loss = 0.0958707258105278, Lv_loss = 0.003809456480666995, Circular Tuning Loss = 1.1434524059295654\n",
      "422) Lyapunov Risk = 1.0335551500320435, MSE = 0.03892047703266144, V_0_loss = tensor([[0.0025]], grad_fn=<PowBackward0>), V_pos_loss = 0.09577774256467819, Lv_loss = 0.003762147855013609, Circular Tuning Loss = 1.1432133913040161\n",
      "423) Lyapunov Risk = 1.0331387519836426, MSE = 0.038947585970163345, V_0_loss = tensor([[0.0025]], grad_fn=<PowBackward0>), V_pos_loss = 0.09568488597869873, Lv_loss = 0.003750924486666918, Circular Tuning Loss = 1.1429752111434937\n",
      "424) Lyapunov Risk = 1.0327259302139282, MSE = 0.03891215845942497, V_0_loss = tensor([[0.0025]], grad_fn=<PowBackward0>), V_pos_loss = 0.09559216350317001, Lv_loss = 0.0037649867590516806, Circular Tuning Loss = 1.142737627029419\n",
      "425) Lyapunov Risk = 1.032313346862793, MSE = 0.03893258050084114, V_0_loss = tensor([[0.0025]], grad_fn=<PowBackward0>), V_pos_loss = 0.09549955278635025, Lv_loss = 0.0037554369773715734, Circular Tuning Loss = 1.142500638961792\n",
      "426) Lyapunov Risk = 1.031903624534607, MSE = 0.03901676461100578, V_0_loss = tensor([[0.0025]], grad_fn=<PowBackward0>), V_pos_loss = 0.09540706127882004, Lv_loss = 0.0037174834869802, Circular Tuning Loss = 1.1422643661499023\n",
      "427) Lyapunov Risk = 1.031495451927185, MSE = 0.03907955810427666, V_0_loss = tensor([[0.0025]], grad_fn=<PowBackward0>), V_pos_loss = 0.09531466662883759, Lv_loss = 0.0036811211612075567, Circular Tuning Loss = 1.142028570175171\n",
      "428) Lyapunov Risk = 1.03108549118042, MSE = 0.03904261067509651, V_0_loss = tensor([[0.0025]], grad_fn=<PowBackward0>), V_pos_loss = 0.09522239863872528, Lv_loss = 0.0036752086598426104, Circular Tuning Loss = 1.1417933702468872\n",
      "429) Lyapunov Risk = 1.0306777954101562, MSE = 0.03896896913647652, V_0_loss = tensor([[0.0025]], grad_fn=<PowBackward0>), V_pos_loss = 0.09513020515441895, Lv_loss = 0.0036764340475201607, Circular Tuning Loss = 1.1415587663650513\n",
      "430) Lyapunov Risk = 1.030268907546997, MSE = 0.03891349956393242, V_0_loss = tensor([[0.0025]], grad_fn=<PowBackward0>), V_pos_loss = 0.09503819048404694, Lv_loss = 0.003664845135062933, Circular Tuning Loss = 1.1413246393203735\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.12500000000000003, -0.12109375000000003]\n",
      "x2 : [0.24609375000000006, 0.25000000000000006]\n",
      "==============================\n",
      "431) Lyapunov Risk = 1.0284881591796875, MSE = 0.038820985704660416, V_0_loss = tensor([[0.0025]], grad_fn=<PowBackward0>), V_pos_loss = 0.09428694099187851, Lv_loss = 0.004298220854252577, Circular Tuning Loss = 1.1336922645568848\n",
      "432) Lyapunov Risk = 1.0280882120132446, MSE = 0.038838647305965424, V_0_loss = tensor([[0.0025]], grad_fn=<PowBackward0>), V_pos_loss = 0.09419581294059753, Lv_loss = 0.004256392829120159, Circular Tuning Loss = 1.133460521697998\n",
      "433) Lyapunov Risk = 1.0276869535446167, MSE = 0.03876640647649765, V_0_loss = tensor([[0.0026]], grad_fn=<PowBackward0>), V_pos_loss = 0.09410473704338074, Lv_loss = 0.004257583525031805, Circular Tuning Loss = 1.1332296133041382\n",
      "434) Lyapunov Risk = 1.02729070186615, MSE = 0.03868415951728821, V_0_loss = tensor([[0.0026]], grad_fn=<PowBackward0>), V_pos_loss = 0.0940137654542923, Lv_loss = 0.004267798271030188, Circular Tuning Loss = 1.1329995393753052\n",
      "435) Lyapunov Risk = 1.0268908739089966, MSE = 0.038727693259716034, V_0_loss = tensor([[0.0026]], grad_fn=<PowBackward0>), V_pos_loss = 0.09392295777797699, Lv_loss = 0.0042271120473742485, Circular Tuning Loss = 1.13277006149292\n",
      "436) Lyapunov Risk = 1.026497721672058, MSE = 0.03877308964729309, V_0_loss = tensor([[0.0026]], grad_fn=<PowBackward0>), V_pos_loss = 0.09383221715688705, Lv_loss = 0.004189755767583847, Circular Tuning Loss = 1.132541537284851\n",
      "437) Lyapunov Risk = 1.026103138923645, MSE = 0.03872989863157272, V_0_loss = tensor([[0.0026]], grad_fn=<PowBackward0>), V_pos_loss = 0.0937415212392807, Lv_loss = 0.0041910698637366295, Circular Tuning Loss = 1.13231360912323\n",
      "438) Lyapunov Risk = 1.025712013244629, MSE = 0.03867634758353233, V_0_loss = tensor([[0.0026]], grad_fn=<PowBackward0>), V_pos_loss = 0.09365088492631912, Lv_loss = 0.004195762798190117, Circular Tuning Loss = 1.1320860385894775\n",
      "439) Lyapunov Risk = 1.025322675704956, MSE = 0.03868499770760536, V_0_loss = tensor([[0.0026]], grad_fn=<PowBackward0>), V_pos_loss = 0.09356031566858292, Lv_loss = 0.004171550739556551, Circular Tuning Loss = 1.131859540939331\n",
      "440) Lyapunov Risk = 1.0249347686767578, MSE = 0.03870846703648567, V_0_loss = tensor([[0.0026]], grad_fn=<PowBackward0>), V_pos_loss = 0.0934697687625885, Lv_loss = 0.0041387067176401615, Circular Tuning Loss = 1.1316332817077637\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.9843750000000004, -1.9765625000000004]\n",
      "x2 : [0, 0.0067658234670659274]\n",
      "==============================\n",
      "441) Lyapunov Risk = 1.0279998779296875, MSE = 0.03867337852716446, V_0_loss = tensor([[0.0026]], grad_fn=<PowBackward0>), V_pos_loss = 0.09273526817560196, Lv_loss = 0.004100274760276079, Circular Tuning Loss = 1.1370692253112793\n",
      "442) Lyapunov Risk = 1.0276190042495728, MSE = 0.03856435418128967, V_0_loss = tensor([[0.0026]], grad_fn=<PowBackward0>), V_pos_loss = 0.0926455408334732, Lv_loss = 0.00412127235904336, Circular Tuning Loss = 1.1368484497070312\n",
      "443) Lyapunov Risk = 1.0272399187088013, MSE = 0.03849378973245621, V_0_loss = tensor([[0.0026]], grad_fn=<PowBackward0>), V_pos_loss = 0.0925559550523758, Lv_loss = 0.00412590941414237, Circular Tuning Loss = 1.1366279125213623\n",
      "444) Lyapunov Risk = 1.0268634557724, MSE = 0.03848943114280701, V_0_loss = tensor([[0.0026]], grad_fn=<PowBackward0>), V_pos_loss = 0.09246649593114853, Lv_loss = 0.004104193300008774, Circular Tuning Loss = 1.1364079713821411\n",
      "445) Lyapunov Risk = 1.0264902114868164, MSE = 0.0384647436439991, V_0_loss = tensor([[0.0027]], grad_fn=<PowBackward0>), V_pos_loss = 0.09237711876630783, Lv_loss = 0.0040909890085458755, Circular Tuning Loss = 1.1361886262893677\n",
      "446) Lyapunov Risk = 1.0261170864105225, MSE = 0.03837266191840172, V_0_loss = tensor([[0.0027]], grad_fn=<PowBackward0>), V_pos_loss = 0.09228786081075668, Lv_loss = 0.004106472712010145, Circular Tuning Loss = 1.135969638824463\n",
      "447) Lyapunov Risk = 1.0257456302642822, MSE = 0.03831186518073082, V_0_loss = tensor([[0.0027]], grad_fn=<PowBackward0>), V_pos_loss = 0.09219866245985031, Lv_loss = 0.004110998939722776, Circular Tuning Loss = 1.1357511281967163\n",
      "448) Lyapunov Risk = 1.0253735780715942, MSE = 0.038341231644153595, V_0_loss = tensor([[0.0027]], grad_fn=<PowBackward0>), V_pos_loss = 0.0921095609664917, Lv_loss = 0.004080208018422127, Circular Tuning Loss = 1.1355328559875488\n",
      "449) Lyapunov Risk = 1.025003433227539, MSE = 0.03838546201586723, V_0_loss = tensor([[0.0027]], grad_fn=<PowBackward0>), V_pos_loss = 0.09202052652835846, Lv_loss = 0.0040451460517942905, Circular Tuning Loss = 1.1353150606155396\n",
      "450) Lyapunov Risk = 1.0246336460113525, MSE = 0.038367271423339844, V_0_loss = tensor([[0.0027]], grad_fn=<PowBackward0>), V_pos_loss = 0.09193157404661179, Lv_loss = 0.004036844242364168, Circular Tuning Loss = 1.1350977420806885\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.9609375000000004, -1.9531250000000004]\n",
      "x2 : [0, 0.0067658234670659274]\n",
      "==============================\n",
      "451) Lyapunov Risk = 1.0275163650512695, MSE = 0.03832346573472023, V_0_loss = tensor([[0.0027]], grad_fn=<PowBackward0>), V_pos_loss = 0.09121361374855042, Lv_loss = 0.004011848941445351, Circular Tuning Loss = 1.1401309967041016\n",
      "452) Lyapunov Risk = 1.0271525382995605, MSE = 0.038294047117233276, V_0_loss = tensor([[0.0027]], grad_fn=<PowBackward0>), V_pos_loss = 0.0911254957318306, Lv_loss = 0.004009537864476442, Circular Tuning Loss = 1.1399184465408325\n",
      "453) Lyapunov Risk = 1.026788353919983, MSE = 0.038289543241262436, V_0_loss = tensor([[0.0027]], grad_fn=<PowBackward0>), V_pos_loss = 0.09103753417730331, Lv_loss = 0.003996442537754774, Circular Tuning Loss = 1.139706015586853\n",
      "454) Lyapunov Risk = 1.0264256000518799, MSE = 0.038262151181697845, V_0_loss = tensor([[0.0027]], grad_fn=<PowBackward0>), V_pos_loss = 0.09094969928264618, Lv_loss = 0.00399181991815567, Circular Tuning Loss = 1.1394940614700317\n",
      "455) Lyapunov Risk = 1.0260653495788574, MSE = 0.03815683349967003, V_0_loss = tensor([[0.0027]], grad_fn=<PowBackward0>), V_pos_loss = 0.09086195379495621, Lv_loss = 0.004017222207039595, Circular Tuning Loss = 1.1392823457717896\n",
      "456) Lyapunov Risk = 1.0257065296173096, MSE = 0.0381137952208519, V_0_loss = tensor([[0.0027]], grad_fn=<PowBackward0>), V_pos_loss = 0.09077433496713638, Lv_loss = 0.004013580270111561, Circular Tuning Loss = 1.1390708684921265\n",
      "457) Lyapunov Risk = 1.0253480672836304, MSE = 0.038082756102085114, V_0_loss = tensor([[0.0027]], grad_fn=<PowBackward0>), V_pos_loss = 0.09068680554628372, Lv_loss = 0.004001249559223652, Circular Tuning Loss = 1.138859748840332\n",
      "458) Lyapunov Risk = 1.0249890089035034, MSE = 0.03804749622941017, V_0_loss = tensor([[0.0028]], grad_fn=<PowBackward0>), V_pos_loss = 0.09059934318065643, Lv_loss = 0.0039877076633274555, Circular Tuning Loss = 1.1386487483978271\n",
      "459) Lyapunov Risk = 1.0246297121047974, MSE = 0.03801877051591873, V_0_loss = tensor([[0.0028]], grad_fn=<PowBackward0>), V_pos_loss = 0.09051194041967392, Lv_loss = 0.0039709266275167465, Circular Tuning Loss = 1.1384382247924805\n",
      "460) Lyapunov Risk = 1.0242719650268555, MSE = 0.03800471872091293, V_0_loss = tensor([[0.0028]], grad_fn=<PowBackward0>), V_pos_loss = 0.09042459726333618, Lv_loss = 0.003949201200157404, Circular Tuning Loss = 1.1382277011871338\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.9531250000000004, -1.9453125000000004]\n",
      "x2 : [0, 0.0067658234670659274]\n",
      "==============================\n",
      "461) Lyapunov Risk = 1.0270694494247437, MSE = 0.03795484080910683, V_0_loss = tensor([[0.0028]], grad_fn=<PowBackward0>), V_pos_loss = 0.08972274512052536, Lv_loss = 0.003915761131793261, Circular Tuning Loss = 1.1430764198303223\n",
      "462) Lyapunov Risk = 1.0267165899276733, MSE = 0.037988267838954926, V_0_loss = tensor([[0.0028]], grad_fn=<PowBackward0>), V_pos_loss = 0.08963625878095627, Lv_loss = 0.0038783038035035133, Circular Tuning Loss = 1.142870306968689\n",
      "463) Lyapunov Risk = 1.0263609886169434, MSE = 0.03790944069623947, V_0_loss = tensor([[0.0028]], grad_fn=<PowBackward0>), V_pos_loss = 0.08954992145299911, Lv_loss = 0.003887760452926159, Circular Tuning Loss = 1.1426644325256348\n",
      "464) Lyapunov Risk = 1.0260077714920044, MSE = 0.03782648220658302, V_0_loss = tensor([[0.0028]], grad_fn=<PowBackward0>), V_pos_loss = 0.08946368098258972, Lv_loss = 0.003899861592799425, Circular Tuning Loss = 1.1424589157104492\n",
      "465) Lyapunov Risk = 1.0256562232971191, MSE = 0.03789312765002251, V_0_loss = tensor([[0.0028]], grad_fn=<PowBackward0>), V_pos_loss = 0.08937756717205048, Lv_loss = 0.0038525587879121304, Circular Tuning Loss = 1.1422536373138428\n",
      "466) Lyapunov Risk = 1.0253033638000488, MSE = 0.03778174892067909, V_0_loss = tensor([[0.0028]], grad_fn=<PowBackward0>), V_pos_loss = 0.0892915204167366, Lv_loss = 0.0038721784949302673, Circular Tuning Loss = 1.1420483589172363\n",
      "467) Lyapunov Risk = 1.0249561071395874, MSE = 0.037679169327020645, V_0_loss = tensor([[0.0028]], grad_fn=<PowBackward0>), V_pos_loss = 0.08920552581548691, Lv_loss = 0.0038841734640300274, Circular Tuning Loss = 1.1418434381484985\n",
      "468) Lyapunov Risk = 1.0246045589447021, MSE = 0.037775296717882156, V_0_loss = tensor([[0.0028]], grad_fn=<PowBackward0>), V_pos_loss = 0.08911963552236557, Lv_loss = 0.003813517512753606, Circular Tuning Loss = 1.1416386365890503\n",
      "469) Lyapunov Risk = 1.0242516994476318, MSE = 0.037739355117082596, V_0_loss = tensor([[0.0028]], grad_fn=<PowBackward0>), V_pos_loss = 0.0890338122844696, Lv_loss = 0.0037934030406177044, Circular Tuning Loss = 1.1414343118667603\n",
      "470) Lyapunov Risk = 1.0239027738571167, MSE = 0.03764506056904793, V_0_loss = tensor([[0.0029]], grad_fn=<PowBackward0>), V_pos_loss = 0.08894800394773483, Lv_loss = 0.0037958002649247646, Circular Tuning Loss = 1.1412298679351807\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.9687500000000004, -1.9609375000000004]\n",
      "x2 : [0, 0.0067658234670659274]\n",
      "==============================\n",
      "471) Lyapunov Risk = 1.0268194675445557, MSE = 0.037747543305158615, V_0_loss = tensor([[0.0029]], grad_fn=<PowBackward0>), V_pos_loss = 0.08826186507940292, Lv_loss = 0.003695607418194413, Circular Tuning Loss = 1.1463184356689453\n",
      "472) Lyapunov Risk = 1.0264722108840942, MSE = 0.03773558884859085, V_0_loss = tensor([[0.0029]], grad_fn=<PowBackward0>), V_pos_loss = 0.08817689120769501, Lv_loss = 0.0036716468166559935, Circular Tuning Loss = 1.146118402481079\n",
      "473) Lyapunov Risk = 1.026124358177185, MSE = 0.03761694207787514, V_0_loss = tensor([[0.0029]], grad_fn=<PowBackward0>), V_pos_loss = 0.08809205144643784, Lv_loss = 0.0036938684061169624, Circular Tuning Loss = 1.1459184885025024\n",
      "474) Lyapunov Risk = 1.0257717370986938, MSE = 0.03765495866537094, V_0_loss = tensor([[0.0029]], grad_fn=<PowBackward0>), V_pos_loss = 0.08800742775201797, Lv_loss = 0.003659432288259268, Circular Tuning Loss = 1.1457186937332153\n",
      "475) Lyapunov Risk = 1.0254275798797607, MSE = 0.037705276161432266, V_0_loss = tensor([[0.0029]], grad_fn=<PowBackward0>), V_pos_loss = 0.08792302012443542, Lv_loss = 0.0036224513314664364, Circular Tuning Loss = 1.1455191373825073\n",
      "476) Lyapunov Risk = 1.0250803232192993, MSE = 0.03751765564084053, V_0_loss = tensor([[0.0029]], grad_fn=<PowBackward0>), V_pos_loss = 0.08783870190382004, Lv_loss = 0.0036733653396368027, Circular Tuning Loss = 1.1453197002410889\n",
      "477) Lyapunov Risk = 1.0247323513031006, MSE = 0.037535153329372406, V_0_loss = tensor([[0.0029]], grad_fn=<PowBackward0>), V_pos_loss = 0.0877545103430748, Lv_loss = 0.003644244046881795, Circular Tuning Loss = 1.145120620727539\n",
      "478) Lyapunov Risk = 1.0243899822235107, MSE = 0.037615612149238586, V_0_loss = tensor([[0.0029]], grad_fn=<PowBackward0>), V_pos_loss = 0.08767041563987732, Lv_loss = 0.0035890541039407253, Circular Tuning Loss = 1.1449215412139893\n",
      "479) Lyapunov Risk = 1.0240402221679688, MSE = 0.037483081221580505, V_0_loss = tensor([[0.0029]], grad_fn=<PowBackward0>), V_pos_loss = 0.08758639544248581, Lv_loss = 0.003614801215007901, Circular Tuning Loss = 1.144722819328308\n",
      "480) Lyapunov Risk = 1.0236937999725342, MSE = 0.03746738284826279, V_0_loss = tensor([[0.0029]], grad_fn=<PowBackward0>), V_pos_loss = 0.08750245720148087, Lv_loss = 0.0035921300295740366, Circular Tuning Loss = 1.1445242166519165\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.062500000000000014, -0.062011718750000014]\n",
      "x2 : [0.12402343750000003, 0.12500000000000003]\n",
      "==============================\n",
      "481) Lyapunov Risk = 1.0209472179412842, MSE = 0.03758428618311882, V_0_loss = tensor([[0.0029]], grad_fn=<PowBackward0>), V_pos_loss = 0.08683191239833832, Lv_loss = 0.0034928859677165747, Circular Tuning Loss = 1.1367204189300537\n",
      "482) Lyapunov Risk = 1.0206000804901123, MSE = 0.03758179768919945, V_0_loss = tensor([[0.0029]], grad_fn=<PowBackward0>), V_pos_loss = 0.08674874901771545, Lv_loss = 0.003470173105597496, Circular Tuning Loss = 1.136523962020874\n",
      "483) Lyapunov Risk = 1.0202586650848389, MSE = 0.03752077743411064, V_0_loss = tensor([[0.0030]], grad_fn=<PowBackward0>), V_pos_loss = 0.08666573464870453, Lv_loss = 0.0034738490357995033, Circular Tuning Loss = 1.1363279819488525\n",
      "484) Lyapunov Risk = 1.0199118852615356, MSE = 0.037683989852666855, V_0_loss = tensor([[0.0030]], grad_fn=<PowBackward0>), V_pos_loss = 0.08658291399478912, Lv_loss = 0.003403358394280076, Circular Tuning Loss = 1.1361325979232788\n",
      "485) Lyapunov Risk = 1.0195696353912354, MSE = 0.03772193193435669, V_0_loss = tensor([[0.0030]], grad_fn=<PowBackward0>), V_pos_loss = 0.08650018274784088, Lv_loss = 0.0033829682506620884, Circular Tuning Loss = 1.1359374523162842\n",
      "486) Lyapunov Risk = 1.0192302465438843, MSE = 0.037643030285835266, V_0_loss = tensor([[0.0030]], grad_fn=<PowBackward0>), V_pos_loss = 0.08641752600669861, Lv_loss = 0.003405899042263627, Circular Tuning Loss = 1.1357427835464478\n",
      "487) Lyapunov Risk = 1.0188862085342407, MSE = 0.037742290645837784, V_0_loss = tensor([[0.0030]], grad_fn=<PowBackward0>), V_pos_loss = 0.08633499592542648, Lv_loss = 0.003367237513884902, Circular Tuning Loss = 1.1355488300323486\n",
      "488) Lyapunov Risk = 1.0185484886169434, MSE = 0.037789225578308105, V_0_loss = tensor([[0.0030]], grad_fn=<PowBackward0>), V_pos_loss = 0.08625255525112152, Lv_loss = 0.0033451777417212725, Circular Tuning Loss = 1.1353552341461182\n",
      "489) Lyapunov Risk = 1.0182080268859863, MSE = 0.03762553259730339, V_0_loss = tensor([[0.0030]], grad_fn=<PowBackward0>), V_pos_loss = 0.08617018908262253, Lv_loss = 0.0033925350289791822, Circular Tuning Loss = 1.135162115097046\n",
      "490) Lyapunov Risk = 1.0178653001785278, MSE = 0.0376463383436203, V_0_loss = tensor([[0.0030]], grad_fn=<PowBackward0>), V_pos_loss = 0.0860878974199295, Lv_loss = 0.00337199866771698, Circular Tuning Loss = 1.1349692344665527\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.062500000000000014, -0.062011718750000014]\n",
      "x2 : [0.12402343750000003, 0.12500000000000003]\n",
      "==============================\n",
      "491) Lyapunov Risk = 1.0151633024215698, MSE = 0.03770362585783005, V_0_loss = tensor([[0.0030]], grad_fn=<PowBackward0>), V_pos_loss = 0.08543229848146439, Lv_loss = 0.003313131630420685, Circular Tuning Loss = 1.127284049987793\n",
      "492) Lyapunov Risk = 1.0148212909698486, MSE = 0.03760045766830444, V_0_loss = tensor([[0.0030]], grad_fn=<PowBackward0>), V_pos_loss = 0.08535070717334747, Lv_loss = 0.0033305136021226645, Circular Tuning Loss = 1.1270934343338013\n",
      "493) Lyapunov Risk = 1.0144836902618408, MSE = 0.03755708783864975, V_0_loss = tensor([[0.0030]], grad_fn=<PowBackward0>), V_pos_loss = 0.08526922017335892, Lv_loss = 0.0033289671409875154, Circular Tuning Loss = 1.1269034147262573\n",
      "494) Lyapunov Risk = 1.0141457319259644, MSE = 0.03772883862257004, V_0_loss = tensor([[0.0030]], grad_fn=<PowBackward0>), V_pos_loss = 0.08518783748149872, Lv_loss = 0.003259390126913786, Circular Tuning Loss = 1.1267139911651611\n",
      "495) Lyapunov Risk = 1.0138047933578491, MSE = 0.03766193240880966, V_0_loss = tensor([[0.0030]], grad_fn=<PowBackward0>), V_pos_loss = 0.08510652929544449, Lv_loss = 0.003271491266787052, Circular Tuning Loss = 1.1265252828598022\n",
      "496) Lyapunov Risk = 1.0134732723236084, MSE = 0.037606220692396164, V_0_loss = tensor([[0.0030]], grad_fn=<PowBackward0>), V_pos_loss = 0.08502529561519623, Lv_loss = 0.003283109748736024, Circular Tuning Loss = 1.1263370513916016\n",
      "497) Lyapunov Risk = 1.0131365060806274, MSE = 0.03779532387852669, V_0_loss = tensor([[0.0031]], grad_fn=<PowBackward0>), V_pos_loss = 0.0849442407488823, Lv_loss = 0.003216613782569766, Circular Tuning Loss = 1.126149296760559\n",
      "498) Lyapunov Risk = 1.012796401977539, MSE = 0.03773051127791405, V_0_loss = tensor([[0.0031]], grad_fn=<PowBackward0>), V_pos_loss = 0.08486324548721313, Lv_loss = 0.003233986208215356, Circular Tuning Loss = 1.1259620189666748\n",
      "499) Lyapunov Risk = 1.0124629735946655, MSE = 0.037642933428287506, V_0_loss = tensor([[0.0031]], grad_fn=<PowBackward0>), V_pos_loss = 0.08478236943483353, Lv_loss = 0.0032585824374109507, Circular Tuning Loss = 1.1257752180099487\n",
      "500) Lyapunov Risk = 1.0121285915374756, MSE = 0.037766337394714355, V_0_loss = tensor([[0.0031]], grad_fn=<PowBackward0>), V_pos_loss = 0.08470166474580765, Lv_loss = 0.003212266368791461, Circular Tuning Loss = 1.1255887746810913\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.059082031250000014, -0.058593750000000014]\n",
      "x2 : [0.12402343750000003, 0.12500000000000003]\n",
      "==============================\n",
      "501) Lyapunov Risk = 1.0094631910324097, MSE = 0.03762997314333916, V_0_loss = tensor([[0.0031]], grad_fn=<PowBackward0>), V_pos_loss = 0.08406057953834534, Lv_loss = 0.003226679051294923, Circular Tuning Loss = 1.1180200576782227\n",
      "502) Lyapunov Risk = 1.0091280937194824, MSE = 0.03766545653343201, V_0_loss = tensor([[0.0031]], grad_fn=<PowBackward0>), V_pos_loss = 0.08398069441318512, Lv_loss = 0.0032067839056253433, Circular Tuning Loss = 1.1178359985351562\n",
      "503) Lyapunov Risk = 1.0087969303131104, MSE = 0.037773240357637405, V_0_loss = tensor([[0.0031]], grad_fn=<PowBackward0>), V_pos_loss = 0.08390092104673386, Lv_loss = 0.003163583343848586, Circular Tuning Loss = 1.1176526546478271\n",
      "504) Lyapunov Risk = 1.0084623098373413, MSE = 0.03765573725104332, V_0_loss = tensor([[0.0031]], grad_fn=<PowBackward0>), V_pos_loss = 0.08382121473550797, Lv_loss = 0.00319262919947505, Circular Tuning Loss = 1.1174699068069458\n",
      "505) Lyapunov Risk = 1.0081262588500977, MSE = 0.03774625062942505, V_0_loss = tensor([[0.0031]], grad_fn=<PowBackward0>), V_pos_loss = 0.08374160528182983, Lv_loss = 0.0031534258741885424, Circular Tuning Loss = 1.1172881126403809\n",
      "506) Lyapunov Risk = 1.0077992677688599, MSE = 0.0378730334341526, V_0_loss = tensor([[0.0031]], grad_fn=<PowBackward0>), V_pos_loss = 0.08366206288337708, Lv_loss = 0.003102272981777787, Circular Tuning Loss = 1.117106556892395\n",
      "507) Lyapunov Risk = 1.0074695348739624, MSE = 0.037701357156038284, V_0_loss = tensor([[0.0031]], grad_fn=<PowBackward0>), V_pos_loss = 0.0835825726389885, Lv_loss = 0.0031469338573515415, Circular Tuning Loss = 1.116925597190857\n",
      "508) Lyapunov Risk = 1.007132649421692, MSE = 0.03784248232841492, V_0_loss = tensor([[0.0031]], grad_fn=<PowBackward0>), V_pos_loss = 0.08350317925214767, Lv_loss = 0.003088840050622821, Circular Tuning Loss = 1.1167453527450562\n",
      "509) Lyapunov Risk = 1.006801962852478, MSE = 0.03785007447004318, V_0_loss = tensor([[0.0031]], grad_fn=<PowBackward0>), V_pos_loss = 0.08342384546995163, Lv_loss = 0.0030735174659639597, Circular Tuning Loss = 1.116565465927124\n",
      "510) Lyapunov Risk = 1.006475567817688, MSE = 0.0376334972679615, V_0_loss = tensor([[0.0031]], grad_fn=<PowBackward0>), V_pos_loss = 0.08334453403949738, Lv_loss = 0.003130258060991764, Circular Tuning Loss = 1.1163859367370605\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.12500000000000003, -0.11718750000000003]\n",
      "x2 : [0.23718750000000005, 0.24718750000000006]\n",
      "==============================\n",
      "511) Lyapunov Risk = 1.004825234413147, MSE = 0.03775634244084358, V_0_loss = tensor([[0.0032]], grad_fn=<PowBackward0>), V_pos_loss = 0.08271750062704086, Lv_loss = 0.003628138219937682, Circular Tuning Loss = 1.1092945337295532\n",
      "512) Lyapunov Risk = 1.0045052766799927, MSE = 0.037839408963918686, V_0_loss = tensor([[0.0032]], grad_fn=<PowBackward0>), V_pos_loss = 0.08263888210058212, Lv_loss = 0.0035856920294463634, Circular Tuning Loss = 1.1091169118881226\n",
      "513) Lyapunov Risk = 1.004187822341919, MSE = 0.03752591088414192, V_0_loss = tensor([[0.0032]], grad_fn=<PowBackward0>), V_pos_loss = 0.08256030082702637, Lv_loss = 0.003690446261316538, Circular Tuning Loss = 1.1089401245117188\n",
      "514) Lyapunov Risk = 1.003839373588562, MSE = 0.03776191547513008, V_0_loss = tensor([[0.0032]], grad_fn=<PowBackward0>), V_pos_loss = 0.08248183876276016, Lv_loss = 0.0035927772987633944, Circular Tuning Loss = 1.1087640523910522\n",
      "515) Lyapunov Risk = 1.003517746925354, MSE = 0.03784940019249916, V_0_loss = tensor([[0.0032]], grad_fn=<PowBackward0>), V_pos_loss = 0.08240342140197754, Lv_loss = 0.0035523909609764814, Circular Tuning Loss = 1.108588457107544\n",
      "516) Lyapunov Risk = 1.0032086372375488, MSE = 0.03754280135035515, V_0_loss = tensor([[0.0032]], grad_fn=<PowBackward0>), V_pos_loss = 0.0823250338435173, Lv_loss = 0.003655143780633807, Circular Tuning Loss = 1.1084133386611938\n",
      "517) Lyapunov Risk = 1.0028551816940308, MSE = 0.03781994804739952, V_0_loss = tensor([[0.0032]], grad_fn=<PowBackward0>), V_pos_loss = 0.08224687725305557, Lv_loss = 0.0035427880939096212, Circular Tuning Loss = 1.1082390546798706\n",
      "518) Lyapunov Risk = 1.002540946006775, MSE = 0.037930093705654144, V_0_loss = tensor([[0.0032]], grad_fn=<PowBackward0>), V_pos_loss = 0.0821688324213028, Lv_loss = 0.00349258491769433, Circular Tuning Loss = 1.108065128326416\n",
      "519) Lyapunov Risk = 1.00224769115448, MSE = 0.03749329596757889, V_0_loss = tensor([[0.0032]], grad_fn=<PowBackward0>), V_pos_loss = 0.08209080249071121, Lv_loss = 0.003641509683802724, Circular Tuning Loss = 1.1078916788101196\n",
      "520) Lyapunov Risk = 1.0018765926361084, MSE = 0.037788935005664825, V_0_loss = tensor([[0.0032]], grad_fn=<PowBackward0>), V_pos_loss = 0.08201286196708679, Lv_loss = 0.003516886383295059, Circular Tuning Loss = 1.107718586921692\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.035156250000000014, -0.031250000000000007]\n",
      "x2 : [0.15625000000000006, 0.16015625000000006]\n",
      "==============================\n",
      "521) Lyapunov Risk = 0.9995964765548706, MSE = 0.03797100856900215, V_0_loss = tensor([[0.0032]], grad_fn=<PowBackward0>), V_pos_loss = 0.08139944821596146, Lv_loss = 0.003566939616575837, Circular Tuning Loss = 1.1004475355148315\n",
      "522) Lyapunov Risk = 0.9992929100990295, MSE = 0.037450771778821945, V_0_loss = tensor([[0.0032]], grad_fn=<PowBackward0>), V_pos_loss = 0.0813220739364624, Lv_loss = 0.0037650323938578367, Circular Tuning Loss = 1.1002767086029053\n",
      "523) Lyapunov Risk = 0.9989154934883118, MSE = 0.037769023329019547, V_0_loss = tensor([[0.0032]], grad_fn=<PowBackward0>), V_pos_loss = 0.08124485611915588, Lv_loss = 0.0036220967303961515, Circular Tuning Loss = 1.1001064777374268\n",
      "524) Lyapunov Risk = 0.9986301064491272, MSE = 0.03801390901207924, V_0_loss = tensor([[0.0032]], grad_fn=<PowBackward0>), V_pos_loss = 0.08116769045591354, Lv_loss = 0.0035175688099116087, Circular Tuning Loss = 1.099936842918396\n",
      "525) Lyapunov Risk = 0.9983269572257996, MSE = 0.03748532012104988, V_0_loss = tensor([[0.0032]], grad_fn=<PowBackward0>), V_pos_loss = 0.0810905173420906, Lv_loss = 0.0037209067959338427, Circular Tuning Loss = 1.099767804145813\n",
      "526) Lyapunov Risk = 0.9979444742202759, MSE = 0.037812091410160065, V_0_loss = tensor([[0.0032]], grad_fn=<PowBackward0>), V_pos_loss = 0.08101347088813782, Lv_loss = 0.003575196024030447, Circular Tuning Loss = 1.0995993614196777\n",
      "527) Lyapunov Risk = 0.9976881742477417, MSE = 0.038163911551237106, V_0_loss = tensor([[0.0032]], grad_fn=<PowBackward0>), V_pos_loss = 0.08093657344579697, Lv_loss = 0.003430628916248679, Circular Tuning Loss = 1.0994315147399902\n",
      "528) Lyapunov Risk = 0.9973520040512085, MSE = 0.03754954785108566, V_0_loss = tensor([[0.0033]], grad_fn=<PowBackward0>), V_pos_loss = 0.08085969090461731, Lv_loss = 0.0036635547876358032, Circular Tuning Loss = 1.0992640256881714\n",
      "529) Lyapunov Risk = 0.9969809055328369, MSE = 0.037749554961919785, V_0_loss = tensor([[0.0033]], grad_fn=<PowBackward0>), V_pos_loss = 0.08078297972679138, Lv_loss = 0.0035671270452439785, Circular Tuning Loss = 1.0990968942642212\n",
      "530) Lyapunov Risk = 0.9967461228370667, MSE = 0.038175616413354874, V_0_loss = tensor([[0.0033]], grad_fn=<PowBackward0>), V_pos_loss = 0.08070647716522217, Lv_loss = 0.0033932183869183064, Circular Tuning Loss = 1.0989301204681396\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.12500000000000003, -0.11718750000000003]\n",
      "x2 : [0.23718750000000005, 0.24718750000000006]\n",
      "==============================\n",
      "531) Lyapunov Risk = 0.9950990676879883, MSE = 0.03752538561820984, V_0_loss = tensor([[0.0033]], grad_fn=<PowBackward0>), V_pos_loss = 0.08010644465684891, Lv_loss = 0.004159843549132347, Circular Tuning Loss = 1.0920456647872925\n",
      "532) Lyapunov Risk = 0.9947370290756226, MSE = 0.03771403431892395, V_0_loss = tensor([[0.0033]], grad_fn=<PowBackward0>), V_pos_loss = 0.0800306499004364, Lv_loss = 0.00405860086902976, Circular Tuning Loss = 1.0918805599212646\n",
      "533) Lyapunov Risk = 0.9944758415222168, MSE = 0.038075536489486694, V_0_loss = tensor([[0.0033]], grad_fn=<PowBackward0>), V_pos_loss = 0.07995493710041046, Lv_loss = 0.0038926631677895784, Circular Tuning Loss = 1.0917162895202637\n",
      "534) Lyapunov Risk = 0.9941196441650391, MSE = 0.037559378892183304, V_0_loss = tensor([[0.0033]], grad_fn=<PowBackward0>), V_pos_loss = 0.07987920939922333, Lv_loss = 0.004099234472960234, Circular Tuning Loss = 1.0915523767471313\n",
      "535) Lyapunov Risk = 0.9937704205513, MSE = 0.037748537957668304, V_0_loss = tensor([[0.0033]], grad_fn=<PowBackward0>), V_pos_loss = 0.07980360835790634, Lv_loss = 0.004001416265964508, Circular Tuning Loss = 1.0913891792297363\n",
      "536) Lyapunov Risk = 0.9934786558151245, MSE = 0.03800315782427788, V_0_loss = tensor([[0.0033]], grad_fn=<PowBackward0>), V_pos_loss = 0.07972806692123413, Lv_loss = 0.003880271688103676, Circular Tuning Loss = 1.09122633934021\n",
      "537) Lyapunov Risk = 0.9931597113609314, MSE = 0.03758866339921951, V_0_loss = tensor([[0.0033]], grad_fn=<PowBackward0>), V_pos_loss = 0.07965250313282013, Lv_loss = 0.004047897178679705, Circular Tuning Loss = 1.0910639762878418\n",
      "538) Lyapunov Risk = 0.9928117990493774, MSE = 0.037867914885282516, V_0_loss = tensor([[0.0033]], grad_fn=<PowBackward0>), V_pos_loss = 0.07957707345485687, Lv_loss = 0.003910568077117205, Circular Tuning Loss = 1.0909020900726318\n",
      "539) Lyapunov Risk = 0.9924880266189575, MSE = 0.03780868649482727, V_0_loss = tensor([[0.0033]], grad_fn=<PowBackward0>), V_pos_loss = 0.07950177788734436, Lv_loss = 0.003922376781702042, Circular Tuning Loss = 1.09074068069458\n",
      "540) Lyapunov Risk = 0.9921796321868896, MSE = 0.037619758397340775, V_0_loss = tensor([[0.0033]], grad_fn=<PowBackward0>), V_pos_loss = 0.07942648231983185, Lv_loss = 0.003991668112576008, Circular Tuning Loss = 1.0905793905258179\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.12500000000000003, -0.11718750000000003]\n",
      "x2 : [0.23718750000000005, 0.24718750000000006]\n",
      "==============================\n",
      "541) Lyapunov Risk = 0.9905909299850464, MSE = 0.03784298896789551, V_0_loss = tensor([[0.0033]], grad_fn=<PowBackward0>), V_pos_loss = 0.07883932441473007, Lv_loss = 0.004372686147689819, Circular Tuning Loss = 1.0837939977645874\n",
      "542) Lyapunov Risk = 0.9902657866477966, MSE = 0.03766435384750366, V_0_loss = tensor([[0.0033]], grad_fn=<PowBackward0>), V_pos_loss = 0.0787646695971489, Lv_loss = 0.004441211000084877, Circular Tuning Loss = 1.0836347341537476\n",
      "543) Lyapunov Risk = 0.98994380235672, MSE = 0.037715837359428406, V_0_loss = tensor([[0.0033]], grad_fn=<PowBackward0>), V_pos_loss = 0.07869020849466324, Lv_loss = 0.004399711266160011, Circular Tuning Loss = 1.0834760665893555\n",
      "544) Lyapunov Risk = 0.9896278381347656, MSE = 0.03780519962310791, V_0_loss = tensor([[0.0033]], grad_fn=<PowBackward0>), V_pos_loss = 0.07861579209566116, Lv_loss = 0.004339536651968956, Circular Tuning Loss = 1.0833179950714111\n",
      "545) Lyapunov Risk = 0.9893182516098022, MSE = 0.03762323781847954, V_0_loss = tensor([[0.0033]], grad_fn=<PowBackward0>), V_pos_loss = 0.07854139804840088, Lv_loss = 0.004408777225762606, Circular Tuning Loss = 1.0831605195999146\n",
      "546) Lyapunov Risk = 0.9890015721321106, MSE = 0.03792562708258629, V_0_loss = tensor([[0.0034]], grad_fn=<PowBackward0>), V_pos_loss = 0.07846710830926895, Lv_loss = 0.004246879834681749, Circular Tuning Loss = 1.0830036401748657\n",
      "547) Lyapunov Risk = 0.9886718988418579, MSE = 0.03772665932774544, V_0_loss = tensor([[0.0034]], grad_fn=<PowBackward0>), V_pos_loss = 0.07839281857013702, Lv_loss = 0.004323430825024843, Circular Tuning Loss = 1.0828471183776855\n",
      "548) Lyapunov Risk = 0.9883513450622559, MSE = 0.03776605799794197, V_0_loss = tensor([[0.0034]], grad_fn=<PowBackward0>), V_pos_loss = 0.07831858843564987, Lv_loss = 0.004287489224225283, Circular Tuning Loss = 1.0826911926269531\n",
      "549) Lyapunov Risk = 0.9880419969558716, MSE = 0.03788932040333748, V_0_loss = tensor([[0.0034]], grad_fn=<PowBackward0>), V_pos_loss = 0.0782444179058075, Lv_loss = 0.004213474225252867, Circular Tuning Loss = 1.0825353860855103\n",
      "550) Lyapunov Risk = 0.9877327084541321, MSE = 0.03757740929722786, V_0_loss = tensor([[0.0034]], grad_fn=<PowBackward0>), V_pos_loss = 0.07817021757364273, Lv_loss = 0.004345574416220188, Circular Tuning Loss = 1.0823800563812256\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.33593750000000011, -0.32933193175325076]\n",
      "x2 : [0.50000000000000011, 0.50390625000000022]\n",
      "==============================\n",
      "551) Lyapunov Risk = 0.9871304631233215, MSE = 0.03780724108219147, V_0_loss = tensor([[0.0034]], grad_fn=<PowBackward0>), V_pos_loss = 0.07760520279407501, Lv_loss = 0.004560266621410847, Circular Tuning Loss = 1.0776220560073853\n",
      "552) Lyapunov Risk = 0.9868102669715881, MSE = 0.03777143731713295, V_0_loss = tensor([[0.0034]], grad_fn=<PowBackward0>), V_pos_loss = 0.07753053307533264, Lv_loss = 0.004557550419121981, Circular Tuning Loss = 1.077466607093811\n",
      "553) Lyapunov Risk = 0.9865095615386963, MSE = 0.0374697707593441, V_0_loss = tensor([[0.0034]], grad_fn=<PowBackward0>), V_pos_loss = 0.07745595276355743, Lv_loss = 0.004693499766290188, Circular Tuning Loss = 1.077311396598816\n",
      "554) Lyapunov Risk = 0.986189603805542, MSE = 0.03782948851585388, V_0_loss = tensor([[0.0034]], grad_fn=<PowBackward0>), V_pos_loss = 0.0773814469575882, Lv_loss = 0.004480937961488962, Circular Tuning Loss = 1.0771560668945312\n",
      "555) Lyapunov Risk = 0.9858442544937134, MSE = 0.037626542150974274, V_0_loss = tensor([[0.0034]], grad_fn=<PowBackward0>), V_pos_loss = 0.07730697095394135, Lv_loss = 0.00455881655216217, Circular Tuning Loss = 1.0770008563995361\n",
      "556) Lyapunov Risk = 0.9855756759643555, MSE = 0.037289369851350784, V_0_loss = tensor([[0.0034]], grad_fn=<PowBackward0>), V_pos_loss = 0.07723251730203629, Lv_loss = 0.0047170016914606094, Circular Tuning Loss = 1.0768460035324097\n",
      "557) Lyapunov Risk = 0.9852625727653503, MSE = 0.037893593311309814, V_0_loss = tensor([[0.0034]], grad_fn=<PowBackward0>), V_pos_loss = 0.07715832442045212, Lv_loss = 0.004382699728012085, Circular Tuning Loss = 1.0766910314559937\n",
      "558) Lyapunov Risk = 0.9848954081535339, MSE = 0.037667497992515564, V_0_loss = tensor([[0.0034]], grad_fn=<PowBackward0>), V_pos_loss = 0.07708433270454407, Lv_loss = 0.004474946763366461, Circular Tuning Loss = 1.0765361785888672\n",
      "559) Lyapunov Risk = 0.9846799969673157, MSE = 0.03712448105216026, V_0_loss = tensor([[0.0034]], grad_fn=<PowBackward0>), V_pos_loss = 0.07701049000024796, Lv_loss = 0.004755642265081406, Circular Tuning Loss = 1.0763815641403198\n",
      "560) Lyapunov Risk = 0.9842923879623413, MSE = 0.03781275823712349, V_0_loss = tensor([[0.0034]], grad_fn=<PowBackward0>), V_pos_loss = 0.07693690061569214, Lv_loss = 0.004375227261334658, Circular Tuning Loss = 1.076227068901062\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.033203125000000014, -0.031250000000000007]\n",
      "x2 : [0.15625000000000006, 0.16015625000000006]\n",
      "==============================\n",
      "561) Lyapunov Risk = 0.9820914268493652, MSE = 0.0377848744392395, V_0_loss = tensor([[0.0034]], grad_fn=<PowBackward0>), V_pos_loss = 0.07637385278940201, Lv_loss = 0.004482440184801817, Circular Tuning Loss = 1.069349765777588\n",
      "562) Lyapunov Risk = 0.9818037152290344, MSE = 0.03724853694438934, V_0_loss = tensor([[0.0034]], grad_fn=<PowBackward0>), V_pos_loss = 0.07630094140768051, Lv_loss = 0.004772266373038292, Circular Tuning Loss = 1.0691970586776733\n",
      "563) Lyapunov Risk = 0.9814353585243225, MSE = 0.03770210221409798, V_0_loss = tensor([[0.0034]], grad_fn=<PowBackward0>), V_pos_loss = 0.07622829079627991, Lv_loss = 0.004497518762946129, Circular Tuning Loss = 1.0690449476242065\n",
      "564) Lyapunov Risk = 0.9811369180679321, MSE = 0.03783266991376877, V_0_loss = tensor([[0.0034]], grad_fn=<PowBackward0>), V_pos_loss = 0.07615571469068527, Lv_loss = 0.004411952570080757, Circular Tuning Loss = 1.0688934326171875\n",
      "565) Lyapunov Risk = 0.9808028936386108, MSE = 0.03745173290371895, V_0_loss = tensor([[0.0034]], grad_fn=<PowBackward0>), V_pos_loss = 0.07608315348625183, Lv_loss = 0.00460303807631135, Circular Tuning Loss = 1.068742275238037\n",
      "566) Lyapunov Risk = 0.9804802536964417, MSE = 0.037531834095716476, V_0_loss = tensor([[0.0034]], grad_fn=<PowBackward0>), V_pos_loss = 0.07601065188646317, Lv_loss = 0.004538610577583313, Circular Tuning Loss = 1.068591594696045\n",
      "567) Lyapunov Risk = 0.9801700115203857, MSE = 0.0377323217689991, V_0_loss = tensor([[0.0034]], grad_fn=<PowBackward0>), V_pos_loss = 0.07593820989131927, Lv_loss = 0.004408760461956263, Circular Tuning Loss = 1.0684415102005005\n",
      "568) Lyapunov Risk = 0.9798479676246643, MSE = 0.03763047605752945, V_0_loss = tensor([[0.0035]], grad_fn=<PowBackward0>), V_pos_loss = 0.07586588710546494, Lv_loss = 0.0044445376843214035, Circular Tuning Loss = 1.0682915449142456\n",
      "569) Lyapunov Risk = 0.9795367121696472, MSE = 0.0373975969851017, V_0_loss = tensor([[0.0035]], grad_fn=<PowBackward0>), V_pos_loss = 0.07579375058412552, Lv_loss = 0.0045556602999567986, Circular Tuning Loss = 1.0681419372558594\n",
      "570) Lyapunov Risk = 0.9792152047157288, MSE = 0.037456758320331573, V_0_loss = tensor([[0.0035]], grad_fn=<PowBackward0>), V_pos_loss = 0.07572176307439804, Lv_loss = 0.004501926712691784, Circular Tuning Loss = 1.0679930448532104\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.035156250000000014, -0.031250000000000007]\n",
      "x2 : [0.15625000000000006, 0.16015625000000006]\n",
      "==============================\n",
      "571) Lyapunov Risk = 0.9770603775978088, MSE = 0.03754033148288727, V_0_loss = tensor([[0.0035]], grad_fn=<PowBackward0>), V_pos_loss = 0.07517095655202866, Lv_loss = 0.004542416427284479, Circular Tuning Loss = 1.061212182044983\n",
      "572) Lyapunov Risk = 0.9767450094223022, MSE = 0.03750790283083916, V_0_loss = tensor([[0.0035]], grad_fn=<PowBackward0>), V_pos_loss = 0.07509948313236237, Lv_loss = 0.004543625749647617, Circular Tuning Loss = 1.0610649585723877\n",
      "573) Lyapunov Risk = 0.9764311909675598, MSE = 0.03742072731256485, V_0_loss = tensor([[0.0035]], grad_fn=<PowBackward0>), V_pos_loss = 0.07502807676792145, Lv_loss = 0.004577623214572668, Circular Tuning Loss = 1.0609183311462402\n",
      "574) Lyapunov Risk = 0.9761151075363159, MSE = 0.03747284412384033, V_0_loss = tensor([[0.0035]], grad_fn=<PowBackward0>), V_pos_loss = 0.07495672255754471, Lv_loss = 0.004529088269919157, Circular Tuning Loss = 1.0607722997665405\n",
      "575) Lyapunov Risk = 0.9758027791976929, MSE = 0.03760329633951187, V_0_loss = tensor([[0.0035]], grad_fn=<PowBackward0>), V_pos_loss = 0.07488539069890976, Lv_loss = 0.0044367071241140366, Circular Tuning Loss = 1.0606268644332886\n",
      "576) Lyapunov Risk = 0.9754891395568848, MSE = 0.03763246908783913, V_0_loss = tensor([[0.0035]], grad_fn=<PowBackward0>), V_pos_loss = 0.07481412589550018, Lv_loss = 0.004404831677675247, Circular Tuning Loss = 1.0604816675186157\n",
      "577) Lyapunov Risk = 0.9751793146133423, MSE = 0.03760116174817085, V_0_loss = tensor([[0.0035]], grad_fn=<PowBackward0>), V_pos_loss = 0.07474291324615479, Lv_loss = 0.004408988635987043, Circular Tuning Loss = 1.0603370666503906\n",
      "578) Lyapunov Risk = 0.9748666882514954, MSE = 0.037631236016750336, V_0_loss = tensor([[0.0035]], grad_fn=<PowBackward0>), V_pos_loss = 0.07467176020145416, Lv_loss = 0.00437536183744669, Circular Tuning Loss = 1.0601927042007446\n",
      "579) Lyapunov Risk = 0.974556565284729, MSE = 0.037672415375709534, V_0_loss = tensor([[0.0035]], grad_fn=<PowBackward0>), V_pos_loss = 0.07460064440965652, Lv_loss = 0.004335485864430666, Circular Tuning Loss = 1.0600488185882568\n",
      "580) Lyapunov Risk = 0.9742438197135925, MSE = 0.03762419894337654, V_0_loss = tensor([[0.0035]], grad_fn=<PowBackward0>), V_pos_loss = 0.07452966272830963, Lv_loss = 0.00434785196557641, Circular Tuning Loss = 1.0599050521850586\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.033203125000000014, -0.031250000000000007]\n",
      "x2 : [0.15625000000000006, 0.16015625000000006]\n",
      "==============================\n",
      "581) Lyapunov Risk = 0.9721066951751709, MSE = 0.03755391389131546, V_0_loss = tensor([[0.0035]], grad_fn=<PowBackward0>), V_pos_loss = 0.07399050891399384, Lv_loss = 0.004464919213205576, Circular Tuning Loss = 1.053220272064209\n",
      "582) Lyapunov Risk = 0.9717942476272583, MSE = 0.037637390196323395, V_0_loss = tensor([[0.0035]], grad_fn=<PowBackward0>), V_pos_loss = 0.07392018288373947, Lv_loss = 0.004397244658321142, Circular Tuning Loss = 1.053078293800354\n",
      "583) Lyapunov Risk = 0.971484363079071, MSE = 0.03767184540629387, V_0_loss = tensor([[0.0035]], grad_fn=<PowBackward0>), V_pos_loss = 0.07384997606277466, Lv_loss = 0.004359286278486252, Circular Tuning Loss = 1.0529370307922363\n",
      "584) Lyapunov Risk = 0.9711712598800659, MSE = 0.037594497203826904, V_0_loss = tensor([[0.0035]], grad_fn=<PowBackward0>), V_pos_loss = 0.07377985119819641, Lv_loss = 0.004387108609080315, Circular Tuning Loss = 1.0527962446212769\n",
      "585) Lyapunov Risk = 0.9708614945411682, MSE = 0.03759002685546875, V_0_loss = tensor([[0.0035]], grad_fn=<PowBackward0>), V_pos_loss = 0.07370978593826294, Lv_loss = 0.00437158765271306, Circular Tuning Loss = 1.052655816078186\n",
      "586) Lyapunov Risk = 0.9705504179000854, MSE = 0.037693001329898834, V_0_loss = tensor([[0.0035]], grad_fn=<PowBackward0>), V_pos_loss = 0.07363977283239365, Lv_loss = 0.004291130695492029, Circular Tuning Loss = 1.0525161027908325\n",
      "587) Lyapunov Risk = 0.9702411890029907, MSE = 0.03771818056702614, V_0_loss = tensor([[0.0035]], grad_fn=<PowBackward0>), V_pos_loss = 0.07356981933116913, Lv_loss = 0.004257751163095236, Circular Tuning Loss = 1.052376389503479\n",
      "588) Lyapunov Risk = 0.9699300527572632, MSE = 0.037625767290592194, V_0_loss = tensor([[0.0035]], grad_fn=<PowBackward0>), V_pos_loss = 0.07349991053342819, Lv_loss = 0.004294205456972122, Circular Tuning Loss = 1.0522372722625732\n",
      "589) Lyapunov Risk = 0.9696193337440491, MSE = 0.03757951781153679, V_0_loss = tensor([[0.0035]], grad_fn=<PowBackward0>), V_pos_loss = 0.07343004643917084, Lv_loss = 0.004303833935409784, Circular Tuning Loss = 1.052098274230957\n",
      "590) Lyapunov Risk = 0.9693077206611633, MSE = 0.03760729730129242, V_0_loss = tensor([[0.0035]], grad_fn=<PowBackward0>), V_pos_loss = 0.07336020469665527, Lv_loss = 0.004270114470273256, Circular Tuning Loss = 1.0519596338272095\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.32031250000000011, -0.31250000000000011]\n",
      "x2 : [0.50000000000000011, 0.50390625000000022]\n",
      "==============================\n",
      "591) Lyapunov Risk = 0.9688804149627686, MSE = 0.037577033042907715, V_0_loss = tensor([[0.0035]], grad_fn=<PowBackward0>), V_pos_loss = 0.0728408694267273, Lv_loss = 0.004690524656325579, Circular Tuning Loss = 1.0474517345428467\n",
      "592) Lyapunov Risk = 0.9685686826705933, MSE = 0.03759066388010979, V_0_loss = tensor([[0.0035]], grad_fn=<PowBackward0>), V_pos_loss = 0.07277057319879532, Lv_loss = 0.004663730971515179, Circular Tuning Loss = 1.04731285572052\n",
      "593) Lyapunov Risk = 0.968256950378418, MSE = 0.03756018355488777, V_0_loss = tensor([[0.0035]], grad_fn=<PowBackward0>), V_pos_loss = 0.0727003663778305, Lv_loss = 0.004662754945456982, Circular Tuning Loss = 1.0471742153167725\n",
      "594) Lyapunov Risk = 0.9679449200630188, MSE = 0.03750719875097275, V_0_loss = tensor([[0.0036]], grad_fn=<PowBackward0>), V_pos_loss = 0.07263018935918808, Lv_loss = 0.004674205090850592, Circular Tuning Loss = 1.047035574913025\n",
      "595) Lyapunov Risk = 0.9676336050033569, MSE = 0.03748202696442604, V_0_loss = tensor([[0.0036]], grad_fn=<PowBackward0>), V_pos_loss = 0.07256007939577103, Lv_loss = 0.004669281654059887, Circular Tuning Loss = 1.0468968152999878\n",
      "596) Lyapunov Risk = 0.9673222303390503, MSE = 0.0375007800757885, V_0_loss = tensor([[0.0036]], grad_fn=<PowBackward0>), V_pos_loss = 0.07249001413583755, Lv_loss = 0.004639067221432924, Circular Tuning Loss = 1.0467582941055298\n",
      "597) Lyapunov Risk = 0.9670109748840332, MSE = 0.037518467754125595, V_0_loss = tensor([[0.0036]], grad_fn=<PowBackward0>), V_pos_loss = 0.07242008298635483, Lv_loss = 0.004611981566995382, Circular Tuning Loss = 1.0466198921203613\n",
      "598) Lyapunov Risk = 0.9666993021965027, MSE = 0.03751549497246742, V_0_loss = tensor([[0.0036]], grad_fn=<PowBackward0>), V_pos_loss = 0.07235019654035568, Lv_loss = 0.004598664585500956, Circular Tuning Loss = 1.0464816093444824\n",
      "599) Lyapunov Risk = 0.9663878083229065, MSE = 0.03750165179371834, V_0_loss = tensor([[0.0036]], grad_fn=<PowBackward0>), V_pos_loss = 0.07228030264377594, Lv_loss = 0.004592420533299446, Circular Tuning Loss = 1.046343445777893\n",
      "600) Lyapunov Risk = 0.9660758972167969, MSE = 0.03749263286590576, V_0_loss = tensor([[0.0036]], grad_fn=<PowBackward0>), V_pos_loss = 0.07221042364835739, Lv_loss = 0.00458289822563529, Circular Tuning Loss = 1.0462054014205933\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.12500000000000003, -0.11718750000000003]\n",
      "x2 : [0.23718750000000005, 0.24718750000000006]\n",
      "==============================\n",
      "601) Lyapunov Risk = 0.9645369052886963, MSE = 0.03748488426208496, V_0_loss = tensor([[0.0036]], grad_fn=<PowBackward0>), V_pos_loss = 0.07169272750616074, Lv_loss = 0.004956915974617004, Circular Tuning Loss = 1.0399365425109863\n",
      "602) Lyapunov Risk = 0.9642238616943359, MSE = 0.03756438195705414, V_0_loss = tensor([[0.0036]], grad_fn=<PowBackward0>), V_pos_loss = 0.07162387669086456, Lv_loss = 0.004884431138634682, Circular Tuning Loss = 1.039799690246582\n",
      "603) Lyapunov Risk = 0.963909924030304, MSE = 0.037536486983299255, V_0_loss = tensor([[0.0036]], grad_fn=<PowBackward0>), V_pos_loss = 0.07155551016330719, Lv_loss = 0.0048801470547914505, Circular Tuning Loss = 1.0396634340286255\n",
      "604) Lyapunov Risk = 0.9635978937149048, MSE = 0.037443339824676514, V_0_loss = tensor([[0.0036]], grad_fn=<PowBackward0>), V_pos_loss = 0.07148730009794235, Lv_loss = 0.004918782506138086, Circular Tuning Loss = 1.0395278930664062\n",
      "605) Lyapunov Risk = 0.9632840156555176, MSE = 0.03747694566845894, V_0_loss = tensor([[0.0036]], grad_fn=<PowBackward0>), V_pos_loss = 0.07141920179128647, Lv_loss = 0.004872262943536043, Circular Tuning Loss = 1.0393924713134766\n",
      "606) Lyapunov Risk = 0.9629719853401184, MSE = 0.03753981366753578, V_0_loss = tensor([[0.0036]], grad_fn=<PowBackward0>), V_pos_loss = 0.07135115563869476, Lv_loss = 0.004808468744158745, Circular Tuning Loss = 1.0392576456069946\n",
      "607) Lyapunov Risk = 0.9626585245132446, MSE = 0.03749993443489075, V_0_loss = tensor([[0.0036]], grad_fn=<PowBackward0>), V_pos_loss = 0.0712832361459732, Lv_loss = 0.004813489969819784, Circular Tuning Loss = 1.0391234159469604\n",
      "608) Lyapunov Risk = 0.9623456001281738, MSE = 0.03742633014917374, V_0_loss = tensor([[0.0036]], grad_fn=<PowBackward0>), V_pos_loss = 0.07121535390615463, Lv_loss = 0.004840721841901541, Circular Tuning Loss = 1.0389893054962158\n",
      "609) Lyapunov Risk = 0.9620317816734314, MSE = 0.03742007911205292, V_0_loss = tensor([[0.0036]], grad_fn=<PowBackward0>), V_pos_loss = 0.07114750891923904, Lv_loss = 0.004823084454983473, Circular Tuning Loss = 1.038855791091919\n",
      "610) Lyapunov Risk = 0.9617183804512024, MSE = 0.03742442652583122, V_0_loss = tensor([[0.0036]], grad_fn=<PowBackward0>), V_pos_loss = 0.071079783141613, Lv_loss = 0.004799197893589735, Circular Tuning Loss = 1.0387225151062012\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.12500000000000003, -0.11718750000000003]\n",
      "x2 : [0.23718750000000005, 0.24718750000000006]\n",
      "==============================\n",
      "611) Lyapunov Risk = 0.9601980447769165, MSE = 0.037370845675468445, V_0_loss = tensor([[0.0036]], grad_fn=<PowBackward0>), V_pos_loss = 0.07057376950979233, Lv_loss = 0.005190345458686352, Circular Tuning Loss = 1.032544732093811\n",
      "612) Lyapunov Risk = 0.9598824977874756, MSE = 0.03741557523608208, V_0_loss = tensor([[0.0036]], grad_fn=<PowBackward0>), V_pos_loss = 0.07050659507513046, Lv_loss = 0.005133685190230608, Circular Tuning Loss = 1.0324128866195679\n",
      "613) Lyapunov Risk = 0.9595668315887451, MSE = 0.03742970526218414, V_0_loss = tensor([[0.0036]], grad_fn=<PowBackward0>), V_pos_loss = 0.07043948769569397, Lv_loss = 0.005096038803458214, Circular Tuning Loss = 1.0322813987731934\n",
      "614) Lyapunov Risk = 0.9592506885528564, MSE = 0.03737632557749748, V_0_loss = tensor([[0.0036]], grad_fn=<PowBackward0>), V_pos_loss = 0.0703725665807724, Lv_loss = 0.005104319658130407, Circular Tuning Loss = 1.0321506261825562\n",
      "615) Lyapunov Risk = 0.9589353799819946, MSE = 0.03738334774971008, V_0_loss = tensor([[0.0036]], grad_fn=<PowBackward0>), V_pos_loss = 0.0703057050704956, Lv_loss = 0.005071668419986963, Circular Tuning Loss = 1.032020092010498\n",
      "616) Lyapunov Risk = 0.9586206078529358, MSE = 0.03745020925998688, V_0_loss = tensor([[0.0036]], grad_fn=<PowBackward0>), V_pos_loss = 0.07023894041776657, Lv_loss = 0.00499794352799654, Circular Tuning Loss = 1.0318901538848877\n",
      "617) Lyapunov Risk = 0.9583051204681396, MSE = 0.0374349020421505, V_0_loss = tensor([[0.0036]], grad_fn=<PowBackward0>), V_pos_loss = 0.07017233967781067, Lv_loss = 0.004982138052582741, Circular Tuning Loss = 1.0317604541778564\n",
      "618) Lyapunov Risk = 0.9579898118972778, MSE = 0.03736085817217827, V_0_loss = tensor([[0.0036]], grad_fn=<PowBackward0>), V_pos_loss = 0.07010578364133835, Lv_loss = 0.005007673986256123, Circular Tuning Loss = 1.0316312313079834\n",
      "619) Lyapunov Risk = 0.9576733708381653, MSE = 0.037351153790950775, V_0_loss = tensor([[0.0036]], grad_fn=<PowBackward0>), V_pos_loss = 0.07003924250602722, Lv_loss = 0.004987429827451706, Circular Tuning Loss = 1.031502366065979\n",
      "620) Lyapunov Risk = 0.9573581218719482, MSE = 0.03735259175300598, V_0_loss = tensor([[0.0036]], grad_fn=<PowBackward0>), V_pos_loss = 0.06997273862361908, Lv_loss = 0.004958676639944315, Circular Tuning Loss = 1.0313737392425537\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.12500000000000003, -0.11718750000000003]\n",
      "x2 : [0.24218750000000006, 0.25000000000000006]\n",
      "==============================\n",
      "621) Lyapunov Risk = 0.9558772444725037, MSE = 0.03728009760379791, V_0_loss = tensor([[0.0036]], grad_fn=<PowBackward0>), V_pos_loss = 0.069477379322052, Lv_loss = 0.005361041985452175, Circular Tuning Loss = 1.0252976417541504\n",
      "622) Lyapunov Risk = 0.9555590748786926, MSE = 0.03730899840593338, V_0_loss = tensor([[0.0036]], grad_fn=<PowBackward0>), V_pos_loss = 0.06941136717796326, Lv_loss = 0.00530864205211401, Circular Tuning Loss = 1.0251703262329102\n",
      "623) Lyapunov Risk = 0.9552408456802368, MSE = 0.037332683801651, V_0_loss = tensor([[0.0036]], grad_fn=<PowBackward0>), V_pos_loss = 0.06934542208909988, Lv_loss = 0.005258813966065645, Circular Tuning Loss = 1.0250434875488281\n",
      "624) Lyapunov Risk = 0.9549223184585571, MSE = 0.03729801997542381, V_0_loss = tensor([[0.0036]], grad_fn=<PowBackward0>), V_pos_loss = 0.06927959620952606, Lv_loss = 0.0052502271719276905, Circular Tuning Loss = 1.0249172449111938\n",
      "625) Lyapunov Risk = 0.9546047449111938, MSE = 0.037303123623132706, V_0_loss = tensor([[0.0036]], grad_fn=<PowBackward0>), V_pos_loss = 0.06921389698982239, Lv_loss = 0.005214203614741564, Circular Tuning Loss = 1.0247912406921387\n",
      "626) Lyapunov Risk = 0.9542871713638306, MSE = 0.037354376167058945, V_0_loss = tensor([[0.0036]], grad_fn=<PowBackward0>), V_pos_loss = 0.06914825737476349, Lv_loss = 0.0051462724804878235, Circular Tuning Loss = 1.0246655941009521\n",
      "627) Lyapunov Risk = 0.9539694786071777, MSE = 0.03735407814383507, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06908264756202698, Lv_loss = 0.005116149317473173, Circular Tuning Loss = 1.0245403051376343\n",
      "628) Lyapunov Risk = 0.9536513090133667, MSE = 0.037296995520591736, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.0690171867609024, Lv_loss = 0.005126906093209982, Circular Tuning Loss = 1.0244152545928955\n",
      "629) Lyapunov Risk = 0.9533325433731079, MSE = 0.03726283833384514, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06895177811384201, Lv_loss = 0.005120459944009781, Circular Tuning Loss = 1.0242904424667358\n",
      "630) Lyapunov Risk = 0.9530140161514282, MSE = 0.037246666848659515, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06888637691736221, Lv_loss = 0.005100435111671686, Circular Tuning Loss = 1.0241657495498657\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.12500000000000003, -0.11718750000000003]\n",
      "x2 : [0.24218750000000006, 0.25000000000000006]\n",
      "==============================\n",
      "631) Lyapunov Risk = 0.9515125155448914, MSE = 0.037191178649663925, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06840134412050247, Lv_loss = 0.005454285070300102, Circular Tuning Loss = 1.018165946006775\n",
      "632) Lyapunov Risk = 0.951191782951355, MSE = 0.037222299724817276, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06833640486001968, Lv_loss = 0.005395219195634127, Circular Tuning Loss = 1.0180423259735107\n",
      "633) Lyapunov Risk = 0.9508702754974365, MSE = 0.03721338137984276, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06827153265476227, Lv_loss = 0.005363903474062681, Circular Tuning Loss = 1.0179191827774048\n",
      "634) Lyapunov Risk = 0.9505481123924255, MSE = 0.03715633973479271, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06820669770240784, Lv_loss = 0.005367355886846781, Circular Tuning Loss = 1.0177963972091675\n",
      "635) Lyapunov Risk = 0.950226366519928, MSE = 0.03715912625193596, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.0681418925523758, Lv_loss = 0.005326780490577221, Circular Tuning Loss = 1.0176738500595093\n",
      "636) Lyapunov Risk = 0.9499047994613647, MSE = 0.037209898233413696, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06807713955640793, Lv_loss = 0.005252048373222351, Circular Tuning Loss = 1.0175516605377197\n",
      "637) Lyapunov Risk = 0.9495832920074463, MSE = 0.03720330074429512, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06801265478134155, Lv_loss = 0.005221476778388023, Circular Tuning Loss = 1.0174295902252197\n",
      "638) Lyapunov Risk = 0.9492610692977905, MSE = 0.03714493662118912, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06794819235801697, Lv_loss = 0.005229654721915722, Circular Tuning Loss = 1.0173077583312988\n",
      "639) Lyapunov Risk = 0.9489385485649109, MSE = 0.037119533866643906, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06788372993469238, Lv_loss = 0.005213994067162275, Circular Tuning Loss = 1.0171860456466675\n",
      "640) Lyapunov Risk = 0.948616087436676, MSE = 0.037086550146341324, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06781931221485138, Lv_loss = 0.005204810760915279, Circular Tuning Loss = 1.0170646905899048\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.033203125000000014, -0.031250000000000007]\n",
      "x2 : [0.15625000000000006, 0.15820312500000006]\n",
      "==============================\n",
      "641) Lyapunov Risk = 0.9465815424919128, MSE = 0.03702981024980545, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06734438985586166, Lv_loss = 0.005260958336293697, Circular Tuning Loss = 1.010888695716858\n",
      "642) Lyapunov Risk = 0.9462592601776123, MSE = 0.03706693649291992, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06728069484233856, Lv_loss = 0.005196182522922754, Circular Tuning Loss = 1.0107686519622803\n",
      "643) Lyapunov Risk = 0.9459359645843506, MSE = 0.03706156462430954, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06721705198287964, Lv_loss = 0.005162077955901623, Circular Tuning Loss = 1.0106489658355713\n",
      "644) Lyapunov Risk = 0.9456122517585754, MSE = 0.037010882049798965, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.0671534389257431, Lv_loss = 0.005161947570741177, Circular Tuning Loss = 1.0105297565460205\n",
      "645) Lyapunov Risk = 0.945288896560669, MSE = 0.037031158804893494, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06708987057209015, Lv_loss = 0.005107074044644833, Circular Tuning Loss = 1.0104109048843384\n",
      "646) Lyapunov Risk = 0.9449663758277893, MSE = 0.03709226846694946, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06702632457017899, Lv_loss = 0.005021749995648861, Circular Tuning Loss = 1.010292410850525\n",
      "647) Lyapunov Risk = 0.9446431398391724, MSE = 0.037077296525239944, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06696280092000961, Lv_loss = 0.004996283445507288, Circular Tuning Loss = 1.010174036026001\n",
      "648) Lyapunov Risk = 0.9443195462226868, MSE = 0.03701528534293175, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06689929962158203, Lv_loss = 0.00500769866630435, Circular Tuning Loss = 1.0100558996200562\n",
      "649) Lyapunov Risk = 0.94399493932724, MSE = 0.03699294850230217, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06683579832315445, Lv_loss = 0.004988843575119972, Circular Tuning Loss = 1.0099380016326904\n",
      "650) Lyapunov Risk = 0.9436704516410828, MSE = 0.03697492554783821, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06677242368459702, Lv_loss = 0.004967784509062767, Circular Tuning Loss = 1.0098202228546143\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.12500000000000003, -0.11718750000000003]\n",
      "x2 : [0.24218750000000006, 0.25000000000000006]\n",
      "==============================\n",
      "651) Lyapunov Risk = 0.9421595335006714, MSE = 0.036906562745571136, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06630723923444748, Lv_loss = 0.0052905515767633915, Circular Tuning Loss = 1.0039737224578857\n",
      "652) Lyapunov Risk = 0.9418336749076843, MSE = 0.036934785544872284, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.0662444457411766, Lv_loss = 0.0052295527420938015, Circular Tuning Loss = 1.003857135772705\n",
      "653) Lyapunov Risk = 0.9415069222450256, MSE = 0.0369076132774353, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06618170440196991, Lv_loss = 0.005211282521486282, Circular Tuning Loss = 1.003740906715393\n",
      "654) Lyapunov Risk = 0.9411801099777222, MSE = 0.03684154525399208, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.0661189928650856, Lv_loss = 0.005223008804023266, Circular Tuning Loss = 1.0036250352859497\n",
      "655) Lyapunov Risk = 0.9408528208732605, MSE = 0.03685761243104935, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06605628877878189, Lv_loss = 0.005169145297259092, Circular Tuning Loss = 1.0035094022750854\n",
      "656) Lyapunov Risk = 0.9405261874198914, MSE = 0.036907121539115906, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06599359214305878, Lv_loss = 0.005089621990919113, Circular Tuning Loss = 1.0033941268920898\n",
      "657) Lyapunov Risk = 0.9401987791061401, MSE = 0.036877263337373734, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06593099981546402, Lv_loss = 0.005074020009487867, Circular Tuning Loss = 1.0032789707183838\n",
      "658) Lyapunov Risk = 0.9398713707923889, MSE = 0.03681831806898117, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06586844474077225, Lv_loss = 0.005082014948129654, Circular Tuning Loss = 1.0031639337539673\n",
      "659) Lyapunov Risk = 0.9395431876182556, MSE = 0.036808568984270096, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06580599397420883, Lv_loss = 0.005051466170698404, Circular Tuning Loss = 1.0030491352081299\n",
      "660) Lyapunov Risk = 0.9392150044441223, MSE = 0.0367940329015255, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06574354320764542, Lv_loss = 0.0050261905416846275, Circular Tuning Loss = 1.0029343366622925\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.033203125000000014, -0.031250000000000007]\n",
      "x2 : [0.15625000000000006, 0.15820312500000006]\n",
      "==============================\n",
      "661) Lyapunov Risk = 0.9372110962867737, MSE = 0.0367295928299427, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06528782099485397, Lv_loss = 0.005076000466942787, Circular Tuning Loss = 0.9969192743301392\n",
      "662) Lyapunov Risk = 0.9368816018104553, MSE = 0.03676383197307587, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06522582471370697, Lv_loss = 0.005009178537875414, Circular Tuning Loss = 0.996805727481842\n",
      "663) Lyapunov Risk = 0.9365516304969788, MSE = 0.036774635314941406, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06516386568546295, Lv_loss = 0.004960556980222464, Circular Tuning Loss = 0.9966922402381897\n",
      "664) Lyapunov Risk = 0.9362213015556335, MSE = 0.03675198182463646, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06510203331708908, Lv_loss = 0.004939005244523287, Circular Tuning Loss = 0.9965792298316956\n",
      "665) Lyapunov Risk = 0.9358919858932495, MSE = 0.03677796572446823, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.0650402382016182, Lv_loss = 0.004877091385424137, Circular Tuning Loss = 0.9964666366577148\n",
      "666) Lyapunov Risk = 0.9355631470680237, MSE = 0.03682814538478851, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06497848033905029, Lv_loss = 0.00479536410421133, Circular Tuning Loss = 0.9963539242744446\n",
      "667) Lyapunov Risk = 0.935233473777771, MSE = 0.03679686412215233, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06491672992706299, Lv_loss = 0.004780877381563187, Circular Tuning Loss = 0.9962414503097534\n",
      "668) Lyapunov Risk = 0.9349036812782288, MSE = 0.03673301264643669, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06485498696565628, Lv_loss = 0.004794029518961906, Circular Tuning Loss = 0.9961292743682861\n",
      "669) Lyapunov Risk = 0.9345726370811462, MSE = 0.03670847788453102, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06479324400424957, Lv_loss = 0.004774990491569042, Circular Tuning Loss = 0.9960172176361084\n",
      "670) Lyapunov Risk = 0.9342421889305115, MSE = 0.03667096421122551, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06473150104284286, Lv_loss = 0.004767539910972118, Circular Tuning Loss = 0.9959052205085754\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.032226562500000014, -0.031250000000000007]\n",
      "x2 : [0.15625000000000006, 0.15820312500000006]\n",
      "==============================\n",
      "671) Lyapunov Risk = 0.9322544932365417, MSE = 0.036586664617061615, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06428482383489609, Lv_loss = 0.0048275054432451725, Circular Tuning Loss = 0.9899690747261047\n",
      "672) Lyapunov Risk = 0.9319229125976562, MSE = 0.036617133766412735, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06422367691993713, Lv_loss = 0.004761281423270702, Circular Tuning Loss = 0.9898582100868225\n",
      "673) Lyapunov Risk = 0.9315904378890991, MSE = 0.036632783710956573, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06416257470846176, Lv_loss = 0.004706023260951042, Circular Tuning Loss = 0.9897477626800537\n",
      "674) Lyapunov Risk = 0.931257426738739, MSE = 0.0366002582013607, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06410151720046997, Lv_loss = 0.004690687637776136, Circular Tuning Loss = 0.989637553691864\n",
      "675) Lyapunov Risk = 0.9309256076812744, MSE = 0.036623984575271606, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06404048204421997, Lv_loss = 0.004628350026905537, Circular Tuning Loss = 0.9895278215408325\n",
      "676) Lyapunov Risk = 0.9305941462516785, MSE = 0.036682743579149246, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06397948414087296, Lv_loss = 0.004537962842732668, Circular Tuning Loss = 0.9894183278083801\n",
      "677) Lyapunov Risk = 0.9302619099617004, MSE = 0.036666885018348694, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06391849368810654, Lv_loss = 0.004511626437306404, Circular Tuning Loss = 0.9893089532852173\n",
      "678) Lyapunov Risk = 0.9299295544624329, MSE = 0.036612577736377716, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06385760754346848, Lv_loss = 0.004518280737102032, Circular Tuning Loss = 0.9891998171806335\n",
      "679) Lyapunov Risk = 0.9295965433120728, MSE = 0.036584533751010895, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06379690766334534, Lv_loss = 0.004502885043621063, Circular Tuning Loss = 0.9890909194946289\n",
      "680) Lyapunov Risk = 0.9292636513710022, MSE = 0.0365433543920517, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06373628973960876, Lv_loss = 0.0044991448521614075, Circular Tuning Loss = 0.9889821410179138\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.12500000000000003, -0.11718750000000003]\n",
      "x2 : [0.24218750000000006, 0.25000000000000006]\n",
      "==============================\n",
      "681) Lyapunov Risk = 0.9277634024620056, MSE = 0.03646612912416458, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06329888105392456, Lv_loss = 0.0047829910181462765, Circular Tuning Loss = 0.9833678603172302\n",
      "682) Lyapunov Risk = 0.9274284839630127, MSE = 0.03650606796145439, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06323869526386261, Lv_loss = 0.004704722668975592, Circular Tuning Loss = 0.9832600355148315\n",
      "683) Lyapunov Risk = 0.9270925521850586, MSE = 0.03648706525564194, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06317858397960663, Lv_loss = 0.0046745771542191505, Circular Tuning Loss = 0.9831526279449463\n",
      "684) Lyapunov Risk = 0.926756739616394, MSE = 0.036417070776224136, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06311861425638199, Lv_loss = 0.004687251057475805, Circular Tuning Loss = 0.9830456376075745\n",
      "685) Lyapunov Risk = 0.926421046257019, MSE = 0.03644382953643799, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06305867433547974, Lv_loss = 0.004616275895386934, Circular Tuning Loss = 0.9829390645027161\n",
      "686) Lyapunov Risk = 0.92608642578125, MSE = 0.03648366034030914, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06299876421689987, Lv_loss = 0.004536143504083157, Circular Tuning Loss = 0.982832670211792\n",
      "687) Lyapunov Risk = 0.9257506132125854, MSE = 0.0364452488720417, V_0_loss = tensor([[0.0037]], grad_fn=<PowBackward0>), V_pos_loss = 0.06293885409832001, Lv_loss = 0.0045257085002958775, Circular Tuning Loss = 0.9827265739440918\n",
      "688) Lyapunov Risk = 0.9254145622253418, MSE = 0.036396268755197525, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.06287899613380432, Lv_loss = 0.004525113385170698, Circular Tuning Loss = 0.9826207160949707\n",
      "689) Lyapunov Risk = 0.9250780940055847, MSE = 0.03638247027993202, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.06281927227973938, Lv_loss = 0.004494563676416874, Circular Tuning Loss = 0.9825150370597839\n",
      "690) Lyapunov Risk = 0.9247414469718933, MSE = 0.03634019196033478, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.06275953352451324, Lv_loss = 0.004489608108997345, Circular Tuning Loss = 0.982409656047821\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.9687500000000004, -1.9609375000000004]\n",
      "x2 : [0, 0.0067658234670659274]\n",
      "==============================\n",
      "691) Lyapunov Risk = 0.9280169010162354, MSE = 0.036268603056669235, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.06233098730444908, Lv_loss = 0.004482397343963385, Circular Tuning Loss = 0.9883677959442139\n",
      "692) Lyapunov Risk = 0.9276825785636902, MSE = 0.03619041293859482, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.06227177754044533, Lv_loss = 0.004507647827267647, Circular Tuning Loss = 0.9882655739784241\n",
      "693) Lyapunov Risk = 0.9273493885993958, MSE = 0.03614998236298561, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.062212686985731125, Lv_loss = 0.00450136000290513, Circular Tuning Loss = 0.9881633520126343\n",
      "694) Lyapunov Risk = 0.9270160794258118, MSE = 0.03610437735915184, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.06215366721153259, Lv_loss = 0.004499832168221474, Circular Tuning Loss = 0.988061249256134\n",
      "695) Lyapunov Risk = 0.9266828298568726, MSE = 0.03605978563427925, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.06209469214081764, Lv_loss = 0.004494582302868366, Circular Tuning Loss = 0.9879589676856995\n",
      "696) Lyapunov Risk = 0.9263488054275513, MSE = 0.03604094311594963, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.06203574687242508, Lv_loss = 0.00446357112377882, Circular Tuning Loss = 0.9878568053245544\n",
      "697) Lyapunov Risk = 0.9260146617889404, MSE = 0.03602603077888489, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.0619768425822258, Lv_loss = 0.004428680986166, Circular Tuning Loss = 0.9877544641494751\n",
      "698) Lyapunov Risk = 0.92568039894104, MSE = 0.036014311015605927, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.06191796809434891, Lv_loss = 0.004391483962535858, Circular Tuning Loss = 0.9876523613929749\n",
      "699) Lyapunov Risk = 0.9253465533256531, MSE = 0.03601433336734772, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.06185924634337425, Lv_loss = 0.004343705717474222, Circular Tuning Loss = 0.9875500202178955\n",
      "700) Lyapunov Risk = 0.9250123500823975, MSE = 0.03598933666944504, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.061800532042980194, Lv_loss = 0.004318152088671923, Circular Tuning Loss = 0.9874475598335266\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.9531250000000004, -1.9453125000000004]\n",
      "x2 : [0, 0.0067658234670659274]\n",
      "==============================\n",
      "701) Lyapunov Risk = 0.928135871887207, MSE = 0.0359356589615345, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.06138075143098831, Lv_loss = 0.004294725600630045, Circular Tuning Loss = 0.9931073784828186\n",
      "702) Lyapunov Risk = 0.9278020858764648, MSE = 0.03587500751018524, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.06132246181368828, Lv_loss = 0.004308945499360561, Circular Tuning Loss = 0.9930076003074646\n",
      "703) Lyapunov Risk = 0.9274687170982361, MSE = 0.03583679348230362, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.06126425042748451, Lv_loss = 0.004307739436626434, Circular Tuning Loss = 0.9929076433181763\n",
      "704) Lyapunov Risk = 0.9271368980407715, MSE = 0.035764679312705994, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.06120609864592552, Lv_loss = 0.004335370380431414, Circular Tuning Loss = 0.9928075075149536\n",
      "705) Lyapunov Risk = 0.9268059134483337, MSE = 0.035690851509571075, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.06114797666668892, Lv_loss = 0.004361200146377087, Circular Tuning Loss = 0.9927071332931519\n",
      "706) Lyapunov Risk = 0.92647385597229, MSE = 0.03566673770546913, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.061089903116226196, Lv_loss = 0.004338511731475592, Circular Tuning Loss = 0.992606520652771\n",
      "707) Lyapunov Risk = 0.9261407852172852, MSE = 0.03565401956439018, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.06103186681866646, Lv_loss = 0.004300575237721205, Circular Tuning Loss = 0.9925057291984558\n",
      "708) Lyapunov Risk = 0.9258075952529907, MSE = 0.035626620054244995, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.06097385659813881, Lv_loss = 0.004272907506674528, Circular Tuning Loss = 0.9924049377441406\n",
      "709) Lyapunov Risk = 0.9254754781723022, MSE = 0.035610273480415344, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.060915909707546234, Lv_loss = 0.004235828295350075, Circular Tuning Loss = 0.9923038482666016\n",
      "710) Lyapunov Risk = 0.9251436591148376, MSE = 0.03561480715870857, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.06085805594921112, Lv_loss = 0.004184355493634939, Circular Tuning Loss = 0.9922026991844177\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.9531250000000004, -1.9453125000000004]\n",
      "x2 : [0, 0.0067658234670659274]\n",
      "==============================\n",
      "711) Lyapunov Risk = 0.9282621145248413, MSE = 0.03559727966785431, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.06044681370258331, Lv_loss = 0.0041324421763420105, Circular Tuning Loss = 0.997850775718689\n",
      "712) Lyapunov Risk = 0.9279292821884155, MSE = 0.03551157936453819, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.06038951873779297, Lv_loss = 0.004170889034867287, Circular Tuning Loss = 0.9977520108222961\n",
      "713) Lyapunov Risk = 0.9275962114334106, MSE = 0.03546200692653656, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.0603322759270668, Lv_loss = 0.004183555021882057, Circular Tuning Loss = 0.9976528286933899\n",
      "714) Lyapunov Risk = 0.9272661209106445, MSE = 0.03543360158801079, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.060275107622146606, Lv_loss = 0.004179371055215597, Circular Tuning Loss = 0.9975535273551941\n",
      "715) Lyapunov Risk = 0.9269369840621948, MSE = 0.035353854298591614, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.060218002647161484, Lv_loss = 0.004214916843920946, Circular Tuning Loss = 0.9974539875984192\n",
      "716) Lyapunov Risk = 0.9266068339347839, MSE = 0.035286255180835724, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.06016100198030472, Lv_loss = 0.004231289029121399, Circular Tuning Loss = 0.9973543882369995\n",
      "717) Lyapunov Risk = 0.9262757301330566, MSE = 0.03527168184518814, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.06010402739048004, Lv_loss = 0.004194971639662981, Circular Tuning Loss = 0.9972544312477112\n",
      "718) Lyapunov Risk = 0.9259440302848816, MSE = 0.03524468466639519, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.060047078877687454, Lv_loss = 0.004166942555457354, Circular Tuning Loss = 0.9971544742584229\n",
      "719) Lyapunov Risk = 0.9256135821342468, MSE = 0.03522639721632004, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.05999011546373367, Lv_loss = 0.0041312165558338165, Circular Tuning Loss = 0.9970541596412659\n",
      "720) Lyapunov Risk = 0.9252834916114807, MSE = 0.035226836800575256, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.05993315204977989, Lv_loss = 0.004081402905285358, Circular Tuning Loss = 0.9969537854194641\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.9765625000000004, -1.9687500000000004]\n",
      "x2 : [0, 0.0067658234670659274]\n",
      "==============================\n",
      "721) Lyapunov Risk = 0.9285470247268677, MSE = 0.0352015420794487, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.05953008309006691, Lv_loss = 0.004035890102386475, Circular Tuning Loss = 1.0028983354568481\n",
      "722) Lyapunov Risk = 0.9282154440879822, MSE = 0.03513675555586815, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.05947352945804596, Lv_loss = 0.004057225305587053, Circular Tuning Loss = 1.0028001070022583\n",
      "723) Lyapunov Risk = 0.9278830289840698, MSE = 0.0351104810833931, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.05941705405712128, Lv_loss = 0.004051384516060352, Circular Tuning Loss = 1.0027015209197998\n",
      "724) Lyapunov Risk = 0.9275531768798828, MSE = 0.03506916016340256, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.05936064198613167, Lv_loss = 0.00406096363440156, Circular Tuning Loss = 1.0026028156280518\n",
      "725) Lyapunov Risk = 0.9272244572639465, MSE = 0.0349862314760685, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.059304267168045044, Lv_loss = 0.004103048238903284, Circular Tuning Loss = 1.002503752708435\n",
      "726) Lyapunov Risk = 0.926895260810852, MSE = 0.0349445678293705, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.059247929602861404, Lv_loss = 0.004102340433746576, Circular Tuning Loss = 1.0024044513702393\n",
      "727) Lyapunov Risk = 0.9265645742416382, MSE = 0.03493763878941536, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.05919172242283821, Lv_loss = 0.00406384002417326, Circular Tuning Loss = 1.002305030822754\n",
      "728) Lyapunov Risk = 0.9262332320213318, MSE = 0.034904878586530685, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.05913560092449188, Lv_loss = 0.004041990730911493, Circular Tuning Loss = 1.002205491065979\n",
      "729) Lyapunov Risk = 0.9259030818939209, MSE = 0.034881703555583954, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.059079479426145554, Lv_loss = 0.004009808413684368, Circular Tuning Loss = 1.0021058320999146\n",
      "730) Lyapunov Risk = 0.9255735874176025, MSE = 0.03488719090819359, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.059023428708314896, Lv_loss = 0.003954640589654446, Circular Tuning Loss = 1.002005934715271\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.12500000000000003, -0.12109375000000003]\n",
      "x2 : [0.24218750000000006, 0.25000000000000006]\n",
      "==============================\n",
      "731) Lyapunov Risk = 0.9239861965179443, MSE = 0.034877046942710876, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.05862860381603241, Lv_loss = 0.004120138473808765, Circular Tuning Loss = 0.9964686632156372\n",
      "732) Lyapunov Risk = 0.9236546158790588, MSE = 0.03493446484208107, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.058573056012392044, Lv_loss = 0.004029335454106331, Circular Tuning Loss = 0.9963691830635071\n",
      "733) Lyapunov Risk = 0.9233225584030151, MSE = 0.034911781549453735, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.058517564088106155, Lv_loss = 0.0040114461444318295, Circular Tuning Loss = 0.9962698817253113\n",
      "734) Lyapunov Risk = 0.9229915738105774, MSE = 0.03485884889960289, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.05846212059259415, Lv_loss = 0.004020282998681068, Circular Tuning Loss = 0.9961707592010498\n",
      "735) Lyapunov Risk = 0.9226604104042053, MSE = 0.034893736243247986, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.05840672552585602, Lv_loss = 0.0039513977244496346, Circular Tuning Loss = 0.9960718750953674\n",
      "736) Lyapunov Risk = 0.9223289489746094, MSE = 0.03485455363988876, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.058351341634988785, Lv_loss = 0.003946579527109861, Circular Tuning Loss = 0.9959731101989746\n",
      "737) Lyapunov Risk = 0.9219980239868164, MSE = 0.034782569855451584, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.05829598009586334, Lv_loss = 0.0039670225232839584, Circular Tuning Loss = 0.9958744645118713\n",
      "738) Lyapunov Risk = 0.9216664433479309, MSE = 0.0347832590341568, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.058240633457899094, Lv_loss = 0.003919686656445265, Circular Tuning Loss = 0.9957758784294128\n",
      "739) Lyapunov Risk = 0.9213341474533081, MSE = 0.03471727669239044, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.058185283094644547, Lv_loss = 0.003930923528969288, Circular Tuning Loss = 0.9956775307655334\n",
      "740) Lyapunov Risk = 0.9210032224655151, MSE = 0.034652229398489, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.058129940181970596, Lv_loss = 0.0039405557326972485, Circular Tuning Loss = 0.9955793023109436\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.12500000000000003, -0.12109375000000003]\n",
      "x2 : [0.24218750000000006, 0.25000000000000006]\n",
      "==============================\n",
      "741) Lyapunov Risk = 0.9194192290306091, MSE = 0.03467085212469101, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.057742733508348465, Lv_loss = 0.0040621343068778515, Circular Tuning Loss = 0.9901091456413269\n",
      "742) Lyapunov Risk = 0.9190860986709595, MSE = 0.034706562757492065, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.05768774822354317, Lv_loss = 0.0039799814112484455, Circular Tuning Loss = 0.9900116324424744\n",
      "743) Lyapunov Risk = 0.9187515377998352, MSE = 0.03463862091302872, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.05763282626867294, Lv_loss = 0.00399402342736721, Circular Tuning Loss = 0.9899144768714905\n",
      "744) Lyapunov Risk = 0.9184160232543945, MSE = 0.034701377153396606, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.0575779490172863, Lv_loss = 0.0038881704676896334, Circular Tuning Loss = 0.9898176789283752\n",
      "745) Lyapunov Risk = 0.918082594871521, MSE = 0.03471974655985832, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.057523101568222046, Lv_loss = 0.0038264128379523754, Circular Tuning Loss = 0.9897210001945496\n",
      "746) Lyapunov Risk = 0.917749285697937, MSE = 0.03469947353005409, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.05746843293309212, Lv_loss = 0.0038027246482670307, Circular Tuning Loss = 0.9896247386932373\n",
      "747) Lyapunov Risk = 0.9174151420593262, MSE = 0.03472340852022171, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.05741408094763756, Lv_loss = 0.0037359888665378094, Circular Tuning Loss = 0.9895286560058594\n",
      "748) Lyapunov Risk = 0.9170809388160706, MSE = 0.034672968089580536, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.05735979974269867, Lv_loss = 0.0037344719748944044, Circular Tuning Loss = 0.9894327521324158\n",
      "749) Lyapunov Risk = 0.9167467355728149, MSE = 0.03459595516324043, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.05730568245053291, Lv_loss = 0.003755514742806554, Circular Tuning Loss = 0.9893369674682617\n",
      "750) Lyapunov Risk = 0.9164132475852966, MSE = 0.03457776829600334, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.057251568883657455, Lv_loss = 0.0037215151824057102, Circular Tuning Loss = 0.9892414808273315\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.37890625000000011, -0.37500000000000011]\n",
      "x2 : [0.62500000000000022, 0.62890625000000022]\n",
      "==============================\n",
      "751) Lyapunov Risk = 0.9163699746131897, MSE = 0.03450654074549675, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.05687247961759567, Lv_loss = 0.0038733328692615032, Circular Tuning Loss = 0.9865359663963318\n",
      "752) Lyapunov Risk = 0.9160358309745789, MSE = 0.03456095978617668, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.056818727403879166, Lv_loss = 0.003764387220144272, Circular Tuning Loss = 0.9864395260810852\n",
      "753) Lyapunov Risk = 0.9156995415687561, MSE = 0.03446783125400543, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.056765150278806686, Lv_loss = 0.0037966123782098293, Circular Tuning Loss = 0.9863433837890625\n",
      "754) Lyapunov Risk = 0.9153648018836975, MSE = 0.03442160040140152, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.05671173706650734, Lv_loss = 0.0037852097302675247, Circular Tuning Loss = 0.9862475991249084\n",
      "755) Lyapunov Risk = 0.9150303602218628, MSE = 0.03446971997618675, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.056658390909433365, Lv_loss = 0.003687563817948103, Circular Tuning Loss = 0.9861518144607544\n",
      "756) Lyapunov Risk = 0.91469407081604, MSE = 0.034426331520080566, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.05660505220293999, Lv_loss = 0.0036816156934946775, Circular Tuning Loss = 0.9860563278198242\n",
      "757) Lyapunov Risk = 0.9143589735031128, MSE = 0.0344182550907135, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.0565517283976078, Lv_loss = 0.0036414475180208683, Circular Tuning Loss = 0.9859607815742493\n",
      "758) Lyapunov Risk = 0.9140247106552124, MSE = 0.034428395330905914, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.056498583406209946, Lv_loss = 0.003580502700060606, Circular Tuning Loss = 0.9858656525611877\n",
      "759) Lyapunov Risk = 0.913689374923706, MSE = 0.03433242440223694, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05644543468952179, Lv_loss = 0.0036194955464452505, Circular Tuning Loss = 0.9857707023620605\n",
      "760) Lyapunov Risk = 0.9133542776107788, MSE = 0.03431432694196701, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05639226362109184, Lv_loss = 0.0035832233261317015, Circular Tuning Loss = 0.9856758117675781\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.032226562500000014, -0.031250000000000007]\n",
      "x2 : [0.15625000000000006, 0.15722656250000006]\n",
      "==============================\n",
      "761) Lyapunov Risk = 0.9113909006118774, MSE = 0.03430534526705742, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.056020788848400116, Lv_loss = 0.0035300529561936855, Circular Tuning Loss = 0.9801000356674194\n",
      "762) Lyapunov Risk = 0.9110550284385681, MSE = 0.034310199320316315, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.055967967957258224, Lv_loss = 0.0034691498149186373, Circular Tuning Loss = 0.9800060987472534\n",
      "763) Lyapunov Risk = 0.9107188582420349, MSE = 0.03429853543639183, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05591518431901932, Lv_loss = 0.0034246493596583605, Circular Tuning Loss = 0.9799125790596008\n",
      "764) Lyapunov Risk = 0.9103835821151733, MSE = 0.03432260826230049, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.055862437933683395, Lv_loss = 0.003345170058310032, Circular Tuning Loss = 0.9798195958137512\n",
      "765) Lyapunov Risk = 0.9100494384765625, MSE = 0.0343477688729763, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05580974370241165, Lv_loss = 0.003266577608883381, Circular Tuning Loss = 0.9797269701957703\n",
      "766) Lyapunov Risk = 0.9097155928611755, MSE = 0.034330371767282486, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.055757127702236176, Lv_loss = 0.0032305498607456684, Circular Tuning Loss = 0.9796345233917236\n",
      "767) Lyapunov Risk = 0.9093819856643677, MSE = 0.034364696592092514, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.055704642087221146, Lv_loss = 0.003142695873975754, Circular Tuning Loss = 0.9795423150062561\n",
      "768) Lyapunov Risk = 0.9090461730957031, MSE = 0.03424542397260666, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05565217137336731, Lv_loss = 0.0032010460272431374, Circular Tuning Loss = 0.9794503450393677\n",
      "769) Lyapunov Risk = 0.908711314201355, MSE = 0.03418847173452377, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05559971183538437, Lv_loss = 0.0032009638380259275, Circular Tuning Loss = 0.9793586730957031\n",
      "770) Lyapunov Risk = 0.9083775281906128, MSE = 0.03418995067477226, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05554725229740143, Lv_loss = 0.0031461401376873255, Circular Tuning Loss = 0.9792670607566833\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.032226562500000014, -0.031250000000000007]\n",
      "x2 : [0.15625000000000006, 0.15722656250000006]\n",
      "==============================\n",
      "771) Lyapunov Risk = 0.9064303636550903, MSE = 0.03409994766116142, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05518302321434021, Lv_loss = 0.0031664581038057804, Circular Tuning Loss = 0.9737605452537537\n",
      "772) Lyapunov Risk = 0.9060949087142944, MSE = 0.03411393240094185, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05513089522719383, Lv_loss = 0.0030918552074581385, Circular Tuning Loss = 0.9736701250076294\n",
      "773) Lyapunov Risk = 0.9057597517967224, MSE = 0.03413436561822891, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05507892742753029, Lv_loss = 0.00301170046441257, Circular Tuning Loss = 0.973580002784729\n",
      "774) Lyapunov Risk = 0.905426025390625, MSE = 0.03410754352807999, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.055026959627866745, Lv_loss = 0.0029827363323420286, Circular Tuning Loss = 0.9734901785850525\n",
      "775) Lyapunov Risk = 0.9050923585891724, MSE = 0.034174222499132156, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.0549749918282032, Lv_loss = 0.0028843083418905735, Circular Tuning Loss = 0.9734006524085999\n",
      "776) Lyapunov Risk = 0.9047597646713257, MSE = 0.03418608754873276, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05492304265499115, Lv_loss = 0.002834346843883395, Circular Tuning Loss = 0.9733115434646606\n",
      "777) Lyapunov Risk = 0.9044265151023865, MSE = 0.034115295857191086, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.0548710934817791, Lv_loss = 0.0028452270198613405, Circular Tuning Loss = 0.9732226133346558\n",
      "778) Lyapunov Risk = 0.9040921926498413, MSE = 0.03412269428372383, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05481915548443794, Lv_loss = 0.0027989214286208153, Circular Tuning Loss = 0.9731337428092957\n",
      "779) Lyapunov Risk = 0.903759241104126, MSE = 0.03409503772854805, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.054767221212387085, Lv_loss = 0.0027782295364886522, Circular Tuning Loss = 0.9730451107025146\n",
      "780) Lyapunov Risk = 0.9034268260002136, MSE = 0.034005604684352875, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05471530184149742, Lv_loss = 0.0028014155104756355, Circular Tuning Loss = 0.9729567766189575\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.12500000000000003, -0.12109375000000003]\n",
      "x2 : [0.24609375000000006, 0.25000000000000006]\n",
      "==============================\n",
      "781) Lyapunov Risk = 0.9018499851226807, MSE = 0.03397704288363457, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05435807257890701, Lv_loss = 0.0029061504174023867, Circular Tuning Loss = 0.967739999294281\n",
      "782) Lyapunov Risk = 0.9015169739723206, MSE = 0.03405636176466942, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05430661514401436, Lv_loss = 0.002805802971124649, Circular Tuning Loss = 0.967652440071106\n",
      "783) Lyapunov Risk = 0.9011813402175903, MSE = 0.03395241126418114, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05425534397363663, Lv_loss = 0.002837393432855606, Circular Tuning Loss = 0.96756511926651\n",
      "784) Lyapunov Risk = 0.9008452296257019, MSE = 0.03398524224758148, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05420417711138725, Lv_loss = 0.002768911886960268, Circular Tuning Loss = 0.9674782752990723\n",
      "785) Lyapunov Risk = 0.9005131125450134, MSE = 0.034057024866342545, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05415303632616997, Lv_loss = 0.002677223179489374, Circular Tuning Loss = 0.9673916101455688\n",
      "786) Lyapunov Risk = 0.9001800417900085, MSE = 0.03397200629115105, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.054101940244436264, Lv_loss = 0.002699122531339526, Circular Tuning Loss = 0.9673053622245789\n",
      "787) Lyapunov Risk = 0.8998439311981201, MSE = 0.033979661762714386, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05405086278915405, Lv_loss = 0.0026509060990065336, Circular Tuning Loss = 0.9672191143035889\n",
      "788) Lyapunov Risk = 0.8995108604431152, MSE = 0.0339767225086689, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05399981513619423, Lv_loss = 0.002610989846289158, Circular Tuning Loss = 0.9671333432197571\n",
      "789) Lyapunov Risk = 0.8991765975952148, MSE = 0.03385230153799057, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.053948771208524704, Lv_loss = 0.002658646320924163, Circular Tuning Loss = 0.9670476913452148\n",
      "790) Lyapunov Risk = 0.8988403677940369, MSE = 0.033856816589832306, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05389774218201637, Lv_loss = 0.0026097989175468683, Circular Tuning Loss = 0.9669620394706726\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.12500000000000003, -0.12109375000000003]\n",
      "x2 : [0.24609375000000006, 0.25000000000000006]\n",
      "==============================\n",
      "791) Lyapunov Risk = 0.8972522020339966, MSE = 0.03384064510464668, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.0535476952791214, Lv_loss = 0.00267798057757318, Circular Tuning Loss = 0.9618047475814819\n",
      "792) Lyapunov Risk = 0.8969161510467529, MSE = 0.033777009695768356, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05349713936448097, Lv_loss = 0.002679596422240138, Circular Tuning Loss = 0.9617199897766113\n",
      "793) Lyapunov Risk = 0.8965792655944824, MSE = 0.03380224481225014, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05344663932919502, Lv_loss = 0.0026143023278564215, Circular Tuning Loss = 0.9616355299949646\n",
      "794) Lyapunov Risk = 0.8962430953979492, MSE = 0.03379546478390694, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05339622125029564, Lv_loss = 0.0025723790749907494, Circular Tuning Loss = 0.961551308631897\n",
      "795) Lyapunov Risk = 0.8959072828292847, MSE = 0.03377307206392288, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05334581434726715, Lv_loss = 0.0025452328845858574, Circular Tuning Loss = 0.9614673256874084\n",
      "796) Lyapunov Risk = 0.8955715894699097, MSE = 0.03379658982157707, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05329541489481926, Lv_loss = 0.0024849355686455965, Circular Tuning Loss = 0.9613834619522095\n",
      "797) Lyapunov Risk = 0.8952356576919556, MSE = 0.03377005085349083, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.053245026618242264, Lv_loss = 0.0024605239741504192, Circular Tuning Loss = 0.9612997174263\n",
      "798) Lyapunov Risk = 0.894899308681488, MSE = 0.03372456505894661, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05319463834166527, Lv_loss = 0.0024505159817636013, Circular Tuning Loss = 0.9612162113189697\n",
      "799) Lyapunov Risk = 0.8945630788803101, MSE = 0.03369796648621559, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05314426124095917, Lv_loss = 0.0024264624807983637, Circular Tuning Loss = 0.9611327052116394\n",
      "800) Lyapunov Risk = 0.894227147102356, MSE = 0.033641964197158813, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05309394374489784, Lv_loss = 0.00242086173966527, Circular Tuning Loss = 0.9610493779182434\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.033203125000000014, -0.032226562500000014]\n",
      "x2 : [0.15917968750000006, 0.16015625000000006]\n",
      "==============================\n",
      "801) Lyapunov Risk = 0.8923183679580688, MSE = 0.03360268101096153, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05275077372789383, Lv_loss = 0.002387524815276265, Circular Tuning Loss = 0.9557427167892456\n",
      "802) Lyapunov Risk = 0.8919819593429565, MSE = 0.03361913561820984, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05270116403698921, Lv_loss = 0.0023307097144424915, Circular Tuning Loss = 0.955660343170166\n",
      "803) Lyapunov Risk = 0.8916447162628174, MSE = 0.03359122946858406, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.0526517853140831, Lv_loss = 0.002306112553924322, Circular Tuning Loss = 0.9555782079696655\n",
      "804) Lyapunov Risk = 0.8913081288337708, MSE = 0.03357827290892601, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05260241776704788, Lv_loss = 0.0022704380098730326, Circular Tuning Loss = 0.9554966688156128\n",
      "805) Lyapunov Risk = 0.8909720778465271, MSE = 0.03361695259809494, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05255308747291565, Lv_loss = 0.0022009958047419786, Circular Tuning Loss = 0.9554153084754944\n",
      "806) Lyapunov Risk = 0.8906363248825073, MSE = 0.03359020873904228, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05250390246510506, Lv_loss = 0.0021795867942273617, Circular Tuning Loss = 0.9553341269493103\n",
      "807) Lyapunov Risk = 0.8903000950813293, MSE = 0.0335860401391983, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05245480313897133, Lv_loss = 0.002139018615707755, Circular Tuning Loss = 0.9552529454231262\n",
      "808) Lyapunov Risk = 0.8899646997451782, MSE = 0.03353017568588257, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05240577086806297, Lv_loss = 0.0021336872596293688, Circular Tuning Loss = 0.9551721215248108\n",
      "809) Lyapunov Risk = 0.8896286487579346, MSE = 0.03349882364273071, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.052356719970703125, Lv_loss = 0.0021126726642251015, Circular Tuning Loss = 0.9550913572311401\n",
      "810) Lyapunov Risk = 0.8892932534217834, MSE = 0.033472996205091476, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.052307650446891785, Lv_loss = 0.0020855660550296307, Circular Tuning Loss = 0.9550105333328247\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.12500000000000003, -0.12304687500000003]\n",
      "x2 : [0.24609375000000006, 0.25000000000000006]\n",
      "==============================\n",
      "811) Lyapunov Risk = 0.8877013921737671, MSE = 0.033386290073394775, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05197140946984291, Lv_loss = 0.0021697646006941795, Circular Tuning Loss = 0.9499750733375549\n",
      "812) Lyapunov Risk = 0.8873645067214966, MSE = 0.033440470695495605, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05192260816693306, Lv_loss = 0.0020838880445808172, Circular Tuning Loss = 0.949894905090332\n",
      "813) Lyapunov Risk = 0.887026846408844, MSE = 0.03340139612555504, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.0518738217651844, Lv_loss = 0.0020664650946855545, Circular Tuning Loss = 0.9498151540756226\n",
      "814) Lyapunov Risk = 0.8866894841194153, MSE = 0.03336656838655472, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05182504653930664, Lv_loss = 0.002043064683675766, Circular Tuning Loss = 0.9497354626655579\n",
      "815) Lyapunov Risk = 0.8863533139228821, MSE = 0.03341378644108772, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05177628993988037, Lv_loss = 0.0019634633790701628, Circular Tuning Loss = 0.949656069278717\n",
      "816) Lyapunov Risk = 0.8860164880752563, MSE = 0.0333743579685688, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.051727525889873505, Lv_loss = 0.0019494920270517468, Circular Tuning Loss = 0.9495769143104553\n",
      "817) Lyapunov Risk = 0.8856792449951172, MSE = 0.03337419778108597, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05167887732386589, Lv_loss = 0.0019043097272515297, Circular Tuning Loss = 0.9494978785514832\n",
      "818) Lyapunov Risk = 0.8853437900543213, MSE = 0.033346306532621384, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05163045972585678, Lv_loss = 0.001878042588941753, Circular Tuning Loss = 0.9494189620018005\n",
      "819) Lyapunov Risk = 0.8850076794624329, MSE = 0.03325789421796799, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05158204957842827, Lv_loss = 0.0018965017516165972, Circular Tuning Loss = 0.9493399262428284\n",
      "820) Lyapunov Risk = 0.8846714496612549, MSE = 0.033248234540224075, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.051533713936805725, Lv_loss = 0.0018558294977992773, Circular Tuning Loss = 0.949260950088501\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.12500000000000003, -0.12304687500000003]\n",
      "x2 : [0.24804687500000006, 0.25000000000000006]\n",
      "==============================\n",
      "821) Lyapunov Risk = 0.8830863833427429, MSE = 0.0332043394446373, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05120406672358513, Lv_loss = 0.0018956302665174007, Circular Tuning Loss = 0.9442871809005737\n",
      "822) Lyapunov Risk = 0.8827492594718933, MSE = 0.033191971480846405, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05115610733628273, Lv_loss = 0.0018545653438195586, Circular Tuning Loss = 0.9442086219787598\n",
      "823) Lyapunov Risk = 0.882411777973175, MSE = 0.033175960183143616, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05110812187194824, Lv_loss = 0.0018154801800847054, Circular Tuning Loss = 0.9441300630569458\n",
      "824) Lyapunov Risk = 0.8820747137069702, MSE = 0.03316492959856987, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05106012150645256, Lv_loss = 0.001771982409991324, Circular Tuning Loss = 0.9440518021583557\n",
      "825) Lyapunov Risk = 0.8817379474639893, MSE = 0.03315751627087593, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05101222172379494, Lv_loss = 0.0017293202690780163, Circular Tuning Loss = 0.9439735412597656\n",
      "826) Lyapunov Risk = 0.8814011812210083, MSE = 0.03316466510295868, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05096429958939552, Lv_loss = 0.0016780066071078181, Circular Tuning Loss = 0.9438952803611755\n",
      "827) Lyapunov Risk = 0.8810643553733826, MSE = 0.0331476666033268, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05091644823551178, Lv_loss = 0.0016429645475000143, Circular Tuning Loss = 0.9438170790672302\n",
      "828) Lyapunov Risk = 0.8807274103164673, MSE = 0.033089324831962585, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05086873471736908, Lv_loss = 0.0016379510052502155, Circular Tuning Loss = 0.9437389373779297\n",
      "829) Lyapunov Risk = 0.8803905248641968, MSE = 0.03305675834417343, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05082106962800026, Lv_loss = 0.0016138323117047548, Circular Tuning Loss = 0.9436608552932739\n",
      "830) Lyapunov Risk = 0.8800538778305054, MSE = 0.03302986919879913, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.050773363560438156, Lv_loss = 0.0015834611840546131, Circular Tuning Loss = 0.9435827732086182\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.036132812500000014, -0.035156250000000014]\n",
      "x2 : [0.17089843750000006, 0.17187500000000006]\n",
      "==============================\n",
      "831) Lyapunov Risk = 0.8782213926315308, MSE = 0.03295961767435074, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.050449930131435394, Lv_loss = 0.0015736258355900645, Circular Tuning Loss = 0.9384778738021851\n",
      "832) Lyapunov Risk = 0.8778835535049438, MSE = 0.03298800811171532, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.0504024475812912, Lv_loss = 0.0015026500914245844, Circular Tuning Loss = 0.9384002685546875\n",
      "833) Lyapunov Risk = 0.8775455355644226, MSE = 0.03294999897480011, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.0503549687564373, Lv_loss = 0.0014804762322455645, Circular Tuning Loss = 0.9383231401443481\n",
      "834) Lyapunov Risk = 0.8772081732749939, MSE = 0.032958049327135086, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.050307489931583405, Lv_loss = 0.0014246940845623612, Circular Tuning Loss = 0.9382461309432983\n",
      "835) Lyapunov Risk = 0.8768723607063293, MSE = 0.03298259526491165, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.050260029733181, Lv_loss = 0.0013609192101284862, Circular Tuning Loss = 0.9381694197654724\n",
      "836) Lyapunov Risk = 0.8765374422073364, MSE = 0.032956600189208984, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.050212711095809937, Lv_loss = 0.0013346591731533408, Circular Tuning Loss = 0.9380927085876465\n",
      "837) Lyapunov Risk = 0.8762022256851196, MSE = 0.03293922543525696, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05016542598605156, Lv_loss = 0.0013001873157918453, Circular Tuning Loss = 0.9380163550376892\n",
      "838) Lyapunov Risk = 0.8758670687675476, MSE = 0.03289952501654625, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.0501181036233902, Lv_loss = 0.0012814132496714592, Circular Tuning Loss = 0.9379399418830872\n",
      "839) Lyapunov Risk = 0.8755320906639099, MSE = 0.032842591404914856, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.05007074773311615, Lv_loss = 0.0012744395062327385, Circular Tuning Loss = 0.937863826751709\n",
      "840) Lyapunov Risk = 0.8751969337463379, MSE = 0.032804396003484726, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.050023362040519714, Lv_loss = 0.0012512357207015157, Circular Tuning Loss = 0.937787652015686\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.43798828125000011, -0.43750000000000011]\n",
      "x2 : [0.75000000000000022, 0.75097656250000022]\n",
      "==============================\n",
      "841) Lyapunov Risk = 0.8757665753364563, MSE = 0.03273434937000275, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.049705881625413895, Lv_loss = 0.0012656368780881166, Circular Tuning Loss = 0.9367014765739441\n",
      "842) Lyapunov Risk = 0.8754323720932007, MSE = 0.032798878848552704, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04965895786881447, Lv_loss = 0.0011608015047386289, Circular Tuning Loss = 0.9366236925125122\n",
      "843) Lyapunov Risk = 0.8750956058502197, MSE = 0.03261761739850044, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04961215332150459, Lv_loss = 0.0012323937844485044, Circular Tuning Loss = 0.9365460276603699\n",
      "844) Lyapunov Risk = 0.8747603297233582, MSE = 0.03256317600607872, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.049565475434064865, Lv_loss = 0.0012081533204764128, Circular Tuning Loss = 0.9364685416221619\n",
      "845) Lyapunov Risk = 0.8744259476661682, MSE = 0.03258208557963371, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04951878637075424, Lv_loss = 0.001142363646067679, Circular Tuning Loss = 0.9363910555839539\n",
      "846) Lyapunov Risk = 0.8740931749343872, MSE = 0.03251313045620918, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04947216063737869, Lv_loss = 0.0011525724548846483, Circular Tuning Loss = 0.9363135695457458\n",
      "847) Lyapunov Risk = 0.8737568855285645, MSE = 0.03254364803433418, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04942554235458374, Lv_loss = 0.0010879989713430405, Circular Tuning Loss = 0.9362360835075378\n",
      "848) Lyapunov Risk = 0.8734221458435059, MSE = 0.03248149901628494, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04937887564301491, Lv_loss = 0.0010965581750497222, Circular Tuning Loss = 0.9361584782600403\n",
      "849) Lyapunov Risk = 0.8730893135070801, MSE = 0.03249356150627136, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.0493321530520916, Lv_loss = 0.0010535261826589704, Circular Tuning Loss = 0.936081051826477\n",
      "850) Lyapunov Risk = 0.8727574348449707, MSE = 0.032534580677747726, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04928537458181381, Lv_loss = 0.000982192112132907, Circular Tuning Loss = 0.9360035061836243\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.43798828125000011, -0.43750000000000011]\n",
      "x2 : [0.75000000000000022, 0.75097656250000022]\n",
      "==============================\n",
      "851) Lyapunov Risk = 0.8733126521110535, MSE = 0.03239510953426361, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04897382855415344, Lv_loss = 0.0010495452443137765, Circular Tuning Loss = 0.9349077939987183\n",
      "852) Lyapunov Risk = 0.8729758262634277, MSE = 0.032505739480257034, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04892745986580849, Lv_loss = 0.000915199052542448, Circular Tuning Loss = 0.9348284602165222\n",
      "853) Lyapunov Risk = 0.8726401925086975, MSE = 0.03239221125841141, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.048881206661462784, Lv_loss = 0.0009338060626760125, Circular Tuning Loss = 0.9347490668296814\n",
      "854) Lyapunov Risk = 0.8723077178001404, MSE = 0.032238855957984924, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.0488349124789238, Lv_loss = 0.000974409282207489, Circular Tuning Loss = 0.9346696734428406\n",
      "855) Lyapunov Risk = 0.8719767332077026, MSE = 0.03226872906088829, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.048788584768772125, Lv_loss = 0.0008964039152488112, Circular Tuning Loss = 0.9345903992652893\n",
      "856) Lyapunov Risk = 0.8716442584991455, MSE = 0.032177578657865524, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04874223843216896, Lv_loss = 0.0009172349818982184, Circular Tuning Loss = 0.9345110058784485\n",
      "857) Lyapunov Risk = 0.871309757232666, MSE = 0.032160684466362, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.048696015030145645, Lv_loss = 0.0008864005212672055, Circular Tuning Loss = 0.9344316124916077\n",
      "858) Lyapunov Risk = 0.8709797859191895, MSE = 0.032106880098581314, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04864973574876785, Lv_loss = 0.0008864259580150247, Circular Tuning Loss = 0.9343523383140564\n",
      "859) Lyapunov Risk = 0.8706480264663696, MSE = 0.03210024908185005, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04860343039035797, Lv_loss = 0.0008653901750221848, Circular Tuning Loss = 0.9342730045318604\n",
      "860) Lyapunov Risk = 0.8703169822692871, MSE = 0.0321698933839798, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.0485570915043354, Lv_loss = 0.0007953832391649485, Circular Tuning Loss = 0.9341936111450195\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.039062500000000014, -0.038085937500000014]\n",
      "x2 : [0.18652343750000006, 0.18750000000000006]\n",
      "==============================\n",
      "861) Lyapunov Risk = 0.8685550689697266, MSE = 0.03207678720355034, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04825138673186302, Lv_loss = 0.0008113942458294332, Circular Tuning Loss = 0.929243266582489\n",
      "862) Lyapunov Risk = 0.8682217597961426, MSE = 0.03213725984096527, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.0482054278254509, Lv_loss = 0.0007542773382738233, Circular Tuning Loss = 0.9291643500328064\n",
      "863) Lyapunov Risk = 0.8678911328315735, MSE = 0.03216128051280975, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04815959557890892, Lv_loss = 0.0007253470248542726, Circular Tuning Loss = 0.9290858507156372\n",
      "864) Lyapunov Risk = 0.8675600290298462, MSE = 0.03212520480155945, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04811376705765724, Lv_loss = 0.0007223539869301021, Circular Tuning Loss = 0.9290074706077576\n",
      "865) Lyapunov Risk = 0.8672296404838562, MSE = 0.032112058252096176, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04806792736053467, Lv_loss = 0.0007125372067093849, Circular Tuning Loss = 0.9289292693138123\n",
      "866) Lyapunov Risk = 0.8668988347053528, MSE = 0.03211035951972008, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.0480220764875412, Lv_loss = 0.000699802883900702, Circular Tuning Loss = 0.928851306438446\n",
      "867) Lyapunov Risk = 0.8665679693222046, MSE = 0.03206491470336914, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04797620698809624, Lv_loss = 0.0006960956961847842, Circular Tuning Loss = 0.9287732839584351\n",
      "868) Lyapunov Risk = 0.8662384152412415, MSE = 0.03197314962744713, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.047930486500263214, Lv_loss = 0.0007033647270873189, Circular Tuning Loss = 0.9286953806877136\n",
      "869) Lyapunov Risk = 0.8659089803695679, MSE = 0.031925104558467865, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.047884732484817505, Lv_loss = 0.0006974353455007076, Circular Tuning Loss = 0.9286177158355713\n",
      "870) Lyapunov Risk = 0.8655803203582764, MSE = 0.031905002892017365, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.047839097678661346, Lv_loss = 0.000683437567204237, Circular Tuning Loss = 0.9285399317741394\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.035156250000000014, -0.034179687500000014]\n",
      "x2 : [0.18652343750000006, 0.18750000000000006]\n",
      "==============================\n",
      "871) Lyapunov Risk = 0.8638302683830261, MSE = 0.03184137120842934, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04753924906253815, Lv_loss = 0.000679895980283618, Circular Tuning Loss = 0.9236464500427246\n",
      "872) Lyapunov Risk = 0.8634993433952332, MSE = 0.0318758562207222, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04749388247728348, Lv_loss = 0.0006608307012356818, Circular Tuning Loss = 0.9235694408416748\n",
      "873) Lyapunov Risk = 0.8631688356399536, MSE = 0.03188251703977585, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.047448527067899704, Lv_loss = 0.000657438300549984, Circular Tuning Loss = 0.9234927296638489\n",
      "874) Lyapunov Risk = 0.8628394603729248, MSE = 0.03188297152519226, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.047403182834386826, Lv_loss = 0.0006552534177899361, Circular Tuning Loss = 0.923416256904602\n",
      "875) Lyapunov Risk = 0.8625116348266602, MSE = 0.03189752250909805, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04735816270112991, Lv_loss = 0.0006490552914328873, Circular Tuning Loss = 0.9233400821685791\n",
      "876) Lyapunov Risk = 0.8621839284896851, MSE = 0.031891774386167526, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.0473131500184536, Lv_loss = 0.0006461293087340891, Circular Tuning Loss = 0.9232643246650696\n",
      "877) Lyapunov Risk = 0.8618553280830383, MSE = 0.03186521679162979, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04726812615990639, Lv_loss = 0.0006407012115232646, Circular Tuning Loss = 0.9231885671615601\n",
      "878) Lyapunov Risk = 0.861526608467102, MSE = 0.031784411519765854, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04722309485077858, Lv_loss = 0.0006449000211432576, Circular Tuning Loss = 0.9231129288673401\n",
      "879) Lyapunov Risk = 0.8611980676651001, MSE = 0.031725406646728516, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04717803746461868, Lv_loss = 0.00064079649746418, Circular Tuning Loss = 0.9230375289916992\n",
      "880) Lyapunov Risk = 0.8608705401420593, MSE = 0.03169500455260277, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.047132961452007294, Lv_loss = 0.0006276423227973282, Circular Tuning Loss = 0.9229621887207031\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.0078125000000000017, -0.0068359375000000017]\n",
      "x2 : [0.18652343750000006, 0.18750000000000006]\n",
      "==============================\n",
      "881) Lyapunov Risk = 0.859137773513794, MSE = 0.03159170225262642, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04683871567249298, Lv_loss = 0.000632661278359592, Circular Tuning Loss = 0.9181340336799622\n",
      "882) Lyapunov Risk = 0.8588083386421204, MSE = 0.031620386987924576, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.0467938594520092, Lv_loss = 0.0006124916253611445, Circular Tuning Loss = 0.9180595874786377\n",
      "883) Lyapunov Risk = 0.858478307723999, MSE = 0.031607627868652344, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.046749014407396317, Lv_loss = 0.0006114376010373235, Circular Tuning Loss = 0.9179853200912476\n",
      "884) Lyapunov Risk = 0.8581487536430359, MSE = 0.031596992164850235, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04670418053865433, Lv_loss = 0.0006116090225987136, Circular Tuning Loss = 0.9179115295410156\n",
      "885) Lyapunov Risk = 0.8578205108642578, MSE = 0.03163362294435501, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04665935039520264, Lv_loss = 0.0006009997450746596, Circular Tuning Loss = 0.9178379774093628\n",
      "886) Lyapunov Risk = 0.8574925065040588, MSE = 0.03162040188908577, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.046614523977041245, Lv_loss = 0.000603527994826436, Circular Tuning Loss = 0.9177646636962891\n",
      "887) Lyapunov Risk = 0.8571640849113464, MSE = 0.03163124993443489, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04656971991062164, Lv_loss = 0.000592160620726645, Circular Tuning Loss = 0.9176914095878601\n",
      "888) Lyapunov Risk = 0.8568357825279236, MSE = 0.03154359012842178, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04652489721775055, Lv_loss = 0.0006030649528838694, Circular Tuning Loss = 0.9176185131072998\n",
      "889) Lyapunov Risk = 0.8565076589584351, MSE = 0.031519901007413864, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04648008570075035, Lv_loss = 0.0005927368183620274, Circular Tuning Loss = 0.91754549741745\n",
      "890) Lyapunov Risk = 0.8561808466911316, MSE = 0.03147969767451286, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04643542692065239, Lv_loss = 0.0005845677806064487, Circular Tuning Loss = 0.9174728393554688\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.0039062500000000009, -0.0029296875000000009]\n",
      "x2 : [0.19433593750000006, 0.19531250000000006]\n",
      "==============================\n",
      "891) Lyapunov Risk = 0.854478120803833, MSE = 0.03137035295367241, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04614667966961861, Lv_loss = 0.000592979893554002, Circular Tuning Loss = 0.912717878818512\n",
      "892) Lyapunov Risk = 0.8541496992111206, MSE = 0.031430378556251526, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04610259458422661, Lv_loss = 0.0005662064650095999, Circular Tuning Loss = 0.9126458764076233\n",
      "893) Lyapunov Risk = 0.8538210988044739, MSE = 0.03138452023267746, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04605855047702789, Lv_loss = 0.0005751354619860649, Circular Tuning Loss = 0.9125744104385376\n",
      "894) Lyapunov Risk = 0.8534934520721436, MSE = 0.03138644993305206, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.046014491468667984, Lv_loss = 0.0005707239033654332, Circular Tuning Loss = 0.912503182888031\n",
      "895) Lyapunov Risk = 0.8531672954559326, MSE = 0.0314096137881279, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.045970525592565536, Lv_loss = 0.0005622246535494924, Circular Tuning Loss = 0.9124321341514587\n",
      "896) Lyapunov Risk = 0.8528411984443665, MSE = 0.03138374537229538, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04592655226588249, Lv_loss = 0.0005662411567755044, Circular Tuning Loss = 0.9123615026473999\n",
      "897) Lyapunov Risk = 0.85251384973526, MSE = 0.03139521926641464, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04588257521390915, Lv_loss = 0.0005541497375816107, Circular Tuning Loss = 0.9122906923294067\n",
      "898) Lyapunov Risk = 0.8521869778633118, MSE = 0.03131294995546341, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04583858326077461, Lv_loss = 0.0005650556995533407, Circular Tuning Loss = 0.9122201800346375\n",
      "899) Lyapunov Risk = 0.8518618941307068, MSE = 0.0312783382833004, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04579465836286545, Lv_loss = 0.0005623046890832484, Circular Tuning Loss = 0.9121497273445129\n",
      "900) Lyapunov Risk = 0.8515375256538391, MSE = 0.03126602619886398, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04575076326727867, Lv_loss = 0.0005511624622158706, Circular Tuning Loss = 0.912079393863678\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.062500000000000014, -0.060546875000000014]\n",
      "x2 : [0.24804687500000006, 0.25000000000000006]\n",
      "==============================\n",
      "901) Lyapunov Risk = 0.8500298261642456, MSE = 0.031161028891801834, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04546753317117691, Lv_loss = 0.0006101739127188921, Circular Tuning Loss = 0.9074898958206177\n",
      "902) Lyapunov Risk = 0.8497018218040466, MSE = 0.031220510601997375, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04542386159300804, Lv_loss = 0.0005803254898637533, Circular Tuning Loss = 0.9074201583862305\n",
      "903) Lyapunov Risk = 0.8493744730949402, MSE = 0.031168222427368164, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04538021609187126, Lv_loss = 0.0005860094679519534, Circular Tuning Loss = 0.9073507189750671\n",
      "904) Lyapunov Risk = 0.8490490317344666, MSE = 0.031166942790150642, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04533659666776657, Lv_loss = 0.0005794062744826078, Circular Tuning Loss = 0.9072815775871277\n",
      "905) Lyapunov Risk = 0.8487245440483093, MSE = 0.03119550459086895, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.045292988419532776, Lv_loss = 0.0005672703264281154, Circular Tuning Loss = 0.9072126746177673\n",
      "906) Lyapunov Risk = 0.8483999967575073, MSE = 0.03116717003285885, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.045249395072460175, Lv_loss = 0.0005720643093809485, Circular Tuning Loss = 0.9071440696716309\n",
      "907) Lyapunov Risk = 0.8480747938156128, MSE = 0.031179413199424744, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04520583152770996, Lv_loss = 0.0005602919263765216, Circular Tuning Loss = 0.9070755839347839\n",
      "908) Lyapunov Risk = 0.8477503061294556, MSE = 0.03111835941672325, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.045162420719861984, Lv_loss = 0.0005672562401741743, Circular Tuning Loss = 0.907007098197937\n",
      "909) Lyapunov Risk = 0.84742671251297, MSE = 0.031084619462490082, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04511900246143341, Lv_loss = 0.0005636495188809931, Circular Tuning Loss = 0.9069387316703796\n",
      "910) Lyapunov Risk = 0.8471034169197083, MSE = 0.03105962835252285, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.045075561851263046, Lv_loss = 0.0005537334945984185, Circular Tuning Loss = 0.9068703651428223\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.062500000000000014, -0.061523437500000014]\n",
      "x2 : [0.24902343750000006, 0.25000000000000006]\n",
      "==============================\n",
      "911) Lyapunov Risk = 0.845594048500061, MSE = 0.03096083365380764, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.044797565788030624, Lv_loss = 0.0005921699339523911, Circular Tuning Loss = 0.9023330211639404\n",
      "912) Lyapunov Risk = 0.845268189907074, MSE = 0.03101661615073681, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04475437477231026, Lv_loss = 0.0005587058840319514, Circular Tuning Loss = 0.9022653698921204\n",
      "913) Lyapunov Risk = 0.8449419736862183, MSE = 0.030952028930187225, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04471120610833168, Lv_loss = 0.0005658392328768969, Circular Tuning Loss = 0.9021977782249451\n",
      "914) Lyapunov Risk = 0.8446168303489685, MSE = 0.030939001590013504, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.044668037444353104, Lv_loss = 0.0005574178067035973, Circular Tuning Loss = 0.9021304845809937\n",
      "915) Lyapunov Risk = 0.8442922830581665, MSE = 0.030964188277721405, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04462490230798721, Lv_loss = 0.0005413445178419352, Circular Tuning Loss = 0.9020633697509766\n",
      "916) Lyapunov Risk = 0.8439679741859436, MSE = 0.03093692846596241, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.044581905007362366, Lv_loss = 0.0005420425441116095, Circular Tuning Loss = 0.9019964933395386\n",
      "917) Lyapunov Risk = 0.8436427712440491, MSE = 0.030931491404771805, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04453892633318901, Lv_loss = 0.0005305844242684543, Circular Tuning Loss = 0.9019297361373901\n",
      "918) Lyapunov Risk = 0.8433179259300232, MSE = 0.030861714854836464, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04449604079127312, Lv_loss = 0.0005393606843426824, Circular Tuning Loss = 0.9018629193305969\n",
      "919) Lyapunov Risk = 0.842994213104248, MSE = 0.030856024473905563, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04445315897464752, Lv_loss = 0.0005272168200463057, Circular Tuning Loss = 0.9017962217330933\n",
      "920) Lyapunov Risk = 0.8426709175109863, MSE = 0.030806606635451317, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.044410306960344315, Lv_loss = 0.0005239596939645708, Circular Tuning Loss = 0.9017294645309448\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.031250000000000007, -0.030273437500000007]\n",
      "x2 : [0.24902343750000006, 0.25000000000000006]\n",
      "==============================\n",
      "921) Lyapunov Risk = 0.8411561846733093, MSE = 0.030715439468622208, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04413752630352974, Lv_loss = 0.0005511757335625589, Circular Tuning Loss = 0.8972494602203369\n",
      "922) Lyapunov Risk = 0.8408302068710327, MSE = 0.030785556882619858, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.044094860553741455, Lv_loss = 0.0005107044125907123, Circular Tuning Loss = 0.8971830010414124\n",
      "923) Lyapunov Risk = 0.8405035734176636, MSE = 0.030707793310284615, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.044052205979824066, Lv_loss = 0.0005211223615333438, Circular Tuning Loss = 0.8971168398857117\n",
      "924) Lyapunov Risk = 0.8401782512664795, MSE = 0.03070227988064289, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.044009555131196976, Lv_loss = 0.00050587288569659, Circular Tuning Loss = 0.8970508575439453\n",
      "925) Lyapunov Risk = 0.839853048324585, MSE = 0.030709607526659966, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.043966904282569885, Lv_loss = 0.0004913890734314919, Circular Tuning Loss = 0.8969850540161133\n",
      "926) Lyapunov Risk = 0.8395285606384277, MSE = 0.030688617378473282, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04392436519265175, Lv_loss = 0.00048619802691973746, Circular Tuning Loss = 0.8969191908836365\n",
      "927) Lyapunov Risk = 0.8392030596733093, MSE = 0.03066173754632473, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04388180375099182, Lv_loss = 0.00047806327347643673, Circular Tuning Loss = 0.8968535661697388\n",
      "928) Lyapunov Risk = 0.8388777375221252, MSE = 0.030574362725019455, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04383920505642891, Lv_loss = 0.0004901928477920592, Circular Tuning Loss = 0.8967879414558411\n",
      "929) Lyapunov Risk = 0.8385535478591919, MSE = 0.03059045411646366, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04379658028483391, Lv_loss = 0.00047250083298422396, Circular Tuning Loss = 0.8967225551605225\n",
      "930) Lyapunov Risk = 0.838229775428772, MSE = 0.03050585277378559, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.043754078447818756, Lv_loss = 0.0004816546570509672, Circular Tuning Loss = 0.8966571092605591\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.47265625000000011, -0.47201770307611979]\n",
      "x2 : [0.85937500000000022, 0.8605056429659792]\n",
      "==============================\n",
      "931) Lyapunov Risk = 0.8394132256507874, MSE = 0.030444201081991196, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04348757863044739, Lv_loss = 0.00048310362035408616, Circular Tuning Loss = 0.8969351053237915\n",
      "932) Lyapunov Risk = 0.8390908241271973, MSE = 0.03059149719774723, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04344421625137329, Lv_loss = 0.00043278964585624635, Circular Tuning Loss = 0.8968670964241028\n",
      "933) Lyapunov Risk = 0.8387663960456848, MSE = 0.030348842963576317, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04340168833732605, Lv_loss = 0.0004688080516643822, Circular Tuning Loss = 0.8967989683151245\n",
      "934) Lyapunov Risk = 0.8384429216384888, MSE = 0.03036743402481079, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04335958510637283, Lv_loss = 0.00043897988507524133, Circular Tuning Loss = 0.8967307209968567\n",
      "935) Lyapunov Risk = 0.8381155133247375, MSE = 0.03030218556523323, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04331745207309723, Lv_loss = 0.0004451732093002647, Circular Tuning Loss = 0.8966624736785889\n",
      "936) Lyapunov Risk = 0.8377923965454102, MSE = 0.030328204855322838, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04327530786395073, Lv_loss = 0.0004350637609604746, Circular Tuning Loss = 0.8965941071510315\n",
      "937) Lyapunov Risk = 0.8374707102775574, MSE = 0.030299145728349686, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.043233148753643036, Lv_loss = 0.0004377298755571246, Circular Tuning Loss = 0.8965258598327637\n",
      "938) Lyapunov Risk = 0.8371499180793762, MSE = 0.030213650315999985, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04319094866514206, Lv_loss = 0.0004626943846233189, Circular Tuning Loss = 0.8964574337005615\n",
      "939) Lyapunov Risk = 0.8368297815322876, MSE = 0.030384430661797523, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04314872995018959, Lv_loss = 0.0004248369368724525, Circular Tuning Loss = 0.8963890671730042\n",
      "940) Lyapunov Risk = 0.8365058302879333, MSE = 0.030218644067645073, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04310648888349533, Lv_loss = 0.000454083172371611, Circular Tuning Loss = 0.8963205218315125\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.066406250000000028, -0.065429687500000028]\n",
      "x2 : [0.24902343750000006, 0.25000000000000006]\n",
      "==============================\n",
      "941) Lyapunov Risk = 0.8349695801734924, MSE = 0.03019503876566887, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04284364730119705, Lv_loss = 0.0004433030844666064, Circular Tuning Loss = 0.891898512840271\n",
      "942) Lyapunov Risk = 0.8346490263938904, MSE = 0.03029964677989483, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04280198737978935, Lv_loss = 0.00041229583439417183, Circular Tuning Loss = 0.8918304443359375\n",
      "943) Lyapunov Risk = 0.8343296051025391, MSE = 0.030144525691866875, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04276047274470329, Lv_loss = 0.000435973284766078, Circular Tuning Loss = 0.8917625546455383\n",
      "944) Lyapunov Risk = 0.834010660648346, MSE = 0.030184997245669365, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04271898418664932, Lv_loss = 0.0004139800148550421, Circular Tuning Loss = 0.8916946649551392\n",
      "945) Lyapunov Risk = 0.833686113357544, MSE = 0.030112143605947495, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.04267752543091774, Lv_loss = 0.00042877497617155313, Circular Tuning Loss = 0.8916269540786743\n",
      "946) Lyapunov Risk = 0.8333635330200195, MSE = 0.03018546663224697, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.04263616353273392, Lv_loss = 0.00040892817196436226, Circular Tuning Loss = 0.8915592432022095\n",
      "947) Lyapunov Risk = 0.833042562007904, MSE = 0.03008160926401615, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.04259488731622696, Lv_loss = 0.0004245401651132852, Circular Tuning Loss = 0.8914915323257446\n",
      "948) Lyapunov Risk = 0.8327236771583557, MSE = 0.030028507113456726, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.04255357012152672, Lv_loss = 0.0004328234645072371, Circular Tuning Loss = 0.8914238214492798\n",
      "949) Lyapunov Risk = 0.8324065804481506, MSE = 0.030141649767756462, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.04251221567392349, Lv_loss = 0.0004029371193610132, Circular Tuning Loss = 0.8913561105728149\n",
      "950) Lyapunov Risk = 0.832086443901062, MSE = 0.029969098046422005, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.04247084632515907, Lv_loss = 0.0004309101786930114, Circular Tuning Loss = 0.891288161277771\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.47753906250000011, -0.47656250000000011]\n",
      "x2 : [0.87890625000000022, 0.87988281250000022]\n",
      "==============================\n",
      "951) Lyapunov Risk = 0.8333500027656555, MSE = 0.030006246641278267, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.0422130785882473, Lv_loss = 0.0004090600705239922, Circular Tuning Loss = 0.8917770981788635\n",
      "952) Lyapunov Risk = 0.8330301642417908, MSE = 0.030101366341114044, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.042171984910964966, Lv_loss = 0.0003771168121602386, Circular Tuning Loss = 0.8917065262794495\n",
      "953) Lyapunov Risk = 0.8327150344848633, MSE = 0.029855554923415184, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.04213089868426323, Lv_loss = 0.0004090334696229547, Circular Tuning Loss = 0.8916359543800354\n",
      "954) Lyapunov Risk = 0.832405149936676, MSE = 0.029933901503682137, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.042089805006980896, Lv_loss = 0.000369252054952085, Circular Tuning Loss = 0.891565203666687\n",
      "955) Lyapunov Risk = 0.8320871591567993, MSE = 0.029723718762397766, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.042048681527376175, Lv_loss = 0.0004099056823179126, Circular Tuning Loss = 0.8914943933486938\n",
      "956) Lyapunov Risk = 0.8317633271217346, MSE = 0.029941143468022346, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.042007531970739365, Lv_loss = 0.0003563329519238323, Circular Tuning Loss = 0.891423225402832\n",
      "957) Lyapunov Risk = 0.8314376473426819, MSE = 0.029662488028407097, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.04196636378765106, Lv_loss = 0.00041380213224329054, Circular Tuning Loss = 0.8913521766662598\n",
      "958) Lyapunov Risk = 0.8311124444007874, MSE = 0.029816290363669395, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.04192517325282097, Lv_loss = 0.000381368154194206, Circular Tuning Loss = 0.8912809491157532\n",
      "959) Lyapunov Risk = 0.8307932019233704, MSE = 0.029818657785654068, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.04188401997089386, Lv_loss = 0.0003806177992373705, Circular Tuning Loss = 0.891209602355957\n",
      "960) Lyapunov Risk = 0.8304760456085205, MSE = 0.029700960963964462, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.04184286668896675, Lv_loss = 0.0003971692640334368, Circular Tuning Loss = 0.8911382555961609\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.063476562500000028, -0.062500000000000014]\n",
      "x2 : [0.31250000000000011, 0.31445312500000011]\n",
      "==============================\n",
      "961) Lyapunov Risk = 0.8291523456573486, MSE = 0.029792459681630135, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.041589491069316864, Lv_loss = 0.00040831713704392314, Circular Tuning Loss = 0.8869732618331909\n",
      "962) Lyapunov Risk = 0.8288343548774719, MSE = 0.02974710613489151, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.041548628360033035, Lv_loss = 0.0004152101755607873, Circular Tuning Loss = 0.8869020342826843\n",
      "963) Lyapunov Risk = 0.8285125494003296, MSE = 0.029774993658065796, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.04150784760713577, Lv_loss = 0.000394830567529425, Circular Tuning Loss = 0.8868309259414673\n",
      "964) Lyapunov Risk = 0.8281934857368469, MSE = 0.029652312397956848, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.04146716371178627, Lv_loss = 0.00041518823127262294, Circular Tuning Loss = 0.8867599368095398\n",
      "965) Lyapunov Risk = 0.8278743028640747, MSE = 0.029721295461058617, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.04142652451992035, Lv_loss = 0.0003924835764337331, Circular Tuning Loss = 0.8866890072822571\n",
      "966) Lyapunov Risk = 0.8275569677352905, MSE = 0.029683468863368034, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.04138588532805443, Lv_loss = 0.00039002299308776855, Circular Tuning Loss = 0.8866181969642639\n",
      "967) Lyapunov Risk = 0.8272413015365601, MSE = 0.029535045847296715, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.041345227509737015, Lv_loss = 0.0004116305790375918, Circular Tuning Loss = 0.8865472078323364\n",
      "968) Lyapunov Risk = 0.8269239664077759, MSE = 0.029615798965096474, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.041304539889097214, Lv_loss = 0.0003800832782872021, Circular Tuning Loss = 0.886476457118988\n",
      "969) Lyapunov Risk = 0.8266079425811768, MSE = 0.029523659497499466, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.04126393049955368, Lv_loss = 0.00039147341158241034, Circular Tuning Loss = 0.8864055871963501\n",
      "970) Lyapunov Risk = 0.8262909650802612, MSE = 0.029510846361517906, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.04122333973646164, Lv_loss = 0.0003787255845963955, Circular Tuning Loss = 0.8863347172737122\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.25000000000000006, -0.24609375000000006]\n",
      "x2 : [0.49218750000000011, 0.50000000000000011]\n",
      "==============================\n",
      "971) Lyapunov Risk = 0.8257386684417725, MSE = 0.029459411278367043, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.040974777191877365, Lv_loss = 0.0005743135698139668, Circular Tuning Loss = 0.8831068873405457\n",
      "972) Lyapunov Risk = 0.8254228234291077, MSE = 0.029607709497213364, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.040934525430202484, Lv_loss = 0.0005268168170005083, Circular Tuning Loss = 0.8830354809761047\n",
      "973) Lyapunov Risk = 0.8251036405563354, MSE = 0.02944459766149521, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.04089434817433357, Lv_loss = 0.0005581285804510117, Circular Tuning Loss = 0.882964015007019\n",
      "974) Lyapunov Risk = 0.8247873187065125, MSE = 0.029476281255483627, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.04085417836904526, Lv_loss = 0.0005352583830244839, Circular Tuning Loss = 0.8828928470611572\n",
      "975) Lyapunov Risk = 0.824470043182373, MSE = 0.029467005282640457, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.040813982486724854, Lv_loss = 0.0005305811064317822, Circular Tuning Loss = 0.8828215003013611\n",
      "976) Lyapunov Risk = 0.8241522908210754, MSE = 0.029435155913233757, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.040773916989564896, Lv_loss = 0.0005221612518653274, Circular Tuning Loss = 0.8827502727508545\n",
      "977) Lyapunov Risk = 0.8238370418548584, MSE = 0.02933112159371376, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.04073389992117882, Lv_loss = 0.000531791418325156, Circular Tuning Loss = 0.8826789855957031\n",
      "978) Lyapunov Risk = 0.823520839214325, MSE = 0.029337313026189804, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.04069386422634125, Lv_loss = 0.0005185044719837606, Circular Tuning Loss = 0.882607638835907\n",
      "979) Lyapunov Risk = 0.82320636510849, MSE = 0.02934759482741356, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.040653813630342484, Lv_loss = 0.0005013311747461557, Circular Tuning Loss = 0.8825364708900452\n",
      "980) Lyapunov Risk = 0.8228918313980103, MSE = 0.029218411073088646, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.040613725781440735, Lv_loss = 0.0005218684673309326, Circular Tuning Loss = 0.8824650645256042\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.47753906250000011, -0.47656250000000011]\n",
      "x2 : [0.90625000000000022, 0.9070831895543563]\n",
      "==============================\n",
      "981) Lyapunov Risk = 0.824289083480835, MSE = 0.029292017221450806, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.040370866656303406, Lv_loss = 0.000489508849568665, Circular Tuning Loss = 0.8832365274429321\n",
      "982) Lyapunov Risk = 0.8239741921424866, MSE = 0.029373662546277046, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.04032999277114868, Lv_loss = 0.000454065331723541, Circular Tuning Loss = 0.8831620216369629\n",
      "983) Lyapunov Risk = 0.8236579298973083, MSE = 0.029141848906874657, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.040290072560310364, Lv_loss = 0.0004879555490333587, Circular Tuning Loss = 0.8830874562263489\n",
      "984) Lyapunov Risk = 0.8233471512794495, MSE = 0.029203714802861214, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.04025043919682503, Lv_loss = 0.00044552478357218206, Circular Tuning Loss = 0.8830126523971558\n",
      "985) Lyapunov Risk = 0.8230348229408264, MSE = 0.029095662757754326, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.040210846811532974, Lv_loss = 0.00046476497664116323, Circular Tuning Loss = 0.882938027381897\n",
      "986) Lyapunov Risk = 0.8227168917655945, MSE = 0.02917259745299816, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.04017132520675659, Lv_loss = 0.0004329372604843229, Circular Tuning Loss = 0.8828633427619934\n",
      "987) Lyapunov Risk = 0.8224016427993774, MSE = 0.028926433995366096, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.04013187810778618, Lv_loss = 0.0004823477356694639, Circular Tuning Loss = 0.8827885985374451\n",
      "988) Lyapunov Risk = 0.822083592414856, MSE = 0.029155271127820015, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.04009244963526726, Lv_loss = 0.0004282582667656243, Circular Tuning Loss = 0.882714033126831\n",
      "989) Lyapunov Risk = 0.8217657208442688, MSE = 0.02901158668100834, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.040053192526102066, Lv_loss = 0.00045532535295933485, Circular Tuning Loss = 0.8826392292976379\n",
      "990) Lyapunov Risk = 0.8214506506919861, MSE = 0.02900267392396927, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.040013931691646576, Lv_loss = 0.00044413714203983545, Circular Tuning Loss = 0.8825644254684448\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.063476562500000028, -0.062500000000000014]\n",
      "x2 : [0.31250000000000011, 0.31347656250000011]\n",
      "==============================\n",
      "991) Lyapunov Risk = 0.8200808167457581, MSE = 0.029028216376900673, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.039774734526872635, Lv_loss = 0.0004291226214263588, Circular Tuning Loss = 0.8784882426261902\n",
      "992) Lyapunov Risk = 0.8197662830352783, MSE = 0.029075738042593002, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.039735645055770874, Lv_loss = 0.00041277980199083686, Circular Tuning Loss = 0.8784136772155762\n",
      "993) Lyapunov Risk = 0.8194504976272583, MSE = 0.028960570693016052, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03969655558466911, Lv_loss = 0.0004210599581710994, Circular Tuning Loss = 0.8783391118049622\n",
      "994) Lyapunov Risk = 0.8191336393356323, MSE = 0.028961151838302612, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03965747728943825, Lv_loss = 0.00041355221765115857, Circular Tuning Loss = 0.878264844417572\n",
      "995) Lyapunov Risk = 0.8188197016716003, MSE = 0.02901432476937771, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03961852192878723, Lv_loss = 0.00040014900150708854, Circular Tuning Loss = 0.8781906962394714\n",
      "996) Lyapunov Risk = 0.8185034990310669, MSE = 0.028873009607195854, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.039579782634973526, Lv_loss = 0.00041594248614273965, Circular Tuning Loss = 0.8781165480613708\n",
      "997) Lyapunov Risk = 0.8181891441345215, MSE = 0.028876110911369324, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.039541058242321014, Lv_loss = 0.00040584802627563477, Circular Tuning Loss = 0.8780427575111389\n",
      "998) Lyapunov Risk = 0.8178752064704895, MSE = 0.028873935341835022, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03950230032205582, Lv_loss = 0.0004007210081908852, Circular Tuning Loss = 0.8779688477516174\n",
      "999) Lyapunov Risk = 0.8175603151321411, MSE = 0.0288416538387537, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.039463676512241364, Lv_loss = 0.00039414639468304813, Circular Tuning Loss = 0.8778950572013855\n",
      "1000) Lyapunov Risk = 0.8172470927238464, MSE = 0.02877676673233509, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.039425041526556015, Lv_loss = 0.0003986114461440593, Circular Tuning Loss = 0.8778212070465088\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.070312500000000028, -0.069335937500000028]\n",
      "x2 : [0.31933593750000011, 0.32031250000000011]\n",
      "==============================\n",
      "1001) Lyapunov Risk = 0.815899670124054, MSE = 0.02884076163172722, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.039190538227558136, Lv_loss = 0.0003799763508141041, Circular Tuning Loss = 0.873807966709137\n",
      "1002) Lyapunov Risk = 0.8155843615531921, MSE = 0.028840478509664536, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03915225714445114, Lv_loss = 0.0003752851043827832, Circular Tuning Loss = 0.8737343549728394\n",
      "1003) Lyapunov Risk = 0.8152704238891602, MSE = 0.02875789813697338, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.039113979786634445, Lv_loss = 0.00038336796569637954, Circular Tuning Loss = 0.8736609816551208\n",
      "1004) Lyapunov Risk = 0.8149564862251282, MSE = 0.028844356536865234, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03907572478055954, Lv_loss = 0.00036499349516816437, Circular Tuning Loss = 0.8735878467559814\n",
      "1005) Lyapunov Risk = 0.8146437406539917, MSE = 0.02874409221112728, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.039037447422742844, Lv_loss = 0.0003749975294340402, Circular Tuning Loss = 0.8735148310661316\n",
      "1006) Lyapunov Risk = 0.8143309950828552, MSE = 0.02876361459493637, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.038999177515506744, Lv_loss = 0.00035930945887230337, Circular Tuning Loss = 0.8734419345855713\n",
      "1007) Lyapunov Risk = 0.8140180110931396, MSE = 0.02863217145204544, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03896088898181915, Lv_loss = 0.00037430302472785115, Circular Tuning Loss = 0.8733690977096558\n",
      "1008) Lyapunov Risk = 0.8137062788009644, MSE = 0.028736712411046028, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03892258182168007, Lv_loss = 0.0003464726032689214, Circular Tuning Loss = 0.8732964992523193\n",
      "1009) Lyapunov Risk = 0.8133950233459473, MSE = 0.02852054126560688, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03888426348567009, Lv_loss = 0.0003746999427676201, Circular Tuning Loss = 0.8732237815856934\n",
      "1010) Lyapunov Risk = 0.8130835294723511, MSE = 0.028696386143565178, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03884591907262802, Lv_loss = 0.00033827906008809805, Circular Tuning Loss = 0.8731512427330017\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.44140625000000011, -0.43750000000000011]\n",
      "x2 : [0.87500000000000022, 0.87890625000000022]\n",
      "==============================\n",
      "1011) Lyapunov Risk = 0.8143682479858398, MSE = 0.02851303666830063, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03861543908715248, Lv_loss = 0.00048030767356976867, Circular Tuning Loss = 0.8734743595123291\n",
      "1012) Lyapunov Risk = 0.8140696883201599, MSE = 0.028795644640922546, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.038577303290367126, Lv_loss = 0.00041045589023269713, Circular Tuning Loss = 0.8733994960784912\n",
      "1013) Lyapunov Risk = 0.813775897026062, MSE = 0.02836538478732109, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03853919357061386, Lv_loss = 0.0004910088609904051, Circular Tuning Loss = 0.8733246922492981\n",
      "1014) Lyapunov Risk = 0.81349116563797, MSE = 0.028800945729017258, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03850109502673149, Lv_loss = 0.0003816386160906404, Circular Tuning Loss = 0.8732499480247498\n",
      "1015) Lyapunov Risk = 0.8132200837135315, MSE = 0.02822376787662506, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.038463007658720016, Lv_loss = 0.0005050746258348227, Circular Tuning Loss = 0.8731749057769775\n",
      "1016) Lyapunov Risk = 0.8129556775093079, MSE = 0.02886820398271084, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03842492401599884, Lv_loss = 0.00035674244281835854, Circular Tuning Loss = 0.8731001019477844\n",
      "1017) Lyapunov Risk = 0.8126975893974304, MSE = 0.02808414027094841, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03838682547211647, Lv_loss = 0.0005409521399997175, Circular Tuning Loss = 0.8730251789093018\n",
      "1018) Lyapunov Risk = 0.8124240636825562, MSE = 0.028965473175048828, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.0383487232029438, Lv_loss = 0.00033791063469834626, Circular Tuning Loss = 0.8729502558708191\n",
      "1019) Lyapunov Risk = 0.8121224045753479, MSE = 0.028028802946209908, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03831059858202934, Lv_loss = 0.0005515626398846507, Circular Tuning Loss = 0.8728752136230469\n",
      "1020) Lyapunov Risk = 0.8117687702178955, MSE = 0.02889181300997734, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03827246278524399, Lv_loss = 0.00033572589745745063, Circular Tuning Loss = 0.8728001117706299\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.25000000000000006, -0.24609375000000006]\n",
      "x2 : [0.49609375000000011, 0.50000000000000011]\n",
      "==============================\n",
      "1021) Lyapunov Risk = 0.8110843300819397, MSE = 0.028071654960513115, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03804595023393631, Lv_loss = 0.0006378816324286163, Circular Tuning Loss = 0.869678258895874\n",
      "1022) Lyapunov Risk = 0.8106929063796997, MSE = 0.028703493997454643, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03800801560282707, Lv_loss = 0.0004511573351919651, Circular Tuning Loss = 0.8696027994155884\n",
      "1023) Lyapunov Risk = 0.8103150129318237, MSE = 0.028191158547997475, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.037970125675201416, Lv_loss = 0.000548549578525126, Circular Tuning Loss = 0.8695275187492371\n",
      "1024) Lyapunov Risk = 0.8099731206893921, MSE = 0.02834724448621273, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03793227672576904, Lv_loss = 0.0004999651573598385, Circular Tuning Loss = 0.8694523572921753\n",
      "1025) Lyapunov Risk = 0.8096702694892883, MSE = 0.028401946648955345, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.037894461303949356, Lv_loss = 0.00048049166798591614, Circular Tuning Loss = 0.8693772554397583\n",
      "1026) Lyapunov Risk = 0.8093910217285156, MSE = 0.028081851080060005, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03785664960741997, Lv_loss = 0.0005519430851563811, Circular Tuning Loss = 0.8693020343780518\n",
      "1027) Lyapunov Risk = 0.8091112375259399, MSE = 0.028504937887191772, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.037818849086761475, Lv_loss = 0.00044302485184744, Circular Tuning Loss = 0.8692270517349243\n",
      "1028) Lyapunov Risk = 0.8088173866271973, MSE = 0.027991479262709618, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03778105229139328, Lv_loss = 0.0005665688076987863, Circular Tuning Loss = 0.8691520690917969\n",
      "1029) Lyapunov Risk = 0.808495283126831, MSE = 0.028476929292082787, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03774326294660568, Lv_loss = 0.0004301066801417619, Circular Tuning Loss = 0.8690769672393799\n",
      "1030) Lyapunov Risk = 0.8081586956977844, MSE = 0.027986176311969757, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03770549222826958, Lv_loss = 0.000535952509380877, Circular Tuning Loss = 0.8690019845962524\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.093750000000000028, -0.092773437500000028]\n",
      "x2 : [0.37402343750000011, 0.37500000000000011]\n",
      "==============================\n",
      "1031) Lyapunov Risk = 0.8069359660148621, MSE = 0.028327904641628265, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.037483204156160355, Lv_loss = 0.0004368967784103006, Circular Tuning Loss = 0.8652740716934204\n",
      "1032) Lyapunov Risk = 0.8066021800041199, MSE = 0.02816803939640522, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.037445779889822006, Lv_loss = 0.00046408531488850713, Circular Tuning Loss = 0.8651989698410034\n",
      "1033) Lyapunov Risk = 0.8062933087348938, MSE = 0.028091488406062126, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03740839287638664, Lv_loss = 0.0004713731468655169, Circular Tuning Loss = 0.8651241064071655\n",
      "1034) Lyapunov Risk = 0.8060004711151123, MSE = 0.02830633521080017, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03737104311585426, Lv_loss = 0.00041837868047878146, Circular Tuning Loss = 0.8650493025779724\n",
      "1035) Lyapunov Risk = 0.8057083487510681, MSE = 0.028002912178635597, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03733371943235397, Lv_loss = 0.000482389674289152, Circular Tuning Loss = 0.8649743795394897\n",
      "1036) Lyapunov Risk = 0.805403470993042, MSE = 0.02832852117717266, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.037296514958143234, Lv_loss = 0.000398030475480482, Circular Tuning Loss = 0.864899754524231\n",
      "1037) Lyapunov Risk = 0.8050829768180847, MSE = 0.02792336791753769, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03725941479206085, Lv_loss = 0.0004769729566760361, Circular Tuning Loss = 0.8648249506950378\n",
      "1038) Lyapunov Risk = 0.8047533631324768, MSE = 0.028225867077708244, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03722236305475235, Lv_loss = 0.00039623078191652894, Circular Tuning Loss = 0.8647501468658447\n",
      "1039) Lyapunov Risk = 0.8044245839118958, MSE = 0.027938900515437126, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03718549758195877, Lv_loss = 0.00044330552918836474, Circular Tuning Loss = 0.8646754622459412\n",
      "1040) Lyapunov Risk = 0.8041051030158997, MSE = 0.028002044185996056, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.037148598581552505, Lv_loss = 0.00041551978210918605, Circular Tuning Loss = 0.8646008372306824\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.10937500000000003, -0.10839843750000003]\n",
      "x2 : [0.37402343750000011, 0.37500000000000011]\n",
      "==============================\n",
      "1041) Lyapunov Risk = 0.8029248714447021, MSE = 0.02802993729710579, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03693077340722084, Lv_loss = 0.0003986898227594793, Circular Tuning Loss = 0.8609052896499634\n",
      "1042) Lyapunov Risk = 0.8026180267333984, MSE = 0.027913883328437805, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03689422458410263, Lv_loss = 0.00041691376827657223, Circular Tuning Loss = 0.8608309030532837\n",
      "1043) Lyapunov Risk = 0.802311360836029, MSE = 0.028068192303180695, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.036857716739177704, Lv_loss = 0.0003768441383726895, Circular Tuning Loss = 0.8607566356658936\n",
      "1044) Lyapunov Risk = 0.8020020723342896, MSE = 0.027873322367668152, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03682129830121994, Lv_loss = 0.00041334499837830663, Circular Tuning Loss = 0.8606827855110168\n",
      "1045) Lyapunov Risk = 0.8016887903213501, MSE = 0.028086315840482712, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03678498789668083, Lv_loss = 0.0003618945775087923, Circular Tuning Loss = 0.8606090545654297\n",
      "1046) Lyapunov Risk = 0.8013719320297241, MSE = 0.027845773845911026, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03674868866801262, Lv_loss = 0.0004003637586720288, Circular Tuning Loss = 0.8605353236198425\n",
      "1047) Lyapunov Risk = 0.8010549545288086, MSE = 0.02797934040427208, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.036712463945150375, Lv_loss = 0.00036316929617896676, Circular Tuning Loss = 0.8604618310928345\n",
      "1048) Lyapunov Risk = 0.8007397651672363, MSE = 0.027845123782753944, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.036676354706287384, Lv_loss = 0.00037869857624173164, Circular Tuning Loss = 0.860388457775116\n",
      "1049) Lyapunov Risk = 0.8004273772239685, MSE = 0.027837486937642097, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03664037212729454, Lv_loss = 0.00036877120146527886, Circular Tuning Loss = 0.8603152632713318\n",
      "1050) Lyapunov Risk = 0.8001172542572021, MSE = 0.027836209163069725, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.036604396998882294, Lv_loss = 0.00036004811408929527, Circular Tuning Loss = 0.8602420687675476\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.12500000000000003, -0.12304687500000003]\n",
      "x2 : [0.49804687500000011, 0.50000000000000011]\n",
      "==============================\n",
      "1051) Lyapunov Risk = 0.7993726134300232, MSE = 0.027739373967051506, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03639088198542595, Lv_loss = 0.0004274984239600599, Circular Tuning Loss = 0.8571763634681702\n",
      "1052) Lyapunov Risk = 0.7990679740905762, MSE = 0.027921156957745552, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.036355093121528625, Lv_loss = 0.00037789795896969736, Circular Tuning Loss = 0.8571028709411621\n",
      "1053) Lyapunov Risk = 0.7987632751464844, MSE = 0.02766364812850952, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03631933405995369, Lv_loss = 0.0004237658577039838, Circular Tuning Loss = 0.8570297956466675\n",
      "1054) Lyapunov Risk = 0.7984557747840881, MSE = 0.027920575812458992, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03628360107541084, Lv_loss = 0.0003555425500962883, Circular Tuning Loss = 0.8569567799568176\n",
      "1055) Lyapunov Risk = 0.7981438636779785, MSE = 0.027651479467749596, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.036247868090867996, Lv_loss = 0.0004069286515004933, Circular Tuning Loss = 0.8568837642669678\n",
      "1056) Lyapunov Risk = 0.7978278398513794, MSE = 0.027872873470187187, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03621215373277664, Lv_loss = 0.0003449525102041662, Circular Tuning Loss = 0.8568110466003418\n",
      "1057) Lyapunov Risk = 0.7975104451179504, MSE = 0.02758404240012169, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03617642819881439, Lv_loss = 0.00039624396595172584, Circular Tuning Loss = 0.8567383289337158\n",
      "1058) Lyapunov Risk = 0.7971926927566528, MSE = 0.0277667548507452, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03614082187414169, Lv_loss = 0.0003435059916228056, Circular Tuning Loss = 0.8566657304763794\n",
      "1059) Lyapunov Risk = 0.7968762516975403, MSE = 0.027568932622671127, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03610534593462944, Lv_loss = 0.0003720620006788522, Circular Tuning Loss = 0.8565932512283325\n",
      "1060) Lyapunov Risk = 0.7965620756149292, MSE = 0.027612833306193352, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.0360698439180851, Lv_loss = 0.0003468070353846997, Circular Tuning Loss = 0.8565208911895752\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.12500000000000003, -0.12402343750000003]\n",
      "x2 : [0.49804687500000011, 0.50000000000000011]\n",
      "==============================\n",
      "1061) Lyapunov Risk = 0.7957900762557983, MSE = 0.027582082897424698, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.035860225558280945, Lv_loss = 0.00037563114892691374, Circular Tuning Loss = 0.8534775972366333\n",
      "1062) Lyapunov Risk = 0.7954763174057007, MSE = 0.02760428749024868, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.035824891179800034, Lv_loss = 0.00035597645910456777, Circular Tuning Loss = 0.8534049987792969\n",
      "1063) Lyapunov Risk = 0.7951632738113403, MSE = 0.027570288628339767, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.035789575427770615, Lv_loss = 0.00034608933492563665, Circular Tuning Loss = 0.85333251953125\n",
      "1064) Lyapunov Risk = 0.7948511242866516, MSE = 0.02755504474043846, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03575431928038597, Lv_loss = 0.00033770882873795927, Circular Tuning Loss = 0.8532602787017822\n",
      "1065) Lyapunov Risk = 0.7945390939712524, MSE = 0.02759566716849804, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03571918606758118, Lv_loss = 0.00031686536385677755, Circular Tuning Loss = 0.8531880974769592\n",
      "1066) Lyapunov Risk = 0.794226884841919, MSE = 0.02749442495405674, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03568405285477638, Lv_loss = 0.0003261043457314372, Circular Tuning Loss = 0.8531160950660706\n",
      "1067) Lyapunov Risk = 0.7939161062240601, MSE = 0.027519866824150085, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.035648904740810394, Lv_loss = 0.00030612628324888647, Circular Tuning Loss = 0.8530439734458923\n",
      "1068) Lyapunov Risk = 0.7936065196990967, MSE = 0.02744874358177185, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03561374917626381, Lv_loss = 0.00030783863621763885, Circular Tuning Loss = 0.8529720306396484\n",
      "1069) Lyapunov Risk = 0.7932969331741333, MSE = 0.027446288615465164, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.035578686743974686, Lv_loss = 0.0002877425868064165, Circular Tuning Loss = 0.8529000878334045\n",
      "1070) Lyapunov Risk = 0.7929883003234863, MSE = 0.027386443689465523, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03554361313581467, Lv_loss = 0.00028554731397889555, Circular Tuning Loss = 0.8528280854225159\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.25000000000000006, -0.24804687500000006]\n",
      "x2 : [0.49804687500000011, 0.50000000000000011]\n",
      "==============================\n",
      "1071) Lyapunov Risk = 0.7923135161399841, MSE = 0.02743508853018284, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03533788397908211, Lv_loss = 0.0003059455775655806, Circular Tuning Loss = 0.8498451113700867\n",
      "1072) Lyapunov Risk = 0.7920053005218506, MSE = 0.0274345763027668, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03530329838395119, Lv_loss = 0.0002913141215685755, Circular Tuning Loss = 0.8497728109359741\n",
      "1073) Lyapunov Risk = 0.7916984558105469, MSE = 0.02738167718052864, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03526877611875534, Lv_loss = 0.0002894323843065649, Circular Tuning Loss = 0.8497005105018616\n",
      "1074) Lyapunov Risk = 0.79139244556427, MSE = 0.02742740698158741, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03523429483175278, Lv_loss = 0.00026591410278342664, Circular Tuning Loss = 0.8496282696723938\n",
      "1075) Lyapunov Risk = 0.7910882830619812, MSE = 0.027327364310622215, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03519986569881439, Lv_loss = 0.0002790165599435568, Circular Tuning Loss = 0.8495561480522156\n",
      "1076) Lyapunov Risk = 0.7907862067222595, MSE = 0.027406854555010796, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.035165492445230484, Lv_loss = 0.00025191850727424026, Circular Tuning Loss = 0.8494840264320374\n",
      "1077) Lyapunov Risk = 0.7904850244522095, MSE = 0.027242511510849, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.035131167620420456, Lv_loss = 0.00027654325822368264, Circular Tuning Loss = 0.8494119048118591\n",
      "1078) Lyapunov Risk = 0.7901856899261475, MSE = 0.027405153959989548, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03509689122438431, Lv_loss = 0.00023330289695877582, Circular Tuning Loss = 0.8493397235870361\n",
      "1079) Lyapunov Risk = 0.7898882031440735, MSE = 0.027165692299604416, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.035062674432992935, Lv_loss = 0.0002717588795349002, Circular Tuning Loss = 0.8492675423622131\n",
      "1080) Lyapunov Risk = 0.7895932793617249, MSE = 0.027404967695474625, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.035028550773859024, Lv_loss = 0.00021460873540490866, Circular Tuning Loss = 0.8491953611373901\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.12500000000000003, -0.12402343750000003]\n",
      "x2 : [0.49902343750000011, 0.50000000000000011]\n",
      "==============================\n",
      "1081) Lyapunov Risk = 0.7887959480285645, MSE = 0.027121631428599358, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03482719883322716, Lv_loss = 0.0002637190918903798, Circular Tuning Loss = 0.8462024927139282\n",
      "1082) Lyapunov Risk = 0.7885134816169739, MSE = 0.027485152706503868, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03479363024234772, Lv_loss = 0.00018472685769665986, Circular Tuning Loss = 0.8461300730705261\n",
      "1083) Lyapunov Risk = 0.7882364988327026, MSE = 0.027035342529416084, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03476022556424141, Lv_loss = 0.0002657676232047379, Circular Tuning Loss = 0.8460578918457031\n",
      "1084) Lyapunov Risk = 0.7879657745361328, MSE = 0.02754385769367218, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03472694754600525, Lv_loss = 0.0001583410776220262, Circular Tuning Loss = 0.8459857702255249\n",
      "1085) Lyapunov Risk = 0.787700891494751, MSE = 0.026960918679833412, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03469378501176834, Lv_loss = 0.0002685263752937317, Circular Tuning Loss = 0.845913827419281\n",
      "1086) Lyapunov Risk = 0.7874400019645691, MSE = 0.0276047233492136, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.034660741686820984, Lv_loss = 0.00013424393546301872, Circular Tuning Loss = 0.8458421230316162\n",
      "1087) Lyapunov Risk = 0.7871789932250977, MSE = 0.026857146993279457, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03462779521942139, Lv_loss = 0.00027672701980918646, Circular Tuning Loss = 0.8457702994346619\n",
      "1088) Lyapunov Risk = 0.7869088053703308, MSE = 0.027652017772197723, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.034594953060150146, Lv_loss = 0.00011327118409099057, Circular Tuning Loss = 0.8456987738609314\n",
      "1089) Lyapunov Risk = 0.7866185903549194, MSE = 0.026798110455274582, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.034562207758426666, Lv_loss = 0.0002723151701502502, Circular Tuning Loss = 0.8456270694732666\n",
      "1090) Lyapunov Risk = 0.7863011360168457, MSE = 0.027579186484217644, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.0345296785235405, Lv_loss = 0.00010658872633939609, Circular Tuning Loss = 0.8455556035041809\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.25000000000000006, -0.24902343750000006]\n",
      "x2 : [0.49902343750000011, 0.50000000000000011]\n",
      "==============================\n",
      "1091) Lyapunov Risk = 0.7855741381645203, MSE = 0.026809850707650185, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.034332938492298126, Lv_loss = 0.00027455188683234155, Circular Tuning Loss = 0.8426213264465332\n",
      "1092) Lyapunov Risk = 0.7852262854576111, MSE = 0.027474340051412582, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03430074453353882, Lv_loss = 0.00010779976582853124, Circular Tuning Loss = 0.8425493836402893\n",
      "1093) Lyapunov Risk = 0.7848717570304871, MSE = 0.026855522766709328, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.034268684685230255, Lv_loss = 0.00022688809258397669, Circular Tuning Loss = 0.8424775004386902\n",
      "1094) Lyapunov Risk = 0.7845305800437927, MSE = 0.027196472510695457, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03423672541975975, Lv_loss = 0.0001343363692285493, Circular Tuning Loss = 0.8424056172370911\n",
      "1095) Lyapunov Risk = 0.784216046333313, MSE = 0.027021905407309532, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03420491889119148, Lv_loss = 0.00016239007527474314, Circular Tuning Loss = 0.8423337936401367\n",
      "1096) Lyapunov Risk = 0.7839289903640747, MSE = 0.026946457102894783, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03417321667075157, Lv_loss = 0.00016730264178477228, Circular Tuning Loss = 0.8422618508338928\n",
      "1097) Lyapunov Risk = 0.7836615443229675, MSE = 0.027150357142090797, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.034141603857278824, Lv_loss = 0.00011701943003572524, Circular Tuning Loss = 0.8421900272369385\n",
      "1098) Lyapunov Risk = 0.7834014892578125, MSE = 0.026827622205018997, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03411008045077324, Lv_loss = 0.00018318850197829306, Circular Tuning Loss = 0.8421178460121155\n",
      "1099) Lyapunov Risk = 0.7831379175186157, MSE = 0.027227245271205902, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.034078631550073624, Lv_loss = 9.420564310858026e-05, Circular Tuning Loss = 0.8420458436012268\n",
      "1100) Lyapunov Risk = 0.7828627824783325, MSE = 0.02674761600792408, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03404725342988968, Lv_loss = 0.00018345244461670518, Circular Tuning Loss = 0.8419735431671143\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.25000000000000006, -0.24902343750000006]\n",
      "x2 : [0.49902343750000011, 0.50000000000000011]\n",
      "==============================\n",
      "1101) Lyapunov Risk = 0.7821598649024963, MSE = 0.02724073827266693, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03385473042726517, Lv_loss = 8.840054942993447e-05, Circular Tuning Loss = 0.8390631675720215\n",
      "1102) Lyapunov Risk = 0.7818454504013062, MSE = 0.026798779144883156, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03382382169365883, Lv_loss = 0.00015313994663301855, Circular Tuning Loss = 0.8389903903007507\n",
      "1103) Lyapunov Risk = 0.7815332412719727, MSE = 0.027065802365541458, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03379306197166443, Lv_loss = 9.387690806761384e-05, Circular Tuning Loss = 0.8389177322387695\n",
      "1104) Lyapunov Risk = 0.7812308073043823, MSE = 0.026860449463129044, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.033762432634830475, Lv_loss = 0.00010933280282188207, Circular Tuning Loss = 0.8388451933860779\n",
      "1105) Lyapunov Risk = 0.7809406518936157, MSE = 0.026903003454208374, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03373197466135025, Lv_loss = 0.00010123828542418778, Circular Tuning Loss = 0.8387724757194519\n",
      "1106) Lyapunov Risk = 0.7806615829467773, MSE = 0.026926055550575256, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03370168060064316, Lv_loss = 9.705226693768054e-05, Circular Tuning Loss = 0.8386997580528259\n",
      "1107) Lyapunov Risk = 0.7803903818130493, MSE = 0.026760244742035866, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.033671554177999496, Lv_loss = 0.00010898990149144083, Circular Tuning Loss = 0.8386270999908447\n",
      "1108) Lyapunov Risk = 0.7801221609115601, MSE = 0.02701099030673504, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.033641498535871506, Lv_loss = 8.829899888951331e-05, Circular Tuning Loss = 0.8385543823242188\n",
      "1109) Lyapunov Risk = 0.7798526883125305, MSE = 0.02667505107820034, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03361152112483978, Lv_loss = 0.00011255981371505186, Circular Tuning Loss = 0.8384815454483032\n",
      "1110) Lyapunov Risk = 0.7795788049697876, MSE = 0.027036791667342186, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03358159586787224, Lv_loss = 8.294816507259384e-05, Circular Tuning Loss = 0.8384086489677429\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.18750000000000006, -0.18652343750000006]\n",
      "x2 : [0.49902343750000011, 0.50000000000000011]\n",
      "==============================\n",
      "1111) Lyapunov Risk = 0.7788718342781067, MSE = 0.02665545605123043, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03339346870779991, Lv_loss = 0.00012838402471970767, Circular Tuning Loss = 0.8354874849319458\n",
      "1112) Lyapunov Risk = 0.7785924077033997, MSE = 0.02704654261469841, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03336391970515251, Lv_loss = 8.100675768218935e-05, Circular Tuning Loss = 0.8354142904281616\n",
      "1113) Lyapunov Risk = 0.7783077955245972, MSE = 0.026636257767677307, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03333449736237526, Lv_loss = 0.00011987510515609756, Circular Tuning Loss = 0.8353409767150879\n",
      "1114) Lyapunov Risk = 0.778020977973938, MSE = 0.026971368119120598, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.033305149525403976, Lv_loss = 7.795130659360439e-05, Circular Tuning Loss = 0.8352676033973694\n",
      "1115) Lyapunov Risk = 0.777734637260437, MSE = 0.026623981073498726, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.033275872468948364, Lv_loss = 0.00011107813043054193, Circular Tuning Loss = 0.8351942300796509\n",
      "1116) Lyapunov Risk = 0.7774478793144226, MSE = 0.02687540277838707, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.033246662467718124, Lv_loss = 7.947959238663316e-05, Circular Tuning Loss = 0.8351209759712219\n",
      "1117) Lyapunov Risk = 0.7771627902984619, MSE = 0.02661890909075737, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.033217523247003555, Lv_loss = 0.00010182180994888768, Circular Tuning Loss = 0.8350475430488586\n",
      "1118) Lyapunov Risk = 0.77688068151474, MSE = 0.026762282475829124, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03318846598267555, Lv_loss = 8.271048136521131e-05, Circular Tuning Loss = 0.8349741101264954\n",
      "1119) Lyapunov Risk = 0.7766017913818359, MSE = 0.026648810133337975, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.033159613609313965, Lv_loss = 8.889556920621544e-05, Circular Tuning Loss = 0.8349006175994873\n",
      "1120) Lyapunov Risk = 0.7763262987136841, MSE = 0.026671152561903, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03313080593943596, Lv_loss = 8.457365038339049e-05, Circular Tuning Loss = 0.8348271250724792\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.24511718750000006, -0.24414062500000006]\n",
      "x2 : [0.49902343750000011, 0.50000000000000011]\n",
      "==============================\n",
      "1121) Lyapunov Risk = 0.7756251096725464, MSE = 0.02668500691652298, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.032946616411209106, Lv_loss = 8.116643584799021e-05, Circular Tuning Loss = 0.8319570422172546\n",
      "1122) Lyapunov Risk = 0.7753517627716064, MSE = 0.026677338406443596, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03291807696223259, Lv_loss = 8.076527592493221e-05, Circular Tuning Loss = 0.8318831920623779\n",
      "1123) Lyapunov Risk = 0.7750784754753113, MSE = 0.026680106297135353, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03288964182138443, Lv_loss = 7.720882422290742e-05, Circular Tuning Loss = 0.8318094611167908\n",
      "1124) Lyapunov Risk = 0.7748056650161743, MSE = 0.026601046323776245, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03286127746105194, Lv_loss = 8.10652127256617e-05, Circular Tuning Loss = 0.8317357301712036\n",
      "1125) Lyapunov Risk = 0.7745333909988403, MSE = 0.026679513975977898, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.032832980155944824, Lv_loss = 7.339110743487254e-05, Circular Tuning Loss = 0.8316621780395508\n",
      "1126) Lyapunov Risk = 0.7742612361907959, MSE = 0.026535553857684135, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03280474245548248, Lv_loss = 8.079196413746104e-05, Circular Tuning Loss = 0.8315885663032532\n",
      "1127) Lyapunov Risk = 0.7739893794059753, MSE = 0.02662227489054203, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03277655690908432, Lv_loss = 7.215408550109714e-05, Circular Tuning Loss = 0.8315150737762451\n",
      "1128) Lyapunov Risk = 0.7737181186676025, MSE = 0.026522699743509293, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.0327485017478466, Lv_loss = 7.790733070578426e-05, Circular Tuning Loss = 0.8314414620399475\n",
      "1129) Lyapunov Risk = 0.7734479904174805, MSE = 0.02659541368484497, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03272052854299545, Lv_loss = 6.958786252653226e-05, Circular Tuning Loss = 0.8313680291175842\n",
      "1130) Lyapunov Risk = 0.7731783390045166, MSE = 0.026481829583644867, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03269270434975624, Lv_loss = 7.687811012146994e-05, Circular Tuning Loss = 0.8312945365905762\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.22363281250000006, -0.22266460776990019]\n",
      "x2 : [0.49902343750000011, 0.50000000000000011]\n",
      "==============================\n",
      "1131) Lyapunov Risk = 0.7724716663360596, MSE = 0.026609182357788086, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03251231461763382, Lv_loss = 6.550233229063451e-05, Circular Tuning Loss = 0.8284332156181335\n",
      "1132) Lyapunov Risk = 0.7721989750862122, MSE = 0.026499398052692413, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03248479962348938, Lv_loss = 7.195408397819847e-05, Circular Tuning Loss = 0.8283595442771912\n",
      "1133) Lyapunov Risk = 0.7719275951385498, MSE = 0.026553183794021606, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03245740756392479, Lv_loss = 6.481639866251498e-05, Circular Tuning Loss = 0.8282860517501831\n",
      "1134) Lyapunov Risk = 0.7716569900512695, MSE = 0.026475127786397934, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.032430220395326614, Lv_loss = 6.829631456639618e-05, Circular Tuning Loss = 0.8282127380371094\n",
      "1135) Lyapunov Risk = 0.7713868618011475, MSE = 0.026516428217291832, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.032403092831373215, Lv_loss = 6.251304876059294e-05, Circular Tuning Loss = 0.8281394243240356\n",
      "1136) Lyapunov Risk = 0.7711177468299866, MSE = 0.02642645314335823, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.032376017421483994, Lv_loss = 6.627584662055597e-05, Circular Tuning Loss = 0.828066349029541\n",
      "1137) Lyapunov Risk = 0.7708494663238525, MSE = 0.026463042944669724, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.032349035143852234, Lv_loss = 6.168463733047247e-05, Circular Tuning Loss = 0.8279933929443359\n",
      "1138) Lyapunov Risk = 0.7705822587013245, MSE = 0.026406561955809593, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.0323222279548645, Lv_loss = 6.400056736310944e-05, Circular Tuning Loss = 0.8279205560684204\n",
      "1139) Lyapunov Risk = 0.7703153491020203, MSE = 0.026424316689372063, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03229557350277901, Lv_loss = 6.057456266717054e-05, Circular Tuning Loss = 0.8278477191925049\n",
      "1140) Lyapunov Risk = 0.7700491547584534, MSE = 0.02639317885041237, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.032268960028886795, Lv_loss = 6.169531843625009e-05, Circular Tuning Loss = 0.8277750015258789\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.43847656250000011, -0.43750000000000011]\n",
      "x2 : [0.93750000000000022, 0.93847656250000022]\n",
      "==============================\n",
      "1141) Lyapunov Risk = 0.7714245915412903, MSE = 0.026424072682857513, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.032092414796352386, Lv_loss = 6.95373018970713e-05, Circular Tuning Loss = 0.8286038637161255\n",
      "1142) Lyapunov Risk = 0.7711575627326965, MSE = 0.026456929743289948, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03206602856516838, Lv_loss = 5.950098784524016e-05, Circular Tuning Loss = 0.828528642654419\n",
      "1143) Lyapunov Risk = 0.7708935737609863, MSE = 0.026297716423869133, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.0320398211479187, Lv_loss = 6.706384010612965e-05, Circular Tuning Loss = 0.8284533619880676\n",
      "1144) Lyapunov Risk = 0.770633339881897, MSE = 0.0264066681265831, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.032013703137636185, Lv_loss = 4.5462260459316894e-05, Circular Tuning Loss = 0.828377902507782\n",
      "1145) Lyapunov Risk = 0.7703765630722046, MSE = 0.026190118864178658, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03198762238025665, Lv_loss = 6.750830652890727e-05, Circular Tuning Loss = 0.8283023834228516\n",
      "1146) Lyapunov Risk = 0.7701258659362793, MSE = 0.026410266757011414, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03196156397461891, Lv_loss = 3.87284453609027e-05, Circular Tuning Loss = 0.8282269835472107\n",
      "1147) Lyapunov Risk = 0.7698854207992554, MSE = 0.026069946587085724, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03193550556898117, Lv_loss = 8.023262489587069e-05, Circular Tuning Loss = 0.8281514644622803\n",
      "1148) Lyapunov Risk = 0.7696616053581238, MSE = 0.026569586247205734, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03190944716334343, Lv_loss = 2.9646093025803566e-05, Circular Tuning Loss = 0.8280758261680603\n",
      "1149) Lyapunov Risk = 0.7694646120071411, MSE = 0.02594861388206482, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.031883399933576584, Lv_loss = 9.584417421137914e-05, Circular Tuning Loss = 0.8280001878738403\n",
      "1150) Lyapunov Risk = 0.7693085670471191, MSE = 0.026821402832865715, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03185734897851944, Lv_loss = 1.4031296814209782e-05, Circular Tuning Loss = 0.8279245495796204\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.45410156250000011, -0.45312500000000011]\n",
      "x2 : [0.96875000000000022, 0.96972656250000022]\n",
      "==============================\n",
      "1151) Lyapunov Risk = 0.7709827423095703, MSE = 0.025828402489423752, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03168394789099693, Lv_loss = 0.000114045302325394, Circular Tuning Loss = 0.8290863633155823\n",
      "1152) Lyapunov Risk = 0.7710256576538086, MSE = 0.02731892466545105, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.031658072024583817, Lv_loss = 3.185235755154281e-06, Circular Tuning Loss = 0.8290080428123474\n",
      "1153) Lyapunov Risk = 0.7711286544799805, MSE = 0.02558446116745472, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03163224458694458, Lv_loss = 0.0001505933905718848, Circular Tuning Loss = 0.8289293646812439\n",
      "1154) Lyapunov Risk = 0.7710893154144287, MSE = 0.02768402174115181, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03160642087459564, Lv_loss = 9.127662679020432e-07, Circular Tuning Loss = 0.8288508653640747\n",
      "1155) Lyapunov Risk = 0.7708238363265991, MSE = 0.025404294952750206, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.031580567359924316, Lv_loss = 0.00016743672313168645, Circular Tuning Loss = 0.8287721276283264\n",
      "1156) Lyapunov Risk = 0.7700549364089966, MSE = 0.02734975330531597, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03155474364757538, Lv_loss = 1.7534848666400649e-06, Circular Tuning Loss = 0.8286935687065125\n",
      "1157) Lyapunov Risk = 0.7692093849182129, MSE = 0.025578171014785767, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03152900189161301, Lv_loss = 9.096422581933439e-05, Circular Tuning Loss = 0.8286146521568298\n",
      "1158) Lyapunov Risk = 0.7686665654182434, MSE = 0.026183422654867172, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03150322288274765, Lv_loss = 3.0143537514959462e-05, Circular Tuning Loss = 0.8285357356071472\n",
      "1159) Lyapunov Risk = 0.7686203718185425, MSE = 0.026675652712583542, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03147757798433304, Lv_loss = 5.446739123726729e-06, Circular Tuning Loss = 0.8284567594528198\n",
      "1160) Lyapunov Risk = 0.7687109708786011, MSE = 0.02549738436937332, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03145203739404678, Lv_loss = 0.00010719495185185224, Circular Tuning Loss = 0.8283774852752686\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.42285156250000011, -0.42187500000000011]\n",
      "x2 : [0.90625000000000022, 0.90722656250000022]\n",
      "==============================\n",
      "1161) Lyapunov Risk = 0.7698601484298706, MSE = 0.02711458131670952, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03128163143992424, Lv_loss = 2.1475264020409668e-06, Circular Tuning Loss = 0.8287850618362427\n",
      "1162) Lyapunov Risk = 0.7692728042602539, MSE = 0.025700122117996216, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.031256262212991714, Lv_loss = 0.00010744333121692762, Circular Tuning Loss = 0.8287034034729004\n",
      "1163) Lyapunov Risk = 0.7687841057777405, MSE = 0.02607438899576664, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.031230919063091278, Lv_loss = 3.9504542655777186e-05, Circular Tuning Loss = 0.8286218047142029\n",
      "1164) Lyapunov Risk = 0.7686154246330261, MSE = 0.026404010131955147, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.031205594539642334, Lv_loss = 9.690821570984554e-06, Circular Tuning Loss = 0.8285401463508606\n",
      "1165) Lyapunov Risk = 0.7685626745223999, MSE = 0.025503063574433327, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.031180452555418015, Lv_loss = 0.00010526257392484695, Circular Tuning Loss = 0.8284583687782288\n",
      "1166) Lyapunov Risk = 0.7683220505714417, MSE = 0.02660212479531765, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.031155310571193695, Lv_loss = 3.0416556455747923e-06, Circular Tuning Loss = 0.8283764719963074\n",
      "1167) Lyapunov Risk = 0.7678748369216919, MSE = 0.02568555250763893, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.031130200251936913, Lv_loss = 7.606147846672684e-05, Circular Tuning Loss = 0.8282945156097412\n",
      "1168) Lyapunov Risk = 0.7674696445465088, MSE = 0.026018965989351273, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.0311051644384861, Lv_loss = 3.214562821085565e-05, Circular Tuning Loss = 0.828212320804596\n",
      "1169) Lyapunov Risk = 0.7672646045684814, MSE = 0.02623799443244934, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.031080195680260658, Lv_loss = 1.1765569070121273e-05, Circular Tuning Loss = 0.8281301259994507\n",
      "1170) Lyapunov Risk = 0.7671341896057129, MSE = 0.025660168379545212, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.031055215746164322, Lv_loss = 7.503862434532493e-05, Circular Tuning Loss = 0.8280476331710815\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.43798828125000011, -0.43750000000000011]\n",
      "x2 : [0.87500000000000022, 0.87597656250000022]\n",
      "==============================\n",
      "1171) Lyapunov Risk = 0.7680924534797668, MSE = 0.026441674679517746, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.030887886881828308, Lv_loss = 3.1907588891044725e-06, Circular Tuning Loss = 0.8281286358833313\n",
      "1172) Lyapunov Risk = 0.7677041292190552, MSE = 0.025738904252648354, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.030863050371408463, Lv_loss = 6.21156141278334e-05, Circular Tuning Loss = 0.8280438780784607\n",
      "1173) Lyapunov Risk = 0.7673855423927307, MSE = 0.025893988087773323, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.030838247388601303, Lv_loss = 2.175263944081962e-05, Circular Tuning Loss = 0.8279591202735901\n",
      "1174) Lyapunov Risk = 0.7671837210655212, MSE = 0.026067016646265984, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.030813464894890785, Lv_loss = 3.895083864335902e-06, Circular Tuning Loss = 0.8278742432594299\n",
      "1175) Lyapunov Risk = 0.7669891715049744, MSE = 0.025523843243718147, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.030788708478212357, Lv_loss = 6.54115792713128e-05, Circular Tuning Loss = 0.8277890682220459\n",
      "1176) Lyapunov Risk = 0.7667080760002136, MSE = 0.02618872933089733, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03076397255063057, Lv_loss = 2.803243887683493e-06, Circular Tuning Loss = 0.8277039527893066\n",
      "1177) Lyapunov Risk = 0.7663741111755371, MSE = 0.025615423917770386, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03073933720588684, Lv_loss = 4.388334127725102e-05, Circular Tuning Loss = 0.8276187181472778\n",
      "1178) Lyapunov Risk = 0.7660802006721497, MSE = 0.02587246149778366, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.030714699998497963, Lv_loss = 1.1410366823838558e-05, Circular Tuning Loss = 0.8275336027145386\n",
      "1179) Lyapunov Risk = 0.7658525705337524, MSE = 0.0260396096855402, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03069007210433483, Lv_loss = 3.5985619888379006e-06, Circular Tuning Loss = 0.8274481296539307\n",
      "1180) Lyapunov Risk = 0.7656344175338745, MSE = 0.02557199075818062, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.030665459111332893, Lv_loss = 4.6648438001284376e-05, Circular Tuning Loss = 0.8273627758026123\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.43798828125000011, -0.43750000000000011]\n",
      "x2 : [0.87500000000000022, 0.87597656250000022]\n",
      "==============================\n",
      "1181) Lyapunov Risk = 0.7665570974349976, MSE = 0.02614828571677208, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.030501069501042366, Lv_loss = 2.282806008224725e-06, Circular Tuning Loss = 0.8274204730987549\n",
      "1182) Lyapunov Risk = 0.7662492990493774, MSE = 0.02565409243106842, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03047678992152214, Lv_loss = 1.3332922208064701e-05, Circular Tuning Loss = 0.8273330330848694\n",
      "1183) Lyapunov Risk = 0.765973687171936, MSE = 0.025717053562402725, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.030452623963356018, Lv_loss = 4.022994744445896e-06, Circular Tuning Loss = 0.8272455334663391\n",
      "1184) Lyapunov Risk = 0.7657354474067688, MSE = 0.025868374854326248, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03042851947247982, Lv_loss = 2.4697594653844135e-06, Circular Tuning Loss = 0.8271580338478088\n",
      "1185) Lyapunov Risk = 0.765501081943512, MSE = 0.02543741464614868, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03040446527302265, Lv_loss = 1.8230297428090125e-05, Circular Tuning Loss = 0.8270706534385681\n",
      "1186) Lyapunov Risk = 0.7652432918548584, MSE = 0.025935964658856392, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.030380429700016975, Lv_loss = 1.6955800674622878e-06, Circular Tuning Loss = 0.8269833326339722\n",
      "1187) Lyapunov Risk = 0.7649590969085693, MSE = 0.025518231093883514, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03035643696784973, Lv_loss = 7.871716661611572e-06, Circular Tuning Loss = 0.826896071434021\n",
      "1188) Lyapunov Risk = 0.7646777629852295, MSE = 0.025756115093827248, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.030332515016198158, Lv_loss = 2.8743645543727325e-06, Circular Tuning Loss = 0.8268088698387146\n",
      "1189) Lyapunov Risk = 0.7644182443618774, MSE = 0.025775210931897163, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.030308689922094345, Lv_loss = 2.663020040927222e-06, Circular Tuning Loss = 0.8267216086387634\n",
      "1190) Lyapunov Risk = 0.7641750574111938, MSE = 0.025561586022377014, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.030284889042377472, Lv_loss = 3.9997412386583164e-06, Circular Tuning Loss = 0.826634407043457\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.25000000000000006, -0.24902343750000006]\n",
      "x2 : [0.71093750000000022, 0.71191406250000022]\n",
      "==============================\n",
      "1191) Lyapunov Risk = 0.7641977667808533, MSE = 0.02587069757282734, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.030123533681035042, Lv_loss = 1.3806806009597494e-06, Circular Tuning Loss = 0.8251158595085144\n",
      "1192) Lyapunov Risk = 0.7639281749725342, MSE = 0.025547582656145096, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03009994886815548, Lv_loss = 3.3107289709732868e-06, Circular Tuning Loss = 0.8250275254249573\n",
      "1193) Lyapunov Risk = 0.7636565566062927, MSE = 0.0256746094673872, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.030076464638113976, Lv_loss = 1.7823583675635746e-06, Circular Tuning Loss = 0.8249391913414001\n",
      "1194) Lyapunov Risk = 0.7633945941925049, MSE = 0.02562529221177101, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03005301021039486, Lv_loss = 1.786032385098224e-06, Circular Tuning Loss = 0.8248507380485535\n",
      "1195) Lyapunov Risk = 0.763142466545105, MSE = 0.02549700438976288, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.03002958744764328, Lv_loss = 2.4918076633184683e-06, Circular Tuning Loss = 0.8247624635696411\n",
      "1196) Lyapunov Risk = 0.7628902196884155, MSE = 0.025704113766551018, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.030006179586052895, Lv_loss = 8.70714472966938e-07, Circular Tuning Loss = 0.824674129486084\n",
      "1197) Lyapunov Risk = 0.7626302242279053, MSE = 0.025469187647104263, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.02998279221355915, Lv_loss = 2.483665866748197e-06, Circular Tuning Loss = 0.8245857357978821\n",
      "1198) Lyapunov Risk = 0.7623642086982727, MSE = 0.025674523785710335, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.029959416016936302, Lv_loss = 9.85806195785699e-07, Circular Tuning Loss = 0.8244974613189697\n",
      "1199) Lyapunov Risk = 0.7620999217033386, MSE = 0.025561058893799782, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.029936054721474648, Lv_loss = 1.426249582436867e-06, Circular Tuning Loss = 0.8244089484214783\n",
      "1200) Lyapunov Risk = 0.7618423104286194, MSE = 0.025553666055202484, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.02991269901394844, Lv_loss = 1.2927475836477242e-06, Circular Tuning Loss = 0.8243206739425659\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.37597656250000011, -0.37500000000000011]\n",
      "x2 : [0.87500000000000022, 0.87597656250000022]\n",
      "==============================\n",
      "1201) Lyapunov Risk = 0.7627068758010864, MSE = 0.025637801736593246, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.029754072427749634, Lv_loss = 3.3872427138703642e-06, Circular Tuning Loss = 0.8242782950401306\n",
      "1202) Lyapunov Risk = 0.7624443769454956, MSE = 0.025519611313939095, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.029730843380093575, Lv_loss = 5.3476069297175854e-06, Circular Tuning Loss = 0.8241878747940063\n",
      "1203) Lyapunov Risk = 0.7621824741363525, MSE = 0.025530505925416946, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.029707632958889008, Lv_loss = 6.139745778455108e-07, Circular Tuning Loss = 0.8240975737571716\n",
      "1204) Lyapunov Risk = 0.7619222402572632, MSE = 0.025490399450063705, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.029684433713555336, Lv_loss = 5.121270874042239e-07, Circular Tuning Loss = 0.8240072131156921\n",
      "1205) Lyapunov Risk = 0.7616629600524902, MSE = 0.02543911337852478, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.02966134250164032, Lv_loss = 6.125986260485661e-07, Circular Tuning Loss = 0.8239169716835022\n",
      "1206) Lyapunov Risk = 0.7614039182662964, MSE = 0.025490224361419678, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.029638230800628662, Lv_loss = 3.3620511885601445e-07, Circular Tuning Loss = 0.8238266110420227\n",
      "1207) Lyapunov Risk = 0.7611441612243652, MSE = 0.025420451536774635, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.029615096747875214, Lv_loss = 6.600438950954413e-07, Circular Tuning Loss = 0.8237361907958984\n",
      "1208) Lyapunov Risk = 0.7608839273452759, MSE = 0.025508513674139977, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.029591945931315422, Lv_loss = 2.63854815329978e-07, Circular Tuning Loss = 0.8236458897590637\n",
      "1209) Lyapunov Risk = 0.7606236338615417, MSE = 0.025449255481362343, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.029568854719400406, Lv_loss = 4.1034058995137457e-07, Circular Tuning Loss = 0.8235554695129395\n",
      "1210) Lyapunov Risk = 0.7603646516799927, MSE = 0.025483012199401855, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.02954576537013054, Lv_loss = 1.589179277061703e-07, Circular Tuning Loss = 0.8234649896621704\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.42236328125000011, -0.42187500000000011]\n",
      "x2 : [0.87500000000000022, 0.87597656250000022]\n",
      "==============================\n",
      "1211) Lyapunov Risk = 0.7612302303314209, MSE = 0.025461750105023384, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.029389705508947372, Lv_loss = 5.193694363470058e-08, Circular Tuning Loss = 0.823444664478302\n",
      "1212) Lyapunov Risk = 0.760970950126648, MSE = 0.025499088689684868, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.029366793110966682, Lv_loss = 0.0, Circular Tuning Loss = 0.8233522176742554\n",
      "1213) Lyapunov Risk = 0.7607128620147705, MSE = 0.025342430919408798, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.029343916103243828, Lv_loss = 0.0, Circular Tuning Loss = 0.8232595920562744\n",
      "1214) Lyapunov Risk = 0.7604556083679199, MSE = 0.025429924950003624, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.029321055859327316, Lv_loss = 0.0, Circular Tuning Loss = 0.8231668472290039\n",
      "1215) Lyapunov Risk = 0.7601975798606873, MSE = 0.02530187927186489, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.029298225417733192, Lv_loss = 0.0, Circular Tuning Loss = 0.8230742812156677\n",
      "1216) Lyapunov Risk = 0.7599387168884277, MSE = 0.02536572329699993, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.02927538938820362, Lv_loss = 0.0, Circular Tuning Loss = 0.8229814171791077\n",
      "1217) Lyapunov Risk = 0.7596801519393921, MSE = 0.02533973939716816, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.029252558946609497, Lv_loss = 0.0, Circular Tuning Loss = 0.8228887319564819\n",
      "1218) Lyapunov Risk = 0.7594231367111206, MSE = 0.02536197379231453, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.02922973223030567, Lv_loss = 0.0, Circular Tuning Loss = 0.8227957487106323\n",
      "1219) Lyapunov Risk = 0.7591673731803894, MSE = 0.02537515014410019, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.029206933453679085, Lv_loss = 0.0, Circular Tuning Loss = 0.8227028250694275\n",
      "1220) Lyapunov Risk = 0.7589125633239746, MSE = 0.02534392662346363, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.02918415516614914, Lv_loss = 0.0, Circular Tuning Loss = 0.8226097226142883\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.40673828125000011, -0.40625000000000011]\n",
      "x2 : [0.87500000000000022, 0.87597656250000022]\n",
      "==============================\n",
      "1221) Lyapunov Risk = 0.7597460150718689, MSE = 0.025389056652784348, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.02903062291443348, Lv_loss = 0.0, Circular Tuning Loss = 0.8225489854812622\n",
      "1222) Lyapunov Risk = 0.7594878673553467, MSE = 0.02536873146891594, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.02900804951786995, Lv_loss = 0.0, Circular Tuning Loss = 0.8224537372589111\n",
      "1223) Lyapunov Risk = 0.7592329382896423, MSE = 0.025257106870412827, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.0289855245500803, Lv_loss = 0.0, Circular Tuning Loss = 0.8223583102226257\n",
      "1224) Lyapunov Risk = 0.758979320526123, MSE = 0.02533273585140705, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.028963221237063408, Lv_loss = 0.0, Circular Tuning Loss = 0.8222627639770508\n",
      "1225) Lyapunov Risk = 0.7587258219718933, MSE = 0.025172550231218338, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.028940992429852486, Lv_loss = 0.0, Circular Tuning Loss = 0.8221672177314758\n",
      "1226) Lyapunov Risk = 0.7584717273712158, MSE = 0.025323599576950073, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.028918888419866562, Lv_loss = 0.0, Circular Tuning Loss = 0.8220714330673218\n",
      "1227) Lyapunov Risk = 0.7582167983055115, MSE = 0.025155577808618546, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.028896789997816086, Lv_loss = 0.0, Circular Tuning Loss = 0.8219756484031677\n",
      "1228) Lyapunov Risk = 0.7579610347747803, MSE = 0.0253183264285326, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.02887469157576561, Lv_loss = 0.0, Circular Tuning Loss = 0.8218798637390137\n",
      "1229) Lyapunov Risk = 0.7577051520347595, MSE = 0.02520829252898693, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.028852608054876328, Lv_loss = 0.0, Circular Tuning Loss = 0.8217839598655701\n",
      "1230) Lyapunov Risk = 0.7574504017829895, MSE = 0.025272144004702568, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.028830524533987045, Lv_loss = 0.0, Circular Tuning Loss = 0.8216881155967712\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.37548828125000011, -0.37500000000000011]\n",
      "x2 : [0.69433593750000022, 0.69531250000000022]\n",
      "==============================\n",
      "1231) Lyapunov Risk = 0.7574654221534729, MSE = 0.0252628605812788, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.028679830953478813, Lv_loss = 0.0, Circular Tuning Loss = 0.8201228380203247\n",
      "1232) Lyapunov Risk = 0.7572112083435059, MSE = 0.025253206491470337, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.028657903894782066, Lv_loss = 0.0, Circular Tuning Loss = 0.8200258612632751\n",
      "1233) Lyapunov Risk = 0.7569574117660522, MSE = 0.02519071102142334, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.028636019676923752, Lv_loss = 0.0, Circular Tuning Loss = 0.8199290037155151\n",
      "1234) Lyapunov Risk = 0.7567038536071777, MSE = 0.025179734453558922, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.028614163398742676, Lv_loss = 0.0, Circular Tuning Loss = 0.8198319673538208\n",
      "1235) Lyapunov Risk = 0.7564504146575928, MSE = 0.02514496073126793, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.028592320159077644, Lv_loss = 0.0, Circular Tuning Loss = 0.8197349905967712\n",
      "1236) Lyapunov Risk = 0.7561976313591003, MSE = 0.02514810860157013, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.02857051230967045, Lv_loss = 0.0, Circular Tuning Loss = 0.8196381330490112\n",
      "1237) Lyapunov Risk = 0.7559449672698975, MSE = 0.025164760649204254, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.02854876220226288, Lv_loss = 0.0, Circular Tuning Loss = 0.8195411562919617\n",
      "1238) Lyapunov Risk = 0.7556928992271423, MSE = 0.025173604488372803, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.02852705493569374, Lv_loss = 0.0, Circular Tuning Loss = 0.8194441795349121\n",
      "1239) Lyapunov Risk = 0.7554413676261902, MSE = 0.02519383653998375, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.02850540541112423, Lv_loss = 0.0, Circular Tuning Loss = 0.8193469047546387\n",
      "1240) Lyapunov Risk = 0.7551901340484619, MSE = 0.025177402421832085, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.028483791276812553, Lv_loss = 0.0, Circular Tuning Loss = 0.8192496299743652\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.40673828125000011, -0.40625000000000011]\n",
      "x2 : [0.84375000000000022, 0.84472656250000022]\n",
      "==============================\n",
      "1241) Lyapunov Risk = 0.755851149559021, MSE = 0.02514895237982273, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.02833571285009384, Lv_loss = 0.0, Circular Tuning Loss = 0.8188735246658325\n",
      "1242) Lyapunov Risk = 0.7556008100509644, MSE = 0.025234133005142212, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.02831430174410343, Lv_loss = 0.0, Circular Tuning Loss = 0.818774402141571\n",
      "1243) Lyapunov Risk = 0.7553519010543823, MSE = 0.024994058534502983, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.028292948380112648, Lv_loss = 0.0, Circular Tuning Loss = 0.8186751008033752\n",
      "1244) Lyapunov Risk = 0.755103349685669, MSE = 0.025222623720765114, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.0282716266810894, Lv_loss = 0.0, Circular Tuning Loss = 0.8185758590698242\n",
      "1245) Lyapunov Risk = 0.754853367805481, MSE = 0.024933556094765663, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.02825038507580757, Lv_loss = 0.0, Circular Tuning Loss = 0.8184764981269836\n",
      "1246) Lyapunov Risk = 0.7546018958091736, MSE = 0.02521391026675701, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.02822922170162201, Lv_loss = 0.0, Circular Tuning Loss = 0.8183771967887878\n",
      "1247) Lyapunov Risk = 0.7543492913246155, MSE = 0.024952832609415054, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.02820810116827488, Lv_loss = 0.0, Circular Tuning Loss = 0.8182779550552368\n",
      "1248) Lyapunov Risk = 0.7540968656539917, MSE = 0.02522614598274231, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.028186995536088943, Lv_loss = 0.0, Circular Tuning Loss = 0.8181787729263306\n",
      "1249) Lyapunov Risk = 0.7538449764251709, MSE = 0.024945128709077835, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.028165895491838455, Lv_loss = 0.0, Circular Tuning Loss = 0.8180795311927795\n",
      "1250) Lyapunov Risk = 0.7535930871963501, MSE = 0.025229942053556442, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.028144802898168564, Lv_loss = 0.0, Circular Tuning Loss = 0.8179804682731628\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.7574264812390652, -1.752843331387101]\n",
      "x2 : [0.94383237365569683, 0.94721528538922983]\n",
      "==============================\n",
      "1251) Lyapunov Risk = 0.7579522132873535, MSE = 0.02489311620593071, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.0279992762953043, Lv_loss = 0.0, Circular Tuning Loss = 0.8257554173469543\n",
      "1252) Lyapunov Risk = 0.7577038407325745, MSE = 0.02518918178975582, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.02797842025756836, Lv_loss = 0.0, Circular Tuning Loss = 0.8256542086601257\n",
      "1253) Lyapunov Risk = 0.75745689868927, MSE = 0.024772631004452705, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.02795773185789585, Lv_loss = 0.0, Circular Tuning Loss = 0.8255525827407837\n",
      "1254) Lyapunov Risk = 0.7572126984596252, MSE = 0.025125695392489433, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.02793707698583603, Lv_loss = 0.0, Circular Tuning Loss = 0.8254507184028625\n",
      "1255) Lyapunov Risk = 0.7569682002067566, MSE = 0.024690886959433556, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.027916541323065758, Lv_loss = 0.0, Circular Tuning Loss = 0.8253487348556519\n",
      "1256) Lyapunov Risk = 0.7567262649536133, MSE = 0.025180634111166, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.027896014973521233, Lv_loss = 0.0, Circular Tuning Loss = 0.8252463936805725\n",
      "1257) Lyapunov Risk = 0.7564871311187744, MSE = 0.024670634418725967, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.027875561267137527, Lv_loss = 0.0, Circular Tuning Loss = 0.8251439332962036\n",
      "1258) Lyapunov Risk = 0.7562486529350281, MSE = 0.025283582508563995, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.027855169028043747, Lv_loss = 0.0, Circular Tuning Loss = 0.8250414729118347\n",
      "1259) Lyapunov Risk = 0.7560106515884399, MSE = 0.02465636655688286, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.027834812179207802, Lv_loss = 0.0, Circular Tuning Loss = 0.8249388933181763\n",
      "1260) Lyapunov Risk = 0.7557725310325623, MSE = 0.02530660107731819, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.02781442366540432, Lv_loss = 0.0, Circular Tuning Loss = 0.824836254119873\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.7751556087352149, -1.7710625816671555]\n",
      "x2 : [0.91676907978743316, 0.92015199152096616]\n",
      "==============================\n",
      "1261) Lyapunov Risk = 0.7600644826889038, MSE = 0.024598052725195885, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.027671637013554573, Lv_loss = 0.0, Circular Tuning Loss = 0.8324623703956604\n",
      "1262) Lyapunov Risk = 0.7598381042480469, MSE = 0.025298187509179115, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.027651475742459297, Lv_loss = 0.0, Circular Tuning Loss = 0.8323573470115662\n",
      "1263) Lyapunov Risk = 0.7596132159233093, MSE = 0.024455849081277847, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.027631575241684914, Lv_loss = 0.0, Circular Tuning Loss = 0.8322516679763794\n",
      "1264) Lyapunov Risk = 0.7593892216682434, MSE = 0.025308828800916672, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.027611685916781425, Lv_loss = 0.0, Circular Tuning Loss = 0.8321456909179688\n",
      "1265) Lyapunov Risk = 0.7591623067855835, MSE = 0.02435428835451603, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.027591902762651443, Lv_loss = 0.0, Circular Tuning Loss = 0.8320391178131104\n",
      "1266) Lyapunov Risk = 0.7589331269264221, MSE = 0.025424180552363396, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.02757212333381176, Lv_loss = 0.0, Circular Tuning Loss = 0.8319324254989624\n",
      "1267) Lyapunov Risk = 0.7587156295776367, MSE = 0.024323180317878723, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.027552422136068344, Lv_loss = 0.0, Circular Tuning Loss = 0.8318252563476562\n",
      "1268) Lyapunov Risk = 0.7584892511367798, MSE = 0.02558135986328125, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.02753272093832493, Lv_loss = 0.0, Circular Tuning Loss = 0.831717848777771\n",
      "1269) Lyapunov Risk = 0.7582648396492004, MSE = 0.024296553805470467, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.027513112872838974, Lv_loss = 0.0, Circular Tuning Loss = 0.8316099643707275\n",
      "1270) Lyapunov Risk = 0.7580190300941467, MSE = 0.0256029199808836, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.027493471279740334, Lv_loss = 0.0, Circular Tuning Loss = 0.8315021395683289\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.7540498619490057, -1.7502828836255917]\n",
      "x2 : [0.95736402058982872, 0.96074693232336172]\n",
      "==============================\n",
      "1271) Lyapunov Risk = 0.7623287439346313, MSE = 0.02427629940211773, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.02735341712832451, Lv_loss = 0.0, Circular Tuning Loss = 0.8391848802566528\n",
      "1272) Lyapunov Risk = 0.7620583772659302, MSE = 0.025474896654486656, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.027334002777934074, Lv_loss = 0.0, Circular Tuning Loss = 0.8390740752220154\n",
      "1273) Lyapunov Risk = 0.7617791891098022, MSE = 0.02426472306251526, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.027314728125929832, Lv_loss = 0.0, Circular Tuning Loss = 0.8389623761177063\n",
      "1274) Lyapunov Risk = 0.7614744901657104, MSE = 0.025259286165237427, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.027295563369989395, Lv_loss = 0.0, Circular Tuning Loss = 0.8388502597808838\n",
      "1275) Lyapunov Risk = 0.7611600160598755, MSE = 0.024371493607759476, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.027276620268821716, Lv_loss = 0.0, Circular Tuning Loss = 0.8387376666069031\n",
      "1276) Lyapunov Risk = 0.7608484029769897, MSE = 0.025043606758117676, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.027257710695266724, Lv_loss = 0.0, Circular Tuning Loss = 0.8386246562004089\n",
      "1277) Lyapunov Risk = 0.7605549693107605, MSE = 0.024609578773379326, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.027238866314291954, Lv_loss = 0.0, Circular Tuning Loss = 0.8385113477706909\n",
      "1278) Lyapunov Risk = 0.7602860331535339, MSE = 0.024836914613842964, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.027220048010349274, Lv_loss = 0.0, Circular Tuning Loss = 0.8383978009223938\n",
      "1279) Lyapunov Risk = 0.7600391507148743, MSE = 0.02485799789428711, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.02720128744840622, Lv_loss = 0.0, Circular Tuning Loss = 0.8382839560508728\n",
      "1280) Lyapunov Risk = 0.7598074078559875, MSE = 0.02461642026901245, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.027182547375559807, Lv_loss = 0.0, Circular Tuning Loss = 0.8381699919700623\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.37158203125000011, -0.37109375000000011]\n",
      "x2 : [0.74707031250000022, 0.74804687500000022]\n",
      "==============================\n",
      "1281) Lyapunov Risk = 0.7599595785140991, MSE = 0.025031093508005142, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.027045192196965218, Lv_loss = 0.0, Circular Tuning Loss = 0.836826503276825\n",
      "1282) Lyapunov Risk = 0.7597160339355469, MSE = 0.024500463157892227, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.027026673778891563, Lv_loss = 1.0804251360241324e-06, Circular Tuning Loss = 0.836711049079895\n",
      "1283) Lyapunov Risk = 0.7594670057296753, MSE = 0.025036808103322983, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.02700825408101082, Lv_loss = 0.0, Circular Tuning Loss = 0.8365956544876099\n",
      "1284) Lyapunov Risk = 0.7592117190361023, MSE = 0.02445576898753643, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.0269898883998394, Lv_loss = 0.0, Circular Tuning Loss = 0.8364800214767456\n",
      "1285) Lyapunov Risk = 0.7589504718780518, MSE = 0.02501322329044342, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.02697152830660343, Lv_loss = 0.0, Circular Tuning Loss = 0.8363645672798157\n",
      "1286) Lyapunov Risk = 0.7586873173713684, MSE = 0.0245079156011343, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.026953214779496193, Lv_loss = 0.0, Circular Tuning Loss = 0.8362489938735962\n",
      "1287) Lyapunov Risk = 0.7584235668182373, MSE = 0.024961138144135475, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.026934895664453506, Lv_loss = 0.0, Circular Tuning Loss = 0.8361334800720215\n",
      "1288) Lyapunov Risk = 0.7581614255905151, MSE = 0.02461271733045578, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.0269166212528944, Lv_loss = 0.0, Circular Tuning Loss = 0.836017906665802\n",
      "1289) Lyapunov Risk = 0.7579011917114258, MSE = 0.024867434054613113, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.026898346841335297, Lv_loss = 0.0, Circular Tuning Loss = 0.8359023332595825\n",
      "1290) Lyapunov Risk = 0.7576448321342468, MSE = 0.02471250295639038, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.02688019350171089, Lv_loss = 0.0, Circular Tuning Loss = 0.8357868194580078\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.37548499815059111, -0.37500000000000011]\n",
      "x2 : [0.76757812500000022, 0.76855468750000022]\n",
      "==============================\n",
      "1291) Lyapunov Risk = 0.7578417062759399, MSE = 0.024739181622862816, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.02674536220729351, Lv_loss = 0.0, Circular Tuning Loss = 0.8345906138420105\n",
      "1292) Lyapunov Risk = 0.7575956583023071, MSE = 0.02487228624522686, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.026727458462119102, Lv_loss = 0.0, Circular Tuning Loss = 0.8344740271568298\n",
      "1293) Lyapunov Risk = 0.7573552131652832, MSE = 0.024549730122089386, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.026709606871008873, Lv_loss = 0.0, Circular Tuning Loss = 0.8343574404716492\n",
      "1294) Lyapunov Risk = 0.7571169137954712, MSE = 0.02497430145740509, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.026691751554608345, Lv_loss = 0.0, Circular Tuning Loss = 0.8342411518096924\n",
      "1295) Lyapunov Risk = 0.7568789124488831, MSE = 0.024459058418869972, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.0266739409416914, Lv_loss = 0.0, Circular Tuning Loss = 0.8341251015663147\n",
      "1296) Lyapunov Risk = 0.7566404938697815, MSE = 0.025046732276678085, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.026656154543161392, Lv_loss = 0.0, Circular Tuning Loss = 0.8340092301368713\n",
      "1297) Lyapunov Risk = 0.7564077377319336, MSE = 0.024423370137810707, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.026638582348823547, Lv_loss = 0.0, Circular Tuning Loss = 0.8338935375213623\n",
      "1298) Lyapunov Risk = 0.7561727166175842, MSE = 0.02513563074171543, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.026621013879776, Lv_loss = 0.0, Circular Tuning Loss = 0.8337780237197876\n",
      "1299) Lyapunov Risk = 0.7559429407119751, MSE = 0.024379974231123924, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.02660346031188965, Lv_loss = 0.0, Circular Tuning Loss = 0.8336626291275024\n",
      "1300) Lyapunov Risk = 0.7557133436203003, MSE = 0.025230761617422104, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.02658584527671337, Lv_loss = 0.0, Circular Tuning Loss = 0.8335475921630859\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.37548828125000011, -0.37500000000000011]\n",
      "x2 : [0.75000000000000022, 0.75097656250000022]\n",
      "==============================\n",
      "1301) Lyapunov Risk = 0.7558578252792358, MSE = 0.024300502613186836, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.02645324170589447, Lv_loss = 0.0, Circular Tuning Loss = 0.8322237133979797\n",
      "1302) Lyapunov Risk = 0.7556509375572205, MSE = 0.025392308831214905, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.026435965672135353, Lv_loss = 0.0, Circular Tuning Loss = 0.8321077227592468\n",
      "1303) Lyapunov Risk = 0.7554388642311096, MSE = 0.024174802005290985, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.026418907567858696, Lv_loss = 0.0, Circular Tuning Loss = 0.8319918513298035\n",
      "1304) Lyapunov Risk = 0.7552169561386108, MSE = 0.025485169142484665, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.026401808485388756, Lv_loss = 0.0, Circular Tuning Loss = 0.8318763375282288\n",
      "1305) Lyapunov Risk = 0.7549773454666138, MSE = 0.024132320657372475, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.02638482116162777, Lv_loss = 0.0, Circular Tuning Loss = 0.831760823726654\n",
      "1306) Lyapunov Risk = 0.7547205090522766, MSE = 0.025480588898062706, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.026367787271738052, Lv_loss = 0.0, Circular Tuning Loss = 0.831645667552948\n",
      "1307) Lyapunov Risk = 0.7544431686401367, MSE = 0.024185815826058388, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.02635100670158863, Lv_loss = 0.0, Circular Tuning Loss = 0.8315304517745972\n",
      "1308) Lyapunov Risk = 0.754150390625, MSE = 0.02536030299961567, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.026334205642342567, Lv_loss = 0.0, Circular Tuning Loss = 0.8314157128334045\n",
      "1309) Lyapunov Risk = 0.7538492679595947, MSE = 0.024319425225257874, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.02631748653948307, Lv_loss = 0.0, Circular Tuning Loss = 0.8313009738922119\n",
      "1310) Lyapunov Risk = 0.7535491585731506, MSE = 0.025151021778583527, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.026300743222236633, Lv_loss = 0.0, Circular Tuning Loss = 0.8311864137649536\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.88262330025815072, -0.88135275021512571]\n",
      "x2 : [1.794307894324525, 1.7953320945407942]\n",
      "==============================\n",
      "1311) Lyapunov Risk = 0.7602499723434448, MSE = 0.02448725327849388, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.026171384379267693, Lv_loss = 0.0, Circular Tuning Loss = 0.8447290658950806\n",
      "1312) Lyapunov Risk = 0.7599655985832214, MSE = 0.024855200201272964, V_0_loss = tensor([[0.0038]], grad_fn=<PowBackward0>), V_pos_loss = 0.02615448459982872, Lv_loss = 0.0, Circular Tuning Loss = 0.8446051478385925\n",
      "1313) Lyapunov Risk = 0.7597007751464844, MSE = 0.024673232808709145, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.026138227432966232, Lv_loss = 0.0, Circular Tuning Loss = 0.8444808721542358\n",
      "1314) Lyapunov Risk = 0.7594518065452576, MSE = 0.024609699845314026, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.026122119277715683, Lv_loss = 0.0, Circular Tuning Loss = 0.8443562984466553\n",
      "1315) Lyapunov Risk = 0.759214460849762, MSE = 0.02483210526406765, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.02610604837536812, Lv_loss = 0.0, Circular Tuning Loss = 0.8442317247390747\n",
      "1316) Lyapunov Risk = 0.758985161781311, MSE = 0.024464081972837448, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.026090096682310104, Lv_loss = 0.0, Circular Tuning Loss = 0.8441067337989807\n",
      "1317) Lyapunov Risk = 0.7587599158287048, MSE = 0.024998629465699196, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.026074180379509926, Lv_loss = 0.0, Circular Tuning Loss = 0.8439817428588867\n",
      "1318) Lyapunov Risk = 0.7585370540618896, MSE = 0.024376988410949707, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.026058314368128777, Lv_loss = 0.0, Circular Tuning Loss = 0.8438565135002136\n",
      "1319) Lyapunov Risk = 0.7583082914352417, MSE = 0.025126300752162933, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.026042453944683075, Lv_loss = 0.0, Circular Tuning Loss = 0.8437311053276062\n",
      "1320) Lyapunov Risk = 0.7580724954605103, MSE = 0.02432767115533352, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.026026690378785133, Lv_loss = 0.0, Circular Tuning Loss = 0.8436055183410645\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.85156250000000022, -0.84375000000000022]\n",
      "x2 : [1.7927479830576558, 1.8027479830576556]\n",
      "==============================\n",
      "1321) Lyapunov Risk = 0.7647666931152344, MSE = 0.025142818689346313, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.02593088708817959, Lv_loss = 0.0, Circular Tuning Loss = 0.8569457530975342\n",
      "1322) Lyapunov Risk = 0.7645153999328613, MSE = 0.024265684187412262, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.02591298148036003, Lv_loss = 0.0, Circular Tuning Loss = 0.8568101525306702\n",
      "1323) Lyapunov Risk = 0.7642518877983093, MSE = 0.025103919208049774, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.025895077735185623, Lv_loss = 0.0, Circular Tuning Loss = 0.8566737174987793\n",
      "1324) Lyapunov Risk = 0.7639791369438171, MSE = 0.024271633476018906, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.025877302512526512, Lv_loss = 0.0, Circular Tuning Loss = 0.8565361499786377\n",
      "1325) Lyapunov Risk = 0.7637017369270325, MSE = 0.02498801238834858, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.025859542191028595, Lv_loss = 0.0, Circular Tuning Loss = 0.8563978672027588\n",
      "1326) Lyapunov Risk = 0.7634228467941284, MSE = 0.02438325434923172, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.025841904804110527, Lv_loss = 0.0, Circular Tuning Loss = 0.8562585115432739\n",
      "1327) Lyapunov Risk = 0.7631494998931885, MSE = 0.024849047884345055, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.02582438848912716, Lv_loss = 0.0, Circular Tuning Loss = 0.8561186194419861\n",
      "1328) Lyapunov Risk = 0.762881875038147, MSE = 0.024543050676584244, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.025806974619627, Lv_loss = 0.0, Circular Tuning Loss = 0.8559780120849609\n",
      "1329) Lyapunov Risk = 0.7626217007637024, MSE = 0.02471480891108513, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.025789625942707062, Lv_loss = 0.0, Circular Tuning Loss = 0.8558369278907776\n",
      "1330) Lyapunov Risk = 0.762365996837616, MSE = 0.024670545011758804, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.025772349908947945, Lv_loss = 0.0, Circular Tuning Loss = 0.8556953072547913\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.85156250000000022, -0.84375000000000022]\n",
      "x2 : [1.7927479830576558, 1.8027479830576556]\n",
      "==============================\n",
      "1331) Lyapunov Risk = 0.7689222693443298, MSE = 0.02458917908370495, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.025652188807725906, Lv_loss = 0.0, Circular Tuning Loss = 0.8688079118728638\n",
      "1332) Lyapunov Risk = 0.7686639428138733, MSE = 0.02468941919505596, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.025633396580815315, Lv_loss = 0.0, Circular Tuning Loss = 0.8686555624008179\n",
      "1333) Lyapunov Risk = 0.7684068083763123, MSE = 0.024510866031050682, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.02561550959944725, Lv_loss = 0.0, Circular Tuning Loss = 0.8685021996498108\n",
      "1334) Lyapunov Risk = 0.7681504487991333, MSE = 0.024672726169228554, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.025598403066396713, Lv_loss = 0.0, Circular Tuning Loss = 0.8683481216430664\n",
      "1335) Lyapunov Risk = 0.7678947448730469, MSE = 0.024470578879117966, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.025582071393728256, Lv_loss = 0.0, Circular Tuning Loss = 0.8681936264038086\n",
      "1336) Lyapunov Risk = 0.7676414847373962, MSE = 0.024696392938494682, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.02556653879582882, Lv_loss = 0.0, Circular Tuning Loss = 0.8680387735366821\n",
      "1337) Lyapunov Risk = 0.7673887014389038, MSE = 0.024451009929180145, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.02555207349359989, Lv_loss = 0.0, Circular Tuning Loss = 0.8678839206695557\n",
      "1338) Lyapunov Risk = 0.7671387195587158, MSE = 0.024752380326390266, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.02553808130323887, Lv_loss = 0.0, Circular Tuning Loss = 0.8677293658256531\n",
      "1339) Lyapunov Risk = 0.7668887376785278, MSE = 0.02442730776965618, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.025524169206619263, Lv_loss = 0.0, Circular Tuning Loss = 0.8675752282142639\n",
      "1340) Lyapunov Risk = 0.7666425108909607, MSE = 0.024803463369607925, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.025510238483548164, Lv_loss = 0.0, Circular Tuning Loss = 0.8674213290214539\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.84607957912035614, -0.8447612253238761]\n",
      "x2 : [1.8110500746821931, 1.812837133387692]\n",
      "==============================\n",
      "1341) Lyapunov Risk = 0.7732300758361816, MSE = 0.02435421384871006, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.025387773290276527, Lv_loss = 0.0, Circular Tuning Loss = 0.8805847764015198\n",
      "1342) Lyapunov Risk = 0.772977352142334, MSE = 0.024785637855529785, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.025373799726366997, Lv_loss = 0.0, Circular Tuning Loss = 0.8804224133491516\n",
      "1343) Lyapunov Risk = 0.77272629737854, MSE = 0.024274222552776337, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.025359828025102615, Lv_loss = 0.0, Circular Tuning Loss = 0.8802599310874939\n",
      "1344) Lyapunov Risk = 0.7724800109863281, MSE = 0.024804262444376945, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.02534591034054756, Lv_loss = 0.0, Circular Tuning Loss = 0.8800974488258362\n",
      "1345) Lyapunov Risk = 0.7722340226173401, MSE = 0.024201074615120888, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.02533206343650818, Lv_loss = 0.0, Circular Tuning Loss = 0.8799347281455994\n",
      "1346) Lyapunov Risk = 0.7719940543174744, MSE = 0.02490219660103321, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.025318201631307602, Lv_loss = 0.0, Circular Tuning Loss = 0.8797720670700073\n",
      "1347) Lyapunov Risk = 0.7717562913894653, MSE = 0.024149123579263687, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.0253043994307518, Lv_loss = 0.0, Circular Tuning Loss = 0.8796092867851257\n",
      "1348) Lyapunov Risk = 0.7715251445770264, MSE = 0.025039205327630043, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.025290539488196373, Lv_loss = 0.0, Circular Tuning Loss = 0.8794463872909546\n",
      "1349) Lyapunov Risk = 0.7713083028793335, MSE = 0.024054083973169327, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.02527686022222042, Lv_loss = 0.0, Circular Tuning Loss = 0.8792832493782043\n",
      "1350) Lyapunov Risk = 0.7711056470870972, MSE = 0.025211000815033913, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.025263238698244095, Lv_loss = 0.0, Circular Tuning Loss = 0.8791203498840332\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.82734048078738442, -0.8203095279885313]\n",
      "x2 : [1.8121178423850268, 1.8180748583190576]\n",
      "==============================\n",
      "1351) Lyapunov Risk = 0.7777230739593506, MSE = 0.023821422830224037, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.025148732587695122, Lv_loss = 0.0, Circular Tuning Loss = 0.8920838236808777\n",
      "1352) Lyapunov Risk = 0.7775970101356506, MSE = 0.025545066222548485, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.025132890790700912, Lv_loss = 0.0, Circular Tuning Loss = 0.8919108510017395\n",
      "1353) Lyapunov Risk = 0.7775484323501587, MSE = 0.023553479462862015, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.025117650628089905, Lv_loss = 0.0, Circular Tuning Loss = 0.8917366862297058\n",
      "1354) Lyapunov Risk = 0.7774808406829834, MSE = 0.025983553379774094, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.025103043764829636, Lv_loss = 0.0, Circular Tuning Loss = 0.8915620446205139\n",
      "1355) Lyapunov Risk = 0.7773504257202148, MSE = 0.023429976776242256, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.025089293718338013, Lv_loss = 0.0, Circular Tuning Loss = 0.8913863897323608\n",
      "1356) Lyapunov Risk = 0.7770400047302246, MSE = 0.026041550561785698, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.02507578395307064, Lv_loss = 0.0, Circular Tuning Loss = 0.8912108540534973\n",
      "1357) Lyapunov Risk = 0.7765566110610962, MSE = 0.023635100573301315, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.025062767788767815, Lv_loss = 0.0, Circular Tuning Loss = 0.8910347819328308\n",
      "1358) Lyapunov Risk = 0.7759935259819031, MSE = 0.02529078908264637, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.025049850344657898, Lv_loss = 0.0, Circular Tuning Loss = 0.8908588886260986\n",
      "1359) Lyapunov Risk = 0.7755675315856934, MSE = 0.024273209273815155, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.02503701113164425, Lv_loss = 0.0, Circular Tuning Loss = 0.8906826376914978\n",
      "1360) Lyapunov Risk = 0.7752989530563354, MSE = 0.02439863793551922, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.02502421662211418, Lv_loss = 0.0, Circular Tuning Loss = 0.8905059099197388\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.81885831118204233, -0.81713328601346502]\n",
      "x2 : [1.8220224904398763, 1.8237397361865615]\n",
      "==============================\n",
      "1361) Lyapunov Risk = 0.7818717956542969, MSE = 0.02505188249051571, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.024905890226364136, Lv_loss = 0.0, Circular Tuning Loss = 0.9034057259559631\n",
      "1362) Lyapunov Risk = 0.7817132472991943, MSE = 0.02386114001274109, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.024893373250961304, Lv_loss = 0.0, Circular Tuning Loss = 0.9032188653945923\n",
      "1363) Lyapunov Risk = 0.7814223170280457, MSE = 0.025268735364079475, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.02488079108297825, Lv_loss = 0.0, Circular Tuning Loss = 0.9030313491821289\n",
      "1364) Lyapunov Risk = 0.78104567527771, MSE = 0.023849446326494217, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.024868454784154892, Lv_loss = 0.0, Circular Tuning Loss = 0.9028430581092834\n",
      "1365) Lyapunov Risk = 0.7806246280670166, MSE = 0.024824902415275574, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.024856137111783028, Lv_loss = 0.0, Circular Tuning Loss = 0.9026544094085693\n",
      "1366) Lyapunov Risk = 0.7802941799163818, MSE = 0.02436210960149765, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.02484409138560295, Lv_loss = 0.0, Circular Tuning Loss = 0.9024649858474731\n",
      "1367) Lyapunov Risk = 0.7800949215888977, MSE = 0.024217702448368073, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.024832211434841156, Lv_loss = 0.0, Circular Tuning Loss = 0.9022752642631531\n",
      "1368) Lyapunov Risk = 0.7799501419067383, MSE = 0.024954592809081078, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.02482038550078869, Lv_loss = 0.0, Circular Tuning Loss = 0.9020850658416748\n",
      "1369) Lyapunov Risk = 0.7797778248786926, MSE = 0.023979797959327698, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.024808790534734726, Lv_loss = 0.0, Circular Tuning Loss = 0.901894211769104\n",
      "1370) Lyapunov Risk = 0.7795021533966064, MSE = 0.02501961588859558, V_0_loss = tensor([[0.0039]], grad_fn=<PowBackward0>), V_pos_loss = 0.024797191843390465, Lv_loss = 0.0, Circular Tuning Loss = 0.901703417301178\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.80577511307078697, -0.80432931464480639]\n",
      "x2 : [1.8297925940139237, 1.8311347174915933]\n",
      "==============================\n",
      "1371) Lyapunov Risk = 0.7858636975288391, MSE = 0.024070659652352333, V_0_loss = tensor([[0.0040]], grad_fn=<PowBackward0>), V_pos_loss = 0.024681689217686653, Lv_loss = 0.0, Circular Tuning Loss = 0.9145207405090332\n",
      "1372) Lyapunov Risk = 0.7855112552642822, MSE = 0.02455812320113182, V_0_loss = tensor([[0.0040]], grad_fn=<PowBackward0>), V_pos_loss = 0.024670375511050224, Lv_loss = 0.0, Circular Tuning Loss = 0.9143195748329163\n",
      "1373) Lyapunov Risk = 0.7852219343185425, MSE = 0.024480050429701805, V_0_loss = tensor([[0.0040]], grad_fn=<PowBackward0>), V_pos_loss = 0.02465934492647648, Lv_loss = 0.0, Circular Tuning Loss = 0.9141178131103516\n",
      "1374) Lyapunov Risk = 0.7849993705749512, MSE = 0.02404753305017948, V_0_loss = tensor([[0.0040]], grad_fn=<PowBackward0>), V_pos_loss = 0.02464851550757885, Lv_loss = 0.0, Circular Tuning Loss = 0.9139155149459839\n",
      "1375) Lyapunov Risk = 0.7847897410392761, MSE = 0.024837657809257507, V_0_loss = tensor([[0.0040]], grad_fn=<PowBackward0>), V_pos_loss = 0.02463771589100361, Lv_loss = 0.0, Circular Tuning Loss = 0.9137129187583923\n",
      "1376) Lyapunov Risk = 0.7845634818077087, MSE = 0.02390732802450657, V_0_loss = tensor([[0.0040]], grad_fn=<PowBackward0>), V_pos_loss = 0.02462700568139553, Lv_loss = 0.0, Circular Tuning Loss = 0.9135096669197083\n",
      "1377) Lyapunov Risk = 0.7842775583267212, MSE = 0.024864573031663895, V_0_loss = tensor([[0.0040]], grad_fn=<PowBackward0>), V_pos_loss = 0.024616315960884094, Lv_loss = 0.0, Circular Tuning Loss = 0.913306713104248\n",
      "1378) Lyapunov Risk = 0.783973753452301, MSE = 0.02408417873084545, V_0_loss = tensor([[0.0040]], grad_fn=<PowBackward0>), V_pos_loss = 0.024605832993984222, Lv_loss = 0.0, Circular Tuning Loss = 0.9131032824516296\n",
      "1379) Lyapunov Risk = 0.7836681008338928, MSE = 0.024543965235352516, V_0_loss = tensor([[0.0040]], grad_fn=<PowBackward0>), V_pos_loss = 0.02459542639553547, Lv_loss = 0.0, Circular Tuning Loss = 0.9128998517990112\n",
      "1380) Lyapunov Risk = 0.7834020256996155, MSE = 0.0244468804448843, V_0_loss = tensor([[0.0040]], grad_fn=<PowBackward0>), V_pos_loss = 0.024585219100117683, Lv_loss = 0.0, Circular Tuning Loss = 0.912696361541748\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.79036294840829135, -0.78973978132937728]\n",
      "x2 : [1.8353825879862347, 1.8362590879242886]\n",
      "==============================\n",
      "1381) Lyapunov Risk = 0.7898064851760864, MSE = 0.024132229387760162, V_0_loss = tensor([[0.0040]], grad_fn=<PowBackward0>), V_pos_loss = 0.024472380056977272, Lv_loss = 0.0, Circular Tuning Loss = 0.9253847002983093\n",
      "1382) Lyapunov Risk = 0.7895723581314087, MSE = 0.0246583241969347, V_0_loss = tensor([[0.0040]], grad_fn=<PowBackward0>), V_pos_loss = 0.024462448433041573, Lv_loss = 0.0, Circular Tuning Loss = 0.9251713156700134\n",
      "1383) Lyapunov Risk = 0.789334237575531, MSE = 0.023967383429408073, V_0_loss = tensor([[0.0040]], grad_fn=<PowBackward0>), V_pos_loss = 0.024452608078718185, Lv_loss = 0.0, Circular Tuning Loss = 0.9249573945999146\n",
      "1384) Lyapunov Risk = 0.7890745997428894, MSE = 0.024700667709112167, V_0_loss = tensor([[0.0040]], grad_fn=<PowBackward0>), V_pos_loss = 0.024442803114652634, Lv_loss = 0.0, Circular Tuning Loss = 0.9247432947158813\n",
      "1385) Lyapunov Risk = 0.7887988090515137, MSE = 0.02400900050997734, V_0_loss = tensor([[0.0040]], grad_fn=<PowBackward0>), V_pos_loss = 0.024433068931102753, Lv_loss = 0.0, Circular Tuning Loss = 0.9245287775993347\n",
      "1386) Lyapunov Risk = 0.7885221838951111, MSE = 0.024596072733402252, V_0_loss = tensor([[0.0040]], grad_fn=<PowBackward0>), V_pos_loss = 0.024423349648714066, Lv_loss = 0.0, Circular Tuning Loss = 0.9243140816688538\n",
      "1387) Lyapunov Risk = 0.7882495522499084, MSE = 0.024137074127793312, V_0_loss = tensor([[0.0040]], grad_fn=<PowBackward0>), V_pos_loss = 0.02441365085542202, Lv_loss = 0.0, Circular Tuning Loss = 0.9240992069244385\n",
      "1388) Lyapunov Risk = 0.7879839539527893, MSE = 0.024465516209602356, V_0_loss = tensor([[0.0040]], grad_fn=<PowBackward0>), V_pos_loss = 0.024403980001807213, Lv_loss = 0.0, Circular Tuning Loss = 0.923884391784668\n",
      "1389) Lyapunov Risk = 0.7877276539802551, MSE = 0.024227920919656754, V_0_loss = tensor([[0.0040]], grad_fn=<PowBackward0>), V_pos_loss = 0.024394290521740913, Lv_loss = 0.0, Circular Tuning Loss = 0.9236695766448975\n",
      "1390) Lyapunov Risk = 0.7874757051467896, MSE = 0.02441232092678547, V_0_loss = tensor([[0.0040]], grad_fn=<PowBackward0>), V_pos_loss = 0.024384643882513046, Lv_loss = 0.0, Circular Tuning Loss = 0.9234549403190613\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.77731442850738008, -0.7750382261317651]\n",
      "x2 : [1.8421847237548636, 1.8437233382572691]\n",
      "==============================\n",
      "1391) Lyapunov Risk = 0.7938255071640015, MSE = 0.02420840784907341, V_0_loss = tensor([[0.0040]], grad_fn=<PowBackward0>), V_pos_loss = 0.02427346631884575, Lv_loss = 0.0, Circular Tuning Loss = 0.9360498785972595\n",
      "1392) Lyapunov Risk = 0.793576717376709, MSE = 0.02443234808743, V_0_loss = tensor([[0.0040]], grad_fn=<PowBackward0>), V_pos_loss = 0.024263886734843254, Lv_loss = 0.0, Circular Tuning Loss = 0.9358251094818115\n",
      "1393) Lyapunov Risk = 0.7933316230773926, MSE = 0.024121934548020363, V_0_loss = tensor([[0.0040]], grad_fn=<PowBackward0>), V_pos_loss = 0.024254342541098595, Lv_loss = 0.0, Circular Tuning Loss = 0.9356001019477844\n",
      "1394) Lyapunov Risk = 0.7930968403816223, MSE = 0.024524860084056854, V_0_loss = tensor([[0.0040]], grad_fn=<PowBackward0>), V_pos_loss = 0.024244872853159904, Lv_loss = 0.0, Circular Tuning Loss = 0.9353746771812439\n",
      "1395) Lyapunov Risk = 0.7928594946861267, MSE = 0.024021705612540245, V_0_loss = tensor([[0.0040]], grad_fn=<PowBackward0>), V_pos_loss = 0.02423541434109211, Lv_loss = 0.0, Circular Tuning Loss = 0.9351491332054138\n",
      "1396) Lyapunov Risk = 0.7926249504089355, MSE = 0.02464161440730095, V_0_loss = tensor([[0.0040]], grad_fn=<PowBackward0>), V_pos_loss = 0.02422630414366722, Lv_loss = 0.0, Circular Tuning Loss = 0.9349235892295837\n",
      "1397) Lyapunov Risk = 0.7923710346221924, MSE = 0.024006588384509087, V_0_loss = tensor([[0.0040]], grad_fn=<PowBackward0>), V_pos_loss = 0.024217218160629272, Lv_loss = 0.0, Circular Tuning Loss = 0.9346981048583984\n",
      "1398) Lyapunov Risk = 0.7921104431152344, MSE = 0.02465316466987133, V_0_loss = tensor([[0.0040]], grad_fn=<PowBackward0>), V_pos_loss = 0.024208182469010353, Lv_loss = 0.0, Circular Tuning Loss = 0.9344725608825684\n",
      "1399) Lyapunov Risk = 0.7918261289596558, MSE = 0.02407499961555004, V_0_loss = tensor([[0.0040]], grad_fn=<PowBackward0>), V_pos_loss = 0.024199167266488075, Lv_loss = 0.0, Circular Tuning Loss = 0.9342471361160278\n",
      "1400) Lyapunov Risk = 0.7915467619895935, MSE = 0.02452077344059944, V_0_loss = tensor([[0.0040]], grad_fn=<PowBackward0>), V_pos_loss = 0.024190207943320274, Lv_loss = 0.0, Circular Tuning Loss = 0.9340218901634216\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.76143706034536307, -0.75953088362113597]\n",
      "x2 : [1.8491222705199624, 1.850165624160631]\n",
      "==============================\n",
      "1401) Lyapunov Risk = 0.797813892364502, MSE = 0.024162709712982178, V_0_loss = tensor([[0.0040]], grad_fn=<PowBackward0>), V_pos_loss = 0.024082204326987267, Lv_loss = 0.0, Circular Tuning Loss = 0.9465230703353882\n",
      "1402) Lyapunov Risk = 0.7975285649299622, MSE = 0.0243141520768404, V_0_loss = tensor([[0.0040]], grad_fn=<PowBackward0>), V_pos_loss = 0.024072101339697838, Lv_loss = 0.0, Circular Tuning Loss = 0.9462874531745911\n",
      "1403) Lyapunov Risk = 0.797244131565094, MSE = 0.024256085976958275, V_0_loss = tensor([[0.0040]], grad_fn=<PowBackward0>), V_pos_loss = 0.024063417688012123, Lv_loss = 0.0, Circular Tuning Loss = 0.9460514783859253\n",
      "1404) Lyapunov Risk = 0.7969656586647034, MSE = 0.024120710790157318, V_0_loss = tensor([[0.0040]], grad_fn=<PowBackward0>), V_pos_loss = 0.02405489608645439, Lv_loss = 0.0, Circular Tuning Loss = 0.9458154439926147\n",
      "1405) Lyapunov Risk = 0.7966920733451843, MSE = 0.02439798414707184, V_0_loss = tensor([[0.0040]], grad_fn=<PowBackward0>), V_pos_loss = 0.024046409875154495, Lv_loss = 0.0, Circular Tuning Loss = 0.9455797672271729\n",
      "1406) Lyapunov Risk = 0.7964186668395996, MSE = 0.024026723578572273, V_0_loss = tensor([[0.0040]], grad_fn=<PowBackward0>), V_pos_loss = 0.024038013070821762, Lv_loss = 0.0, Circular Tuning Loss = 0.9453436732292175\n",
      "1407) Lyapunov Risk = 0.7961456179618835, MSE = 0.024469787254929543, V_0_loss = tensor([[0.0040]], grad_fn=<PowBackward0>), V_pos_loss = 0.024029657244682312, Lv_loss = 0.0, Circular Tuning Loss = 0.9451079964637756\n",
      "1408) Lyapunov Risk = 0.7958667874336243, MSE = 0.024026812985539436, V_0_loss = tensor([[0.0040]], grad_fn=<PowBackward0>), V_pos_loss = 0.024021344259381294, Lv_loss = 0.0, Circular Tuning Loss = 0.944872260093689\n",
      "1409) Lyapunov Risk = 0.7955864071846008, MSE = 0.02440653368830681, V_0_loss = tensor([[0.0040]], grad_fn=<PowBackward0>), V_pos_loss = 0.024012986570596695, Lv_loss = 0.0, Circular Tuning Loss = 0.9446368217468262\n",
      "1410) Lyapunov Risk = 0.7953058481216431, MSE = 0.02411067858338356, V_0_loss = tensor([[0.0041]], grad_fn=<PowBackward0>), V_pos_loss = 0.024004671722650528, Lv_loss = 0.0, Circular Tuning Loss = 0.9444015622138977\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.72656250000000022, -0.71875000000000022]\n",
      "x2 : [1.8413058177424653, 1.8513058177424651]\n",
      "==============================\n",
      "1411) Lyapunov Risk = 0.8014547228813171, MSE = 0.024237988516688347, V_0_loss = tensor([[0.0041]], grad_fn=<PowBackward0>), V_pos_loss = 0.02391819842159748, Lv_loss = 0.0, Circular Tuning Loss = 0.9565847516059875\n",
      "1412) Lyapunov Risk = 0.8011781573295593, MSE = 0.024198021739721298, V_0_loss = tensor([[0.0041]], grad_fn=<PowBackward0>), V_pos_loss = 0.023907266557216644, Lv_loss = 0.0, Circular Tuning Loss = 0.9563391804695129\n",
      "1413) Lyapunov Risk = 0.8009046316146851, MSE = 0.02411969006061554, V_0_loss = tensor([[0.0041]], grad_fn=<PowBackward0>), V_pos_loss = 0.023896463215351105, Lv_loss = 0.0, Circular Tuning Loss = 0.9560928344726562\n",
      "1414) Lyapunov Risk = 0.8006329536437988, MSE = 0.024266505613923073, V_0_loss = tensor([[0.0041]], grad_fn=<PowBackward0>), V_pos_loss = 0.02388593927025795, Lv_loss = 0.0, Circular Tuning Loss = 0.9558457732200623\n",
      "1415) Lyapunov Risk = 0.8003605604171753, MSE = 0.024065840989351273, V_0_loss = tensor([[0.0041]], grad_fn=<PowBackward0>), V_pos_loss = 0.023875491693615913, Lv_loss = 0.0, Circular Tuning Loss = 0.9555980563163757\n",
      "1416) Lyapunov Risk = 0.8000860214233398, MSE = 0.02428250014781952, V_0_loss = tensor([[0.0041]], grad_fn=<PowBackward0>), V_pos_loss = 0.02386508695781231, Lv_loss = 0.0, Circular Tuning Loss = 0.9553501009941101\n",
      "1417) Lyapunov Risk = 0.7998106479644775, MSE = 0.024101249873638153, V_0_loss = tensor([[0.0041]], grad_fn=<PowBackward0>), V_pos_loss = 0.02385486289858818, Lv_loss = 0.0, Circular Tuning Loss = 0.9551015496253967\n",
      "1418) Lyapunov Risk = 0.7995366454124451, MSE = 0.024234967306256294, V_0_loss = tensor([[0.0041]], grad_fn=<PowBackward0>), V_pos_loss = 0.023845119401812553, Lv_loss = 0.0, Circular Tuning Loss = 0.9548529386520386\n",
      "1419) Lyapunov Risk = 0.7992653846740723, MSE = 0.024166403338313103, V_0_loss = tensor([[0.0041]], grad_fn=<PowBackward0>), V_pos_loss = 0.02383611910045147, Lv_loss = 0.0, Circular Tuning Loss = 0.9546043872833252\n",
      "1420) Lyapunov Risk = 0.7989967465400696, MSE = 0.024174535647034645, V_0_loss = tensor([[0.0041]], grad_fn=<PowBackward0>), V_pos_loss = 0.023827804252505302, Lv_loss = 0.0, Circular Tuning Loss = 0.954355776309967\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.72744216159688724, -0.71875000000000022]\n",
      "x2 : [1.8463058177424652, 1.8529993668966065]\n",
      "==============================\n",
      "1421) Lyapunov Risk = 0.8050718903541565, MSE = 0.024196915328502655, V_0_loss = tensor([[0.0041]], grad_fn=<PowBackward0>), V_pos_loss = 0.023722514510154724, Lv_loss = 0.0, Circular Tuning Loss = 0.9663951992988586\n",
      "1422) Lyapunov Risk = 0.8048019409179688, MSE = 0.02410883828997612, V_0_loss = tensor([[0.0041]], grad_fn=<PowBackward0>), V_pos_loss = 0.023714924231171608, Lv_loss = 0.0, Circular Tuning Loss = 0.966137170791626\n",
      "1423) Lyapunov Risk = 0.8045327663421631, MSE = 0.02418620139360428, V_0_loss = tensor([[0.0041]], grad_fn=<PowBackward0>), V_pos_loss = 0.023707784712314606, Lv_loss = 0.0, Circular Tuning Loss = 0.9658792614936829\n",
      "1424) Lyapunov Risk = 0.8042640686035156, MSE = 0.024123046547174454, V_0_loss = tensor([[0.0041]], grad_fn=<PowBackward0>), V_pos_loss = 0.02370080165565014, Lv_loss = 0.0, Circular Tuning Loss = 0.965621292591095\n",
      "1425) Lyapunov Risk = 0.8039986491203308, MSE = 0.024118490517139435, V_0_loss = tensor([[0.0041]], grad_fn=<PowBackward0>), V_pos_loss = 0.02369404211640358, Lv_loss = 0.0, Circular Tuning Loss = 0.9653632640838623\n",
      "1426) Lyapunov Risk = 0.8037394881248474, MSE = 0.02422819286584854, V_0_loss = tensor([[0.0041]], grad_fn=<PowBackward0>), V_pos_loss = 0.023687543347477913, Lv_loss = 0.0, Circular Tuning Loss = 0.9651056528091431\n",
      "1427) Lyapunov Risk = 0.8034907579421997, MSE = 0.02404842898249626, V_0_loss = tensor([[0.0041]], grad_fn=<PowBackward0>), V_pos_loss = 0.023681269958615303, Lv_loss = 0.0, Circular Tuning Loss = 0.9648481607437134\n",
      "1428) Lyapunov Risk = 0.8032547831535339, MSE = 0.024362266063690186, V_0_loss = tensor([[0.0041]], grad_fn=<PowBackward0>), V_pos_loss = 0.02367502450942993, Lv_loss = 0.0, Circular Tuning Loss = 0.9645910859107971\n",
      "1429) Lyapunov Risk = 0.8030373454093933, MSE = 0.023967646062374115, V_0_loss = tensor([[0.0041]], grad_fn=<PowBackward0>), V_pos_loss = 0.02366887405514717, Lv_loss = 0.0, Circular Tuning Loss = 0.9643343687057495\n",
      "1430) Lyapunov Risk = 0.8028411269187927, MSE = 0.024503808468580246, V_0_loss = tensor([[0.0041]], grad_fn=<PowBackward0>), V_pos_loss = 0.023662662133574486, Lv_loss = 0.0, Circular Tuning Loss = 0.9640780687332153\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.71035325098977675, -0.70273550065985124]\n",
      "x2 : [1.858867334376457, 1.8656711926207907]\n",
      "==============================\n",
      "1431) Lyapunov Risk = 0.8090390563011169, MSE = 0.0239203292876482, V_0_loss = tensor([[0.0041]], grad_fn=<PowBackward0>), V_pos_loss = 0.02356470189988613, Lv_loss = 0.0, Circular Tuning Loss = 0.9761558771133423\n",
      "1432) Lyapunov Risk = 0.8088864088058472, MSE = 0.024615973234176636, V_0_loss = tensor([[0.0041]], grad_fn=<PowBackward0>), V_pos_loss = 0.023556672036647797, Lv_loss = 0.0, Circular Tuning Loss = 0.9758893847465515\n",
      "1433) Lyapunov Risk = 0.8087517619132996, MSE = 0.023931749165058136, V_0_loss = tensor([[0.0041]], grad_fn=<PowBackward0>), V_pos_loss = 0.02354942075908184, Lv_loss = 0.0, Circular Tuning Loss = 0.9756222367286682\n",
      "1434) Lyapunov Risk = 0.8086155652999878, MSE = 0.02476048655807972, V_0_loss = tensor([[0.0041]], grad_fn=<PowBackward0>), V_pos_loss = 0.023542847484350204, Lv_loss = 0.0, Circular Tuning Loss = 0.9753552079200745\n",
      "1435) Lyapunov Risk = 0.8084238767623901, MSE = 0.023890364915132523, V_0_loss = tensor([[0.0041]], grad_fn=<PowBackward0>), V_pos_loss = 0.02353699877858162, Lv_loss = 0.0, Circular Tuning Loss = 0.9750878214836121\n",
      "1436) Lyapunov Risk = 0.8081227540969849, MSE = 0.024882953613996506, V_0_loss = tensor([[0.0041]], grad_fn=<PowBackward0>), V_pos_loss = 0.023531241342425346, Lv_loss = 0.0, Circular Tuning Loss = 0.9748209714889526\n",
      "1437) Lyapunov Risk = 0.8077186942100525, MSE = 0.02371305041015148, V_0_loss = tensor([[0.0041]], grad_fn=<PowBackward0>), V_pos_loss = 0.023525603115558624, Lv_loss = 0.0, Circular Tuning Loss = 0.9745541214942932\n",
      "1438) Lyapunov Risk = 0.8072413206100464, MSE = 0.024903807789087296, V_0_loss = tensor([[0.0041]], grad_fn=<PowBackward0>), V_pos_loss = 0.023519812151789665, Lv_loss = 0.0, Circular Tuning Loss = 0.9742879867553711\n",
      "1439) Lyapunov Risk = 0.8067854642868042, MSE = 0.02354065142571926, V_0_loss = tensor([[0.0041]], grad_fn=<PowBackward0>), V_pos_loss = 0.023514172062277794, Lv_loss = 0.0, Circular Tuning Loss = 0.9740217328071594\n",
      "1440) Lyapunov Risk = 0.8064160943031311, MSE = 0.02477663941681385, V_0_loss = tensor([[0.0041]], grad_fn=<PowBackward0>), V_pos_loss = 0.023508604615926743, Lv_loss = 0.0, Circular Tuning Loss = 0.9737563133239746\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.69789621320325357, -0.69616351100271134]\n",
      "x2 : [1.8738751404151275, 1.8749283628844007]\n",
      "==============================\n",
      "1441) Lyapunov Risk = 0.8125120401382446, MSE = 0.02362464927136898, V_0_loss = tensor([[0.0041]], grad_fn=<PowBackward0>), V_pos_loss = 0.02340768650174141, Lv_loss = 0.0, Circular Tuning Loss = 0.9858436584472656\n",
      "1442) Lyapunov Risk = 0.8122673034667969, MSE = 0.024507155641913414, V_0_loss = tensor([[0.0041]], grad_fn=<PowBackward0>), V_pos_loss = 0.023401785641908646, Lv_loss = 0.0, Circular Tuning Loss = 0.985568106174469\n",
      "1443) Lyapunov Risk = 0.8120162487030029, MSE = 0.0239238440990448, V_0_loss = tensor([[0.0041]], grad_fn=<PowBackward0>), V_pos_loss = 0.02339647337794304, Lv_loss = 0.0, Circular Tuning Loss = 0.9852920770645142\n",
      "1444) Lyapunov Risk = 0.8117121458053589, MSE = 0.024180948734283447, V_0_loss = tensor([[0.0041]], grad_fn=<PowBackward0>), V_pos_loss = 0.02339123748242855, Lv_loss = 0.0, Circular Tuning Loss = 0.9850159287452698\n",
      "1445) Lyapunov Risk = 0.811360776424408, MSE = 0.024150552228093147, V_0_loss = tensor([[0.0041]], grad_fn=<PowBackward0>), V_pos_loss = 0.02338595688343048, Lv_loss = 0.0, Circular Tuning Loss = 0.9847398400306702\n",
      "1446) Lyapunov Risk = 0.8109894394874573, MSE = 0.023952065035700798, V_0_loss = tensor([[0.0041]], grad_fn=<PowBackward0>), V_pos_loss = 0.02338077686727047, Lv_loss = 0.0, Circular Tuning Loss = 0.9844635128974915\n",
      "1447) Lyapunov Risk = 0.8106552362442017, MSE = 0.024268660694360733, V_0_loss = tensor([[0.0041]], grad_fn=<PowBackward0>), V_pos_loss = 0.02337569184601307, Lv_loss = 0.0, Circular Tuning Loss = 0.9841870665550232\n",
      "1448) Lyapunov Risk = 0.8103998899459839, MSE = 0.02376866526901722, V_0_loss = tensor([[0.0041]], grad_fn=<PowBackward0>), V_pos_loss = 0.02337069809436798, Lv_loss = 0.0, Circular Tuning Loss = 0.983910858631134\n",
      "1449) Lyapunov Risk = 0.8101970553398132, MSE = 0.024488402530550957, V_0_loss = tensor([[0.0041]], grad_fn=<PowBackward0>), V_pos_loss = 0.023365847766399384, Lv_loss = 0.0, Circular Tuning Loss = 0.983634889125824\n",
      "1450) Lyapunov Risk = 0.8099900484085083, MSE = 0.023701388388872147, V_0_loss = tensor([[0.0041]], grad_fn=<PowBackward0>), V_pos_loss = 0.02336115390062332, Lv_loss = 0.0, Circular Tuning Loss = 0.9833589792251587\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.67968750000000022, -0.67187500000000022]\n",
      "x2 : [1.8698687265640879, 1.8768186428481433]\n",
      "==============================\n",
      "1451) Lyapunov Risk = 0.8160075545310974, MSE = 0.02454962767660618, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.023264121264219284, Lv_loss = 0.0, Circular Tuning Loss = 0.9952195882797241\n",
      "1452) Lyapunov Risk = 0.8156826496124268, MSE = 0.023683587089180946, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.023257916793227196, Lv_loss = 0.0, Circular Tuning Loss = 0.9949334859848022\n",
      "1453) Lyapunov Risk = 0.8153243064880371, MSE = 0.024393945932388306, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.023252638056874275, Lv_loss = 0.0, Circular Tuning Loss = 0.9946467876434326\n",
      "1454) Lyapunov Risk = 0.8149712085723877, MSE = 0.023750655353069305, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.02324795350432396, Lv_loss = 0.0, Circular Tuning Loss = 0.9943597316741943\n",
      "1455) Lyapunov Risk = 0.8146589398384094, MSE = 0.024178490042686462, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.02324361726641655, Lv_loss = 0.0, Circular Tuning Loss = 0.9940725564956665\n",
      "1456) Lyapunov Risk = 0.8143836855888367, MSE = 0.023891203105449677, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.023239506408572197, Lv_loss = 0.0, Circular Tuning Loss = 0.9937856197357178\n",
      "1457) Lyapunov Risk = 0.8141227960586548, MSE = 0.024105103686451912, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.023235639557242393, Lv_loss = 0.0, Circular Tuning Loss = 0.9934987425804138\n",
      "1458) Lyapunov Risk = 0.8138524293899536, MSE = 0.023964712396264076, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.023232048377394676, Lv_loss = 0.0, Circular Tuning Loss = 0.9932119250297546\n",
      "1459) Lyapunov Risk = 0.8135648369789124, MSE = 0.024070410057902336, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.023228418081998825, Lv_loss = 0.0, Circular Tuning Loss = 0.9929254651069641\n",
      "1460) Lyapunov Risk = 0.8132638335227966, MSE = 0.023998593911528587, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.02322503924369812, Lv_loss = 0.0, Circular Tuning Loss = 0.9926393628120422\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.66267026170789878, -0.66100568035607565]\n",
      "x2 : [1.8848680012455643, 1.8862389977669225]\n",
      "==============================\n",
      "1461) Lyapunov Risk = 0.819242000579834, MSE = 0.02400215156376362, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.023129364475607872, Lv_loss = 0.0, Circular Tuning Loss = 1.0045087337493896\n",
      "1462) Lyapunov Risk = 0.8189426064491272, MSE = 0.02395952306687832, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.023124607279896736, Lv_loss = 0.0, Circular Tuning Loss = 1.004212498664856\n",
      "1463) Lyapunov Risk = 0.8186579346656799, MSE = 0.023963848128914833, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.02312139794230461, Lv_loss = 0.0, Circular Tuning Loss = 1.0039161443710327\n",
      "1464) Lyapunov Risk = 0.818382740020752, MSE = 0.023935895413160324, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.02311819978058338, Lv_loss = 0.0, Circular Tuning Loss = 1.0036200284957886\n",
      "1465) Lyapunov Risk = 0.818108856678009, MSE = 0.02395576238632202, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.023115091025829315, Lv_loss = 0.0, Circular Tuning Loss = 1.0033236742019653\n",
      "1466) Lyapunov Risk = 0.8178306818008423, MSE = 0.023958055302500725, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.023111965507268906, Lv_loss = 0.0, Circular Tuning Loss = 1.0030277967453003\n",
      "1467) Lyapunov Risk = 0.8175442218780518, MSE = 0.02395661361515522, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.02310887724161148, Lv_loss = 0.0, Circular Tuning Loss = 1.0027319192886353\n",
      "1468) Lyapunov Risk = 0.817253053188324, MSE = 0.023994602262973785, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.02310575358569622, Lv_loss = 0.0, Circular Tuning Loss = 1.0024365186691284\n",
      "1469) Lyapunov Risk = 0.8169607520103455, MSE = 0.023928694427013397, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.023102618753910065, Lv_loss = 0.0, Circular Tuning Loss = 1.0021417140960693\n",
      "1470) Lyapunov Risk = 0.8166707754135132, MSE = 0.024010688066482544, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.023099418729543686, Lv_loss = 0.0, Circular Tuning Loss = 1.0018471479415894\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.62457284182994455, -0.61721751648848366]\n",
      "x2 : [1.8480796328747955, 1.8580796328747953]\n",
      "==============================\n",
      "1471) Lyapunov Risk = 0.8222531080245972, MSE = 0.0238832738250494, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.023003237321972847, Lv_loss = 0.0, Circular Tuning Loss = 1.0128943920135498\n",
      "1472) Lyapunov Risk = 0.8219662308692932, MSE = 0.02396097034215927, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.022999918088316917, Lv_loss = 0.0, Circular Tuning Loss = 1.012591004371643\n",
      "1473) Lyapunov Risk = 0.8216818571090698, MSE = 0.023879677057266235, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.022996796295046806, Lv_loss = 0.0, Circular Tuning Loss = 1.0122877359390259\n",
      "1474) Lyapunov Risk = 0.8213973641395569, MSE = 0.023901376873254776, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.022993896156549454, Lv_loss = 0.0, Circular Tuning Loss = 1.0119847059249878\n",
      "1475) Lyapunov Risk = 0.8211120963096619, MSE = 0.023926418274641037, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.02299104817211628, Lv_loss = 0.0, Circular Tuning Loss = 1.011682152748108\n",
      "1476) Lyapunov Risk = 0.8208261132240295, MSE = 0.023844921961426735, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.022988205775618553, Lv_loss = 0.0, Circular Tuning Loss = 1.011379599571228\n",
      "1477) Lyapunov Risk = 0.8205406665802002, MSE = 0.024009421467781067, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.022985419258475304, Lv_loss = 0.0, Circular Tuning Loss = 1.0110775232315063\n",
      "1478) Lyapunov Risk = 0.8202565312385559, MSE = 0.02379736863076687, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.02298271469771862, Lv_loss = 0.0, Circular Tuning Loss = 1.0107758045196533\n",
      "1479) Lyapunov Risk = 0.8199735879898071, MSE = 0.024085119366645813, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.02298024110496044, Lv_loss = 0.0, Circular Tuning Loss = 1.0104745626449585\n",
      "1480) Lyapunov Risk = 0.8196903467178345, MSE = 0.0237543024122715, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.022977864369750023, Lv_loss = 0.0, Circular Tuning Loss = 1.0101733207702637\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.50945367391406582, -0.50000000000000011]\n",
      "x2 : [1.7243177784161499, 1.7316341196122724]\n",
      "==============================\n",
      "1481) Lyapunov Risk = 0.8240678906440735, MSE = 0.024111075326800346, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.022885335609316826, Lv_loss = 0.0, Circular Tuning Loss = 1.018837571144104\n",
      "1482) Lyapunov Risk = 0.8237853646278381, MSE = 0.023667195811867714, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.022881921380758286, Lv_loss = 0.0, Circular Tuning Loss = 1.0185284614562988\n",
      "1483) Lyapunov Risk = 0.8235008120536804, MSE = 0.024128224700689316, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.02287888154387474, Lv_loss = 0.0, Circular Tuning Loss = 1.018219232559204\n",
      "1484) Lyapunov Risk = 0.823215901851654, MSE = 0.023621123284101486, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.022876597940921783, Lv_loss = 0.0, Circular Tuning Loss = 1.0179098844528198\n",
      "1485) Lyapunov Risk = 0.8229312896728516, MSE = 0.024129273369908333, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.022874515503644943, Lv_loss = 0.0, Circular Tuning Loss = 1.0176010131835938\n",
      "1486) Lyapunov Risk = 0.8226465582847595, MSE = 0.023643817752599716, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.022872528061270714, Lv_loss = 0.0, Circular Tuning Loss = 1.0172922611236572\n",
      "1487) Lyapunov Risk = 0.8223646879196167, MSE = 0.0241409782320261, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.02287052571773529, Lv_loss = 0.0, Circular Tuning Loss = 1.0169837474822998\n",
      "1488) Lyapunov Risk = 0.8220850229263306, MSE = 0.023685181513428688, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.022868618369102478, Lv_loss = 0.0, Circular Tuning Loss = 1.016675353050232\n",
      "1489) Lyapunov Risk = 0.8218092918395996, MSE = 0.024162879213690758, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.022866681218147278, Lv_loss = 0.0, Circular Tuning Loss = 1.0163675546646118\n",
      "1490) Lyapunov Risk = 0.821535587310791, MSE = 0.02366279624402523, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.02286483533680439, Lv_loss = 0.0, Circular Tuning Loss = 1.0160598754882812\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.50885275253448081, -0.50000000000000011]\n",
      "x2 : [1.7499316008129433, 1.7599316008129431]\n",
      "==============================\n",
      "1491) Lyapunov Risk = 0.8260828256607056, MSE = 0.02420513890683651, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.0227724090218544, Lv_loss = 0.0, Circular Tuning Loss = 1.025026798248291\n",
      "1492) Lyapunov Risk = 0.8258252143859863, MSE = 0.023539148271083832, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.022770371288061142, Lv_loss = 0.0, Circular Tuning Loss = 1.024710774421692\n",
      "1493) Lyapunov Risk = 0.8255817890167236, MSE = 0.02433556318283081, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.022768650203943253, Lv_loss = 0.0, Circular Tuning Loss = 1.0243951082229614\n",
      "1494) Lyapunov Risk = 0.8253541588783264, MSE = 0.023388167843222618, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.022767292335629463, Lv_loss = 0.0, Circular Tuning Loss = 1.0240793228149414\n",
      "1495) Lyapunov Risk = 0.8251380920410156, MSE = 0.024538226425647736, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.02276592142879963, Lv_loss = 0.0, Circular Tuning Loss = 1.0237640142440796\n",
      "1496) Lyapunov Risk = 0.8249364495277405, MSE = 0.023288382217288017, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.022764701396226883, Lv_loss = 2.538489525250043e-07, Circular Tuning Loss = 1.0234485864639282\n",
      "1497) Lyapunov Risk = 0.8247814178466797, MSE = 0.024844832718372345, V_0_loss = tensor([[0.0042]], grad_fn=<PowBackward0>), V_pos_loss = 0.022763391956686974, Lv_loss = 0.0, Circular Tuning Loss = 1.0231339931488037\n",
      "1498) Lyapunov Risk = 0.8246641755104065, MSE = 0.023144621402025223, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022762242704629898, Lv_loss = 1.4506985053230892e-06, Circular Tuning Loss = 1.0228192806243896\n",
      "1499) Lyapunov Risk = 0.8245747089385986, MSE = 0.025263499468564987, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.02276097796857357, Lv_loss = 0.0, Circular Tuning Loss = 1.0225051641464233\n",
      "1500) Lyapunov Risk = 0.8244384527206421, MSE = 0.02298974059522152, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.02275986410677433, Lv_loss = 2.75054026133148e-06, Circular Tuning Loss = 1.0221911668777466\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.53723855834474432, -0.5279289187585583]\n",
      "x2 : [1.8204260788445352, 1.8272534667421336]\n",
      "==============================\n",
      "1501) Lyapunov Risk = 0.8294824361801147, MSE = 0.025392724201083183, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022669216617941856, Lv_loss = 0.0, Circular Tuning Loss = 1.0321754217147827\n",
      "1502) Lyapunov Risk = 0.8289639949798584, MSE = 0.023001577705144882, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022667303681373596, Lv_loss = 2.3590371256432263e-06, Circular Tuning Loss = 1.0318527221679688\n",
      "1503) Lyapunov Risk = 0.8282930254936218, MSE = 0.024745404720306396, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022665949538350105, Lv_loss = 0.0, Circular Tuning Loss = 1.0315303802490234\n",
      "1504) Lyapunov Risk = 0.8276753425598145, MSE = 0.023394454270601273, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022664790973067284, Lv_loss = 3.1488962548564814e-08, Circular Tuning Loss = 1.03120756149292\n",
      "1505) Lyapunov Risk = 0.8272338509559631, MSE = 0.023783616721630096, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.02266368269920349, Lv_loss = 0.0, Circular Tuning Loss = 1.0308854579925537\n",
      "1506) Lyapunov Risk = 0.8270196318626404, MSE = 0.02420593798160553, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022662773728370667, Lv_loss = 0.0, Circular Tuning Loss = 1.030563473701477\n",
      "1507) Lyapunov Risk = 0.8268840312957764, MSE = 0.02325293980538845, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022661972790956497, Lv_loss = 2.6326600277570833e-07, Circular Tuning Loss = 1.03024160861969\n",
      "1508) Lyapunov Risk = 0.8266648054122925, MSE = 0.02458440512418747, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022661127150058746, Lv_loss = 0.0, Circular Tuning Loss = 1.0299204587936401\n",
      "1509) Lyapunov Risk = 0.8263571262359619, MSE = 0.023283885791897774, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.02266034297645092, Lv_loss = 6.377146632985387e-07, Circular Tuning Loss = 1.0295994281768799\n",
      "1510) Lyapunov Risk = 0.8259555697441101, MSE = 0.024263083934783936, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022659413516521454, Lv_loss = 0.0, Circular Tuning Loss = 1.0292788743972778\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.1269531250000004, -1.1250000000000004]\n",
      "x2 : [-0.054126587736527419, -0.050743676002994453]\n",
      "==============================\n",
      "1511) Lyapunov Risk = 0.8254497647285461, MSE = 0.02372937649488449, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.02256866544485092, Lv_loss = 0.0, Circular Tuning Loss = 1.0270920991897583\n",
      "1512) Lyapunov Risk = 0.8251594305038452, MSE = 0.023651599884033203, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022567851468920708, Lv_loss = 0.0, Circular Tuning Loss = 1.026773452758789\n",
      "1513) Lyapunov Risk = 0.8248962759971619, MSE = 0.024162178859114647, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.02256724424660206, Lv_loss = 0.0, Circular Tuning Loss = 1.0264551639556885\n",
      "1514) Lyapunov Risk = 0.8246337175369263, MSE = 0.023331882432103157, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022566646337509155, Lv_loss = 0.0, Circular Tuning Loss = 1.026137351989746\n",
      "1515) Lyapunov Risk = 0.8243114352226257, MSE = 0.024264123290777206, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022566109895706177, Lv_loss = 0.0, Circular Tuning Loss = 1.0258201360702515\n",
      "1516) Lyapunov Risk = 0.8239797949790955, MSE = 0.023421768099069595, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022565633058547974, Lv_loss = 0.0, Circular Tuning Loss = 1.025503396987915\n",
      "1517) Lyapunov Risk = 0.823653519153595, MSE = 0.024015503004193306, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.02256523072719574, Lv_loss = 0.0, Circular Tuning Loss = 1.025187373161316\n",
      "1518) Lyapunov Risk = 0.8233757019042969, MSE = 0.02380260080099106, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.02256503328680992, Lv_loss = 0.0, Circular Tuning Loss = 1.024871587753296\n",
      "1519) Lyapunov Risk = 0.8231308460235596, MSE = 0.023659255355596542, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.02256486751139164, Lv_loss = 0.0, Circular Tuning Loss = 1.0245566368103027\n",
      "1520) Lyapunov Risk = 0.8228738903999329, MSE = 0.024066688492894173, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022564729675650597, Lv_loss = 0.0, Circular Tuning Loss = 1.0242421627044678\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.1269531250000004, -1.1250000000000004]\n",
      "x2 : [-0.094721528538922989, -0.091338616805390016]\n",
      "==============================\n",
      "1521) Lyapunov Risk = 0.8225024342536926, MSE = 0.023468395695090294, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.02247540093958378, Lv_loss = 0.0, Circular Tuning Loss = 1.0221235752105713\n",
      "1522) Lyapunov Risk = 0.8221817016601562, MSE = 0.02410844713449478, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022475259378552437, Lv_loss = 0.0, Circular Tuning Loss = 1.021811604499817\n",
      "1523) Lyapunov Risk = 0.8218541741371155, MSE = 0.023478588089346886, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022475140169262886, Lv_loss = 0.0, Circular Tuning Loss = 1.0215003490447998\n",
      "1524) Lyapunov Risk = 0.8215335607528687, MSE = 0.02393038012087345, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022475028410553932, Lv_loss = 0.0, Circular Tuning Loss = 1.021189570426941\n",
      "1525) Lyapunov Risk = 0.8212522864341736, MSE = 0.023671526461839676, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022474974393844604, Lv_loss = 0.0, Circular Tuning Loss = 1.0208797454833984\n",
      "1526) Lyapunov Risk = 0.8209906816482544, MSE = 0.023805642500519753, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022474998608231544, Lv_loss = 0.0, Circular Tuning Loss = 1.0205703973770142\n",
      "1527) Lyapunov Risk = 0.820736289024353, MSE = 0.023843349888920784, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022475140169262886, Lv_loss = 0.0, Circular Tuning Loss = 1.0202616453170776\n",
      "1528) Lyapunov Risk = 0.8204817771911621, MSE = 0.02364812232553959, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022475339472293854, Lv_loss = 0.0, Circular Tuning Loss = 1.0199536085128784\n",
      "1529) Lyapunov Risk = 0.820209264755249, MSE = 0.023969998583197594, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022475576028227806, Lv_loss = 0.0, Circular Tuning Loss = 1.0196462869644165\n",
      "1530) Lyapunov Risk = 0.8199142217636108, MSE = 0.023557137697935104, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.02247578464448452, Lv_loss = 0.0, Circular Tuning Loss = 1.0193395614624023\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0644531250000004, -1.0625000000000004]\n",
      "x2 : [-0.10317880787275539, -0.10149102775976142]\n",
      "==============================\n",
      "1531) Lyapunov Risk = 0.8194252848625183, MSE = 0.023931866511702538, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.02238749898970127, Lv_loss = 0.0, Circular Tuning Loss = 1.0169878005981445\n",
      "1532) Lyapunov Risk = 0.8191195726394653, MSE = 0.023607781156897545, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022387754172086716, Lv_loss = 0.0, Circular Tuning Loss = 1.0166836977005005\n",
      "1533) Lyapunov Risk = 0.8188326954841614, MSE = 0.023823179304599762, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022388244047760963, Lv_loss = 0.0, Circular Tuning Loss = 1.0163805484771729\n",
      "1534) Lyapunov Risk = 0.8185590505599976, MSE = 0.02367016114294529, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022388825193047523, Lv_loss = 0.0, Circular Tuning Loss = 1.016078233718872\n",
      "1535) Lyapunov Risk = 0.8182962536811829, MSE = 0.02377375401556492, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022389378398656845, Lv_loss = 0.0, Circular Tuning Loss = 1.0157767534255981\n",
      "1536) Lyapunov Risk = 0.8180384039878845, MSE = 0.023746326565742493, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022390058264136314, Lv_loss = 0.0, Circular Tuning Loss = 1.0154763460159302\n",
      "1537) Lyapunov Risk = 0.8177791237831116, MSE = 0.02376702055335045, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.02239070273935795, Lv_loss = 0.0, Circular Tuning Loss = 1.0151766538619995\n",
      "1538) Lyapunov Risk = 0.8175147175788879, MSE = 0.023721005767583847, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022391323000192642, Lv_loss = 0.0, Circular Tuning Loss = 1.0148779153823853\n",
      "1539) Lyapunov Risk = 0.8172450065612793, MSE = 0.02380260080099106, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.02239188924431801, Lv_loss = 0.0, Circular Tuning Loss = 1.014580249786377\n",
      "1540) Lyapunov Risk = 0.8169732093811035, MSE = 0.023615766316652298, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022392496466636658, Lv_loss = 0.0, Circular Tuning Loss = 1.0142831802368164\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.50686787994521165, -0.50000000000000011]\n",
      "x2 : [1.8988957990147768, 1.9058089289476485]\n",
      "==============================\n",
      "1541) Lyapunov Risk = 0.8224837183952332, MSE = 0.02386445365846157, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022305428981781006, Lv_loss = 0.0, Circular Tuning Loss = 1.0251822471618652\n",
      "1542) Lyapunov Risk = 0.8222228288650513, MSE = 0.023471593856811523, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.02230585366487503, Lv_loss = 0.0, Circular Tuning Loss = 1.0248774290084839\n",
      "1543) Lyapunov Risk = 0.8219801187515259, MSE = 0.024053726345300674, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022306468337774277, Lv_loss = 0.0, Circular Tuning Loss = 1.0245729684829712\n",
      "1544) Lyapunov Risk = 0.8217562437057495, MSE = 0.023299548774957657, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022307053208351135, Lv_loss = 0.0, Circular Tuning Loss = 1.0242687463760376\n",
      "1545) Lyapunov Risk = 0.8215879201889038, MSE = 0.024355698376893997, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.02230767346918583, Lv_loss = 0.0, Circular Tuning Loss = 1.0239648818969727\n",
      "1546) Lyapunov Risk = 0.8214830160140991, MSE = 0.02304295264184475, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022308306768536568, Lv_loss = 2.7881530968443258e-06, Circular Tuning Loss = 1.0236613750457764\n",
      "1547) Lyapunov Risk = 0.8214070796966553, MSE = 0.024803252890706062, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022309070453047752, Lv_loss = 0.0, Circular Tuning Loss = 1.0233584642410278\n",
      "1548) Lyapunov Risk = 0.8212985396385193, MSE = 0.02287713624536991, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.02230989933013916, Lv_loss = 8.980357051768806e-06, Circular Tuning Loss = 1.023055911064148\n",
      "1549) Lyapunov Risk = 0.8211100697517395, MSE = 0.024983208626508713, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022310614585876465, Lv_loss = 0.0, Circular Tuning Loss = 1.0227539539337158\n",
      "1550) Lyapunov Risk = 0.8208512663841248, MSE = 0.022973084822297096, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022311365231871605, Lv_loss = 1.137810068030376e-05, Circular Tuning Loss = 1.0224523544311523\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.50141036143634532, -0.50000000000000011]\n",
      "x2 : [1.931456389215342, 1.9334652001325461]\n",
      "==============================\n",
      "1551) Lyapunov Risk = 0.8265254497528076, MSE = 0.024733057245612144, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022224852815270424, Lv_loss = 0.0, Circular Tuning Loss = 1.0337154865264893\n",
      "1552) Lyapunov Risk = 0.8262113332748413, MSE = 0.0232869703322649, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022225527092814445, Lv_loss = 7.16509748599492e-06, Circular Tuning Loss = 1.0334055423736572\n",
      "1553) Lyapunov Risk = 0.8258817791938782, MSE = 0.024343080818653107, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022226151078939438, Lv_loss = 0.0, Circular Tuning Loss = 1.0330955982208252\n",
      "1554) Lyapunov Risk = 0.8254613280296326, MSE = 0.023481188341975212, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022226771339774132, Lv_loss = 2.0704669623228256e-06, Circular Tuning Loss = 1.0327856540679932\n",
      "1555) Lyapunov Risk = 0.8249585628509521, MSE = 0.023946555331349373, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022227274253964424, Lv_loss = 0.0, Circular Tuning Loss = 1.0324758291244507\n",
      "1556) Lyapunov Risk = 0.8244695067405701, MSE = 0.023606009781360626, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.02222779020667076, Lv_loss = 0.0, Circular Tuning Loss = 1.0321662425994873\n",
      "1557) Lyapunov Risk = 0.8240786790847778, MSE = 0.023595381528139114, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022228240966796875, Lv_loss = 0.0, Circular Tuning Loss = 1.031856894493103\n",
      "1558) Lyapunov Risk = 0.8238176107406616, MSE = 0.023771943524479866, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.02222873829305172, Lv_loss = 0.0, Circular Tuning Loss = 1.0315479040145874\n",
      "1559) Lyapunov Risk = 0.8236539363861084, MSE = 0.02343338541686535, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.02222929708659649, Lv_loss = 5.3674227729061386e-08, Circular Tuning Loss = 1.0312392711639404\n",
      "1560) Lyapunov Risk = 0.8235104084014893, MSE = 0.024018410593271255, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.02222980000078678, Lv_loss = 0.0, Circular Tuning Loss = 1.0309312343597412\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0078125000000004, -1.0058593750000004]\n",
      "x2 : [-0.12347627827395317, -0.12178482240718669]\n",
      "==============================\n",
      "1561) Lyapunov Risk = 0.8230636119842529, MSE = 0.023339079692959785, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022143900394439697, Lv_loss = 1.8417614455756848e-06, Circular Tuning Loss = 1.028348445892334\n",
      "1562) Lyapunov Risk = 0.82280033826828, MSE = 0.024159343913197517, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022144416347146034, Lv_loss = 0.0, Circular Tuning Loss = 1.0280427932739258\n",
      "1563) Lyapunov Risk = 0.8224557042121887, MSE = 0.023259548470377922, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.02214493229985237, Lv_loss = 2.5398352931915724e-07, Circular Tuning Loss = 1.0277376174926758\n",
      "1564) Lyapunov Risk = 0.822068452835083, MSE = 0.0240124873816967, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022145366296172142, Lv_loss = 0.0, Circular Tuning Loss = 1.027433156967163\n",
      "1565) Lyapunov Risk = 0.8217053413391113, MSE = 0.023347966372966766, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022145846858620644, Lv_loss = 0.0, Circular Tuning Loss = 1.0271292924880981\n",
      "1566) Lyapunov Risk = 0.8213986754417419, MSE = 0.023781152442097664, V_0_loss = tensor([[0.0043]], grad_fn=<PowBackward0>), V_pos_loss = 0.022146452218294144, Lv_loss = 0.0, Circular Tuning Loss = 1.026826024055481\n",
      "1567) Lyapunov Risk = 0.8211396336555481, MSE = 0.023587804287672043, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.022147195413708687, Lv_loss = 0.0, Circular Tuning Loss = 1.0265233516693115\n",
      "1568) Lyapunov Risk = 0.8209128975868225, MSE = 0.02351645566523075, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02214820869266987, Lv_loss = 0.0, Circular Tuning Loss = 1.0262216329574585\n",
      "1569) Lyapunov Risk = 0.820690929889679, MSE = 0.02385999821126461, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02214915119111538, Lv_loss = 0.0, Circular Tuning Loss = 1.0259207487106323\n",
      "1570) Lyapunov Risk = 0.8204461932182312, MSE = 0.02333126589655876, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02215011790394783, Lv_loss = 0.0, Circular Tuning Loss = 1.025620460510254\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.99804687500000022, -0.99609375000000022]\n",
      "x2 : [-0.054687500000000014, -0.052734375000000014]\n",
      "==============================\n",
      "1571) Lyapunov Risk = 0.8198802471160889, MSE = 0.0239639263600111, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.0220651738345623, Lv_loss = 0.0, Circular Tuning Loss = 1.0229696035385132\n",
      "1572) Lyapunov Risk = 0.8195781707763672, MSE = 0.02331143245100975, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.022066136822104454, Lv_loss = 3.009107629736718e-08, Circular Tuning Loss = 1.0226719379425049\n",
      "1573) Lyapunov Risk = 0.8192816972732544, MSE = 0.023819556459784508, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02206716313958168, Lv_loss = 0.0, Circular Tuning Loss = 1.022375226020813\n",
      "1574) Lyapunov Risk = 0.8189926147460938, MSE = 0.023482216522097588, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02206818386912346, Lv_loss = 0.0, Circular Tuning Loss = 1.0220792293548584\n",
      "1575) Lyapunov Risk = 0.8187292814254761, MSE = 0.023566672578454018, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02206917107105255, Lv_loss = 0.0, Circular Tuning Loss = 1.0217839479446411\n",
      "1576) Lyapunov Risk = 0.818492591381073, MSE = 0.023776013404130936, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.022070148959755898, Lv_loss = 0.0, Circular Tuning Loss = 1.0214896202087402\n",
      "1577) Lyapunov Risk = 0.8182643055915833, MSE = 0.02338661625981331, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02207115665078163, Lv_loss = 4.108252369405818e-07, Circular Tuning Loss = 1.021195650100708\n",
      "1578) Lyapunov Risk = 0.8180214762687683, MSE = 0.023877974599599838, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.022072166204452515, Lv_loss = 0.0, Circular Tuning Loss = 1.0209025144577026\n",
      "1579) Lyapunov Risk = 0.8177599310874939, MSE = 0.023384086787700653, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02207326702773571, Lv_loss = 4.130963020543277e-07, Circular Tuning Loss = 1.020609736442566\n",
      "1580) Lyapunov Risk = 0.8174893260002136, MSE = 0.023717816919088364, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.022074325010180473, Lv_loss = 0.0, Circular Tuning Loss = 1.0203179121017456\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.99023437500000022, -0.98828125000000022]\n",
      "x2 : [-0.031250000000000007, -0.029296875000000007]\n",
      "==============================\n",
      "1581) Lyapunov Risk = 0.8169049024581909, MSE = 0.02353319525718689, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021990176290273666, Lv_loss = 0.0, Circular Tuning Loss = 1.0176597833633423\n",
      "1582) Lyapunov Risk = 0.8166453242301941, MSE = 0.02356531284749508, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021991262212395668, Lv_loss = 0.0, Circular Tuning Loss = 1.0173702239990234\n",
      "1583) Lyapunov Risk = 0.8163878321647644, MSE = 0.023653360083699226, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021992381662130356, Lv_loss = 0.0, Circular Tuning Loss = 1.0170811414718628\n",
      "1584) Lyapunov Risk = 0.8161314725875854, MSE = 0.023527948185801506, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02199353091418743, Lv_loss = 0.0, Circular Tuning Loss = 1.016792893409729\n",
      "1585) Lyapunov Risk = 0.8158792853355408, MSE = 0.023677444085478783, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02199484035372734, Lv_loss = 0.0, Circular Tuning Loss = 1.0165050029754639\n",
      "1586) Lyapunov Risk = 0.8156342506408691, MSE = 0.02357986569404602, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02199619635939598, Lv_loss = 0.0, Circular Tuning Loss = 1.0162177085876465\n",
      "1587) Lyapunov Risk = 0.8153939247131348, MSE = 0.023632964119315147, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021997619420289993, Lv_loss = 0.0, Circular Tuning Loss = 1.0159310102462769\n",
      "1588) Lyapunov Risk = 0.8151530027389526, MSE = 0.023595966398715973, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02199913002550602, Lv_loss = 0.0, Circular Tuning Loss = 1.0156450271606445\n",
      "1589) Lyapunov Risk = 0.8149075508117676, MSE = 0.02360069379210472, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.022000649943947792, Lv_loss = 0.0, Circular Tuning Loss = 1.0153595209121704\n",
      "1590) Lyapunov Risk = 0.8146575093269348, MSE = 0.02354494109749794, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.022002214565873146, Lv_loss = 0.0, Circular Tuning Loss = 1.0150744915008545\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0644531250000004, -1.0625000000000004]\n",
      "x2 : [-0.054126587736527419, -0.05243513186976094]\n",
      "==============================\n",
      "1591) Lyapunov Risk = 0.814239501953125, MSE = 0.0236371923238039, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02191914990544319, Lv_loss = 0.0, Circular Tuning Loss = 1.0127573013305664\n",
      "1592) Lyapunov Risk = 0.8139880299568176, MSE = 0.023519935086369514, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02192075364291668, Lv_loss = 0.0, Circular Tuning Loss = 1.012474536895752\n",
      "1593) Lyapunov Risk = 0.8137412071228027, MSE = 0.02366865612566471, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021922433748841286, Lv_loss = 0.0, Circular Tuning Loss = 1.0121923685073853\n",
      "1594) Lyapunov Risk = 0.8134971261024475, MSE = 0.023532815277576447, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021924203261733055, Lv_loss = 0.0, Circular Tuning Loss = 1.0119109153747559\n",
      "1595) Lyapunov Risk = 0.8132534027099609, MSE = 0.0236655380576849, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02192601002752781, Lv_loss = 0.0, Circular Tuning Loss = 1.0116300582885742\n",
      "1596) Lyapunov Risk = 0.8130100965499878, MSE = 0.02359275333583355, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02192787081003189, Lv_loss = 0.0, Circular Tuning Loss = 1.0113495588302612\n",
      "1597) Lyapunov Risk = 0.8127682209014893, MSE = 0.023597273975610733, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021929755806922913, Lv_loss = 0.0, Circular Tuning Loss = 1.0110697746276855\n",
      "1598) Lyapunov Risk = 0.8125278353691101, MSE = 0.023645786568522453, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02193165197968483, Lv_loss = 0.0, Circular Tuning Loss = 1.010790467262268\n",
      "1599) Lyapunov Risk = 0.8122894167900085, MSE = 0.02349509671330452, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021933570504188538, Lv_loss = 0.0, Circular Tuning Loss = 1.0105117559432983\n",
      "1600) Lyapunov Risk = 0.8120514154434204, MSE = 0.023676306009292603, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02193552255630493, Lv_loss = 0.0, Circular Tuning Loss = 1.010233759880066\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0039062500000004, -1.0019531250000004]\n",
      "x2 : [-0.089647160938623544, -0.087955705071857057]\n",
      "==============================\n",
      "1601) Lyapunov Risk = 0.8115869164466858, MSE = 0.023455632850527763, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02185354009270668, Lv_loss = 0.0, Circular Tuning Loss = 1.0077440738677979\n",
      "1602) Lyapunov Risk = 0.8113545179367065, MSE = 0.023738693445920944, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.0218557957559824, Lv_loss = 0.0, Circular Tuning Loss = 1.0074682235717773\n",
      "1603) Lyapunov Risk = 0.8111270070075989, MSE = 0.023433789610862732, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02185812033712864, Lv_loss = 0.0, Circular Tuning Loss = 1.0071929693222046\n",
      "1604) Lyapunov Risk = 0.8109045028686523, MSE = 0.02381747029721737, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021860435605049133, Lv_loss = 0.0, Circular Tuning Loss = 1.0069184303283691\n",
      "1605) Lyapunov Risk = 0.8106868863105774, MSE = 0.02341550774872303, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02186279371380806, Lv_loss = 0.0, Circular Tuning Loss = 1.006644368171692\n",
      "1606) Lyapunov Risk = 0.8104764223098755, MSE = 0.023902833461761475, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021865123882889748, Lv_loss = 0.0, Circular Tuning Loss = 1.0063709020614624\n",
      "1607) Lyapunov Risk = 0.8102748394012451, MSE = 0.023370614275336266, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02186751179397106, Lv_loss = 0.0, Circular Tuning Loss = 1.0060977935791016\n",
      "1608) Lyapunov Risk = 0.8100850582122803, MSE = 0.02397877350449562, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021869877353310585, Lv_loss = 0.0, Circular Tuning Loss = 1.0058252811431885\n",
      "1609) Lyapunov Risk = 0.8099099397659302, MSE = 0.023294812068343163, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021872323006391525, Lv_loss = 1.3574831427831668e-06, Circular Tuning Loss = 1.005553126335144\n",
      "1610) Lyapunov Risk = 0.8097566962242126, MSE = 0.024123867973685265, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021874776110053062, Lv_loss = 0.0, Circular Tuning Loss = 1.005281686782837\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0019531250000004, -1.0000000000000002]\n",
      "x2 : [0, 0.0016914558667664819]\n",
      "==============================\n",
      "1611) Lyapunov Risk = 0.8093879222869873, MSE = 0.023131845518946648, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02179378643631935, Lv_loss = 6.453838523157174e-06, Circular Tuning Loss = 1.0027494430541992\n",
      "1612) Lyapunov Risk = 0.8093504905700684, MSE = 0.024572869762778282, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021796192973852158, Lv_loss = 0.0, Circular Tuning Loss = 1.0024800300598145\n",
      "1613) Lyapunov Risk = 0.809374213218689, MSE = 0.02293514832854271, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021798759698867798, Lv_loss = 2.0418867279659025e-05, Circular Tuning Loss = 1.0022106170654297\n",
      "1614) Lyapunov Risk = 0.809360146522522, MSE = 0.025047793984413147, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021801218390464783, Lv_loss = 0.0, Circular Tuning Loss = 1.0019422769546509\n",
      "1615) Lyapunov Risk = 0.8092536330223083, MSE = 0.02288242056965828, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02180390991270542, Lv_loss = 3.573622234398499e-05, Circular Tuning Loss = 1.0016741752624512\n",
      "1616) Lyapunov Risk = 0.8089410066604614, MSE = 0.025060059502720833, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02180641144514084, Lv_loss = 0.0, Circular Tuning Loss = 1.0014070272445679\n",
      "1617) Lyapunov Risk = 0.8084555268287659, MSE = 0.02298731356859207, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021809061989188194, Lv_loss = 2.485259756213054e-05, Circular Tuning Loss = 1.0011401176452637\n",
      "1618) Lyapunov Risk = 0.8078469038009644, MSE = 0.024405134841799736, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02181154489517212, Lv_loss = 0.0, Circular Tuning Loss = 1.0008740425109863\n",
      "1619) Lyapunov Risk = 0.8072870969772339, MSE = 0.023298563435673714, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021814076229929924, Lv_loss = 0.0, Circular Tuning Loss = 1.0006085634231567\n",
      "1620) Lyapunov Risk = 0.8068884611129761, MSE = 0.02363629639148712, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021816570311784744, Lv_loss = 0.0, Circular Tuning Loss = 1.0003440380096436\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.37592360295518701, -0.37500000000000011]\n",
      "x2 : [1.9632470535232109, 1.9645292056877142]\n",
      "==============================\n",
      "1621) Lyapunov Risk = 0.8125180006027222, MSE = 0.023750633001327515, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02173623815178871, Lv_loss = 0.0, Circular Tuning Loss = 1.0114760398864746\n",
      "1622) Lyapunov Risk = 0.8124389052391052, MSE = 0.023234661668539047, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021738816052675247, Lv_loss = 0.0, Circular Tuning Loss = 1.011204719543457\n",
      "1623) Lyapunov Risk = 0.8124161958694458, MSE = 0.02428256720304489, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02174137905240059, Lv_loss = 0.0, Circular Tuning Loss = 1.0109339952468872\n",
      "1624) Lyapunov Risk = 0.8123224973678589, MSE = 0.02307664416730404, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021744079887866974, Lv_loss = 9.763918569660746e-06, Circular Tuning Loss = 1.0106631517410278\n",
      "1625) Lyapunov Risk = 0.812107264995575, MSE = 0.024441029876470566, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021746739745140076, Lv_loss = 0.0, Circular Tuning Loss = 1.0103931427001953\n",
      "1626) Lyapunov Risk = 0.8117436170578003, MSE = 0.02307533286511898, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021749479696154594, Lv_loss = 7.298102900676895e-06, Circular Tuning Loss = 1.0101230144500732\n",
      "1627) Lyapunov Risk = 0.811341404914856, MSE = 0.024098046123981476, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021752111613750458, Lv_loss = 0.0, Circular Tuning Loss = 1.0098536014556885\n",
      "1628) Lyapunov Risk = 0.8109662532806396, MSE = 0.02327732928097248, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02175482176244259, Lv_loss = 0.0, Circular Tuning Loss = 1.0095844268798828\n",
      "1629) Lyapunov Risk = 0.8106848001480103, MSE = 0.023593273013830185, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02175760827958584, Lv_loss = 0.0, Circular Tuning Loss = 1.009315848350525\n",
      "1630) Lyapunov Risk = 0.8105049729347229, MSE = 0.0237469132989645, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02176043950021267, Lv_loss = 0.0, Circular Tuning Loss = 1.0090481042861938\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0019531250000004, -1.0000000000000002]\n",
      "x2 : [0, 0.0016914558667664819]\n",
      "==============================\n",
      "1631) Lyapunov Risk = 0.8101072907447815, MSE = 0.023260075598955154, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021680835634469986, Lv_loss = 0.0, Circular Tuning Loss = 1.0065184831619263\n",
      "1632) Lyapunov Risk = 0.8099562525749207, MSE = 0.024102065712213516, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021683720871806145, Lv_loss = 0.0, Circular Tuning Loss = 1.0062530040740967\n",
      "1633) Lyapunov Risk = 0.8097444772720337, MSE = 0.023154405876994133, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021686725318431854, Lv_loss = 0.0, Circular Tuning Loss = 1.0059882402420044\n",
      "1634) Lyapunov Risk = 0.809460461139679, MSE = 0.02401062287390232, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02168959379196167, Lv_loss = 0.0, Circular Tuning Loss = 1.005724310874939\n",
      "1635) Lyapunov Risk = 0.8091562390327454, MSE = 0.023292798548936844, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021692633628845215, Lv_loss = 0.0, Circular Tuning Loss = 1.0054609775543213\n",
      "1636) Lyapunov Risk = 0.8088733553886414, MSE = 0.02366020157933235, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.0216955728828907, Lv_loss = 0.0, Circular Tuning Loss = 1.0051987171173096\n",
      "1637) Lyapunov Risk = 0.8086455464363098, MSE = 0.0236358642578125, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021698538213968277, Lv_loss = 0.0, Circular Tuning Loss = 1.004936933517456\n",
      "1638) Lyapunov Risk = 0.808462381362915, MSE = 0.023355521261692047, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021701520308852196, Lv_loss = 0.0, Circular Tuning Loss = 1.0046757459640503\n",
      "1639) Lyapunov Risk = 0.8082864880561829, MSE = 0.023890521377325058, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021704446524381638, Lv_loss = 0.0, Circular Tuning Loss = 1.0044152736663818\n",
      "1640) Lyapunov Risk = 0.8080943822860718, MSE = 0.02326921373605728, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02170741558074951, Lv_loss = 0.0, Circular Tuning Loss = 1.004155158996582\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.33984375000000011, -0.33789062500000011]\n",
      "x2 : [1.9699874780377606, 1.9712508530212765]\n",
      "==============================\n",
      "1641) Lyapunov Risk = 0.8136640191078186, MSE = 0.023870043456554413, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021629158407449722, Lv_loss = 0.0, Circular Tuning Loss = 1.0151983499526978\n",
      "1642) Lyapunov Risk = 0.8134153485298157, MSE = 0.023337682709097862, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02163141593337059, Lv_loss = 0.0, Circular Tuning Loss = 1.0149307250976562\n",
      "1643) Lyapunov Risk = 0.8131576776504517, MSE = 0.023671982809901237, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021634407341480255, Lv_loss = 0.0, Circular Tuning Loss = 1.014663577079773\n",
      "1644) Lyapunov Risk = 0.8129103183746338, MSE = 0.02350231260061264, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021637406200170517, Lv_loss = 0.0, Circular Tuning Loss = 1.0143967866897583\n",
      "1645) Lyapunov Risk = 0.8126816749572754, MSE = 0.02347119338810444, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021640397608280182, Lv_loss = 0.0, Circular Tuning Loss = 1.0141299962997437\n",
      "1646) Lyapunov Risk = 0.8124698996543884, MSE = 0.023647090420126915, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021643396466970444, Lv_loss = 0.0, Circular Tuning Loss = 1.013863444328308\n",
      "1647) Lyapunov Risk = 0.8122673630714417, MSE = 0.02338252030313015, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021646466106176376, Lv_loss = 0.0, Circular Tuning Loss = 1.0135974884033203\n",
      "1648) Lyapunov Risk = 0.8120657205581665, MSE = 0.023721307516098022, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02164948359131813, Lv_loss = 0.0, Circular Tuning Loss = 1.013331651687622\n",
      "1649) Lyapunov Risk = 0.8118540048599243, MSE = 0.0233742855489254, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021652506664395332, Lv_loss = 0.0, Circular Tuning Loss = 1.0130661725997925\n",
      "1650) Lyapunov Risk = 0.8116320371627808, MSE = 0.023732976987957954, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021655628457665443, Lv_loss = 0.0, Circular Tuning Loss = 1.0128010511398315\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0019531250000004, -1.0000000000000002]\n",
      "x2 : [0, 0.0016914558667664819]\n",
      "==============================\n",
      "1651) Lyapunov Risk = 0.8111474514007568, MSE = 0.023396020755171776, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02157733403146267, Lv_loss = 0.0, Circular Tuning Loss = 1.0102742910385132\n",
      "1652) Lyapunov Risk = 0.8109158277511597, MSE = 0.02369656413793564, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02158040925860405, Lv_loss = 0.0, Circular Tuning Loss = 1.0100107192993164\n",
      "1653) Lyapunov Risk = 0.8106846809387207, MSE = 0.023422786965966225, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021583514288067818, Lv_loss = 0.0, Circular Tuning Loss = 1.0097477436065674\n",
      "1654) Lyapunov Risk = 0.8104599714279175, MSE = 0.023594236001372337, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021586600691080093, Lv_loss = 0.0, Circular Tuning Loss = 1.009485125541687\n",
      "1655) Lyapunov Risk = 0.8102409243583679, MSE = 0.02349555306136608, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021589715033769608, Lv_loss = 0.0, Circular Tuning Loss = 1.009223222732544\n",
      "1656) Lyapunov Risk = 0.8100271821022034, MSE = 0.02351120486855507, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021592948585748672, Lv_loss = 0.0, Circular Tuning Loss = 1.0089616775512695\n",
      "1657) Lyapunov Risk = 0.809817910194397, MSE = 0.02360926754772663, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021596189588308334, Lv_loss = 0.0, Circular Tuning Loss = 1.0087007284164429\n",
      "1658) Lyapunov Risk = 0.809611439704895, MSE = 0.02342941053211689, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021599430590867996, Lv_loss = 0.0, Circular Tuning Loss = 1.0084402561187744\n",
      "1659) Lyapunov Risk = 0.8094043135643005, MSE = 0.023694144561886787, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021602701395750046, Lv_loss = 0.0, Circular Tuning Loss = 1.0081804990768433\n",
      "1660) Lyapunov Risk = 0.8091949820518494, MSE = 0.023362817242741585, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02160598151385784, Lv_loss = 0.0, Circular Tuning Loss = 1.0079212188720703\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0019531250000004, -1.0000000000000002]\n",
      "x2 : [0, 0.0016914558667664819]\n",
      "==============================\n",
      "1661) Lyapunov Risk = 0.8087437152862549, MSE = 0.023720568045973778, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.0215283315628767, Lv_loss = 0.0, Circular Tuning Loss = 1.0054266452789307\n",
      "1662) Lyapunov Risk = 0.8085275292396545, MSE = 0.02335692010819912, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02153168059885502, Lv_loss = 0.0, Circular Tuning Loss = 1.005169153213501\n",
      "1663) Lyapunov Risk = 0.8083105087280273, MSE = 0.023680809885263443, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021534999832510948, Lv_loss = 0.0, Circular Tuning Loss = 1.0049124956130981\n",
      "1664) Lyapunov Risk = 0.808094322681427, MSE = 0.023410895839333534, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02153833955526352, Lv_loss = 0.0, Circular Tuning Loss = 1.0046563148498535\n",
      "1665) Lyapunov Risk = 0.8078781962394714, MSE = 0.023638779297471046, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021541653200984, Lv_loss = 0.0, Circular Tuning Loss = 1.004400610923767\n",
      "1666) Lyapunov Risk = 0.8076646327972412, MSE = 0.023504238575696945, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021545007824897766, Lv_loss = 0.0, Circular Tuning Loss = 1.0041455030441284\n",
      "1667) Lyapunov Risk = 0.8074537515640259, MSE = 0.02356037311255932, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021548418328166008, Lv_loss = 0.0, Circular Tuning Loss = 1.0038909912109375\n",
      "1668) Lyapunov Risk = 0.8072448968887329, MSE = 0.02357122115790844, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021551884710788727, Lv_loss = 0.0, Circular Tuning Loss = 1.0036369562149048\n",
      "1669) Lyapunov Risk = 0.8070379495620728, MSE = 0.02347732149064541, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02155543491244316, Lv_loss = 0.0, Circular Tuning Loss = 1.0033836364746094\n",
      "1670) Lyapunov Risk = 0.8068323135375977, MSE = 0.023599941283464432, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.0215589702129364, Lv_loss = 0.0, Circular Tuning Loss = 1.0031309127807617\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0019531250000004, -1.0000000000000002]\n",
      "x2 : [0, 0.0016914558667664819]\n",
      "==============================\n",
      "1671) Lyapunov Risk = 0.8064039945602417, MSE = 0.023435158655047417, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021482065320014954, Lv_loss = 0.0, Circular Tuning Loss = 1.0006670951843262\n",
      "1672) Lyapunov Risk = 0.8062029480934143, MSE = 0.02365408092737198, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.0214855894446373, Lv_loss = 0.0, Circular Tuning Loss = 1.0004165172576904\n",
      "1673) Lyapunov Risk = 0.8060026168823242, MSE = 0.0234213899821043, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02148929238319397, Lv_loss = 0.0, Circular Tuning Loss = 1.0001662969589233\n",
      "1674) Lyapunov Risk = 0.8058033585548401, MSE = 0.023682381957769394, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02149299904704094, Lv_loss = 0.0, Circular Tuning Loss = 0.9999170303344727\n",
      "1675) Lyapunov Risk = 0.8056049346923828, MSE = 0.02343173883855343, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02149689570069313, Lv_loss = 0.0, Circular Tuning Loss = 0.9996680617332458\n",
      "1676) Lyapunov Risk = 0.805406928062439, MSE = 0.023707251995801926, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021500781178474426, Lv_loss = 0.0, Circular Tuning Loss = 0.9994196891784668\n",
      "1677) Lyapunov Risk = 0.8052102327346802, MSE = 0.023413896560668945, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02150469459593296, Lv_loss = 1.2097583521608613e-06, Circular Tuning Loss = 0.9991716742515564\n",
      "1678) Lyapunov Risk = 0.8050152063369751, MSE = 0.02374228835105896, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021508583799004555, Lv_loss = 0.0, Circular Tuning Loss = 0.9989244341850281\n",
      "1679) Lyapunov Risk = 0.8048260807991028, MSE = 0.02332364208996296, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02151249162852764, Lv_loss = 1.0518824637983926e-05, Circular Tuning Loss = 0.9986774325370789\n",
      "1680) Lyapunov Risk = 0.8046435117721558, MSE = 0.023834077641367912, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021516356617212296, Lv_loss = 0.0, Circular Tuning Loss = 0.9984311461448669\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0019531250000004, -1.0000000000000002]\n",
      "x2 : [0, 0.0016914558667664819]\n",
      "==============================\n",
      "1681) Lyapunov Risk = 0.8042658567428589, MSE = 0.023208126425743103, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021440276876091957, Lv_loss = 2.5342720618937165e-05, Circular Tuning Loss = 0.9959980845451355\n",
      "1682) Lyapunov Risk = 0.8041157126426697, MSE = 0.02402857132256031, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021444162353873253, Lv_loss = 0.0, Circular Tuning Loss = 0.9957534074783325\n",
      "1683) Lyapunov Risk = 0.8039947748184204, MSE = 0.023072119802236557, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021448086947202682, Lv_loss = 3.8872352888574824e-05, Circular Tuning Loss = 0.9955092668533325\n",
      "1684) Lyapunov Risk = 0.8038977384567261, MSE = 0.02429448813199997, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021451909095048904, Lv_loss = 0.0, Circular Tuning Loss = 0.9952658414840698\n",
      "1685) Lyapunov Risk = 0.8038464784622192, MSE = 0.02294357679784298, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021455984562635422, Lv_loss = 7.292831287486479e-05, Circular Tuning Loss = 0.9950227737426758\n",
      "1686) Lyapunov Risk = 0.8038233518600464, MSE = 0.02462388016283512, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021459918469190598, Lv_loss = 0.0, Circular Tuning Loss = 0.9947804808616638\n",
      "1687) Lyapunov Risk = 0.8038363456726074, MSE = 0.022857144474983215, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021463992074131966, Lv_loss = 0.00012279405200388283, Circular Tuning Loss = 0.9945384860038757\n",
      "1688) Lyapunov Risk = 0.8038319945335388, MSE = 0.02491503208875656, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02146786078810692, Lv_loss = 0.0, Circular Tuning Loss = 0.9942975640296936\n",
      "1689) Lyapunov Risk = 0.803769588470459, MSE = 0.022844091057777405, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021471915766596794, Lv_loss = 0.00014441009261645377, Circular Tuning Loss = 0.9940562844276428\n",
      "1690) Lyapunov Risk = 0.8035598397254944, MSE = 0.02494051121175289, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02147575095295906, Lv_loss = 0.0, Circular Tuning Loss = 0.9938163161277771\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0019531250000004, -1.0000000000000002]\n",
      "x2 : [0, 0.0016914558667664819]\n",
      "==============================\n",
      "1691) Lyapunov Risk = 0.8030046224594116, MSE = 0.022897515445947647, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02140023745596409, Lv_loss = 0.00014010768791195005, Circular Tuning Loss = 0.9914136528968811\n",
      "1692) Lyapunov Risk = 0.8024957180023193, MSE = 0.02456374280154705, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021404169499874115, Lv_loss = 0.0, Circular Tuning Loss = 0.9911752939224243\n",
      "1693) Lyapunov Risk = 0.8019512295722961, MSE = 0.02305980585515499, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02140834555029869, Lv_loss = 6.1241582443472e-05, Circular Tuning Loss = 0.9909371137619019\n",
      "1694) Lyapunov Risk = 0.8015058040618896, MSE = 0.023904476314783096, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021412460133433342, Lv_loss = 0.0, Circular Tuning Loss = 0.9906995296478271\n",
      "1695) Lyapunov Risk = 0.8012403845787048, MSE = 0.023496799170970917, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021416710689663887, Lv_loss = 0.0, Circular Tuning Loss = 0.9904624223709106\n",
      "1696) Lyapunov Risk = 0.8011293411254883, MSE = 0.023394189774990082, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021421026438474655, Lv_loss = 1.460560361010721e-05, Circular Tuning Loss = 0.9902256727218628\n",
      "1697) Lyapunov Risk = 0.8010916113853455, MSE = 0.024050388485193253, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021425319835543633, Lv_loss = 0.0, Circular Tuning Loss = 0.9899893999099731\n",
      "1698) Lyapunov Risk = 0.8010343313217163, MSE = 0.02308158576488495, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021429704502224922, Lv_loss = 7.901526259956881e-05, Circular Tuning Loss = 0.9897534251213074\n",
      "1699) Lyapunov Risk = 0.8008943796157837, MSE = 0.024350296705961227, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021434001624584198, Lv_loss = 0.0, Circular Tuning Loss = 0.9895179867744446\n",
      "1700) Lyapunov Risk = 0.8006479740142822, MSE = 0.02297515794634819, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02143842913210392, Lv_loss = 8.447730215266347e-05, Circular Tuning Loss = 0.9892827868461609\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0019531250000004, -1.0000000000000002]\n",
      "x2 : [0, 0.0016914558667664819]\n",
      "==============================\n",
      "1701) Lyapunov Risk = 0.8001453280448914, MSE = 0.024189412593841553, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021363621577620506, Lv_loss = 0.0, Circular Tuning Loss = 0.9869068264961243\n",
      "1702) Lyapunov Risk = 0.7998212575912476, MSE = 0.02318544313311577, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021368036046624184, Lv_loss = 3.34698888764251e-05, Circular Tuning Loss = 0.9866730570793152\n",
      "1703) Lyapunov Risk = 0.799560010433197, MSE = 0.023721085861325264, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021372461691498756, Lv_loss = 0.0, Circular Tuning Loss = 0.986440122127533\n",
      "1704) Lyapunov Risk = 0.799375057220459, MSE = 0.02363337017595768, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021376989781856537, Lv_loss = 0.0, Circular Tuning Loss = 0.9862073063850403\n",
      "1705) Lyapunov Risk = 0.7992468476295471, MSE = 0.0233139768242836, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021381691098213196, Lv_loss = 1.7704256606521085e-05, Circular Tuning Loss = 0.9859750866889954\n",
      "1706) Lyapunov Risk = 0.7991385459899902, MSE = 0.024056488648056984, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021386390551924706, Lv_loss = 0.0, Circular Tuning Loss = 0.9857436418533325\n",
      "1707) Lyapunov Risk = 0.799009382724762, MSE = 0.023086410015821457, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02139125019311905, Lv_loss = 6.732217298122123e-05, Circular Tuning Loss = 0.9855127930641174\n",
      "1708) Lyapunov Risk = 0.7988498210906982, MSE = 0.024169577285647392, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021396009251475334, Lv_loss = 0.0, Circular Tuning Loss = 0.9852830767631531\n",
      "1709) Lyapunov Risk = 0.7991752624511719, MSE = 0.022561578080058098, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021400300785899162, Lv_loss = 0.00013313244562596083, Circular Tuning Loss = 0.9850553274154663\n",
      "1710) Lyapunov Risk = 0.7996712923049927, MSE = 0.025166412815451622, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021404437720775604, Lv_loss = 0.0, Circular Tuning Loss = 0.984828531742096\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0039062500000004, -1.0000000000000002]\n",
      "x2 : [0, 0.0033829117335329637]\n",
      "==============================\n",
      "1711) Lyapunov Risk = 0.802260160446167, MSE = 0.021888745948672295, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021328888833522797, Lv_loss = 0.00042370238224975765, Circular Tuning Loss = 0.9824906587600708\n",
      "1712) Lyapunov Risk = 0.80475252866745, MSE = 0.028344927355647087, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02133171632885933, Lv_loss = 0.0, Circular Tuning Loss = 0.9822694063186646\n",
      "1713) Lyapunov Risk = 0.8072052597999573, MSE = 0.02220560610294342, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02133338525891304, Lv_loss = 0.0007086241967044771, Circular Tuning Loss = 0.9820520877838135\n",
      "1714) Lyapunov Risk = 0.8026008009910583, MSE = 0.027147604152560234, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021334970369935036, Lv_loss = 0.0, Circular Tuning Loss = 0.9818359613418579\n",
      "1715) Lyapunov Risk = 0.7985597848892212, MSE = 0.022741466760635376, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021335933357477188, Lv_loss = 0.00014206240302883089, Circular Tuning Loss = 0.9816229343414307\n",
      "1716) Lyapunov Risk = 0.7983013391494751, MSE = 0.022434713318943977, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02133708819746971, Lv_loss = 0.00016486982349306345, Circular Tuning Loss = 0.9814099669456482\n",
      "1717) Lyapunov Risk = 0.8001366257667542, MSE = 0.026472287252545357, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021338436752557755, Lv_loss = 0.0, Circular Tuning Loss = 0.9811968803405762\n",
      "1718) Lyapunov Risk = 0.8007988333702087, MSE = 0.022486621513962746, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021338926628232002, Lv_loss = 0.0004225212906021625, Circular Tuning Loss = 0.9809867143630981\n",
      "1719) Lyapunov Risk = 0.7985142469406128, MSE = 0.02484053559601307, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021339476108551025, Lv_loss = 0.0, Circular Tuning Loss = 0.9807769060134888\n",
      "1720) Lyapunov Risk = 0.7975502610206604, MSE = 0.024250445887446404, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.0213396605104208, Lv_loss = 0.0, Circular Tuning Loss = 0.9805689454078674\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0019531250000004, -1.0000000000000002]\n",
      "x2 : [0, 0.0016914558667664819]\n",
      "==============================\n",
      "1721) Lyapunov Risk = 0.7967261672019958, MSE = 0.0225218553096056, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021262258291244507, Lv_loss = 6.529060192406178e-05, Circular Tuning Loss = 0.9782648682594299\n",
      "1722) Lyapunov Risk = 0.7967496514320374, MSE = 0.024188624694943428, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021263310685753822, Lv_loss = 0.0, Circular Tuning Loss = 0.9780562520027161\n",
      "1723) Lyapunov Risk = 0.7972235679626465, MSE = 0.02362298034131527, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02126425690948963, Lv_loss = 0.00010445313091622666, Circular Tuning Loss = 0.977848470211029\n",
      "1724) Lyapunov Risk = 0.7962743043899536, MSE = 0.023529164493083954, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.0212655421346426, Lv_loss = 2.4213557026087074e-07, Circular Tuning Loss = 0.9776400923728943\n",
      "1725) Lyapunov Risk = 0.7955322861671448, MSE = 0.02384326048195362, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02126721478998661, Lv_loss = 0.0, Circular Tuning Loss = 0.9774311184883118\n",
      "1726) Lyapunov Risk = 0.7964308857917786, MSE = 0.023082775995135307, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021268539130687714, Lv_loss = 0.0001233356015291065, Circular Tuning Loss = 0.9772235751152039\n",
      "1727) Lyapunov Risk = 0.7966127395629883, MSE = 0.02458186075091362, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021270092576742172, Lv_loss = 0.0, Circular Tuning Loss = 0.9770156145095825\n",
      "1728) Lyapunov Risk = 0.7957400679588318, MSE = 0.022815799340605736, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021271146833896637, Lv_loss = 2.7813162887468934e-05, Circular Tuning Loss = 0.9768098592758179\n",
      "1729) Lyapunov Risk = 0.7949286103248596, MSE = 0.023633059114217758, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.02127242088317871, Lv_loss = 0.0, Circular Tuning Loss = 0.976603627204895\n",
      "1730) Lyapunov Risk = 0.7954638004302979, MSE = 0.024149319157004356, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021274104714393616, Lv_loss = 0.0, Circular Tuning Loss = 0.9763969779014587\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0019531250000004, -1.0000000000000002]\n",
      "x2 : [0, 0.0033829117335329637]\n",
      "==============================\n",
      "1731) Lyapunov Risk = 0.7963609099388123, MSE = 0.022486185654997826, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.021197712048888206, Lv_loss = 0.00035665155155584216, Circular Tuning Loss = 0.9741184115409851\n",
      "1732) Lyapunov Risk = 0.7953172326087952, MSE = 0.024780217558145523, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.021199148148298264, Lv_loss = 0.0, Circular Tuning Loss = 0.9739139080047607\n",
      "1733) Lyapunov Risk = 0.794400691986084, MSE = 0.02268717996776104, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02119983732700348, Lv_loss = 6.33954769000411e-05, Circular Tuning Loss = 0.9737120270729065\n",
      "1734) Lyapunov Risk = 0.7942636609077454, MSE = 0.023098886013031006, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.021200846880674362, Lv_loss = 0.0, Circular Tuning Loss = 0.9735097885131836\n",
      "1735) Lyapunov Risk = 0.7947337031364441, MSE = 0.02466448023915291, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.021202243864536285, Lv_loss = 0.0, Circular Tuning Loss = 0.9733069539070129\n",
      "1736) Lyapunov Risk = 0.795206606388092, MSE = 0.02221735566854477, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.021202975884079933, Lv_loss = 0.00018710635777097195, Circular Tuning Loss = 0.9731065034866333\n",
      "1737) Lyapunov Risk = 0.7938501238822937, MSE = 0.024212241172790527, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.021203912794589996, Lv_loss = 0.0, Circular Tuning Loss = 0.9729061126708984\n",
      "1738) Lyapunov Risk = 0.7932872176170349, MSE = 0.023369716480374336, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.021204300224781036, Lv_loss = 0.0, Circular Tuning Loss = 0.9727078676223755\n",
      "1739) Lyapunov Risk = 0.7932864427566528, MSE = 0.022845633327960968, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.021205222234129906, Lv_loss = 7.606445433339104e-05, Circular Tuning Loss = 0.9725086688995361\n",
      "1740) Lyapunov Risk = 0.7933518290519714, MSE = 0.024124084040522575, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.0212066862732172, Lv_loss = 0.0, Circular Tuning Loss = 0.9723089337348938\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0019531250000004, -1.0000000000000002]\n",
      "x2 : [0, 0.0016914558667664819]\n",
      "==============================\n",
      "1741) Lyapunov Risk = 0.793157696723938, MSE = 0.02259206771850586, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02113044261932373, Lv_loss = 0.00014156672114040703, Circular Tuning Loss = 0.9700603485107422\n",
      "1742) Lyapunov Risk = 0.7926439046859741, MSE = 0.023789139464497566, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02113168314099312, Lv_loss = 0.0, Circular Tuning Loss = 0.9698632955551147\n",
      "1743) Lyapunov Risk = 0.7924433946609497, MSE = 0.023043446242809296, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.021132439374923706, Lv_loss = 0.0, Circular Tuning Loss = 0.9696678519248962\n",
      "1744) Lyapunov Risk = 0.7922354936599731, MSE = 0.02329386956989765, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.021133625879883766, Lv_loss = 0.0, Circular Tuning Loss = 0.9694718718528748\n",
      "1745) Lyapunov Risk = 0.7921881079673767, MSE = 0.02378716878592968, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.021135257557034492, Lv_loss = 0.0, Circular Tuning Loss = 0.9692752361297607\n",
      "1746) Lyapunov Risk = 0.7925320267677307, MSE = 0.02260267548263073, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.021136337891221046, Lv_loss = 0.00016264717851299793, Circular Tuning Loss = 0.9690803289413452\n",
      "1747) Lyapunov Risk = 0.7924813628196716, MSE = 0.024378126487135887, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02113773673772812, Lv_loss = 0.0, Circular Tuning Loss = 0.9688849449157715\n",
      "1748) Lyapunov Risk = 0.7919976115226746, MSE = 0.022728536278009415, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.021138371899724007, Lv_loss = 9.293340553995222e-05, Circular Tuning Loss = 0.9686921238899231\n",
      "1749) Lyapunov Risk = 0.7914752960205078, MSE = 0.02345127984881401, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.021139446645975113, Lv_loss = 0.0, Circular Tuning Loss = 0.9684987664222717\n",
      "1750) Lyapunov Risk = 0.7913089990615845, MSE = 0.023272061720490456, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.021140243858098984, Lv_loss = 0.0, Circular Tuning Loss = 0.9683063626289368\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0019531250000004, -1.0000000000000002]\n",
      "x2 : [0, 0.0016914558667664819]\n",
      "==============================\n",
      "1751) Lyapunov Risk = 0.791103184223175, MSE = 0.022993288934230804, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.0210646353662014, Lv_loss = 0.0, Circular Tuning Loss = 0.966083288192749\n",
      "1752) Lyapunov Risk = 0.7911434173583984, MSE = 0.023824570700526237, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.021066032350063324, Lv_loss = 0.0, Circular Tuning Loss = 0.9658908247947693\n",
      "1753) Lyapunov Risk = 0.791263222694397, MSE = 0.022561008110642433, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.021066678687930107, Lv_loss = 0.00014476801152341068, Circular Tuning Loss = 0.9657009243965149\n",
      "1754) Lyapunov Risk = 0.7910820245742798, MSE = 0.02415880374610424, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.021067654713988304, Lv_loss = 0.0, Circular Tuning Loss = 0.9655106067657471\n",
      "1755) Lyapunov Risk = 0.7907089591026306, MSE = 0.022714443504810333, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.021067768335342407, Lv_loss = 1.7422238443032256e-06, Circular Tuning Loss = 0.9653233885765076\n",
      "1756) Lyapunov Risk = 0.7903546690940857, MSE = 0.023512976244091988, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.021068358793854713, Lv_loss = 0.0, Circular Tuning Loss = 0.965135395526886\n",
      "1757) Lyapunov Risk = 0.7901710867881775, MSE = 0.023073410615324974, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02106848917901516, Lv_loss = 0.0, Circular Tuning Loss = 0.9649491906166077\n",
      "1758) Lyapunov Risk = 0.7900651097297668, MSE = 0.02343173511326313, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.021069012582302094, Lv_loss = 0.0, Circular Tuning Loss = 0.9647625684738159\n",
      "1759) Lyapunov Risk = 0.7900526523590088, MSE = 0.02275577001273632, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.021069034934043884, Lv_loss = 6.59131255815737e-05, Circular Tuning Loss = 0.9645775556564331\n",
      "1760) Lyapunov Risk = 0.7902434468269348, MSE = 0.024075394496321678, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.021069515496492386, Lv_loss = 0.0, Circular Tuning Loss = 0.9643920063972473\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0019531250000004, -1.0000000000000002]\n",
      "x2 : [0, 0.0016914558667664819]\n",
      "==============================\n",
      "1761) Lyapunov Risk = 0.790006697177887, MSE = 0.02249685861170292, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020993106067180634, Lv_loss = 0.00013693986693397164, Circular Tuning Loss = 0.9621995687484741\n",
      "1762) Lyapunov Risk = 0.7896458506584167, MSE = 0.023884139955043793, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02099318616092205, Lv_loss = 0.0, Circular Tuning Loss = 0.9620164036750793\n",
      "1763) Lyapunov Risk = 0.7892773747444153, MSE = 0.022898338735103607, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020992634817957878, Lv_loss = 0.0, Circular Tuning Loss = 0.9618354439735413\n",
      "1764) Lyapunov Risk = 0.789089024066925, MSE = 0.023387642577290535, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020992567762732506, Lv_loss = 0.0, Circular Tuning Loss = 0.9616540670394897\n",
      "1765) Lyapunov Risk = 0.7889317274093628, MSE = 0.022975176572799683, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020992083474993706, Lv_loss = 0.0, Circular Tuning Loss = 0.9614743590354919\n",
      "1766) Lyapunov Risk = 0.7888638973236084, MSE = 0.023502716794610023, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020991813391447067, Lv_loss = 0.0, Circular Tuning Loss = 0.9612947106361389\n",
      "1767) Lyapunov Risk = 0.7888033986091614, MSE = 0.022724192589521408, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020991012454032898, Lv_loss = 2.656521974131465e-05, Circular Tuning Loss = 0.9611175060272217\n",
      "1768) Lyapunov Risk = 0.7889565825462341, MSE = 0.02397190034389496, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020990699529647827, Lv_loss = 0.0, Circular Tuning Loss = 0.9609395265579224\n",
      "1769) Lyapunov Risk = 0.7888140678405762, MSE = 0.022518044337630272, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020989645272493362, Lv_loss = 7.490623102057725e-05, Circular Tuning Loss = 0.9607642292976379\n",
      "1770) Lyapunov Risk = 0.7885911464691162, MSE = 0.0238268431276083, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020989075303077698, Lv_loss = 0.0, Circular Tuning Loss = 0.9605880975723267\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0019531250000004, -1.0000000000000002]\n",
      "x2 : [0, 0.0016914558667664819]\n",
      "==============================\n",
      "1771) Lyapunov Risk = 0.7881149649620056, MSE = 0.02279704250395298, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02091234177350998, Lv_loss = 1.7661619722275645e-07, Circular Tuning Loss = 0.9584254026412964\n",
      "1772) Lyapunov Risk = 0.7879739999771118, MSE = 0.023553280159831047, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020911606028676033, Lv_loss = 0.0, Circular Tuning Loss = 0.958251416683197\n",
      "1773) Lyapunov Risk = 0.7877926826477051, MSE = 0.022827085107564926, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020910365507006645, Lv_loss = 1.6453229534363345e-07, Circular Tuning Loss = 0.9580796360969543\n",
      "1774) Lyapunov Risk = 0.7877100110054016, MSE = 0.023550763726234436, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020909393206238747, Lv_loss = 0.0, Circular Tuning Loss = 0.9579076170921326\n",
      "1775) Lyapunov Risk = 0.7875255346298218, MSE = 0.02280201017856598, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020907822996377945, Lv_loss = 3.268000341449806e-07, Circular Tuning Loss = 0.9577377438545227\n",
      "1776) Lyapunov Risk = 0.7874082922935486, MSE = 0.023418743163347244, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020906545221805573, Lv_loss = 0.0, Circular Tuning Loss = 0.9575678110122681\n",
      "1777) Lyapunov Risk = 0.7872740626335144, MSE = 0.022775305435061455, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02090471051633358, Lv_loss = 3.4111974400730105e-07, Circular Tuning Loss = 0.957399845123291\n",
      "1778) Lyapunov Risk = 0.7872607111930847, MSE = 0.023561187088489532, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02090325392782688, Lv_loss = 0.0, Circular Tuning Loss = 0.9572312235832214\n",
      "1779) Lyapunov Risk = 0.787131130695343, MSE = 0.02262500673532486, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020901285111904144, Lv_loss = 7.542944899796566e-07, Circular Tuning Loss = 0.9570643305778503\n",
      "1780) Lyapunov Risk = 0.7871840596199036, MSE = 0.02384929172694683, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02089996263384819, Lv_loss = 0.0, Circular Tuning Loss = 0.9568965435028076\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0009765625000004, -1.0000000000000002]\n",
      "x2 : [0, 0.0016914558667664819]\n",
      "==============================\n",
      "1781) Lyapunov Risk = 0.78676438331604, MSE = 0.02266479842364788, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02082313783466816, Lv_loss = 1.406483534083236e-06, Circular Tuning Loss = 0.9547604918479919\n",
      "1782) Lyapunov Risk = 0.7865880131721497, MSE = 0.023579781875014305, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020821588113904, Lv_loss = 0.0, Circular Tuning Loss = 0.9545947313308716\n",
      "1783) Lyapunov Risk = 0.7863315939903259, MSE = 0.022939367219805717, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02081942930817604, Lv_loss = 0.0, Circular Tuning Loss = 0.9544309973716736\n",
      "1784) Lyapunov Risk = 0.7861803770065308, MSE = 0.022986991330981255, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020817160606384277, Lv_loss = 0.0, Circular Tuning Loss = 0.9542680978775024\n",
      "1785) Lyapunov Risk = 0.7861320972442627, MSE = 0.023372232913970947, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020814819261431694, Lv_loss = 0.0, Circular Tuning Loss = 0.9541058540344238\n",
      "1786) Lyapunov Risk = 0.7861390709877014, MSE = 0.022573107853531837, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.0208121370524168, Lv_loss = 5.286238433654944e-07, Circular Tuning Loss = 0.9539449214935303\n",
      "1787) Lyapunov Risk = 0.7863051295280457, MSE = 0.023900093510746956, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020810123533010483, Lv_loss = 0.0, Circular Tuning Loss = 0.9537826776504517\n",
      "1788) Lyapunov Risk = 0.7860098481178284, MSE = 0.02253817208111286, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020807674154639244, Lv_loss = 9.182828216580674e-05, Circular Tuning Loss = 0.9536222815513611\n",
      "1789) Lyapunov Risk = 0.7858673334121704, MSE = 0.02371128648519516, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020805761218070984, Lv_loss = 0.0, Circular Tuning Loss = 0.9534607529640198\n",
      "1790) Lyapunov Risk = 0.785464882850647, MSE = 0.02297685481607914, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02080330066382885, Lv_loss = 3.952038696297677e-07, Circular Tuning Loss = 0.9533012509346008\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0039062500000004, -1.0029296875000004]\n",
      "x2 : [0.0016914558667664819, 0.0033829117335329637]\n",
      "==============================\n",
      "1791) Lyapunov Risk = 0.785264790058136, MSE = 0.022815480828285217, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020726293325424194, Lv_loss = 5.265933822329316e-08, Circular Tuning Loss = 0.9512003064155579\n",
      "1792) Lyapunov Risk = 0.7854527831077576, MSE = 0.023856554180383682, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02072369121015072, Lv_loss = 0.0, Circular Tuning Loss = 0.9510424137115479\n",
      "1793) Lyapunov Risk = 0.7854312062263489, MSE = 0.02249124087393284, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02072065882384777, Lv_loss = 3.136330803954479e-07, Circular Tuning Loss = 0.9508861303329468\n",
      "1794) Lyapunov Risk = 0.7852082252502441, MSE = 0.023799527436494827, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02071830816566944, Lv_loss = 0.0, Circular Tuning Loss = 0.9507284164428711\n",
      "1795) Lyapunov Risk = 0.784783124923706, MSE = 0.02273533120751381, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020715488120913506, Lv_loss = 9.025966960507503e-07, Circular Tuning Loss = 0.9505722522735596\n",
      "1796) Lyapunov Risk = 0.7846044301986694, MSE = 0.022891540080308914, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020712630823254585, Lv_loss = 8.028688398553641e-07, Circular Tuning Loss = 0.9504166841506958\n",
      "1797) Lyapunov Risk = 0.7846206426620483, MSE = 0.023453932255506516, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020709529519081116, Lv_loss = 0.0, Circular Tuning Loss = 0.9502620100975037\n",
      "1798) Lyapunov Risk = 0.7845572233200073, MSE = 0.022576142102479935, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020705990493297577, Lv_loss = 7.438323450514872e-07, Circular Tuning Loss = 0.9501088261604309\n",
      "1799) Lyapunov Risk = 0.7846974730491638, MSE = 0.02393283322453499, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020703140646219254, Lv_loss = 0.0, Circular Tuning Loss = 0.9499539732933044\n",
      "1800) Lyapunov Risk = 0.7843383550643921, MSE = 0.022613830864429474, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020700005814433098, Lv_loss = 5.038886001784704e-07, Circular Tuning Loss = 0.949800431728363\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0156250000000004, -1.0136718750000004]\n",
      "x2 : [0.025371838001497227, 0.02706329386826371]\n",
      "==============================\n",
      "1801) Lyapunov Risk = 0.7840611338615417, MSE = 0.023634355515241623, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020623857155442238, Lv_loss = 0.0, Circular Tuning Loss = 0.947749137878418\n",
      "1802) Lyapunov Risk = 0.783781886100769, MSE = 0.0230477936565876, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02062099799513817, Lv_loss = 1.2545291383503354e-07, Circular Tuning Loss = 0.9475961327552795\n",
      "1803) Lyapunov Risk = 0.7837488055229187, MSE = 0.022736772894859314, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020617784932255745, Lv_loss = 3.4710819818428718e-06, Circular Tuning Loss = 0.9474444389343262\n",
      "1804) Lyapunov Risk = 0.7838437557220459, MSE = 0.02376597560942173, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020614605396986008, Lv_loss = 0.0, Circular Tuning Loss = 0.9472929835319519\n",
      "1805) Lyapunov Risk = 0.7836316823959351, MSE = 0.022557390853762627, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020611053332686424, Lv_loss = 2.3259826775756665e-06, Circular Tuning Loss = 0.9471429586410522\n",
      "1806) Lyapunov Risk = 0.7835529446601868, MSE = 0.023612894117832184, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020608339458703995, Lv_loss = 0.0, Circular Tuning Loss = 0.9469910860061646\n",
      "1807) Lyapunov Risk = 0.7832534313201904, MSE = 0.022690972313284874, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020605234429240227, Lv_loss = 6.333023520710412e-06, Circular Tuning Loss = 0.9468407034873962\n",
      "1808) Lyapunov Risk = 0.7830429673194885, MSE = 0.02298668585717678, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020602120086550713, Lv_loss = 2.9296296588654513e-07, Circular Tuning Loss = 0.9466904401779175\n",
      "1809) Lyapunov Risk = 0.782963752746582, MSE = 0.023262670263648033, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020598679780960083, Lv_loss = 0.0, Circular Tuning Loss = 0.9465413689613342\n",
      "1810) Lyapunov Risk = 0.7828793525695801, MSE = 0.02275349758565426, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02059497870504856, Lv_loss = 2.1054403021025792e-07, Circular Tuning Loss = 0.9463934898376465\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0156250000000004, -1.0136718750000004]\n",
      "x2 : [0.025371838001497227, 0.02706329386826371]\n",
      "==============================\n",
      "1811) Lyapunov Risk = 0.7826594114303589, MSE = 0.023264041170477867, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020518360659480095, Lv_loss = 0.0, Circular Tuning Loss = 0.9443684816360474\n",
      "1812) Lyapunov Risk = 0.7824887037277222, MSE = 0.02290249988436699, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020514555275440216, Lv_loss = 0.0, Circular Tuning Loss = 0.9442218542098999\n",
      "1813) Lyapunov Risk = 0.7823528051376343, MSE = 0.022931693121790886, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02051078900694847, Lv_loss = 0.0, Circular Tuning Loss = 0.9440755844116211\n",
      "1814) Lyapunov Risk = 0.7822650671005249, MSE = 0.02314014546573162, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020506953820586205, Lv_loss = 0.0, Circular Tuning Loss = 0.9439297318458557\n",
      "1815) Lyapunov Risk = 0.7821733951568604, MSE = 0.022784819826483727, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020502904430031776, Lv_loss = 1.8428989960739273e-06, Circular Tuning Loss = 0.9437848925590515\n",
      "1816) Lyapunov Risk = 0.7820408344268799, MSE = 0.023167259991168976, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020498860627412796, Lv_loss = 0.0, Circular Tuning Loss = 0.9436402320861816\n",
      "1817) Lyapunov Risk = 0.7818877100944519, MSE = 0.022909021005034447, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.0204946156591177, Lv_loss = 0.0, Circular Tuning Loss = 0.9434965252876282\n",
      "1818) Lyapunov Risk = 0.7817732095718384, MSE = 0.022935917600989342, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020490318536758423, Lv_loss = 0.0, Circular Tuning Loss = 0.9433532953262329\n",
      "1819) Lyapunov Risk = 0.781682550907135, MSE = 0.023165706545114517, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02048599347472191, Lv_loss = 0.0, Circular Tuning Loss = 0.9432103633880615\n",
      "1820) Lyapunov Risk = 0.7815843224525452, MSE = 0.022802051156759262, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020481472834944725, Lv_loss = 0.0, Circular Tuning Loss = 0.9430685639381409\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0156250000000004, -1.0146484375000004]\n",
      "x2 : [0.025371838001497227, 0.02706329386826371]\n",
      "==============================\n",
      "1821) Lyapunov Risk = 0.7813758254051208, MSE = 0.023223208263516426, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020404692739248276, Lv_loss = 0.0, Circular Tuning Loss = 0.9410699605941772\n",
      "1822) Lyapunov Risk = 0.7812291383743286, MSE = 0.022933954373002052, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020400159060955048, Lv_loss = 0.0, Circular Tuning Loss = 0.9409295320510864\n",
      "1823) Lyapunov Risk = 0.7811133861541748, MSE = 0.022950997576117516, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02039562724530697, Lv_loss = 0.0, Circular Tuning Loss = 0.9407895803451538\n",
      "1824) Lyapunov Risk = 0.7810253500938416, MSE = 0.023204896599054337, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02039109356701374, Lv_loss = 0.0, Circular Tuning Loss = 0.9406499266624451\n",
      "1825) Lyapunov Risk = 0.7809171080589294, MSE = 0.022828249260783195, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02038641646504402, Lv_loss = 0.0, Circular Tuning Loss = 0.9405108094215393\n",
      "1826) Lyapunov Risk = 0.7807945013046265, MSE = 0.023190075531601906, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020381862297654152, Lv_loss = 0.0, Circular Tuning Loss = 0.9403716325759888\n",
      "1827) Lyapunov Risk = 0.7806604504585266, MSE = 0.022939268499612808, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02037716470658779, Lv_loss = 0.0, Circular Tuning Loss = 0.9402331709861755\n",
      "1828) Lyapunov Risk = 0.7805395722389221, MSE = 0.02298155054450035, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02037253975868225, Lv_loss = 0.0, Circular Tuning Loss = 0.9400947690010071\n",
      "1829) Lyapunov Risk = 0.7804469466209412, MSE = 0.02315523661673069, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02036794275045395, Lv_loss = 0.0, Circular Tuning Loss = 0.939956784248352\n",
      "1830) Lyapunov Risk = 0.7803436517715454, MSE = 0.022833548486232758, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02036321721971035, Lv_loss = 2.075688314562285e-07, Circular Tuning Loss = 0.9398190975189209\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0156250000000004, -1.0146484375000004]\n",
      "x2 : [0.025371838001497227, 0.02706329386826371]\n",
      "==============================\n",
      "1831) Lyapunov Risk = 0.7801451683044434, MSE = 0.023138243705034256, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020286863669753075, Lv_loss = 0.0, Circular Tuning Loss = 0.937842845916748\n",
      "1832) Lyapunov Risk = 0.7800131440162659, MSE = 0.022975429892539978, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020282141864299774, Lv_loss = 0.0, Circular Tuning Loss = 0.9377065896987915\n",
      "1833) Lyapunov Risk = 0.7798985242843628, MSE = 0.022982347756624222, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020277464762330055, Lv_loss = 0.0, Circular Tuning Loss = 0.9375705122947693\n",
      "1834) Lyapunov Risk = 0.7797970175743103, MSE = 0.02311939001083374, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020272832363843918, Lv_loss = 0.0, Circular Tuning Loss = 0.9374346733093262\n",
      "1835) Lyapunov Risk = 0.7796991467475891, MSE = 0.02287672646343708, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02026807703077793, Lv_loss = 0.0, Circular Tuning Loss = 0.9372994303703308\n",
      "1836) Lyapunov Risk = 0.779590904712677, MSE = 0.02317921072244644, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020263459533452988, Lv_loss = 0.0, Circular Tuning Loss = 0.9371642470359802\n",
      "1837) Lyapunov Risk = 0.7794740200042725, MSE = 0.0228573027998209, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020258622244000435, Lv_loss = 1.0984889087239935e-07, Circular Tuning Loss = 0.9370299577713013\n",
      "1838) Lyapunov Risk = 0.779350996017456, MSE = 0.023116033524274826, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020253855735063553, Lv_loss = 0.0, Circular Tuning Loss = 0.9368956089019775\n",
      "1839) Lyapunov Risk = 0.7792277932167053, MSE = 0.02297118678689003, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020248981192708015, Lv_loss = 0.0, Circular Tuning Loss = 0.9367619752883911\n",
      "1840) Lyapunov Risk = 0.7791358828544617, MSE = 0.022844785824418068, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02024400234222412, Lv_loss = 7.407299307260473e-08, Circular Tuning Loss = 0.9366287589073181\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0312500000000004, -1.0292968750000004]\n",
      "x2 : [0.025371838001497227, 0.02706329386826371]\n",
      "==============================\n",
      "1841) Lyapunov Risk = 0.7790217995643616, MSE = 0.023281993344426155, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020168140530586243, Lv_loss = 0.0, Circular Tuning Loss = 0.9347268342971802\n",
      "1842) Lyapunov Risk = 0.7789193391799927, MSE = 0.02272971160709858, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02016311325132847, Lv_loss = 3.227685851925344e-07, Circular Tuning Loss = 0.9345947504043579\n",
      "1843) Lyapunov Risk = 0.7788103818893433, MSE = 0.023321229964494705, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02015834115445614, Lv_loss = 0.0, Circular Tuning Loss = 0.9344621896743774\n",
      "1844) Lyapunov Risk = 0.7786514759063721, MSE = 0.022893870249390602, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02015337161719799, Lv_loss = 1.3037455914854945e-07, Circular Tuning Loss = 0.9343302845954895\n",
      "1845) Lyapunov Risk = 0.7785215973854065, MSE = 0.0230701956897974, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02014848403632641, Lv_loss = 0.0, Circular Tuning Loss = 0.9341984391212463\n",
      "1846) Lyapunov Risk = 0.7784112095832825, MSE = 0.02311873808503151, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020143508911132812, Lv_loss = 0.0, Circular Tuning Loss = 0.9340669512748718\n",
      "1847) Lyapunov Risk = 0.7783101201057434, MSE = 0.02289860136806965, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02013845555484295, Lv_loss = 9.60767820856745e-08, Circular Tuning Loss = 0.9339358806610107\n",
      "1848) Lyapunov Risk = 0.7782214283943176, MSE = 0.02317163720726967, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020133523270487785, Lv_loss = 0.0, Circular Tuning Loss = 0.9338045716285706\n",
      "1849) Lyapunov Risk = 0.7781224250793457, MSE = 0.022782793268561363, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020128414034843445, Lv_loss = 4.032303309031704e-07, Circular Tuning Loss = 0.9336740374565125\n",
      "1850) Lyapunov Risk = 0.7780389785766602, MSE = 0.02325853332877159, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020123561844229698, Lv_loss = 0.0, Circular Tuning Loss = 0.9335431456565857\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0156250000000004, -1.0146484375000004]\n",
      "x2 : [0.025371838001497227, 0.02706329386826371]\n",
      "==============================\n",
      "1851) Lyapunov Risk = 0.7778399586677551, MSE = 0.02275429666042328, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02004823088645935, Lv_loss = 5.919587806602067e-07, Circular Tuning Loss = 0.9316094517707825\n",
      "1852) Lyapunov Risk = 0.7777240872383118, MSE = 0.023222150281071663, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02004345692694187, Lv_loss = 0.0, Circular Tuning Loss = 0.931479275226593\n",
      "1853) Lyapunov Risk = 0.7775816321372986, MSE = 0.022915776818990707, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020038535818457603, Lv_loss = 1.9324674838117062e-07, Circular Tuning Loss = 0.9313498735427856\n",
      "1854) Lyapunov Risk = 0.7774686813354492, MSE = 0.022984104230999947, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020033610984683037, Lv_loss = 0.0, Circular Tuning Loss = 0.9312206506729126\n",
      "1855) Lyapunov Risk = 0.7773698568344116, MSE = 0.023118767887353897, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020028600469231606, Lv_loss = 0.0, Circular Tuning Loss = 0.9310917258262634\n",
      "1856) Lyapunov Risk = 0.7772608995437622, MSE = 0.022890985012054443, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020023537799715996, Lv_loss = 2.5531798542033357e-07, Circular Tuning Loss = 0.9309631586074829\n",
      "1857) Lyapunov Risk = 0.7771680951118469, MSE = 0.023103153333067894, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020018581300973892, Lv_loss = 1.5238587991461827e-07, Circular Tuning Loss = 0.930834174156189\n",
      "1858) Lyapunov Risk = 0.7770653963088989, MSE = 0.022802967578172684, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020013492554426193, Lv_loss = 7.80853838477924e-07, Circular Tuning Loss = 0.9307059645652771\n",
      "1859) Lyapunov Risk = 0.7769498825073242, MSE = 0.023052804172039032, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020008452236652374, Lv_loss = 2.918135919571796e-07, Circular Tuning Loss = 0.9305778741836548\n",
      "1860) Lyapunov Risk = 0.7768319845199585, MSE = 0.022869503125548363, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020003264769911766, Lv_loss = 4.40612296870313e-07, Circular Tuning Loss = 0.9304503202438354\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.1269531250000004, -1.1250000000000004]\n",
      "x2 : [0.21650635094610968, 0.21819780681287615]\n",
      "==============================\n",
      "1861) Lyapunov Risk = 0.7767940163612366, MSE = 0.023068049922585487, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01992853730916977, Lv_loss = 1.1380240749758741e-07, Circular Tuning Loss = 0.9289478659629822\n",
      "1862) Lyapunov Risk = 0.7766982913017273, MSE = 0.02284330129623413, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019923357293009758, Lv_loss = 4.297571933875588e-07, Circular Tuning Loss = 0.9288208484649658\n",
      "1863) Lyapunov Risk = 0.7766029238700867, MSE = 0.023175058886408806, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019918333739042282, Lv_loss = 6.900204851945091e-08, Circular Tuning Loss = 0.9286935925483704\n",
      "1864) Lyapunov Risk = 0.7764890789985657, MSE = 0.022849997505545616, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019913172349333763, Lv_loss = 6.685317543997371e-07, Circular Tuning Loss = 0.9285668134689331\n",
      "1865) Lyapunov Risk = 0.7763862609863281, MSE = 0.02309844270348549, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019908100366592407, Lv_loss = 3.619503274876479e-07, Circular Tuning Loss = 0.9284398555755615\n",
      "1866) Lyapunov Risk = 0.7762746214866638, MSE = 0.02290705032646656, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019902875646948814, Lv_loss = 7.301521236513508e-07, Circular Tuning Loss = 0.9283134937286377\n",
      "1867) Lyapunov Risk = 0.7761634588241577, MSE = 0.022949974983930588, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01989760994911194, Lv_loss = 4.953264465257234e-07, Circular Tuning Loss = 0.9281874299049377\n",
      "1868) Lyapunov Risk = 0.7760578393936157, MSE = 0.022974083200097084, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01989230327308178, Lv_loss = 4.467234475669102e-07, Circular Tuning Loss = 0.9280616044998169\n",
      "1869) Lyapunov Risk = 0.7759585976600647, MSE = 0.02286495454609394, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01988697238266468, Lv_loss = 7.007369049460976e-07, Circular Tuning Loss = 0.9279361367225647\n",
      "1870) Lyapunov Risk = 0.7758784294128418, MSE = 0.02308230847120285, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01988176815211773, Lv_loss = 4.794595156454307e-07, Circular Tuning Loss = 0.9278103113174438\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0156250000000004, -1.0146484375000004]\n",
      "x2 : [0.025371838001497227, 0.02706329386826371]\n",
      "==============================\n",
      "1871) Lyapunov Risk = 0.7757388949394226, MSE = 0.02273748256266117, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019807448610663414, Lv_loss = 5.236600372882094e-06, Circular Tuning Loss = 0.92591392993927\n",
      "1872) Lyapunov Risk = 0.7756757736206055, MSE = 0.023302707821130753, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019802385941147804, Lv_loss = 2.8220949843671406e-07, Circular Tuning Loss = 0.9257896542549133\n",
      "1873) Lyapunov Risk = 0.7755330801010132, MSE = 0.022793695330619812, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01979718916118145, Lv_loss = 3.932577783416491e-06, Circular Tuning Loss = 0.9256657958030701\n",
      "1874) Lyapunov Risk = 0.775406002998352, MSE = 0.02315373905003071, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019792137667536736, Lv_loss = 3.364266945027339e-07, Circular Tuning Loss = 0.9255419969558716\n",
      "1875) Lyapunov Risk = 0.7752811908721924, MSE = 0.022949744015932083, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01978692039847374, Lv_loss = 7.617487653988064e-07, Circular Tuning Loss = 0.9254187941551208\n",
      "1876) Lyapunov Risk = 0.7751738429069519, MSE = 0.02293076179921627, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01978166587650776, Lv_loss = 7.816569222995895e-07, Circular Tuning Loss = 0.9252960085868835\n",
      "1877) Lyapunov Risk = 0.7750795483589172, MSE = 0.02303156815469265, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019776375964283943, Lv_loss = 6.407200316971284e-07, Circular Tuning Loss = 0.9251736402511597\n",
      "1878) Lyapunov Risk = 0.7750046253204346, MSE = 0.022749662399291992, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019770938903093338, Lv_loss = 5.547786258830456e-06, Circular Tuning Loss = 0.9250516891479492\n",
      "1879) Lyapunov Risk = 0.774960458278656, MSE = 0.02323192171752453, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019765716046094894, Lv_loss = 6.218925250323082e-07, Circular Tuning Loss = 0.9249296188354492\n",
      "1880) Lyapunov Risk = 0.7748541831970215, MSE = 0.022660614922642708, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.0197603777050972, Lv_loss = 1.1517568054841831e-05, Circular Tuning Loss = 0.9248079657554626\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0312500000000004, -1.0292968750000004]\n",
      "x2 : [0.05243513186976094, 0.054126587736527419]\n",
      "==============================\n",
      "1881) Lyapunov Risk = 0.7747301459312439, MSE = 0.023283660411834717, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019686929881572723, Lv_loss = 7.117783411558776e-07, Circular Tuning Loss = 0.9229718446731567\n",
      "1882) Lyapunov Risk = 0.7745649218559265, MSE = 0.0228637233376503, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01968173310160637, Lv_loss = 6.26550263405079e-06, Circular Tuning Loss = 0.9228507876396179\n",
      "1883) Lyapunov Risk = 0.774441123008728, MSE = 0.022960295900702477, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01967649906873703, Lv_loss = 1.2564432836370543e-06, Circular Tuning Loss = 0.922730028629303\n",
      "1884) Lyapunov Risk = 0.7743622064590454, MSE = 0.02320326305925846, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019671225920319557, Lv_loss = 2.2823330425580934e-07, Circular Tuning Loss = 0.922609269618988\n",
      "1885) Lyapunov Risk = 0.7743032574653625, MSE = 0.022750316187739372, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019665848463773727, Lv_loss = 5.7546390053175855e-06, Circular Tuning Loss = 0.9224892258644104\n",
      "1886) Lyapunov Risk = 0.7742909789085388, MSE = 0.023386655375361443, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01966084912419319, Lv_loss = 3.765016458601167e-07, Circular Tuning Loss = 0.9223687648773193\n",
      "1887) Lyapunov Risk = 0.7741920948028564, MSE = 0.022678226232528687, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019655738025903702, Lv_loss = 2.1772617401438765e-05, Circular Tuning Loss = 0.9222493171691895\n",
      "1888) Lyapunov Risk = 0.7740722894668579, MSE = 0.02324496954679489, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01965079829096794, Lv_loss = 4.001398338004947e-06, Circular Tuning Loss = 0.9221300482749939\n",
      "1889) Lyapunov Risk = 0.7738741636276245, MSE = 0.022854257375001907, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019645700231194496, Lv_loss = 1.06430579762673e-05, Circular Tuning Loss = 0.9220118522644043\n",
      "1890) Lyapunov Risk = 0.7737359404563904, MSE = 0.02290031500160694, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019640548154711723, Lv_loss = 5.007227173337014e-06, Circular Tuning Loss = 0.9218940734863281\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0312500000000004, -1.0292968750000004]\n",
      "x2 : [0.05243513186976094, 0.054126587736527419]\n",
      "==============================\n",
      "1891) Lyapunov Risk = 0.7736732363700867, MSE = 0.023277319967746735, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019567811861634254, Lv_loss = 3.1998462191040744e-07, Circular Tuning Loss = 0.9200785756111145\n",
      "1892) Lyapunov Risk = 0.7736839652061462, MSE = 0.022662261500954628, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019562646746635437, Lv_loss = 1.1450956662883982e-05, Circular Tuning Loss = 0.91996169090271\n",
      "1893) Lyapunov Risk = 0.7737451791763306, MSE = 0.02364574745297432, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019557829946279526, Lv_loss = 1.027176637080629e-07, Circular Tuning Loss = 0.9198445081710815\n",
      "1894) Lyapunov Risk = 0.773600697517395, MSE = 0.022663762792944908, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019552797079086304, Lv_loss = 2.8690446924883872e-05, Circular Tuning Loss = 0.9197279214859009\n",
      "1895) Lyapunov Risk = 0.7734017968177795, MSE = 0.02340961992740631, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01954795978963375, Lv_loss = 3.0970313673606142e-06, Circular Tuning Loss = 0.9196115732192993\n",
      "1896) Lyapunov Risk = 0.7731440663337708, MSE = 0.02295776456594467, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01954294741153717, Lv_loss = 1.0650745025486685e-05, Circular Tuning Loss = 0.9194959998130798\n",
      "1897) Lyapunov Risk = 0.773061990737915, MSE = 0.0227628443390131, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019537756219506264, Lv_loss = 9.773757483344525e-06, Circular Tuning Loss = 0.919381320476532\n",
      "1898) Lyapunov Risk = 0.7731717824935913, MSE = 0.02356831356883049, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019532738253474236, Lv_loss = 0.0, Circular Tuning Loss = 0.9192665815353394\n",
      "1899) Lyapunov Risk = 0.7732262015342712, MSE = 0.022514501586556435, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019527535885572433, Lv_loss = 2.1483885575435124e-05, Circular Tuning Loss = 0.9191519618034363\n",
      "1900) Lyapunov Risk = 0.7735791206359863, MSE = 0.02410617470741272, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019523030146956444, Lv_loss = 1.2807338523046496e-09, Circular Tuning Loss = 0.9190359115600586\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0078125000000004, -1.0068359375000004]\n",
      "x2 : [0.018606014534431302, 0.020297470401197781]\n",
      "==============================\n",
      "1901) Lyapunov Risk = 0.7735361456871033, MSE = 0.022352434694767, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01945093460381031, Lv_loss = 7.041331264190376e-05, Circular Tuning Loss = 0.9171754121780396\n",
      "1902) Lyapunov Risk = 0.7737551331520081, MSE = 0.024630490690469742, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019446684047579765, Lv_loss = 0.0, Circular Tuning Loss = 0.9170597195625305\n",
      "1903) Lyapunov Risk = 0.7731149196624756, MSE = 0.022461721673607826, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019441774114966393, Lv_loss = 4.426167288329452e-05, Circular Tuning Loss = 0.9169458746910095\n",
      "1904) Lyapunov Risk = 0.7725914716720581, MSE = 0.023848244920372963, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019437411800026894, Lv_loss = 0.0, Circular Tuning Loss = 0.9168312549591064\n",
      "1905) Lyapunov Risk = 0.772212564945221, MSE = 0.02297399565577507, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01943259686231613, Lv_loss = 5.304227215674473e-06, Circular Tuning Loss = 0.9167177677154541\n",
      "1906) Lyapunov Risk = 0.772114634513855, MSE = 0.0228089839220047, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01942787505686283, Lv_loss = 9.68880340224132e-06, Circular Tuning Loss = 0.9166041612625122\n",
      "1907) Lyapunov Risk = 0.7722082138061523, MSE = 0.02351417951285839, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019423238933086395, Lv_loss = 9.498741633251484e-07, Circular Tuning Loss = 0.9164906740188599\n",
      "1908) Lyapunov Risk = 0.7723140716552734, MSE = 0.022302472963929176, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019418222829699516, Lv_loss = 4.929631177219562e-05, Circular Tuning Loss = 0.9163782000541687\n",
      "1909) Lyapunov Risk = 0.7725288271903992, MSE = 0.023957177996635437, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019413793459534645, Lv_loss = 2.0055388176842825e-06, Circular Tuning Loss = 0.9162647724151611\n",
      "1910) Lyapunov Risk = 0.7722092866897583, MSE = 0.022346626967191696, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01940883696079254, Lv_loss = 5.321091157384217e-05, Circular Tuning Loss = 0.916153073310852\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0625000000000004, -1.0605468750000004]\n",
      "x2 : [0.05243513186976094, 0.054126587736527419]\n",
      "==============================\n",
      "1911) Lyapunov Risk = 0.7718843221664429, MSE = 0.023638535290956497, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019337879493832588, Lv_loss = 1.87959335562482e-06, Circular Tuning Loss = 0.9144819974899292\n",
      "1912) Lyapunov Risk = 0.771567702293396, MSE = 0.02293339930474758, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019332945346832275, Lv_loss = 1.1297975106572267e-05, Circular Tuning Loss = 0.914371132850647\n",
      "1913) Lyapunov Risk = 0.7714412808418274, MSE = 0.023076675832271576, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019328132271766663, Lv_loss = 6.044129804649856e-06, Circular Tuning Loss = 0.91426020860672\n",
      "1914) Lyapunov Risk = 0.7714091539382935, MSE = 0.023396683856844902, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019323265179991722, Lv_loss = 1.2544417131721275e-06, Circular Tuning Loss = 0.9141497015953064\n",
      "1915) Lyapunov Risk = 0.7713595032691956, MSE = 0.022711046040058136, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01931823417544365, Lv_loss = 2.1681416910723783e-05, Circular Tuning Loss = 0.9140394926071167\n",
      "1916) Lyapunov Risk = 0.7712758183479309, MSE = 0.0232790969312191, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019313350319862366, Lv_loss = 1.0969927643600386e-05, Circular Tuning Loss = 0.9139294624328613\n",
      "1917) Lyapunov Risk = 0.7711005806922913, MSE = 0.022694729268550873, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01930825784802437, Lv_loss = 2.8744188966811635e-05, Circular Tuning Loss = 0.9138203859329224\n",
      "1918) Lyapunov Risk = 0.7709430456161499, MSE = 0.022873474285006523, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01930316537618637, Lv_loss = 1.6860101823112927e-05, Circular Tuning Loss = 0.9137116074562073\n",
      "1919) Lyapunov Risk = 0.7708550095558167, MSE = 0.02298075519502163, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01929793879389763, Lv_loss = 1.0304325769538991e-05, Circular Tuning Loss = 0.9136037230491638\n",
      "1920) Lyapunov Risk = 0.7708365321159363, MSE = 0.022747542709112167, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019292570650577545, Lv_loss = 1.4333491890283767e-05, Circular Tuning Loss = 0.913496196269989\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0625000000000004, -1.0605468750000004]\n",
      "x2 : [0.10656171960628835, 0.10825317547305484]\n",
      "==============================\n",
      "1921) Lyapunov Risk = 0.7708513140678406, MSE = 0.023454468697309494, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019221635535359383, Lv_loss = 3.781533905566903e-06, Circular Tuning Loss = 0.9118333458900452\n",
      "1922) Lyapunov Risk = 0.7708624601364136, MSE = 0.02258138172328472, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019216172397136688, Lv_loss = 4.802368493983522e-05, Circular Tuning Loss = 0.9117264747619629\n",
      "1923) Lyapunov Risk = 0.7708125114440918, MSE = 0.023748047649860382, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019210990518331528, Lv_loss = 5.7488241509418e-06, Circular Tuning Loss = 0.9116190671920776\n",
      "1924) Lyapunov Risk = 0.7705807089805603, MSE = 0.022689029574394226, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019205359742045403, Lv_loss = 4.443882789928466e-05, Circular Tuning Loss = 0.9115129113197327\n",
      "1925) Lyapunov Risk = 0.770342230796814, MSE = 0.02329227514564991, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019199902191758156, Lv_loss = 1.3985188161314e-05, Circular Tuning Loss = 0.9114066958427429\n",
      "1926) Lyapunov Risk = 0.7702087759971619, MSE = 0.02305332012474537, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019194206222891808, Lv_loss = 1.672222606430296e-05, Circular Tuning Loss = 0.9113010168075562\n",
      "1927) Lyapunov Risk = 0.7702013254165649, MSE = 0.02270360291004181, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019188418984413147, Lv_loss = 2.8316884709056467e-05, Circular Tuning Loss = 0.9111958146095276\n",
      "1928) Lyapunov Risk = 0.7702939510345459, MSE = 0.02354332059621811, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019182946532964706, Lv_loss = 3.845845185423968e-06, Circular Tuning Loss = 0.9110898375511169\n",
      "1929) Lyapunov Risk = 0.7703832387924194, MSE = 0.022314725443720818, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019177084788680077, Lv_loss = 6.607019167859107e-05, Circular Tuning Loss = 0.9109847545623779\n",
      "1930) Lyapunov Risk = 0.7707436084747314, MSE = 0.024233147501945496, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019172081723809242, Lv_loss = 1.7684961903796648e-06, Circular Tuning Loss = 0.9108781814575195\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0078125000000004, -1.0068359375000004]\n",
      "x2 : [0.05243513186976094, 0.054126587736527419]\n",
      "==============================\n",
      "1931) Lyapunov Risk = 0.7702726721763611, MSE = 0.022455688565969467, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019101468846201897, Lv_loss = 8.009454177226871e-05, Circular Tuning Loss = 0.9090588092803955\n",
      "1932) Lyapunov Risk = 0.7698137760162354, MSE = 0.023535162210464478, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01909640245139599, Lv_loss = 1.2277963833184913e-05, Circular Tuning Loss = 0.9089532494544983\n",
      "1933) Lyapunov Risk = 0.7695637345314026, MSE = 0.023261474445462227, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019090989604592323, Lv_loss = 1.1688065569614992e-05, Circular Tuning Loss = 0.9088487029075623\n",
      "1934) Lyapunov Risk = 0.7695926427841187, MSE = 0.02276202104985714, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019085459411144257, Lv_loss = 2.178281829401385e-05, Circular Tuning Loss = 0.9087443947792053\n",
      "1935) Lyapunov Risk = 0.7697158455848694, MSE = 0.023818615823984146, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019080236554145813, Lv_loss = 2.1472190780968958e-07, Circular Tuning Loss = 0.9086394906044006\n",
      "1936) Lyapunov Risk = 0.7697631120681763, MSE = 0.022423064336180687, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019074635580182076, Lv_loss = 5.746607348555699e-05, Circular Tuning Loss = 0.9085353016853333\n",
      "1937) Lyapunov Risk = 0.769986629486084, MSE = 0.02402995340526104, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019069751724600792, Lv_loss = 7.110001206456218e-06, Circular Tuning Loss = 0.9084296822547913\n",
      "1938) Lyapunov Risk = 0.7695567607879639, MSE = 0.02245713770389557, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019064437597990036, Lv_loss = 8.710078691365197e-05, Circular Tuning Loss = 0.9083254337310791\n",
      "1939) Lyapunov Risk = 0.7690877318382263, MSE = 0.023269319906830788, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01905936561524868, Lv_loss = 2.6475181584828533e-05, Circular Tuning Loss = 0.9082208871841431\n",
      "1940) Lyapunov Risk = 0.7688611149787903, MSE = 0.02308948151767254, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01905393972992897, Lv_loss = 1.775545024429448e-05, Circular Tuning Loss = 0.908117413520813\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0625000000000004, -1.0605468750000004]\n",
      "x2 : [0.05243513186976094, 0.054126587736527419]\n",
      "==============================\n",
      "1941) Lyapunov Risk = 0.769026517868042, MSE = 0.022763818502426147, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018983829766511917, Lv_loss = 2.2313473891699687e-05, Circular Tuning Loss = 0.9064974784851074\n",
      "1942) Lyapunov Risk = 0.7692826986312866, MSE = 0.023936832323670387, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018978694453835487, Lv_loss = 5.0352745972759294e-08, Circular Tuning Loss = 0.906393826007843\n",
      "1943) Lyapunov Risk = 0.7692989706993103, MSE = 0.022450832650065422, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018973203375935555, Lv_loss = 5.2873609092785046e-05, Circular Tuning Loss = 0.9062907099723816\n",
      "1944) Lyapunov Risk = 0.7695486545562744, MSE = 0.024387679994106293, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018968550488352776, Lv_loss = 2.196510422436404e-06, Circular Tuning Loss = 0.9061858654022217\n",
      "1945) Lyapunov Risk = 0.7690006494522095, MSE = 0.022453557699918747, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01896335370838642, Lv_loss = 9.375685476697981e-05, Circular Tuning Loss = 0.9060821533203125\n",
      "1946) Lyapunov Risk = 0.7684239149093628, MSE = 0.02325170859694481, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018958358094096184, Lv_loss = 2.8230602765688673e-05, Circular Tuning Loss = 0.9059787392616272\n",
      "1947) Lyapunov Risk = 0.7683424949645996, MSE = 0.02335667796432972, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018952982500195503, Lv_loss = 8.058457751758397e-06, Circular Tuning Loss = 0.9058761596679688\n",
      "1948) Lyapunov Risk = 0.7688145637512207, MSE = 0.022437162697315216, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018947282806038857, Lv_loss = 3.378683322807774e-05, Circular Tuning Loss = 0.9057744741439819\n",
      "1949) Lyapunov Risk = 0.7696599960327148, MSE = 0.02486644685268402, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018942587077617645, Lv_loss = 0.0, Circular Tuning Loss = 0.9056703448295593\n",
      "1950) Lyapunov Risk = 0.7692736387252808, MSE = 0.0222235806286335, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018937474116683006, Lv_loss = 9.577511082170531e-05, Circular Tuning Loss = 0.9055669903755188\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0625000000000004, -1.0605468750000004]\n",
      "x2 : [0.10656171960628835, 0.10825317547305484]\n",
      "==============================\n",
      "1951) Lyapunov Risk = 0.7688724398612976, MSE = 0.024213053286075592, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018869344145059586, Lv_loss = 1.117572082875995e-05, Circular Tuning Loss = 0.9039484858512878\n",
      "1952) Lyapunov Risk = 0.7680799961090088, MSE = 0.02296634577214718, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01886456273496151, Lv_loss = 7.167945295805112e-05, Circular Tuning Loss = 0.9038453698158264\n",
      "1953) Lyapunov Risk = 0.7681235671043396, MSE = 0.022553060203790665, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018859419971704483, Lv_loss = 6.47860870230943e-05, Circular Tuning Loss = 0.9037437438964844\n",
      "1954) Lyapunov Risk = 0.7688714861869812, MSE = 0.024667898193001747, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018854565918445587, Lv_loss = 0.0, Circular Tuning Loss = 0.9036415815353394\n",
      "1955) Lyapunov Risk = 0.768700122833252, MSE = 0.022404316812753677, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018849320709705353, Lv_loss = 5.027011866332032e-05, Circular Tuning Loss = 0.903539776802063\n",
      "1956) Lyapunov Risk = 0.7682605385780334, MSE = 0.023966751992702484, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018845006823539734, Lv_loss = 4.886820192950836e-07, Circular Tuning Loss = 0.903436005115509\n",
      "1957) Lyapunov Risk = 0.7676681280136108, MSE = 0.022876443341374397, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01884029433131218, Lv_loss = 6.114829011494294e-05, Circular Tuning Loss = 0.9033330082893372\n",
      "1958) Lyapunov Risk = 0.7676267027854919, MSE = 0.022468945011496544, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01883521117269993, Lv_loss = 8.931617048801854e-05, Circular Tuning Loss = 0.9032315015792847\n",
      "1959) Lyapunov Risk = 0.7680644989013672, MSE = 0.024178054183721542, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018830306828022003, Lv_loss = 3.81679546990199e-06, Circular Tuning Loss = 0.9031299352645874\n",
      "1960) Lyapunov Risk = 0.7678440809249878, MSE = 0.022487448528409004, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.0188249871134758, Lv_loss = 6.926352943992242e-05, Circular Tuning Loss = 0.9030295014381409\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0625000000000004, -1.0605468750000004]\n",
      "x2 : [0.10656171960628835, 0.10825317547305484]\n",
      "==============================\n",
      "1961) Lyapunov Risk = 0.7676716446876526, MSE = 0.023748306557536125, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01875697635114193, Lv_loss = 2.905306246248074e-06, Circular Tuning Loss = 0.9014265537261963\n",
      "1962) Lyapunov Risk = 0.7671462893486023, MSE = 0.02299082651734352, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018751956522464752, Lv_loss = 2.6003319362644106e-05, Circular Tuning Loss = 0.9013257026672363\n",
      "1963) Lyapunov Risk = 0.7669059038162231, MSE = 0.023009533062577248, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01874706707894802, Lv_loss = 2.3796352252247743e-05, Circular Tuning Loss = 0.9012244939804077\n",
      "1964) Lyapunov Risk = 0.7669719457626343, MSE = 0.02322005294263363, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.0187419131398201, Lv_loss = 1.402033831254812e-05, Circular Tuning Loss = 0.9011240601539612\n",
      "1965) Lyapunov Risk = 0.7670031785964966, MSE = 0.022874755784869194, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018736490979790688, Lv_loss = 4.657531462726183e-05, Circular Tuning Loss = 0.901024580001831\n",
      "1966) Lyapunov Risk = 0.7668703198432922, MSE = 0.023359233513474464, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018731174990534782, Lv_loss = 1.1089781764894724e-05, Circular Tuning Loss = 0.9009250402450562\n",
      "1967) Lyapunov Risk = 0.7666624784469604, MSE = 0.022611286491155624, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01872553862631321, Lv_loss = 5.3815212595509365e-05, Circular Tuning Loss = 0.9008264541625977\n",
      "1968) Lyapunov Risk = 0.766659677028656, MSE = 0.0233903918415308, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018720261752605438, Lv_loss = 1.1885777894349303e-05, Circular Tuning Loss = 0.9007271528244019\n",
      "1969) Lyapunov Risk = 0.7665374279022217, MSE = 0.02277143858373165, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.0187146607786417, Lv_loss = 4.245513991918415e-05, Circular Tuning Loss = 0.9006286859512329\n",
      "1970) Lyapunov Risk = 0.7663848400115967, MSE = 0.023096123710274696, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01870928518474102, Lv_loss = 2.527000651753042e-05, Circular Tuning Loss = 0.9005298614501953\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0625000000000004, -1.0605468750000004]\n",
      "x2 : [0.10656171960628835, 0.10825317547305484]\n",
      "==============================\n",
      "1971) Lyapunov Risk = 0.7662453055381775, MSE = 0.02301456779241562, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01864081434905529, Lv_loss = 2.0329909602878615e-05, Circular Tuning Loss = 0.8989452123641968\n",
      "1972) Lyapunov Risk = 0.7662070393562317, MSE = 0.022867223247885704, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018634874373674393, Lv_loss = 2.0745343135786243e-05, Circular Tuning Loss = 0.8988483548164368\n",
      "1973) Lyapunov Risk = 0.7663103938102722, MSE = 0.023567181080579758, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01862918771803379, Lv_loss = 5.213944859860931e-06, Circular Tuning Loss = 0.8987509608268738\n",
      "1974) Lyapunov Risk = 0.7661669254302979, MSE = 0.022696932777762413, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018623244017362595, Lv_loss = 4.303640525904484e-05, Circular Tuning Loss = 0.898654043674469\n",
      "1975) Lyapunov Risk = 0.7660019993782043, MSE = 0.02337374910712242, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018617680296301842, Lv_loss = 1.2769860404659994e-05, Circular Tuning Loss = 0.8985564708709717\n",
      "1976) Lyapunov Risk = 0.7658399939537048, MSE = 0.022907936945557594, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018611853942275047, Lv_loss = 4.231760249240324e-05, Circular Tuning Loss = 0.898459792137146\n",
      "1977) Lyapunov Risk = 0.765861988067627, MSE = 0.02274005115032196, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018605787307024002, Lv_loss = 4.2661140469135717e-05, Circular Tuning Loss = 0.8983641862869263\n",
      "1978) Lyapunov Risk = 0.7660194635391235, MSE = 0.02374526672065258, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01860002428293228, Lv_loss = 3.3493272439955035e-06, Circular Tuning Loss = 0.8982682228088379\n",
      "1979) Lyapunov Risk = 0.7657787203788757, MSE = 0.022551262751221657, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01859402284026146, Lv_loss = 5.18476044817362e-05, Circular Tuning Loss = 0.8981728553771973\n",
      "1980) Lyapunov Risk = 0.7656804323196411, MSE = 0.02353852614760399, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018588630482554436, Lv_loss = 8.30353019409813e-06, Circular Tuning Loss = 0.8980767130851746\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0625000000000004, -1.0605468750000004]\n",
      "x2 : [0.10656171960628835, 0.10825317547305484]\n",
      "==============================\n",
      "1981) Lyapunov Risk = 0.7655639052391052, MSE = 0.022924011573195457, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01852080598473549, Lv_loss = 4.7146611905191094e-05, Circular Tuning Loss = 0.8965063691139221\n",
      "1982) Lyapunov Risk = 0.7655166387557983, MSE = 0.022801868617534637, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018514888361096382, Lv_loss = 3.8323956687236205e-05, Circular Tuning Loss = 0.8964121341705322\n",
      "1983) Lyapunov Risk = 0.7656557559967041, MSE = 0.02388889156281948, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018509244546294212, Lv_loss = 7.337142733376822e-07, Circular Tuning Loss = 0.8963174819946289\n",
      "1984) Lyapunov Risk = 0.765434205532074, MSE = 0.022589266300201416, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018503356724977493, Lv_loss = 5.135315950610675e-05, Circular Tuning Loss = 0.8962234258651733\n",
      "1985) Lyapunov Risk = 0.76544189453125, MSE = 0.023661701008677483, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018498102203011513, Lv_loss = 5.666398919856874e-06, Circular Tuning Loss = 0.8961278796195984\n",
      "1986) Lyapunov Risk = 0.7652304768562317, MSE = 0.022917490452528, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.0184925589710474, Lv_loss = 4.579838059726171e-05, Circular Tuning Loss = 0.896032989025116\n",
      "1987) Lyapunov Risk = 0.765075147151947, MSE = 0.022751452401280403, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01848672889173031, Lv_loss = 3.838474731310271e-05, Circular Tuning Loss = 0.895939290523529\n",
      "1988) Lyapunov Risk = 0.7652555108070374, MSE = 0.023887092247605324, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.0184811782091856, Lv_loss = 7.111058266673354e-07, Circular Tuning Loss = 0.8958451151847839\n",
      "1989) Lyapunov Risk = 0.7651504278182983, MSE = 0.02252149023115635, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018475396558642387, Lv_loss = 6.39863865217194e-05, Circular Tuning Loss = 0.8957513570785522\n",
      "1990) Lyapunov Risk = 0.7653555274009705, MSE = 0.02395453490316868, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018470458686351776, Lv_loss = 3.0131088806228945e-06, Circular Tuning Loss = 0.8956558704376221\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0625000000000004, -1.0605468750000004]\n",
      "x2 : [0.05243513186976094, 0.054126587736527419]\n",
      "==============================\n",
      "1991) Lyapunov Risk = 0.7649959921836853, MSE = 0.022781595587730408, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018403619527816772, Lv_loss = 7.085200923029333e-05, Circular Tuning Loss = 0.8941085338592529\n",
      "1992) Lyapunov Risk = 0.7646101713180542, MSE = 0.022942423820495605, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01839822344481945, Lv_loss = 2.088256223942153e-05, Circular Tuning Loss = 0.8940145373344421\n",
      "1993) Lyapunov Risk = 0.764567494392395, MSE = 0.023509535938501358, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018392572179436684, Lv_loss = 2.9117552458046703e-06, Circular Tuning Loss = 0.8939215540885925\n",
      "1994) Lyapunov Risk = 0.7647020220756531, MSE = 0.022748015820980072, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018386652693152428, Lv_loss = 1.7262773326365277e-05, Circular Tuning Loss = 0.8938290476799011\n",
      "1995) Lyapunov Risk = 0.7649751305580139, MSE = 0.023997895419597626, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018381455913186073, Lv_loss = 3.4637284329619433e-07, Circular Tuning Loss = 0.8937346935272217\n",
      "1996) Lyapunov Risk = 0.7645990252494812, MSE = 0.0225765872746706, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018375977873802185, Lv_loss = 7.344232290051877e-05, Circular Tuning Loss = 0.8936408162117004\n",
      "1997) Lyapunov Risk = 0.7642887234687805, MSE = 0.02343381755053997, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018370917066931725, Lv_loss = 1.5661345969419926e-05, Circular Tuning Loss = 0.8935460448265076\n",
      "1998) Lyapunov Risk = 0.7640847563743591, MSE = 0.023072700947523117, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018365569412708282, Lv_loss = 2.1684711100533605e-05, Circular Tuning Loss = 0.8934522867202759\n",
      "1999) Lyapunov Risk = 0.7642390131950378, MSE = 0.02263401262462139, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01835993304848671, Lv_loss = 4.4807398808188736e-05, Circular Tuning Loss = 0.8933597207069397\n",
      "2000) Lyapunov Risk = 0.764677107334137, MSE = 0.024274786934256554, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018354730680584908, Lv_loss = 0.0, Circular Tuning Loss = 0.893265962600708\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0625000000000004, -1.0605468750000004]\n",
      "x2 : [0.10656171960628835, 0.10825317547305484]\n",
      "==============================\n",
      "2001) Lyapunov Risk = 0.764406681060791, MSE = 0.02246111072599888, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018288183957338333, Lv_loss = 3.9999802538659424e-05, Circular Tuning Loss = 0.8917229175567627\n",
      "2002) Lyapunov Risk = 0.7642917633056641, MSE = 0.024100149050354958, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01828363910317421, Lv_loss = 4.923269898426952e-07, Circular Tuning Loss = 0.8916274905204773\n",
      "2003) Lyapunov Risk = 0.7637516856193542, MSE = 0.02276431955397129, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018278658390045166, Lv_loss = 5.0968024879693985e-05, Circular Tuning Loss = 0.8915327191352844\n",
      "2004) Lyapunov Risk = 0.7637548446655273, MSE = 0.022607047110795975, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01827336475253105, Lv_loss = 6.116024451330304e-05, Circular Tuning Loss = 0.8914393186569214\n",
      "2005) Lyapunov Risk = 0.7642823457717896, MSE = 0.024314798414707184, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018268153071403503, Lv_loss = 8.698570042042775e-08, Circular Tuning Loss = 0.8913461565971375\n",
      "2006) Lyapunov Risk = 0.7639175057411194, MSE = 0.022431595250964165, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018262580037117004, Lv_loss = 3.5543216654332355e-05, Circular Tuning Loss = 0.8912535309791565\n",
      "2007) Lyapunov Risk = 0.7637635469436646, MSE = 0.023906160145998, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01825803332030773, Lv_loss = 4.686707200107776e-07, Circular Tuning Loss = 0.8911582827568054\n",
      "2008) Lyapunov Risk = 0.7632895708084106, MSE = 0.02279462106525898, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018253067508339882, Lv_loss = 2.282577770529315e-05, Circular Tuning Loss = 0.8910639882087708\n",
      "2009) Lyapunov Risk = 0.7633326053619385, MSE = 0.02255333587527275, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018247731029987335, Lv_loss = 4.380842437967658e-05, Circular Tuning Loss = 0.8909709453582764\n",
      "2010) Lyapunov Risk = 0.7639833688735962, MSE = 0.02440304309129715, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01824270188808441, Lv_loss = 8.999743528192994e-08, Circular Tuning Loss = 0.8908774256706238\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0312500000000004, -1.0302734375000004]\n",
      "x2 : [0.10656171960628835, 0.10825317547305484]\n",
      "==============================\n",
      "2011) Lyapunov Risk = 0.7634846568107605, MSE = 0.022418702021241188, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018176918849349022, Lv_loss = 5.923461867496371e-05, Circular Tuning Loss = 0.8892436027526855\n",
      "2012) Lyapunov Risk = 0.763313353061676, MSE = 0.023795703426003456, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018172431737184525, Lv_loss = 1.4436749324886478e-06, Circular Tuning Loss = 0.889149010181427\n",
      "2013) Lyapunov Risk = 0.7628958821296692, MSE = 0.023012878373265266, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01816752180457115, Lv_loss = 1.706636612652801e-05, Circular Tuning Loss = 0.8890553712844849\n",
      "2014) Lyapunov Risk = 0.7629265189170837, MSE = 0.02258220873773098, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01816224306821823, Lv_loss = 2.2425341740017757e-05, Circular Tuning Loss = 0.8889630436897278\n",
      "2015) Lyapunov Risk = 0.7634695768356323, MSE = 0.02435223013162613, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01815735176205635, Lv_loss = 0.0, Circular Tuning Loss = 0.8888698816299438\n",
      "2016) Lyapunov Risk = 0.7630796432495117, MSE = 0.022506993263959885, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018152058124542236, Lv_loss = 2.967013460875023e-05, Circular Tuning Loss = 0.8887775540351868\n",
      "2017) Lyapunov Risk = 0.7629364132881165, MSE = 0.02372238226234913, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018147580325603485, Lv_loss = 2.2796309622208355e-06, Circular Tuning Loss = 0.8886831998825073\n",
      "2018) Lyapunov Risk = 0.7625070810317993, MSE = 0.022962048649787903, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01814267970621586, Lv_loss = 1.9942037397413515e-05, Circular Tuning Loss = 0.8885899782180786\n",
      "2019) Lyapunov Risk = 0.7624428272247314, MSE = 0.022577162832021713, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018137415871024132, Lv_loss = 2.4777446014923044e-05, Circular Tuning Loss = 0.888498067855835\n",
      "2020) Lyapunov Risk = 0.7627307176589966, MSE = 0.02391555905342102, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01813223585486412, Lv_loss = 2.2959999057547975e-07, Circular Tuning Loss = 0.888405978679657\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0625000000000004, -1.0605468750000004]\n",
      "x2 : [0.10656171960628835, 0.10825317547305484]\n",
      "==============================\n",
      "2021) Lyapunov Risk = 0.7625620365142822, MSE = 0.022689225152134895, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018066879361867905, Lv_loss = 1.6905309166759253e-05, Circular Tuning Loss = 0.8868885040283203\n",
      "2022) Lyapunov Risk = 0.7623013257980347, MSE = 0.023267142474651337, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018061699345707893, Lv_loss = 3.1267888971342472e-06, Circular Tuning Loss = 0.8867966532707214\n",
      "2023) Lyapunov Risk = 0.7620294094085693, MSE = 0.02307506464421749, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01805618591606617, Lv_loss = 8.35287482914282e-06, Circular Tuning Loss = 0.8867054581642151\n",
      "2024) Lyapunov Risk = 0.7620030641555786, MSE = 0.02270578220486641, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01805036887526512, Lv_loss = 1.6953763406490907e-05, Circular Tuning Loss = 0.8866150379180908\n",
      "2025) Lyapunov Risk = 0.7621142864227295, MSE = 0.023434650152921677, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018044572323560715, Lv_loss = 1.555026983623975e-06, Circular Tuning Loss = 0.88652503490448\n",
      "2026) Lyapunov Risk = 0.7619554996490479, MSE = 0.022867510095238686, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018038533627986908, Lv_loss = 1.4062722584640142e-05, Circular Tuning Loss = 0.8864353895187378\n",
      "2027) Lyapunov Risk = 0.7617185711860657, MSE = 0.022894831374287605, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01803240180015564, Lv_loss = 9.883664461085573e-06, Circular Tuning Loss = 0.8863462805747986\n",
      "2028) Lyapunov Risk = 0.7616031169891357, MSE = 0.023100247606635094, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018026044592261314, Lv_loss = 3.734830443136161e-06, Circular Tuning Loss = 0.8862578868865967\n",
      "2029) Lyapunov Risk = 0.7616299390792847, MSE = 0.022867443040013313, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018019473180174828, Lv_loss = 9.08884612726979e-06, Circular Tuning Loss = 0.8861700296401978\n",
      "2030) Lyapunov Risk = 0.7616131901741028, MSE = 0.023224836215376854, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.018013032153248787, Lv_loss = 2.6208699637209065e-06, Circular Tuning Loss = 0.8860820531845093\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0625000000000004, -1.0605468750000004]\n",
      "x2 : [0.10656171960628835, 0.10825317547305484]\n",
      "==============================\n",
      "2031) Lyapunov Risk = 0.7614706754684448, MSE = 0.022790540009737015, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01794716902077198, Lv_loss = 1.4322475180961192e-05, Circular Tuning Loss = 0.8845803737640381\n",
      "2032) Lyapunov Risk = 0.7613138556480408, MSE = 0.02310483157634735, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.017940595746040344, Lv_loss = 7.122712759155547e-06, Circular Tuning Loss = 0.8844931125640869\n",
      "2033) Lyapunov Risk = 0.7612549662590027, MSE = 0.023035449907183647, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.017933854833245277, Lv_loss = 6.710048637614818e-06, Circular Tuning Loss = 0.8844068646430969\n",
      "2034) Lyapunov Risk = 0.7612586617469788, MSE = 0.022849176079034805, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01792694628238678, Lv_loss = 8.994432391773444e-06, Circular Tuning Loss = 0.8843215703964233\n",
      "2035) Lyapunov Risk = 0.7612723112106323, MSE = 0.023567156866192818, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.017920300364494324, Lv_loss = 2.6006750886153895e-07, Circular Tuning Loss = 0.8842357993125916\n",
      "2036) Lyapunov Risk = 0.7610718607902527, MSE = 0.022724099457263947, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.017913492396473885, Lv_loss = 1.2107708244002424e-05, Circular Tuning Loss = 0.8841506242752075\n",
      "2037) Lyapunov Risk = 0.7609431743621826, MSE = 0.02328185737133026, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.017907019704580307, Lv_loss = 3.061706820517429e-06, Circular Tuning Loss = 0.8840650320053101\n",
      "2038) Lyapunov Risk = 0.7608352303504944, MSE = 0.023041827604174614, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.017900345847010612, Lv_loss = 8.364248969883192e-06, Circular Tuning Loss = 0.8839805126190186\n",
      "2039) Lyapunov Risk = 0.7608212232589722, MSE = 0.022718392312526703, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.017893481999635696, Lv_loss = 1.374357543681981e-05, Circular Tuning Loss = 0.8838971853256226\n",
      "2040) Lyapunov Risk = 0.7608743906021118, MSE = 0.02362092211842537, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.017886878922581673, Lv_loss = 2.683070761122508e-07, Circular Tuning Loss = 0.8838135600090027\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0625000000000004, -1.0605468750000004]\n",
      "x2 : [0.10656171960628835, 0.10825317547305484]\n",
      "==============================\n",
      "2041) Lyapunov Risk = 0.7606950998306274, MSE = 0.022719431668519974, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01782148703932762, Lv_loss = 1.0129132533620577e-05, Circular Tuning Loss = 0.882327675819397\n",
      "2042) Lyapunov Risk = 0.7605494856834412, MSE = 0.023217055946588516, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.017815126106142998, Lv_loss = 8.503935191583878e-07, Circular Tuning Loss = 0.8822441697120667\n",
      "2043) Lyapunov Risk = 0.7604411840438843, MSE = 0.023072566837072372, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.017808547243475914, Lv_loss = 3.374125526534044e-06, Circular Tuning Loss = 0.882161557674408\n",
      "2044) Lyapunov Risk = 0.7604239583015442, MSE = 0.022775324061512947, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.017801757901906967, Lv_loss = 8.263434210675769e-06, Circular Tuning Loss = 0.8820798993110657\n",
      "2045) Lyapunov Risk = 0.7604934573173523, MSE = 0.023634279146790504, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.017795264720916748, Lv_loss = 1.6067929209384602e-07, Circular Tuning Loss = 0.8819977045059204\n",
      "2046) Lyapunov Risk = 0.7603130340576172, MSE = 0.022724071517586708, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.017788566648960114, Lv_loss = 1.0465345440024976e-05, Circular Tuning Loss = 0.8819162845611572\n",
      "2047) Lyapunov Risk = 0.7601831555366516, MSE = 0.02326153963804245, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01778218522667885, Lv_loss = 7.923470093373908e-07, Circular Tuning Loss = 0.8818345069885254\n",
      "2048) Lyapunov Risk = 0.7600548267364502, MSE = 0.023076489567756653, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01777559518814087, Lv_loss = 3.3456853998359293e-06, Circular Tuning Loss = 0.8817536234855652\n",
      "2049) Lyapunov Risk = 0.7600262761116028, MSE = 0.02275698632001877, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.017768792808055878, Lv_loss = 7.173934591264697e-06, Circular Tuning Loss = 0.8816736936569214\n",
      "2050) Lyapunov Risk = 0.7601264119148254, MSE = 0.023660089820623398, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01776231825351715, Lv_loss = 0.0, Circular Tuning Loss = 0.8815930485725403\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0625000000000004, -1.0605468750000004]\n",
      "x2 : [0.10656171960628835, 0.10825317547305484]\n",
      "==============================\n",
      "2051) Lyapunov Risk = 0.7600381970405579, MSE = 0.022661492228507996, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01769760064780712, Lv_loss = 9.97164625005098e-06, Circular Tuning Loss = 0.8801207542419434\n",
      "2052) Lyapunov Risk = 0.7599864602088928, MSE = 0.023564128205180168, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01769150421023369, Lv_loss = 3.094677936132939e-07, Circular Tuning Loss = 0.8800393342971802\n",
      "2053) Lyapunov Risk = 0.7597429752349854, MSE = 0.02292172610759735, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.017685167491436005, Lv_loss = 6.945637778699165e-06, Circular Tuning Loss = 0.8799588680267334\n",
      "2054) Lyapunov Risk = 0.7596651911735535, MSE = 0.022792644798755646, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01767859235405922, Lv_loss = 5.62715285923332e-06, Circular Tuning Loss = 0.8798792958259583\n",
      "2055) Lyapunov Risk = 0.7598482966423035, MSE = 0.023818038403987885, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.017672188580036163, Lv_loss = 0.0, Circular Tuning Loss = 0.8797996044158936\n",
      "2056) Lyapunov Risk = 0.7597569227218628, MSE = 0.022646980360150337, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.017665565013885498, Lv_loss = 6.430041139537934e-06, Circular Tuning Loss = 0.8797202110290527\n",
      "2057) Lyapunov Risk = 0.759830892086029, MSE = 0.02388366498053074, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.017659813165664673, Lv_loss = 0.0, Circular Tuning Loss = 0.8796386122703552\n",
      "2058) Lyapunov Risk = 0.7594635486602783, MSE = 0.022754710167646408, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.01765378937125206, Lv_loss = 1.2881673683295958e-05, Circular Tuning Loss = 0.8795577883720398\n",
      "2059) Lyapunov Risk = 0.7592697143554688, MSE = 0.02279862016439438, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.017647577449679375, Lv_loss = 8.296386113215704e-06, Circular Tuning Loss = 0.8794775605201721\n",
      "2060) Lyapunov Risk = 0.7593432664871216, MSE = 0.023630574345588684, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.017641160637140274, Lv_loss = 0.0, Circular Tuning Loss = 0.8793985843658447\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0937500000000004, -1.0917968750000004]\n",
      "x2 : [0.10656171960628835, 0.10825317547305484]\n",
      "==============================\n",
      "2061) Lyapunov Risk = 0.7594394683837891, MSE = 0.022688912227749825, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.017577070742845535, Lv_loss = 1.219437535837642e-06, Circular Tuning Loss = 0.8780469298362732\n",
      "2062) Lyapunov Risk = 0.7595195770263672, MSE = 0.02384345978498459, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.01757127046585083, Lv_loss = 0.0, Circular Tuning Loss = 0.8779658675193787\n",
      "2063) Lyapunov Risk = 0.7592023015022278, MSE = 0.022672023624181747, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.017565203830599785, Lv_loss = 8.845593583828304e-06, Circular Tuning Loss = 0.8778854608535767\n",
      "2064) Lyapunov Risk = 0.7589730024337769, MSE = 0.02323780581355095, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.017559396103024483, Lv_loss = 6.813206141487171e-07, Circular Tuning Loss = 0.8778045773506165\n",
      "2065) Lyapunov Risk = 0.758880615234375, MSE = 0.02325935661792755, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.01755334995687008, Lv_loss = 5.497057600223343e-07, Circular Tuning Loss = 0.8777244091033936\n",
      "2066) Lyapunov Risk = 0.7589036822319031, MSE = 0.022747980430722237, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.017547089606523514, Lv_loss = 3.5890295748686185e-06, Circular Tuning Loss = 0.8776451349258423\n",
      "2067) Lyapunov Risk = 0.758988082408905, MSE = 0.023742901161313057, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.017541151493787766, Lv_loss = 0.0, Circular Tuning Loss = 0.8775648474693298\n",
      "2068) Lyapunov Risk = 0.7587646245956421, MSE = 0.02273985557258129, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.017534950748085976, Lv_loss = 7.228647405099764e-07, Circular Tuning Loss = 0.8774849772453308\n",
      "2069) Lyapunov Risk = 0.7586607336997986, MSE = 0.023509131744503975, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.017529364675283432, Lv_loss = 0.0, Circular Tuning Loss = 0.8774033188819885\n",
      "2070) Lyapunov Risk = 0.7584678530693054, MSE = 0.022802822291851044, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.01752348430454731, Lv_loss = 4.418526259541977e-06, Circular Tuning Loss = 0.8773224353790283\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.1250000000000004, -1.1230468750000004]\n",
      "x2 : [0.10656171960628835, 0.10825317547305484]\n",
      "==============================\n",
      "2071) Lyapunov Risk = 0.7585474848747253, MSE = 0.02278740704059601, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.017460498958826065, Lv_loss = 3.4234933536936296e-06, Circular Tuning Loss = 0.8760907053947449\n",
      "2072) Lyapunov Risk = 0.7586581707000732, MSE = 0.023623261600732803, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.017454400658607483, Lv_loss = 0.0, Circular Tuning Loss = 0.8760111331939697\n",
      "2073) Lyapunov Risk = 0.7585935592651367, MSE = 0.02261427231132984, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.017448054626584053, Lv_loss = 7.997005582183192e-07, Circular Tuning Loss = 0.8759320974349976\n",
      "2074) Lyapunov Risk = 0.7586265802383423, MSE = 0.023860901594161987, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.017442500218749046, Lv_loss = 0.0, Circular Tuning Loss = 0.8758506178855896\n",
      "2075) Lyapunov Risk = 0.7582894563674927, MSE = 0.02273821271955967, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.017436670139431953, Lv_loss = 2.782329147521523e-06, Circular Tuning Loss = 0.8757696747779846\n",
      "2076) Lyapunov Risk = 0.7581230401992798, MSE = 0.023009708151221275, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.017430884763598442, Lv_loss = 5.912575602451398e-07, Circular Tuning Loss = 0.8756887316703796\n",
      "2077) Lyapunov Risk = 0.7581233978271484, MSE = 0.023472988978028297, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.017424840480089188, Lv_loss = 0.0, Circular Tuning Loss = 0.8756087422370911\n",
      "2078) Lyapunov Risk = 0.7580822706222534, MSE = 0.02271539345383644, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.01741854101419449, Lv_loss = 5.486322152137291e-07, Circular Tuning Loss = 0.8755295276641846\n",
      "2079) Lyapunov Risk = 0.7581660151481628, MSE = 0.023747939616441727, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.017412859946489334, Lv_loss = 0.0, Circular Tuning Loss = 0.8754484057426453\n",
      "2080) Lyapunov Risk = 0.7579344511032104, MSE = 0.022663885727524757, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.017406901344656944, Lv_loss = 1.0733303952292772e-06, Circular Tuning Loss = 0.8753679394721985\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.2519531250000004, -1.2500000000000004]\n",
      "x2 : [0.21650635094610968, 0.21988926267964265]\n",
      "==============================\n",
      "2081) Lyapunov Risk = 0.7581408023834229, MSE = 0.02329280413687229, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.017345016822218895, Lv_loss = 9.495594355257708e-08, Circular Tuning Loss = 0.8746641278266907\n",
      "2082) Lyapunov Risk = 0.7579818964004517, MSE = 0.023014025762677193, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.017339155077934265, Lv_loss = 3.939692589938204e-07, Circular Tuning Loss = 0.8745838403701782\n",
      "2083) Lyapunov Risk = 0.7579602003097534, MSE = 0.022757116705179214, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.017333053052425385, Lv_loss = 4.3611527189568733e-07, Circular Tuning Loss = 0.8745046257972717\n",
      "2084) Lyapunov Risk = 0.7581352591514587, MSE = 0.02378661185503006, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.017327267676591873, Lv_loss = 0.0, Circular Tuning Loss = 0.8744243383407593\n",
      "2085) Lyapunov Risk = 0.7580314874649048, MSE = 0.022627269849181175, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.017321227118372917, Lv_loss = 5.090647618999355e-07, Circular Tuning Loss = 0.8743444681167603\n",
      "2086) Lyapunov Risk = 0.7580471038818359, MSE = 0.0238371342420578, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.01731596328318119, Lv_loss = 0.0, Circular Tuning Loss = 0.874262273311615\n",
      "2087) Lyapunov Risk = 0.7577551603317261, MSE = 0.022706205025315285, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.017310233786702156, Lv_loss = 1.8635358856045059e-06, Circular Tuning Loss = 0.8741816282272339\n",
      "2088) Lyapunov Risk = 0.7575260996818542, MSE = 0.023102423176169395, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.017304537817835808, Lv_loss = 1.6070407582446933e-07, Circular Tuning Loss = 0.8741011023521423\n",
      "2089) Lyapunov Risk = 0.7574973106384277, MSE = 0.023396365344524384, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.017298584803938866, Lv_loss = 0.0, Circular Tuning Loss = 0.8740217089653015\n",
      "2090) Lyapunov Risk = 0.7576109170913696, MSE = 0.02263825573027134, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.017292363569140434, Lv_loss = 1.9323688604799827e-07, Circular Tuning Loss = 0.8739428520202637\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.6094342467310798, 1.6116242091296598]\n",
      "x2 : [-1.103497705191399, -1.1005025694112776]\n",
      "==============================\n",
      "2091) Lyapunov Risk = 0.7659450769424438, MSE = 0.024074744433164597, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.01813018135726452, Lv_loss = 0.0, Circular Tuning Loss = 0.8870903849601746\n",
      "2092) Lyapunov Risk = 0.7657475471496582, MSE = 0.022392792627215385, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.01812388189136982, Lv_loss = 4.738314601127058e-06, Circular Tuning Loss = 0.8870089650154114\n",
      "2093) Lyapunov Risk = 0.7655573487281799, MSE = 0.023744840174913406, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.01811813749372959, Lv_loss = 0.0, Circular Tuning Loss = 0.8869253396987915\n",
      "2094) Lyapunov Risk = 0.7651516795158386, MSE = 0.02287030592560768, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.01811167038977146, Lv_loss = 5.466873176374065e-07, Circular Tuning Loss = 0.8868427872657776\n",
      "2095) Lyapunov Risk = 0.7651516199111938, MSE = 0.02267000451683998, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.01810474507510662, Lv_loss = 3.9211045077536255e-07, Circular Tuning Loss = 0.886760950088501\n",
      "2096) Lyapunov Risk = 0.7657085061073303, MSE = 0.02432386390864849, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.018098045140504837, Lv_loss = 0.0, Circular Tuning Loss = 0.8866779804229736\n",
      "2097) Lyapunov Risk = 0.7655701041221619, MSE = 0.022428128868341446, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.018090782687067986, Lv_loss = 4.70688576115208e-07, Circular Tuning Loss = 0.8865952491760254\n",
      "2098) Lyapunov Risk = 0.7651350498199463, MSE = 0.023742787539958954, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.018084198236465454, Lv_loss = 0.0, Circular Tuning Loss = 0.8865103721618652\n",
      "2099) Lyapunov Risk = 0.7647446990013123, MSE = 0.02290252596139908, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.018077006563544273, Lv_loss = 2.0441244430458028e-07, Circular Tuning Loss = 0.8864268064498901\n",
      "2100) Lyapunov Risk = 0.7648084759712219, MSE = 0.022498413920402527, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.018069423735141754, Lv_loss = 8.27053213470208e-07, Circular Tuning Loss = 0.8863440155982971\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.6094342467310798, 1.6116242091296598]\n",
      "x2 : [-1.0885220262907915, -1.0855268905106699]\n",
      "==============================\n",
      "2101) Lyapunov Risk = 0.7733359932899475, MSE = 0.024255236610770226, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.018893931061029434, Lv_loss = 0.0, Circular Tuning Loss = 0.8992598056793213\n",
      "2102) Lyapunov Risk = 0.7731002569198608, MSE = 0.02235392853617668, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.018885666504502296, Lv_loss = 1.8787965245792293e-06, Circular Tuning Loss = 0.8991757035255432\n",
      "2103) Lyapunov Risk = 0.7726873755455017, MSE = 0.023657897487282753, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.018877889961004257, Lv_loss = 0.0, Circular Tuning Loss = 0.899089515209198\n",
      "2104) Lyapunov Risk = 0.7723008990287781, MSE = 0.023135734722018242, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.01886948198080063, Lv_loss = 0.0, Circular Tuning Loss = 0.8990033268928528\n",
      "2105) Lyapunov Risk = 0.7724897861480713, MSE = 0.022490927949547768, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.018860528245568275, Lv_loss = 3.5328653780197783e-07, Circular Tuning Loss = 0.8989177942276001\n",
      "2106) Lyapunov Risk = 0.7733013033866882, MSE = 0.024647092446684837, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.018852196633815765, Lv_loss = 0.0, Circular Tuning Loss = 0.8988297581672668\n",
      "2107) Lyapunov Risk = 0.7729195356369019, MSE = 0.022398393601179123, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.01884310133755207, Lv_loss = 4.030956461065216e-06, Circular Tuning Loss = 0.8987427949905396\n",
      "2108) Lyapunov Risk = 0.772360622882843, MSE = 0.023596836254000664, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.018834590911865234, Lv_loss = 0.0, Circular Tuning Loss = 0.8986539840698242\n",
      "2109) Lyapunov Risk = 0.7719298005104065, MSE = 0.023221556097269058, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.018825417384505272, Lv_loss = 0.0, Circular Tuning Loss = 0.8985662460327148\n",
      "2110) Lyapunov Risk = 0.7721089124679565, MSE = 0.02245868369936943, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.018815768882632256, Lv_loss = 2.4070581616797426e-07, Circular Tuning Loss = 0.8984793424606323\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.5989458859641057, 1.6020817282989961]\n",
      "x2 : [-0.9742785792574935, -0.97258712339072706]\n",
      "==============================\n",
      "2111) Lyapunov Risk = 0.78006511926651, MSE = 0.024469953030347824, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.019598089158535004, Lv_loss = 0.0, Circular Tuning Loss = 0.9101756811141968\n",
      "2112) Lyapunov Risk = 0.7797509431838989, MSE = 0.022460725158452988, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.019587961956858635, Lv_loss = 5.686131885340728e-07, Circular Tuning Loss = 0.9100857377052307\n",
      "2113) Lyapunov Risk = 0.7791479825973511, MSE = 0.023488830775022507, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.019578298553824425, Lv_loss = 0.0, Circular Tuning Loss = 0.9099937081336975\n",
      "2114) Lyapunov Risk = 0.7787525653839111, MSE = 0.02318749763071537, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.019567962735891342, Lv_loss = 0.0, Circular Tuning Loss = 0.9099017977714539\n",
      "2115) Lyapunov Risk = 0.7789477705955505, MSE = 0.022464539855718613, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.019557014107704163, Lv_loss = 4.4952258804187295e-07, Circular Tuning Loss = 0.9098105430603027\n",
      "2116) Lyapunov Risk = 0.7796980738639832, MSE = 0.024470007047057152, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.019546642899513245, Lv_loss = 0.0, Circular Tuning Loss = 0.9097174406051636\n",
      "2117) Lyapunov Risk = 0.7792500853538513, MSE = 0.02250596694648266, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.019535481929779053, Lv_loss = 4.3170996377739357e-07, Circular Tuning Loss = 0.9096249341964722\n",
      "2118) Lyapunov Risk = 0.7785881161689758, MSE = 0.02349812537431717, V_0_loss = tensor([[0.0044]], grad_fn=<PowBackward0>), V_pos_loss = 0.019524892792105675, Lv_loss = 0.0, Circular Tuning Loss = 0.9095305800437927\n",
      "2119) Lyapunov Risk = 0.7782696485519409, MSE = 0.0232248418033123, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.01951374113559723, Lv_loss = 0.0, Circular Tuning Loss = 0.9094371199607849\n",
      "2120) Lyapunov Risk = 0.7786377668380737, MSE = 0.02247367613017559, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.019502082839608192, Lv_loss = 2.3680786398472264e-07, Circular Tuning Loss = 0.9093443155288696\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.6796082446851437, 1.6896082446851435]\n",
      "x2 : [-1.0401709904610867, -1.030170990461087]\n",
      "==============================\n",
      "2121) Lyapunov Risk = 0.787409245967865, MSE = 0.02443813532590866, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02029120922088623, Lv_loss = 0.00011915067443624139, Circular Tuning Loss = 0.9224620461463928\n",
      "2122) Lyapunov Risk = 0.7867923378944397, MSE = 0.022422339767217636, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020278960466384888, Lv_loss = 0.00011548909969860688, Circular Tuning Loss = 0.9223668575286865\n",
      "2123) Lyapunov Risk = 0.7861666083335876, MSE = 0.023344026878476143, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020267190411686897, Lv_loss = 0.00011256871948717162, Circular Tuning Loss = 0.9222698211669922\n",
      "2124) Lyapunov Risk = 0.7859845161437988, MSE = 0.02320116199553013, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02025468274950981, Lv_loss = 0.00010983541869791225, Circular Tuning Loss = 0.9221734404563904\n",
      "2125) Lyapunov Risk = 0.7863243818283081, MSE = 0.022514432668685913, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02024155668914318, Lv_loss = 0.0001070681755663827, Circular Tuning Loss = 0.9220775961875916\n",
      "2126) Lyapunov Risk = 0.7867392897605896, MSE = 0.02434316650032997, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02022901549935341, Lv_loss = 0.0001050925930030644, Circular Tuning Loss = 0.921980082988739\n",
      "2127) Lyapunov Risk = 0.786096453666687, MSE = 0.022497493773698807, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020215723663568497, Lv_loss = 0.00010064127127407119, Circular Tuning Loss = 0.9218833446502686\n",
      "2128) Lyapunov Risk = 0.7856540083885193, MSE = 0.02334074303507805, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02020302414894104, Lv_loss = 9.69575994531624e-05, Circular Tuning Loss = 0.9217852354049683\n",
      "2129) Lyapunov Risk = 0.7855352759361267, MSE = 0.023181555792689323, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020189661532640457, Lv_loss = 9.375708759762347e-05, Circular Tuning Loss = 0.9216883182525635\n",
      "2130) Lyapunov Risk = 0.7857222557067871, MSE = 0.0225638709962368, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020175738260149956, Lv_loss = 9.061433229362592e-05, Circular Tuning Loss = 0.9215927720069885\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.8063542261093515, 1.8089372266455135]\n",
      "x2 : [-0.75777222831138391, -0.75608077244461747]\n",
      "==============================\n",
      "2131) Lyapunov Risk = 0.7937242388725281, MSE = 0.02428327314555645, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02086534909904003, Lv_loss = 9.63646307354793e-05, Circular Tuning Loss = 0.9339796900749207\n",
      "2132) Lyapunov Risk = 0.7932143211364746, MSE = 0.022413186728954315, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02085074409842491, Lv_loss = 8.675503340782598e-05, Circular Tuning Loss = 0.9338812232017517\n",
      "2133) Lyapunov Risk = 0.7927316427230835, MSE = 0.0233476422727108, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02083658054471016, Lv_loss = 7.926832768134773e-05, Circular Tuning Loss = 0.93378084897995\n",
      "2134) Lyapunov Risk = 0.7925891280174255, MSE = 0.02320152334868908, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020821621641516685, Lv_loss = 7.547378481831402e-05, Circular Tuning Loss = 0.9336810111999512\n",
      "2135) Lyapunov Risk = 0.7928299307823181, MSE = 0.022474192082881927, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020805971696972847, Lv_loss = 7.174621714511886e-05, Circular Tuning Loss = 0.9335816502571106\n",
      "2136) Lyapunov Risk = 0.7931442260742188, MSE = 0.0242427010089159, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020790936425328255, Lv_loss = 6.844267772976309e-05, Circular Tuning Loss = 0.9334808588027954\n",
      "2137) Lyapunov Risk = 0.79258131980896, MSE = 0.02249646931886673, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02077511139214039, Lv_loss = 6.367037713062018e-05, Circular Tuning Loss = 0.9333807826042175\n",
      "2138) Lyapunov Risk = 0.792198121547699, MSE = 0.02329203672707081, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020759886130690575, Lv_loss = 5.9135792980669066e-05, Circular Tuning Loss = 0.9332793354988098\n",
      "2139) Lyapunov Risk = 0.7920636534690857, MSE = 0.023214679211378098, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020744027569890022, Lv_loss = 5.4871248721610755e-05, Circular Tuning Loss = 0.9331790208816528\n",
      "2140) Lyapunov Risk = 0.7922200560569763, MSE = 0.022559283301234245, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.020727572962641716, Lv_loss = 5.0959057261934504e-05, Circular Tuning Loss = 0.9330796003341675\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.6636138310941644, 1.6650397154034333]\n",
      "x2 : [-1.1094879767516423, -1.1079904088615815]\n",
      "==============================\n",
      "2141) Lyapunov Risk = 0.8006551265716553, MSE = 0.02418316900730133, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02151561714708805, Lv_loss = 4.6895092964405194e-05, Circular Tuning Loss = 0.946430504322052\n",
      "2142) Lyapunov Risk = 0.8002387285232544, MSE = 0.022488662973046303, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.021498480811715126, Lv_loss = 4.154518319410272e-05, Circular Tuning Loss = 0.9463286399841309\n",
      "2143) Lyapunov Risk = 0.7998160719871521, MSE = 0.023357754573225975, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02148180827498436, Lv_loss = 3.665685289888643e-05, Circular Tuning Loss = 0.9462252855300903\n",
      "2144) Lyapunov Risk = 0.7996248006820679, MSE = 0.023169944062829018, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02146437205374241, Lv_loss = 3.170045238221064e-05, Circular Tuning Loss = 0.9461226463317871\n",
      "2145) Lyapunov Risk = 0.799829363822937, MSE = 0.022519107908010483, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02144620567560196, Lv_loss = 2.7556863642530516e-05, Circular Tuning Loss = 0.9460207223892212\n",
      "2146) Lyapunov Risk = 0.8001337051391602, MSE = 0.024205517023801804, V_0_loss = tensor([[0.0045]], grad_fn=<PowBackward0>), V_pos_loss = 0.02142861671745777, Lv_loss = 2.3318165403907187e-05, Circular Tuning Loss = 0.9459176063537598\n",
      "2147) Lyapunov Risk = 0.7997110486030579, MSE = 0.022511722519993782, V_0_loss = tensor([[0.0046]], grad_fn=<PowBackward0>), V_pos_loss = 0.021410197019577026, Lv_loss = 1.7607788322493434e-05, Circular Tuning Loss = 0.9458153247833252\n",
      "2148) Lyapunov Risk = 0.7992560863494873, MSE = 0.023331554606556892, V_0_loss = tensor([[0.0046]], grad_fn=<PowBackward0>), V_pos_loss = 0.021392371505498886, Lv_loss = 1.2538941518869251e-05, Circular Tuning Loss = 0.9457119107246399\n",
      "2149) Lyapunov Risk = 0.799065113067627, MSE = 0.023199675604701042, V_0_loss = tensor([[0.0046]], grad_fn=<PowBackward0>), V_pos_loss = 0.021373886615037918, Lv_loss = 7.050245130812982e-06, Circular Tuning Loss = 0.9456096291542053\n",
      "2150) Lyapunov Risk = 0.7992255687713623, MSE = 0.02259526401758194, V_0_loss = tensor([[0.0046]], grad_fn=<PowBackward0>), V_pos_loss = 0.021354835480451584, Lv_loss = 3.1722395306132967e-06, Circular Tuning Loss = 0.9455083608627319\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.6794866985573871, 1.6820474716212654]\n",
      "x2 : [-1.0300966228607875, -1.0284051669940211]\n",
      "==============================\n",
      "2151) Lyapunov Risk = 0.8072847127914429, MSE = 0.02415691316127777, V_0_loss = tensor([[0.0046]], grad_fn=<PowBackward0>), V_pos_loss = 0.02210909128189087, Lv_loss = 9.31509816837206e-07, Circular Tuning Loss = 0.958240807056427\n",
      "2152) Lyapunov Risk = 0.8069609999656677, MSE = 0.02253160998225212, V_0_loss = tensor([[0.0046]], grad_fn=<PowBackward0>), V_pos_loss = 0.022089308127760887, Lv_loss = 0.0, Circular Tuning Loss = 0.9581368565559387\n",
      "2153) Lyapunov Risk = 0.8064756989479065, MSE = 0.023400379344820976, V_0_loss = tensor([[0.0046]], grad_fn=<PowBackward0>), V_pos_loss = 0.022070027887821198, Lv_loss = 0.0, Circular Tuning Loss = 0.9580314755439758\n",
      "2154) Lyapunov Risk = 0.80622798204422, MSE = 0.023168308660387993, V_0_loss = tensor([[0.0046]], grad_fn=<PowBackward0>), V_pos_loss = 0.022049961611628532, Lv_loss = 0.0, Circular Tuning Loss = 0.957926869392395\n",
      "2155) Lyapunov Risk = 0.8063589930534363, MSE = 0.022647522389888763, V_0_loss = tensor([[0.0046]], grad_fn=<PowBackward0>), V_pos_loss = 0.022029316052794456, Lv_loss = 0.0, Circular Tuning Loss = 0.9578229784965515\n",
      "2156) Lyapunov Risk = 0.8066332340240479, MSE = 0.02412908896803856, V_0_loss = tensor([[0.0046]], grad_fn=<PowBackward0>), V_pos_loss = 0.02200927771627903, Lv_loss = 0.0, Circular Tuning Loss = 0.9577180743217468\n",
      "2157) Lyapunov Risk = 0.8063902854919434, MSE = 0.022545328363776207, V_0_loss = tensor([[0.0046]], grad_fn=<PowBackward0>), V_pos_loss = 0.02198834717273712, Lv_loss = 0.0, Circular Tuning Loss = 0.9576142430305481\n",
      "2158) Lyapunov Risk = 0.8058651685714722, MSE = 0.02345564402639866, V_0_loss = tensor([[0.0046]], grad_fn=<PowBackward0>), V_pos_loss = 0.02196798473596573, Lv_loss = 0.0, Circular Tuning Loss = 0.9575100541114807\n",
      "2159) Lyapunov Risk = 0.8056067228317261, MSE = 0.023165039718151093, V_0_loss = tensor([[0.0046]], grad_fn=<PowBackward0>), V_pos_loss = 0.021946953609585762, Lv_loss = 0.0, Circular Tuning Loss = 0.9574072957038879\n",
      "2160) Lyapunov Risk = 0.8056416511535645, MSE = 0.022783035412430763, V_0_loss = tensor([[0.0046]], grad_fn=<PowBackward0>), V_pos_loss = 0.02192569151520729, Lv_loss = 0.0, Circular Tuning Loss = 0.9573053121566772\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.7140571349197433, 1.7153375214516824]\n",
      "x2 : [-1.0300966228607875, -1.0284051669940211]\n",
      "==============================\n",
      "2161) Lyapunov Risk = 0.8138314485549927, MSE = 0.024017581716179848, V_0_loss = tensor([[0.0046]], grad_fn=<PowBackward0>), V_pos_loss = 0.022667311131954193, Lv_loss = 0.0, Circular Tuning Loss = 0.9703466892242432\n",
      "2162) Lyapunov Risk = 0.8137366771697998, MSE = 0.022519351914525032, V_0_loss = tensor([[0.0046]], grad_fn=<PowBackward0>), V_pos_loss = 0.022645099088549614, Lv_loss = 0.0, Circular Tuning Loss = 0.9702430963516235\n",
      "2163) Lyapunov Risk = 0.8132051825523376, MSE = 0.02359621971845627, V_0_loss = tensor([[0.0046]], grad_fn=<PowBackward0>), V_pos_loss = 0.02262324094772339, Lv_loss = 0.0, Circular Tuning Loss = 0.9701388478279114\n",
      "2164) Lyapunov Risk = 0.8128839135169983, MSE = 0.02311917021870613, V_0_loss = tensor([[0.0046]], grad_fn=<PowBackward0>), V_pos_loss = 0.022600466385483742, Lv_loss = 0.0, Circular Tuning Loss = 0.9700352549552917\n",
      "2165) Lyapunov Risk = 0.8128273487091064, MSE = 0.022936774417757988, V_0_loss = tensor([[0.0046]], grad_fn=<PowBackward0>), V_pos_loss = 0.022577669471502304, Lv_loss = 0.0, Circular Tuning Loss = 0.9699317216873169\n",
      "2166) Lyapunov Risk = 0.813066303730011, MSE = 0.023940609768033028, V_0_loss = tensor([[0.0047]], grad_fn=<PowBackward0>), V_pos_loss = 0.022555425763130188, Lv_loss = 0.0, Circular Tuning Loss = 0.9698275923728943\n",
      "2167) Lyapunov Risk = 0.8131167888641357, MSE = 0.022504635155200958, V_0_loss = tensor([[0.0047]], grad_fn=<PowBackward0>), V_pos_loss = 0.022532183676958084, Lv_loss = 0.0, Circular Tuning Loss = 0.9697247743606567\n",
      "2168) Lyapunov Risk = 0.8126139640808105, MSE = 0.023739295080304146, V_0_loss = tensor([[0.0047]], grad_fn=<PowBackward0>), V_pos_loss = 0.022509418427944183, Lv_loss = 0.0, Circular Tuning Loss = 0.9696216583251953\n",
      "2169) Lyapunov Risk = 0.8122652769088745, MSE = 0.023023122921586037, V_0_loss = tensor([[0.0047]], grad_fn=<PowBackward0>), V_pos_loss = 0.022485680878162384, Lv_loss = 0.0, Circular Tuning Loss = 0.969519853591919\n",
      "2170) Lyapunov Risk = 0.8120936155319214, MSE = 0.023313185200095177, V_0_loss = tensor([[0.0047]], grad_fn=<PowBackward0>), V_pos_loss = 0.022462602704763412, Lv_loss = 0.0, Circular Tuning Loss = 0.9694175720214844\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.012812500000000001, -0.0028125000000000016]\n",
      "x2 : [-0.49718750000000012, -0.48718750000000011]\n",
      "==============================\n",
      "2171) Lyapunov Risk = 0.8110018372535706, MSE = 0.02315836399793625, V_0_loss = tensor([[0.0047]], grad_fn=<PowBackward0>), V_pos_loss = 0.022434459999203682, Lv_loss = 0.0, Circular Tuning Loss = 0.9670999646186829\n",
      "2172) Lyapunov Risk = 0.810866117477417, MSE = 0.02315770648419857, V_0_loss = tensor([[0.0047]], grad_fn=<PowBackward0>), V_pos_loss = 0.022410819306969643, Lv_loss = 0.0, Circular Tuning Loss = 0.966998815536499\n",
      "2173) Lyapunov Risk = 0.8107383847236633, MSE = 0.02330170013010502, V_0_loss = tensor([[0.0047]], grad_fn=<PowBackward0>), V_pos_loss = 0.022387105971574783, Lv_loss = 0.0, Circular Tuning Loss = 0.9668979644775391\n",
      "2174) Lyapunov Risk = 0.8106679916381836, MSE = 0.022914905101060867, V_0_loss = tensor([[0.0047]], grad_fn=<PowBackward0>), V_pos_loss = 0.02236294373869896, Lv_loss = 0.0, Circular Tuning Loss = 0.9667981266975403\n",
      "2175) Lyapunov Risk = 0.8106928467750549, MSE = 0.023750323802232742, V_0_loss = tensor([[0.0047]], grad_fn=<PowBackward0>), V_pos_loss = 0.022339360788464546, Lv_loss = 0.0, Circular Tuning Loss = 0.9666979908943176\n",
      "2176) Lyapunov Risk = 0.8107821941375732, MSE = 0.022565560415387154, V_0_loss = tensor([[0.0047]], grad_fn=<PowBackward0>), V_pos_loss = 0.022314755246043205, Lv_loss = 0.0, Circular Tuning Loss = 0.9665996432304382\n",
      "2177) Lyapunov Risk = 0.8103709816932678, MSE = 0.023717833682894707, V_0_loss = tensor([[0.0047]], grad_fn=<PowBackward0>), V_pos_loss = 0.022290749475359917, Lv_loss = 0.0, Circular Tuning Loss = 0.966500997543335\n",
      "2178) Lyapunov Risk = 0.8101405501365662, MSE = 0.023052120581269264, V_0_loss = tensor([[0.0047]], grad_fn=<PowBackward0>), V_pos_loss = 0.0222660880535841, Lv_loss = 0.0, Circular Tuning Loss = 0.9664037227630615\n",
      "2179) Lyapunov Risk = 0.8099479675292969, MSE = 0.023252762854099274, V_0_loss = tensor([[0.0047]], grad_fn=<PowBackward0>), V_pos_loss = 0.02224208414554596, Lv_loss = 0.0, Circular Tuning Loss = 0.9663059711456299\n",
      "2180) Lyapunov Risk = 0.8098119497299194, MSE = 0.0233025923371315, V_0_loss = tensor([[0.0047]], grad_fn=<PowBackward0>), V_pos_loss = 0.02221812680363655, Lv_loss = 0.0, Circular Tuning Loss = 0.9662089943885803\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.2207031250000004, -1.2187500000000004]\n",
      "x2 : [0.18944305707784598, 0.19282596881137892]\n",
      "==============================\n",
      "2181) Lyapunov Risk = 0.8098565340042114, MSE = 0.02293306589126587, V_0_loss = tensor([[0.0047]], grad_fn=<PowBackward0>), V_pos_loss = 0.022124260663986206, Lv_loss = 0.0, Circular Tuning Loss = 0.9650848507881165\n",
      "2182) Lyapunov Risk = 0.8099479079246521, MSE = 0.023855432868003845, V_0_loss = tensor([[0.0047]], grad_fn=<PowBackward0>), V_pos_loss = 0.022100655362010002, Lv_loss = 0.0, Circular Tuning Loss = 0.9649892449378967\n",
      "2183) Lyapunov Risk = 0.8100341558456421, MSE = 0.022655677050352097, V_0_loss = tensor([[0.0047]], grad_fn=<PowBackward0>), V_pos_loss = 0.022076133638620377, Lv_loss = 0.0, Circular Tuning Loss = 0.9648952484130859\n",
      "2184) Lyapunov Risk = 0.809592068195343, MSE = 0.023795410990715027, V_0_loss = tensor([[0.0047]], grad_fn=<PowBackward0>), V_pos_loss = 0.022052206099033356, Lv_loss = 0.0, Circular Tuning Loss = 0.9648010730743408\n",
      "2185) Lyapunov Risk = 0.8093107342720032, MSE = 0.02325250580906868, V_0_loss = tensor([[0.0047]], grad_fn=<PowBackward0>), V_pos_loss = 0.022028004750609398, Lv_loss = 0.0, Circular Tuning Loss = 0.9647073149681091\n",
      "2186) Lyapunov Risk = 0.8091228008270264, MSE = 0.023139385506510735, V_0_loss = tensor([[0.0048]], grad_fn=<PowBackward0>), V_pos_loss = 0.022004464641213417, Lv_loss = 0.0, Circular Tuning Loss = 0.9646132588386536\n",
      "2187) Lyapunov Risk = 0.8091995120048523, MSE = 0.023649029433727264, V_0_loss = tensor([[0.0048]], grad_fn=<PowBackward0>), V_pos_loss = 0.021981479600071907, Lv_loss = 0.0, Circular Tuning Loss = 0.9645189642906189\n",
      "2188) Lyapunov Risk = 0.8094437718391418, MSE = 0.02257312834262848, V_0_loss = tensor([[0.0048]], grad_fn=<PowBackward0>), V_pos_loss = 0.021957505494356155, Lv_loss = 0.0, Circular Tuning Loss = 0.964426577091217\n",
      "2189) Lyapunov Risk = 0.809194803237915, MSE = 0.024054616689682007, V_0_loss = tensor([[0.0048]], grad_fn=<PowBackward0>), V_pos_loss = 0.021934082731604576, Lv_loss = 0.0, Circular Tuning Loss = 0.9643338918685913\n",
      "2190) Lyapunov Risk = 0.8088703751564026, MSE = 0.02286512404680252, V_0_loss = tensor([[0.0048]], grad_fn=<PowBackward0>), V_pos_loss = 0.021909750998020172, Lv_loss = 0.0, Circular Tuning Loss = 0.9642427563667297\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.0019531250000000004, 0]\n",
      "x2 : [-2.0000000000000004, -1.9980468750000004]\n",
      "==============================\n",
      "2191) Lyapunov Risk = 0.8144229650497437, MSE = 0.023312995210289955, V_0_loss = tensor([[0.0048]], grad_fn=<PowBackward0>), V_pos_loss = 0.022205471992492676, Lv_loss = 0.0, Circular Tuning Loss = 0.9752237200737\n",
      "2192) Lyapunov Risk = 0.8145036697387695, MSE = 0.023947324603796005, V_0_loss = tensor([[0.0048]], grad_fn=<PowBackward0>), V_pos_loss = 0.02218165434896946, Lv_loss = 0.0, Circular Tuning Loss = 0.9751295447349548\n",
      "2193) Lyapunov Risk = 0.8151133060455322, MSE = 0.02235635742545128, V_0_loss = tensor([[0.0048]], grad_fn=<PowBackward0>), V_pos_loss = 0.022156715393066406, Lv_loss = 0.0, Circular Tuning Loss = 0.9750363826751709\n",
      "2194) Lyapunov Risk = 0.8145197629928589, MSE = 0.02407575398683548, V_0_loss = tensor([[0.0048]], grad_fn=<PowBackward0>), V_pos_loss = 0.022132152691483498, Lv_loss = 0.0, Circular Tuning Loss = 0.9749428033828735\n",
      "2195) Lyapunov Risk = 0.8139646649360657, MSE = 0.023030215874314308, V_0_loss = tensor([[0.0048]], grad_fn=<PowBackward0>), V_pos_loss = 0.022106479853391647, Lv_loss = 0.0, Circular Tuning Loss = 0.9748504757881165\n",
      "2196) Lyapunov Risk = 0.8137603402137756, MSE = 0.02304483950138092, V_0_loss = tensor([[0.0048]], grad_fn=<PowBackward0>), V_pos_loss = 0.022081347182393074, Lv_loss = 0.0, Circular Tuning Loss = 0.9747576713562012\n",
      "2197) Lyapunov Risk = 0.813829779624939, MSE = 0.023927956819534302, V_0_loss = tensor([[0.0048]], grad_fn=<PowBackward0>), V_pos_loss = 0.0220566987991333, Lv_loss = 0.0, Circular Tuning Loss = 0.9746646285057068\n",
      "2198) Lyapunov Risk = 0.814191460609436, MSE = 0.022554604336619377, V_0_loss = tensor([[0.0048]], grad_fn=<PowBackward0>), V_pos_loss = 0.022030986845493317, Lv_loss = 0.0, Circular Tuning Loss = 0.9745727777481079\n",
      "2199) Lyapunov Risk = 0.8136537075042725, MSE = 0.02394646219909191, V_0_loss = tensor([[0.0048]], grad_fn=<PowBackward0>), V_pos_loss = 0.02200576290488243, Lv_loss = 0.0, Circular Tuning Loss = 0.9744808673858643\n",
      "2200) Lyapunov Risk = 0.8133256435394287, MSE = 0.023261792957782745, V_0_loss = tensor([[0.0048]], grad_fn=<PowBackward0>), V_pos_loss = 0.021979913115501404, Lv_loss = 0.0, Circular Tuning Loss = 0.9743895530700684\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.0019531250000000004, 0]\n",
      "x2 : [-2.0000000000000004, -1.9980468750000004]\n",
      "==============================\n",
      "2201) Lyapunov Risk = 0.8189211487770081, MSE = 0.023122364655137062, V_0_loss = tensor([[0.0048]], grad_fn=<PowBackward0>), V_pos_loss = 0.022267157211899757, Lv_loss = 0.0, Circular Tuning Loss = 0.9852796196937561\n",
      "2202) Lyapunov Risk = 0.8189001083374023, MSE = 0.023714695125818253, V_0_loss = tensor([[0.0048]], grad_fn=<PowBackward0>), V_pos_loss = 0.022241640836000443, Lv_loss = 0.0, Circular Tuning Loss = 0.985185444355011\n",
      "2203) Lyapunov Risk = 0.8191882371902466, MSE = 0.022645676508545876, V_0_loss = tensor([[0.0048]], grad_fn=<PowBackward0>), V_pos_loss = 0.022214919328689575, Lv_loss = 0.0, Circular Tuning Loss = 0.9850919842720032\n",
      "2204) Lyapunov Risk = 0.8188374042510986, MSE = 0.023899024352431297, V_0_loss = tensor([[0.0048]], grad_fn=<PowBackward0>), V_pos_loss = 0.022188425064086914, Lv_loss = 0.0, Circular Tuning Loss = 0.9849982261657715\n",
      "2205) Lyapunov Risk = 0.8185788989067078, MSE = 0.023027002811431885, V_0_loss = tensor([[0.0048]], grad_fn=<PowBackward0>), V_pos_loss = 0.02216094732284546, Lv_loss = 0.0, Circular Tuning Loss = 0.9849051237106323\n",
      "2206) Lyapunov Risk = 0.8182635307312012, MSE = 0.023270290344953537, V_0_loss = tensor([[0.0048]], grad_fn=<PowBackward0>), V_pos_loss = 0.022133843973279, Lv_loss = 0.0, Circular Tuning Loss = 0.984811544418335\n",
      "2207) Lyapunov Risk = 0.8182110786437988, MSE = 0.023785149678587914, V_0_loss = tensor([[0.0048]], grad_fn=<PowBackward0>), V_pos_loss = 0.022107146680355072, Lv_loss = 0.0, Circular Tuning Loss = 0.9847177863121033\n",
      "2208) Lyapunov Risk = 0.8183414936065674, MSE = 0.022807041183114052, V_0_loss = tensor([[0.0048]], grad_fn=<PowBackward0>), V_pos_loss = 0.02208009734749794, Lv_loss = 0.0, Circular Tuning Loss = 0.9846242070198059\n",
      "2209) Lyapunov Risk = 0.8180547952651978, MSE = 0.023704877123236656, V_0_loss = tensor([[0.0049]], grad_fn=<PowBackward0>), V_pos_loss = 0.022053366526961327, Lv_loss = 0.0, Circular Tuning Loss = 0.9845306277275085\n",
      "2210) Lyapunov Risk = 0.8178219795227051, MSE = 0.023065321147441864, V_0_loss = tensor([[0.0049]], grad_fn=<PowBackward0>), V_pos_loss = 0.022025657817721367, Lv_loss = 0.0, Circular Tuning Loss = 0.9844381213188171\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.0019531250000000004, 0]\n",
      "x2 : [-2.0000000000000004, -1.9980468750000004]\n",
      "==============================\n",
      "2211) Lyapunov Risk = 0.8233455419540405, MSE = 0.023532696068286896, V_0_loss = tensor([[0.0049]], grad_fn=<PowBackward0>), V_pos_loss = 0.02230333350598812, Lv_loss = 0.0, Circular Tuning Loss = 0.9952425360679626\n",
      "2212) Lyapunov Risk = 0.8232421875, MSE = 0.023581894114613533, V_0_loss = tensor([[0.0049]], grad_fn=<PowBackward0>), V_pos_loss = 0.022275593131780624, Lv_loss = 0.0, Circular Tuning Loss = 0.9951469898223877\n",
      "2213) Lyapunov Risk = 0.8232018351554871, MSE = 0.023153157904744148, V_0_loss = tensor([[0.0049]], grad_fn=<PowBackward0>), V_pos_loss = 0.022247908636927605, Lv_loss = 0.0, Circular Tuning Loss = 0.9950507879257202\n",
      "2214) Lyapunov Risk = 0.8230277895927429, MSE = 0.023639816790819168, V_0_loss = tensor([[0.0049]], grad_fn=<PowBackward0>), V_pos_loss = 0.022220343351364136, Lv_loss = 0.0, Circular Tuning Loss = 0.9949541687965393\n",
      "2215) Lyapunov Risk = 0.8228402137756348, MSE = 0.023183107376098633, V_0_loss = tensor([[0.0049]], grad_fn=<PowBackward0>), V_pos_loss = 0.022192226722836494, Lv_loss = 0.0, Circular Tuning Loss = 0.994857668876648\n",
      "2216) Lyapunov Risk = 0.8226502537727356, MSE = 0.02353082038462162, V_0_loss = tensor([[0.0049]], grad_fn=<PowBackward0>), V_pos_loss = 0.02216433919966221, Lv_loss = 0.0, Circular Tuning Loss = 0.9947611093521118\n",
      "2217) Lyapunov Risk = 0.8225269913673401, MSE = 0.023370543494820595, V_0_loss = tensor([[0.0049]], grad_fn=<PowBackward0>), V_pos_loss = 0.022136308252811432, Lv_loss = 0.0, Circular Tuning Loss = 0.9946645498275757\n",
      "2218) Lyapunov Risk = 0.8224149942398071, MSE = 0.02335456572473049, V_0_loss = tensor([[0.0049]], grad_fn=<PowBackward0>), V_pos_loss = 0.022108515724539757, Lv_loss = 0.0, Circular Tuning Loss = 0.9945679306983948\n",
      "2219) Lyapunov Risk = 0.8222669959068298, MSE = 0.023543981835246086, V_0_loss = tensor([[0.0049]], grad_fn=<PowBackward0>), V_pos_loss = 0.022080913186073303, Lv_loss = 0.0, Circular Tuning Loss = 0.9944711923599243\n",
      "2220) Lyapunov Risk = 0.8221079111099243, MSE = 0.023275693878531456, V_0_loss = tensor([[0.0049]], grad_fn=<PowBackward0>), V_pos_loss = 0.022053297609090805, Lv_loss = 0.0, Circular Tuning Loss = 0.9943745136260986\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.0019531250000000004, 0]\n",
      "x2 : [-2.0000000000000004, -1.9980468750000004]\n",
      "==============================\n",
      "2221) Lyapunov Risk = 0.8277068138122559, MSE = 0.023495681583881378, V_0_loss = tensor([[0.0049]], grad_fn=<PowBackward0>), V_pos_loss = 0.022323770448565483, Lv_loss = 0.0, Circular Tuning Loss = 1.0050773620605469\n",
      "2222) Lyapunov Risk = 0.8275806903839111, MSE = 0.023454120382666588, V_0_loss = tensor([[0.0049]], grad_fn=<PowBackward0>), V_pos_loss = 0.02229548990726471, Lv_loss = 0.0, Circular Tuning Loss = 1.0049779415130615\n",
      "2223) Lyapunov Risk = 0.8274532556533813, MSE = 0.02330450341105461, V_0_loss = tensor([[0.0049]], grad_fn=<PowBackward0>), V_pos_loss = 0.022266961634159088, Lv_loss = 0.0, Circular Tuning Loss = 1.004878044128418\n",
      "2224) Lyapunov Risk = 0.8273119330406189, MSE = 0.023612074553966522, V_0_loss = tensor([[0.0049]], grad_fn=<PowBackward0>), V_pos_loss = 0.022238433361053467, Lv_loss = 0.0, Circular Tuning Loss = 1.0047777891159058\n",
      "2225) Lyapunov Risk = 0.8271552324295044, MSE = 0.023295165970921516, V_0_loss = tensor([[0.0049]], grad_fn=<PowBackward0>), V_pos_loss = 0.0222097747027874, Lv_loss = 0.0, Circular Tuning Loss = 1.004677414894104\n",
      "2226) Lyapunov Risk = 0.8270113468170166, MSE = 0.023372041061520576, V_0_loss = tensor([[0.0049]], grad_fn=<PowBackward0>), V_pos_loss = 0.022181160748004913, Lv_loss = 0.0, Circular Tuning Loss = 1.0045768022537231\n",
      "2227) Lyapunov Risk = 0.8269087672233582, MSE = 0.023546062409877777, V_0_loss = tensor([[0.0049]], grad_fn=<PowBackward0>), V_pos_loss = 0.022152531892061234, Lv_loss = 0.0, Circular Tuning Loss = 1.0044764280319214\n",
      "2228) Lyapunov Risk = 0.8267917037010193, MSE = 0.023183142766356468, V_0_loss = tensor([[0.0049]], grad_fn=<PowBackward0>), V_pos_loss = 0.022123612463474274, Lv_loss = 0.0, Circular Tuning Loss = 1.004377841949463\n",
      "2229) Lyapunov Risk = 0.8266438841819763, MSE = 0.02343386970460415, V_0_loss = tensor([[0.0049]], grad_fn=<PowBackward0>), V_pos_loss = 0.02209458313882351, Lv_loss = 0.0, Circular Tuning Loss = 1.004280686378479\n",
      "2230) Lyapunov Risk = 0.8265200257301331, MSE = 0.023443909361958504, V_0_loss = tensor([[0.0049]], grad_fn=<PowBackward0>), V_pos_loss = 0.02206534333527088, Lv_loss = 0.0, Circular Tuning Loss = 1.0041850805282593\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.0019531250000000004, 0]\n",
      "x2 : [-2.0000000000000004, -1.9980468750000004]\n",
      "==============================\n",
      "2231) Lyapunov Risk = 0.8321042656898499, MSE = 0.023213086649775505, V_0_loss = tensor([[0.0049]], grad_fn=<PowBackward0>), V_pos_loss = 0.02232670783996582, Lv_loss = 0.0, Circular Tuning Loss = 1.0148017406463623\n",
      "2232) Lyapunov Risk = 0.8319763541221619, MSE = 0.023466212674975395, V_0_loss = tensor([[0.0049]], grad_fn=<PowBackward0>), V_pos_loss = 0.022296471521258354, Lv_loss = 0.0, Circular Tuning Loss = 1.0147055387496948\n",
      "2233) Lyapunov Risk = 0.831847071647644, MSE = 0.02338140644133091, V_0_loss = tensor([[0.0049]], grad_fn=<PowBackward0>), V_pos_loss = 0.022265899926424026, Lv_loss = 0.0, Circular Tuning Loss = 1.0146098136901855\n",
      "2234) Lyapunov Risk = 0.8317267298698425, MSE = 0.023260192945599556, V_0_loss = tensor([[0.0050]], grad_fn=<PowBackward0>), V_pos_loss = 0.02223503589630127, Lv_loss = 0.0, Circular Tuning Loss = 1.0145148038864136\n",
      "2235) Lyapunov Risk = 0.8316042423248291, MSE = 0.023448193445801735, V_0_loss = tensor([[0.0050]], grad_fn=<PowBackward0>), V_pos_loss = 0.02220400609076023, Lv_loss = 0.0, Circular Tuning Loss = 1.0144201517105103\n",
      "2236) Lyapunov Risk = 0.8314793109893799, MSE = 0.023276254534721375, V_0_loss = tensor([[0.0050]], grad_fn=<PowBackward0>), V_pos_loss = 0.022172635421156883, Lv_loss = 0.0, Circular Tuning Loss = 1.0143263339996338\n",
      "2237) Lyapunov Risk = 0.8313598036766052, MSE = 0.02328995056450367, V_0_loss = tensor([[0.0050]], grad_fn=<PowBackward0>), V_pos_loss = 0.022141074761748314, Lv_loss = 0.0, Circular Tuning Loss = 1.0142327547073364\n",
      "2238) Lyapunov Risk = 0.8312397003173828, MSE = 0.023395944386720657, V_0_loss = tensor([[0.0050]], grad_fn=<PowBackward0>), V_pos_loss = 0.02210935205221176, Lv_loss = 0.0, Circular Tuning Loss = 1.0141397714614868\n",
      "2239) Lyapunov Risk = 0.8311129808425903, MSE = 0.023257393389940262, V_0_loss = tensor([[0.0050]], grad_fn=<PowBackward0>), V_pos_loss = 0.0220774095505476, Lv_loss = 0.0, Circular Tuning Loss = 1.014047384262085\n",
      "2240) Lyapunov Risk = 0.8309886455535889, MSE = 0.023341646417975426, V_0_loss = tensor([[0.0050]], grad_fn=<PowBackward0>), V_pos_loss = 0.022045409306883812, Lv_loss = 0.0, Circular Tuning Loss = 1.0139554738998413\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.0019531250000000004, 0]\n",
      "x2 : [-2.0000000000000004, -1.9980468750000004]\n",
      "==============================\n",
      "2241) Lyapunov Risk = 0.8365061283111572, MSE = 0.023357797414064407, V_0_loss = tensor([[0.0050]], grad_fn=<PowBackward0>), V_pos_loss = 0.022295907139778137, Lv_loss = 0.0, Circular Tuning Loss = 1.0244762897491455\n",
      "2242) Lyapunov Risk = 0.8363845944404602, MSE = 0.023261360824108124, V_0_loss = tensor([[0.0050]], grad_fn=<PowBackward0>), V_pos_loss = 0.022262800484895706, Lv_loss = 0.0, Circular Tuning Loss = 1.0243817567825317\n",
      "2243) Lyapunov Risk = 0.8362569808959961, MSE = 0.02331705391407013, V_0_loss = tensor([[0.0050]], grad_fn=<PowBackward0>), V_pos_loss = 0.02222934179008007, Lv_loss = 0.0, Circular Tuning Loss = 1.024287223815918\n",
      "2244) Lyapunov Risk = 0.8361327648162842, MSE = 0.023342980071902275, V_0_loss = tensor([[0.0050]], grad_fn=<PowBackward0>), V_pos_loss = 0.022195570170879364, Lv_loss = 0.0, Circular Tuning Loss = 1.0241925716400146\n",
      "2245) Lyapunov Risk = 0.836011528968811, MSE = 0.023234743624925613, V_0_loss = tensor([[0.0050]], grad_fn=<PowBackward0>), V_pos_loss = 0.022161586210131645, Lv_loss = 0.0, Circular Tuning Loss = 1.0240976810455322\n",
      "2246) Lyapunov Risk = 0.8358913064002991, MSE = 0.023294098675251007, V_0_loss = tensor([[0.0050]], grad_fn=<PowBackward0>), V_pos_loss = 0.022127320989966393, Lv_loss = 0.0, Circular Tuning Loss = 1.024003267288208\n",
      "2247) Lyapunov Risk = 0.8357729315757751, MSE = 0.023282645270228386, V_0_loss = tensor([[0.0050]], grad_fn=<PowBackward0>), V_pos_loss = 0.022092744708061218, Lv_loss = 0.0, Circular Tuning Loss = 1.0239098072052002\n",
      "2248) Lyapunov Risk = 0.8356565833091736, MSE = 0.02318110316991806, V_0_loss = tensor([[0.0050]], grad_fn=<PowBackward0>), V_pos_loss = 0.022057833150029182, Lv_loss = 0.0, Circular Tuning Loss = 1.0238173007965088\n",
      "2249) Lyapunov Risk = 0.8355385065078735, MSE = 0.023297637701034546, V_0_loss = tensor([[0.0050]], grad_fn=<PowBackward0>), V_pos_loss = 0.022022712975740433, Lv_loss = 0.0, Circular Tuning Loss = 1.0237256288528442\n",
      "2250) Lyapunov Risk = 0.8354180455207825, MSE = 0.0232020765542984, V_0_loss = tensor([[0.0050]], grad_fn=<PowBackward0>), V_pos_loss = 0.021987341344356537, Lv_loss = 0.0, Circular Tuning Loss = 1.023634672164917\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.0019531250000000004, 0]\n",
      "x2 : [-2.0000000000000004, -1.9980468750000004]\n",
      "==============================\n",
      "2251) Lyapunov Risk = 0.840883731842041, MSE = 0.023172970861196518, V_0_loss = tensor([[0.0050]], grad_fn=<PowBackward0>), V_pos_loss = 0.02222631499171257, Lv_loss = 0.0, Circular Tuning Loss = 1.0340653657913208\n",
      "2252) Lyapunov Risk = 0.8407663702964783, MSE = 0.023292090743780136, V_0_loss = tensor([[0.0050]], grad_fn=<PowBackward0>), V_pos_loss = 0.022189613431692123, Lv_loss = 0.0, Circular Tuning Loss = 1.0339722633361816\n",
      "2253) Lyapunov Risk = 0.8406436443328857, MSE = 0.02316339686512947, V_0_loss = tensor([[0.0050]], grad_fn=<PowBackward0>), V_pos_loss = 0.022152483463287354, Lv_loss = 0.0, Circular Tuning Loss = 1.033879280090332\n",
      "2254) Lyapunov Risk = 0.840520977973938, MSE = 0.023212887346744537, V_0_loss = tensor([[0.0050]], grad_fn=<PowBackward0>), V_pos_loss = 0.02211502380669117, Lv_loss = 0.0, Circular Tuning Loss = 1.033786416053772\n",
      "2255) Lyapunov Risk = 0.8404014110565186, MSE = 0.023245474323630333, V_0_loss = tensor([[0.0050]], grad_fn=<PowBackward0>), V_pos_loss = 0.02207736298441887, Lv_loss = 0.0, Circular Tuning Loss = 1.033693552017212\n",
      "2256) Lyapunov Risk = 0.8402823805809021, MSE = 0.02311963587999344, V_0_loss = tensor([[0.0050]], grad_fn=<PowBackward0>), V_pos_loss = 0.02203940600156784, Lv_loss = 0.0, Circular Tuning Loss = 1.0336010456085205\n",
      "2257) Lyapunov Risk = 0.84015953540802, MSE = 0.023219484835863113, V_0_loss = tensor([[0.0050]], grad_fn=<PowBackward0>), V_pos_loss = 0.02200123853981495, Lv_loss = 0.0, Circular Tuning Loss = 1.0335090160369873\n",
      "2258) Lyapunov Risk = 0.84003746509552, MSE = 0.023166010156273842, V_0_loss = tensor([[0.0050]], grad_fn=<PowBackward0>), V_pos_loss = 0.02196282148361206, Lv_loss = 0.0, Circular Tuning Loss = 1.0334171056747437\n",
      "2259) Lyapunov Risk = 0.8399165868759155, MSE = 0.023136576637625694, V_0_loss = tensor([[0.0050]], grad_fn=<PowBackward0>), V_pos_loss = 0.021924249827861786, Lv_loss = 0.0, Circular Tuning Loss = 1.0333255529403687\n",
      "2260) Lyapunov Risk = 0.839794933795929, MSE = 0.023180367425084114, V_0_loss = tensor([[0.0050]], grad_fn=<PowBackward0>), V_pos_loss = 0.021885527297854424, Lv_loss = 0.0, Circular Tuning Loss = 1.0332341194152832\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.0019531250000000004, 0]\n",
      "x2 : [-2.0000000000000004, -1.9980468750000004]\n",
      "==============================\n",
      "2261) Lyapunov Risk = 0.8452003002166748, MSE = 0.02314378134906292, V_0_loss = tensor([[0.0050]], grad_fn=<PowBackward0>), V_pos_loss = 0.022112546488642693, Lv_loss = 0.0, Circular Tuning Loss = 1.0435692071914673\n",
      "2262) Lyapunov Risk = 0.8450767993927002, MSE = 0.023113010451197624, V_0_loss = tensor([[0.0050]], grad_fn=<PowBackward0>), V_pos_loss = 0.022072533145546913, Lv_loss = 0.0, Circular Tuning Loss = 1.0434741973876953\n",
      "2263) Lyapunov Risk = 0.8449525237083435, MSE = 0.02315598726272583, V_0_loss = tensor([[0.0050]], grad_fn=<PowBackward0>), V_pos_loss = 0.022032156586647034, Lv_loss = 0.0, Circular Tuning Loss = 1.0433789491653442\n",
      "2264) Lyapunov Risk = 0.8448276519775391, MSE = 0.02313077822327614, V_0_loss = tensor([[0.0050]], grad_fn=<PowBackward0>), V_pos_loss = 0.021991446614265442, Lv_loss = 0.0, Circular Tuning Loss = 1.043283462524414\n",
      "2265) Lyapunov Risk = 0.8447030186653137, MSE = 0.02308785729110241, V_0_loss = tensor([[0.0051]], grad_fn=<PowBackward0>), V_pos_loss = 0.021950440481305122, Lv_loss = 0.0, Circular Tuning Loss = 1.0431876182556152\n",
      "2266) Lyapunov Risk = 0.8445777893066406, MSE = 0.023125339299440384, V_0_loss = tensor([[0.0051]], grad_fn=<PowBackward0>), V_pos_loss = 0.021909169852733612, Lv_loss = 0.0, Circular Tuning Loss = 1.0430915355682373\n",
      "2267) Lyapunov Risk = 0.8444525599479675, MSE = 0.023105980828404427, V_0_loss = tensor([[0.0051]], grad_fn=<PowBackward0>), V_pos_loss = 0.021867679432034492, Lv_loss = 0.0, Circular Tuning Loss = 1.0429952144622803\n",
      "2268) Lyapunov Risk = 0.8443277478218079, MSE = 0.02306956611573696, V_0_loss = tensor([[0.0051]], grad_fn=<PowBackward0>), V_pos_loss = 0.02182599902153015, Lv_loss = 0.0, Circular Tuning Loss = 1.0428987741470337\n",
      "2269) Lyapunov Risk = 0.8442022800445557, MSE = 0.02310262992978096, V_0_loss = tensor([[0.0051]], grad_fn=<PowBackward0>), V_pos_loss = 0.0217842198908329, Lv_loss = 0.0, Circular Tuning Loss = 1.042802095413208\n",
      "2270) Lyapunov Risk = 0.8440768122673035, MSE = 0.023090466856956482, V_0_loss = tensor([[0.0051]], grad_fn=<PowBackward0>), V_pos_loss = 0.02174239233136177, Lv_loss = 0.0, Circular Tuning Loss = 1.0427054166793823\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.0019531250000000004, 0]\n",
      "x2 : [-2.0000000000000004, -1.9980468750000004]\n",
      "==============================\n",
      "2271) Lyapunov Risk = 0.8494201302528381, MSE = 0.023063885048031807, V_0_loss = tensor([[0.0051]], grad_fn=<PowBackward0>), V_pos_loss = 0.0219565536826849, Lv_loss = 0.0, Circular Tuning Loss = 1.0529357194900513\n",
      "2272) Lyapunov Risk = 0.8492916226387024, MSE = 0.023062391206622124, V_0_loss = tensor([[0.0051]], grad_fn=<PowBackward0>), V_pos_loss = 0.02191341482102871, Lv_loss = 0.0, Circular Tuning Loss = 1.0528349876403809\n",
      "2273) Lyapunov Risk = 0.8491628766059875, MSE = 0.023069744929671288, V_0_loss = tensor([[0.0051]], grad_fn=<PowBackward0>), V_pos_loss = 0.021869894117116928, Lv_loss = 0.0, Circular Tuning Loss = 1.0527335405349731\n",
      "2274) Lyapunov Risk = 0.8490338921546936, MSE = 0.0230396781116724, V_0_loss = tensor([[0.0051]], grad_fn=<PowBackward0>), V_pos_loss = 0.021826043725013733, Lv_loss = 0.0, Circular Tuning Loss = 1.0526317358016968\n",
      "2275) Lyapunov Risk = 0.8489044904708862, MSE = 0.0230306014418602, V_0_loss = tensor([[0.0051]], grad_fn=<PowBackward0>), V_pos_loss = 0.021781928837299347, Lv_loss = 0.0, Circular Tuning Loss = 1.0525295734405518\n",
      "2276) Lyapunov Risk = 0.8487751483917236, MSE = 0.02304677851498127, V_0_loss = tensor([[0.0051]], grad_fn=<PowBackward0>), V_pos_loss = 0.02173757366836071, Lv_loss = 0.0, Circular Tuning Loss = 1.0524271726608276\n",
      "2277) Lyapunov Risk = 0.8486454486846924, MSE = 0.02301464043557644, V_0_loss = tensor([[0.0051]], grad_fn=<PowBackward0>), V_pos_loss = 0.021693002432584763, Lv_loss = 0.0, Circular Tuning Loss = 1.0523247718811035\n",
      "2278) Lyapunov Risk = 0.8485153317451477, MSE = 0.02302454225718975, V_0_loss = tensor([[0.0051]], grad_fn=<PowBackward0>), V_pos_loss = 0.02164824865758419, Lv_loss = 0.0, Circular Tuning Loss = 1.0522222518920898\n",
      "2279) Lyapunov Risk = 0.8483853340148926, MSE = 0.023033345118165016, V_0_loss = tensor([[0.0051]], grad_fn=<PowBackward0>), V_pos_loss = 0.02160332351922989, Lv_loss = 0.0, Circular Tuning Loss = 1.0521196126937866\n",
      "2280) Lyapunov Risk = 0.8482552170753479, MSE = 0.023011818528175354, V_0_loss = tensor([[0.0051]], grad_fn=<PowBackward0>), V_pos_loss = 0.021558301523327827, Lv_loss = 0.0, Circular Tuning Loss = 1.0520168542861938\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.0019531250000000004, 0]\n",
      "x2 : [-2.0000000000000004, -1.9980468750000004]\n",
      "==============================\n",
      "2281) Lyapunov Risk = 0.8535356521606445, MSE = 0.023022901266813278, V_0_loss = tensor([[0.0051]], grad_fn=<PowBackward0>), V_pos_loss = 0.021759703755378723, Lv_loss = 0.0, Circular Tuning Loss = 1.0621423721313477\n",
      "2282) Lyapunov Risk = 0.8534020185470581, MSE = 0.023001616820693016, V_0_loss = tensor([[0.0051]], grad_fn=<PowBackward0>), V_pos_loss = 0.021713314577937126, Lv_loss = 0.0, Circular Tuning Loss = 1.0620348453521729\n",
      "2283) Lyapunov Risk = 0.8532682657241821, MSE = 0.022991538047790527, V_0_loss = tensor([[0.0051]], grad_fn=<PowBackward0>), V_pos_loss = 0.02166656032204628, Lv_loss = 0.0, Circular Tuning Loss = 1.0619268417358398\n",
      "2284) Lyapunov Risk = 0.8531342148780823, MSE = 0.022992901504039764, V_0_loss = tensor([[0.0051]], grad_fn=<PowBackward0>), V_pos_loss = 0.02161947824060917, Lv_loss = 0.0, Circular Tuning Loss = 1.061818242073059\n",
      "2285) Lyapunov Risk = 0.8529996275901794, MSE = 0.022969620302319527, V_0_loss = tensor([[0.0051]], grad_fn=<PowBackward0>), V_pos_loss = 0.021572096273303032, Lv_loss = 0.0, Circular Tuning Loss = 1.0617090463638306\n",
      "2286) Lyapunov Risk = 0.8528649806976318, MSE = 0.022967765107750893, V_0_loss = tensor([[0.0051]], grad_fn=<PowBackward0>), V_pos_loss = 0.0215244609862566, Lv_loss = 0.0, Circular Tuning Loss = 1.061599850654602\n",
      "2287) Lyapunov Risk = 0.8527300953865051, MSE = 0.022972218692302704, V_0_loss = tensor([[0.0051]], grad_fn=<PowBackward0>), V_pos_loss = 0.021476631984114647, Lv_loss = 0.0, Circular Tuning Loss = 1.0614901781082153\n",
      "2288) Lyapunov Risk = 0.8525950312614441, MSE = 0.02295897901058197, V_0_loss = tensor([[0.0051]], grad_fn=<PowBackward0>), V_pos_loss = 0.021428629755973816, Lv_loss = 0.0, Circular Tuning Loss = 1.061380386352539\n",
      "2289) Lyapunov Risk = 0.8524600267410278, MSE = 0.022977152839303017, V_0_loss = tensor([[0.0051]], grad_fn=<PowBackward0>), V_pos_loss = 0.021380476653575897, Lv_loss = 0.0, Circular Tuning Loss = 1.0612705945968628\n",
      "2290) Lyapunov Risk = 0.8523249626159668, MSE = 0.022969083860516548, V_0_loss = tensor([[0.0051]], grad_fn=<PowBackward0>), V_pos_loss = 0.021332193166017532, Lv_loss = 0.0, Circular Tuning Loss = 1.061160683631897\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.0019531250000000004, 0]\n",
      "x2 : [-2.0000000000000004, -1.9980468750000004]\n",
      "==============================\n",
      "2291) Lyapunov Risk = 0.8575382232666016, MSE = 0.02297072298824787, V_0_loss = tensor([[0.0051]], grad_fn=<PowBackward0>), V_pos_loss = 0.021519556641578674, Lv_loss = 0.0, Circular Tuning Loss = 1.071173906326294\n",
      "2292) Lyapunov Risk = 0.857399582862854, MSE = 0.022951046004891396, V_0_loss = tensor([[0.0052]], grad_fn=<PowBackward0>), V_pos_loss = 0.021469855681061745, Lv_loss = 0.0, Circular Tuning Loss = 1.0710591077804565\n",
      "2293) Lyapunov Risk = 0.857260525226593, MSE = 0.022947512567043304, V_0_loss = tensor([[0.0052]], grad_fn=<PowBackward0>), V_pos_loss = 0.021419811993837357, Lv_loss = 0.0, Circular Tuning Loss = 1.0709435939788818\n",
      "2294) Lyapunov Risk = 0.8571211695671082, MSE = 0.02293652668595314, V_0_loss = tensor([[0.0052]], grad_fn=<PowBackward0>), V_pos_loss = 0.021369436755776405, Lv_loss = 0.0, Circular Tuning Loss = 1.070827603340149\n",
      "2295) Lyapunov Risk = 0.856981635093689, MSE = 0.022913208231329918, V_0_loss = tensor([[0.0052]], grad_fn=<PowBackward0>), V_pos_loss = 0.021318763494491577, Lv_loss = 0.0, Circular Tuning Loss = 1.070711374282837\n",
      "2296) Lyapunov Risk = 0.8568419218063354, MSE = 0.02292068861424923, V_0_loss = tensor([[0.0052]], grad_fn=<PowBackward0>), V_pos_loss = 0.021267835050821304, Lv_loss = 0.0, Circular Tuning Loss = 1.0705947875976562\n",
      "2297) Lyapunov Risk = 0.8567017316818237, MSE = 0.022907471284270287, V_0_loss = tensor([[0.0052]], grad_fn=<PowBackward0>), V_pos_loss = 0.02121672034263611, Lv_loss = 0.0, Circular Tuning Loss = 1.070478081703186\n",
      "2298) Lyapunov Risk = 0.856561541557312, MSE = 0.022900979965925217, V_0_loss = tensor([[0.0052]], grad_fn=<PowBackward0>), V_pos_loss = 0.021165424957871437, Lv_loss = 0.0, Circular Tuning Loss = 1.0703613758087158\n",
      "2299) Lyapunov Risk = 0.8564211130142212, MSE = 0.022919878363609314, V_0_loss = tensor([[0.0052]], grad_fn=<PowBackward0>), V_pos_loss = 0.021113967522978783, Lv_loss = 0.0, Circular Tuning Loss = 1.0702447891235352\n",
      "2300) Lyapunov Risk = 0.856280505657196, MSE = 0.022909823805093765, V_0_loss = tensor([[0.0052]], grad_fn=<PowBackward0>), V_pos_loss = 0.02106238342821598, Lv_loss = 0.0, Circular Tuning Loss = 1.070128083229065\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.0019531250000000004, 0]\n",
      "x2 : [-2.0000000000000004, -1.9980468750000004]\n",
      "==============================\n",
      "2301) Lyapunov Risk = 0.8614253401756287, MSE = 0.02291099913418293, V_0_loss = tensor([[0.0052]], grad_fn=<PowBackward0>), V_pos_loss = 0.02123536542057991, Lv_loss = 0.0, Circular Tuning Loss = 1.0800296068191528\n",
      "2302) Lyapunov Risk = 0.8612809777259827, MSE = 0.02289062738418579, V_0_loss = tensor([[0.0052]], grad_fn=<PowBackward0>), V_pos_loss = 0.021182246506214142, Lv_loss = 0.0, Circular Tuning Loss = 1.079908013343811\n",
      "2303) Lyapunov Risk = 0.8611360788345337, MSE = 0.02288922667503357, V_0_loss = tensor([[0.0052]], grad_fn=<PowBackward0>), V_pos_loss = 0.02112876996397972, Lv_loss = 0.0, Circular Tuning Loss = 1.079785943031311\n",
      "2304) Lyapunov Risk = 0.8609908819198608, MSE = 0.022874118760228157, V_0_loss = tensor([[0.0052]], grad_fn=<PowBackward0>), V_pos_loss = 0.021074969321489334, Lv_loss = 0.0, Circular Tuning Loss = 1.0796633958816528\n",
      "2305) Lyapunov Risk = 0.8608456254005432, MSE = 0.022850969806313515, V_0_loss = tensor([[0.0052]], grad_fn=<PowBackward0>), V_pos_loss = 0.021020881831645966, Lv_loss = 0.0, Circular Tuning Loss = 1.0795406103134155\n",
      "2306) Lyapunov Risk = 0.8607000112533569, MSE = 0.022852279245853424, V_0_loss = tensor([[0.0052]], grad_fn=<PowBackward0>), V_pos_loss = 0.02096664533019066, Lv_loss = 0.0, Circular Tuning Loss = 1.0794175863265991\n",
      "2307) Lyapunov Risk = 0.8605543375015259, MSE = 0.022843657061457634, V_0_loss = tensor([[0.0052]], grad_fn=<PowBackward0>), V_pos_loss = 0.02091224491596222, Lv_loss = 0.0, Circular Tuning Loss = 1.0792946815490723\n",
      "2308) Lyapunov Risk = 0.8604081273078918, MSE = 0.022845471277832985, V_0_loss = tensor([[0.0052]], grad_fn=<PowBackward0>), V_pos_loss = 0.020857669413089752, Lv_loss = 0.0, Circular Tuning Loss = 1.0791716575622559\n",
      "2309) Lyapunov Risk = 0.8602619767189026, MSE = 0.022851543501019478, V_0_loss = tensor([[0.0052]], grad_fn=<PowBackward0>), V_pos_loss = 0.020802943035960197, Lv_loss = 0.0, Circular Tuning Loss = 1.079048991203308\n",
      "2310) Lyapunov Risk = 0.860115647315979, MSE = 0.02284858375787735, V_0_loss = tensor([[0.0052]], grad_fn=<PowBackward0>), V_pos_loss = 0.020748106762766838, Lv_loss = 0.0, Circular Tuning Loss = 1.0789262056350708\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.0019531250000000004, 0]\n",
      "x2 : [-2.0000000000000004, -1.9980468750000004]\n",
      "==============================\n",
      "2311) Lyapunov Risk = 0.8651915192604065, MSE = 0.022857526317238808, V_0_loss = tensor([[0.0052]], grad_fn=<PowBackward0>), V_pos_loss = 0.02090621553361416, Lv_loss = 0.0, Circular Tuning Loss = 1.0887162685394287\n",
      "2312) Lyapunov Risk = 0.8650414943695068, MSE = 0.02284177765250206, V_0_loss = tensor([[0.0053]], grad_fn=<PowBackward0>), V_pos_loss = 0.02084990032017231, Lv_loss = 0.0, Circular Tuning Loss = 1.0885885953903198\n",
      "2313) Lyapunov Risk = 0.8648911714553833, MSE = 0.0228384118527174, V_0_loss = tensor([[0.0053]], grad_fn=<PowBackward0>), V_pos_loss = 0.02079327590763569, Lv_loss = 0.0, Circular Tuning Loss = 1.0884603261947632\n",
      "2314) Lyapunov Risk = 0.8647407293319702, MSE = 0.0228264220058918, V_0_loss = tensor([[0.0053]], grad_fn=<PowBackward0>), V_pos_loss = 0.020736446604132652, Lv_loss = 0.0, Circular Tuning Loss = 1.088331699371338\n",
      "2315) Lyapunov Risk = 0.8645899891853333, MSE = 0.02281525358557701, V_0_loss = tensor([[0.0053]], grad_fn=<PowBackward0>), V_pos_loss = 0.020679432898759842, Lv_loss = 0.0, Circular Tuning Loss = 1.088202953338623\n",
      "2316) Lyapunov Risk = 0.8644390106201172, MSE = 0.022810013964772224, V_0_loss = tensor([[0.0053]], grad_fn=<PowBackward0>), V_pos_loss = 0.020622288808226585, Lv_loss = 0.0, Circular Tuning Loss = 1.0880742073059082\n",
      "2317) Lyapunov Risk = 0.8642879724502563, MSE = 0.02280791848897934, V_0_loss = tensor([[0.0053]], grad_fn=<PowBackward0>), V_pos_loss = 0.020565014332532883, Lv_loss = 0.0, Circular Tuning Loss = 1.0879454612731934\n",
      "2318) Lyapunov Risk = 0.8641371726989746, MSE = 0.022808682173490524, V_0_loss = tensor([[0.0053]], grad_fn=<PowBackward0>), V_pos_loss = 0.02050764486193657, Lv_loss = 0.0, Circular Tuning Loss = 1.0878167152404785\n",
      "2319) Lyapunov Risk = 0.8639864325523376, MSE = 0.02280641905963421, V_0_loss = tensor([[0.0053]], grad_fn=<PowBackward0>), V_pos_loss = 0.02045021951198578, Lv_loss = 0.0, Circular Tuning Loss = 1.0876877307891846\n",
      "2320) Lyapunov Risk = 0.8638358116149902, MSE = 0.022812267765402794, V_0_loss = tensor([[0.0053]], grad_fn=<PowBackward0>), V_pos_loss = 0.020392779260873795, Lv_loss = 0.0, Circular Tuning Loss = 1.087558627128601\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.0019531250000000004, 0]\n",
      "x2 : [-2.0000000000000004, -1.9980468750000004]\n",
      "==============================\n",
      "2321) Lyapunov Risk = 0.8688410520553589, MSE = 0.022803371772170067, V_0_loss = tensor([[0.0053]], grad_fn=<PowBackward0>), V_pos_loss = 0.020536161959171295, Lv_loss = 0.0, Circular Tuning Loss = 1.0972315073013306\n",
      "2322) Lyapunov Risk = 0.8686869144439697, MSE = 0.02280428074300289, V_0_loss = tensor([[0.0053]], grad_fn=<PowBackward0>), V_pos_loss = 0.02047732099890709, Lv_loss = 0.0, Circular Tuning Loss = 1.09709632396698\n",
      "2323) Lyapunov Risk = 0.8685328960418701, MSE = 0.022809039801359177, V_0_loss = tensor([[0.0053]], grad_fn=<PowBackward0>), V_pos_loss = 0.020418208092451096, Lv_loss = 0.0, Circular Tuning Loss = 1.0969605445861816\n",
      "2324) Lyapunov Risk = 0.8683791160583496, MSE = 0.022799843922257423, V_0_loss = tensor([[0.0053]], grad_fn=<PowBackward0>), V_pos_loss = 0.02035890333354473, Lv_loss = 0.0, Circular Tuning Loss = 1.096824049949646\n",
      "2325) Lyapunov Risk = 0.8682254552841187, MSE = 0.022821832448244095, V_0_loss = tensor([[0.0053]], grad_fn=<PowBackward0>), V_pos_loss = 0.020299535244703293, Lv_loss = 0.0, Circular Tuning Loss = 1.096686840057373\n",
      "2326) Lyapunov Risk = 0.8680732250213623, MSE = 0.02275903709232807, V_0_loss = tensor([[0.0053]], grad_fn=<PowBackward0>), V_pos_loss = 0.020240115001797676, Lv_loss = 0.0, Circular Tuning Loss = 1.0965489149093628\n",
      "2327) Lyapunov Risk = 0.8679289817810059, MSE = 0.022911835461854935, V_0_loss = tensor([[0.0053]], grad_fn=<PowBackward0>), V_pos_loss = 0.02018086239695549, Lv_loss = 0.0, Circular Tuning Loss = 1.096410870552063\n",
      "2328) Lyapunov Risk = 0.8677911162376404, MSE = 0.022634711116552353, V_0_loss = tensor([[0.0053]], grad_fn=<PowBackward0>), V_pos_loss = 0.020121466368436813, Lv_loss = 0.0, Circular Tuning Loss = 1.096272587776184\n",
      "2329) Lyapunov Risk = 0.8676438927650452, MSE = 0.023007357493042946, V_0_loss = tensor([[0.0053]], grad_fn=<PowBackward0>), V_pos_loss = 0.020062435418367386, Lv_loss = 0.0, Circular Tuning Loss = 1.0961341857910156\n",
      "2330) Lyapunov Risk = 0.8674824237823486, MSE = 0.02265818417072296, V_0_loss = tensor([[0.0053]], grad_fn=<PowBackward0>), V_pos_loss = 0.02000337280333042, Lv_loss = 0.0, Circular Tuning Loss = 1.095995545387268\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.0019531250000000004, 0]\n",
      "x2 : [-2.0000000000000004, -1.9980468750000004]\n",
      "==============================\n",
      "2331) Lyapunov Risk = 0.8724071979522705, MSE = 0.02288779802620411, V_0_loss = tensor([[0.0054]], grad_fn=<PowBackward0>), V_pos_loss = 0.020133651793003082, Lv_loss = 0.0, Circular Tuning Loss = 1.1055554151535034\n",
      "2332) Lyapunov Risk = 0.8722490072250366, MSE = 0.02276562713086605, V_0_loss = tensor([[0.0054]], grad_fn=<PowBackward0>), V_pos_loss = 0.020073525607585907, Lv_loss = 0.0, Circular Tuning Loss = 1.105411410331726\n",
      "2333) Lyapunov Risk = 0.8720910549163818, MSE = 0.022795842960476875, V_0_loss = tensor([[0.0054]], grad_fn=<PowBackward0>), V_pos_loss = 0.020013442263007164, Lv_loss = 0.0, Circular Tuning Loss = 1.1052666902542114\n",
      "2334) Lyapunov Risk = 0.8719353675842285, MSE = 0.022828388959169388, V_0_loss = tensor([[0.0054]], grad_fn=<PowBackward0>), V_pos_loss = 0.019953319802880287, Lv_loss = 0.0, Circular Tuning Loss = 1.1051218509674072\n",
      "2335) Lyapunov Risk = 0.8717787861824036, MSE = 0.02273128367960453, V_0_loss = tensor([[0.0054]], grad_fn=<PowBackward0>), V_pos_loss = 0.019893283024430275, Lv_loss = 0.0, Circular Tuning Loss = 1.1049766540527344\n",
      "2336) Lyapunov Risk = 0.8716201782226562, MSE = 0.022813960909843445, V_0_loss = tensor([[0.0054]], grad_fn=<PowBackward0>), V_pos_loss = 0.019833358004689217, Lv_loss = 0.0, Circular Tuning Loss = 1.1048316955566406\n",
      "2337) Lyapunov Risk = 0.8714615106582642, MSE = 0.022765669971704483, V_0_loss = tensor([[0.0054]], grad_fn=<PowBackward0>), V_pos_loss = 0.019773555919528008, Lv_loss = 0.0, Circular Tuning Loss = 1.1046868562698364\n",
      "2338) Lyapunov Risk = 0.8713041543960571, MSE = 0.022767294198274612, V_0_loss = tensor([[0.0054]], grad_fn=<PowBackward0>), V_pos_loss = 0.019713951274752617, Lv_loss = 0.0, Circular Tuning Loss = 1.1045422554016113\n",
      "2339) Lyapunov Risk = 0.8711475133895874, MSE = 0.022809509187936783, V_0_loss = tensor([[0.0054]], grad_fn=<PowBackward0>), V_pos_loss = 0.019654493778944016, Lv_loss = 0.0, Circular Tuning Loss = 1.1043978929519653\n",
      "2340) Lyapunov Risk = 0.8709903955459595, MSE = 0.022746972739696503, V_0_loss = tensor([[0.0054]], grad_fn=<PowBackward0>), V_pos_loss = 0.019595135003328323, Lv_loss = 0.0, Circular Tuning Loss = 1.104253888130188\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.0019531250000000004, 0]\n",
      "x2 : [-2.0000000000000004, -1.9980468750000004]\n",
      "==============================\n",
      "2341) Lyapunov Risk = 0.8758606910705566, MSE = 0.022790223360061646, V_0_loss = tensor([[0.0054]], grad_fn=<PowBackward0>), V_pos_loss = 0.019712314009666443, Lv_loss = 0.0, Circular Tuning Loss = 1.1136996746063232\n",
      "2342) Lyapunov Risk = 0.8757005929946899, MSE = 0.02274812012910843, V_0_loss = tensor([[0.0054]], grad_fn=<PowBackward0>), V_pos_loss = 0.01965181715786457, Lv_loss = 0.0, Circular Tuning Loss = 1.1135504245758057\n",
      "2343) Lyapunov Risk = 0.8755407929420471, MSE = 0.02274584025144577, V_0_loss = tensor([[0.0054]], grad_fn=<PowBackward0>), V_pos_loss = 0.019591160118579865, Lv_loss = 0.0, Circular Tuning Loss = 1.113400936126709\n",
      "2344) Lyapunov Risk = 0.875381350517273, MSE = 0.022763129323720932, V_0_loss = tensor([[0.0054]], grad_fn=<PowBackward0>), V_pos_loss = 0.019530370831489563, Lv_loss = 0.0, Circular Tuning Loss = 1.1132510900497437\n",
      "2345) Lyapunov Risk = 0.8752217292785645, MSE = 0.02271655946969986, V_0_loss = tensor([[0.0054]], grad_fn=<PowBackward0>), V_pos_loss = 0.019469477236270905, Lv_loss = 0.0, Circular Tuning Loss = 1.1131011247634888\n",
      "2346) Lyapunov Risk = 0.8750617504119873, MSE = 0.02272764779627323, V_0_loss = tensor([[0.0054]], grad_fn=<PowBackward0>), V_pos_loss = 0.01940849795937538, Lv_loss = 0.0, Circular Tuning Loss = 1.1129511594772339\n",
      "2347) Lyapunov Risk = 0.8749022483825684, MSE = 0.02274584397673607, V_0_loss = tensor([[0.0054]], grad_fn=<PowBackward0>), V_pos_loss = 0.01934754103422165, Lv_loss = 0.0, Circular Tuning Loss = 1.1128010749816895\n",
      "2348) Lyapunov Risk = 0.874742865562439, MSE = 0.02269427850842476, V_0_loss = tensor([[0.0054]], grad_fn=<PowBackward0>), V_pos_loss = 0.019286559894680977, Lv_loss = 0.0, Circular Tuning Loss = 1.1126513481140137\n",
      "2349) Lyapunov Risk = 0.8745828866958618, MSE = 0.022738924250006676, V_0_loss = tensor([[0.0054]], grad_fn=<PowBackward0>), V_pos_loss = 0.01922556944191456, Lv_loss = 0.0, Circular Tuning Loss = 1.1125015020370483\n",
      "2350) Lyapunov Risk = 0.8744235038757324, MSE = 0.022718315944075584, V_0_loss = tensor([[0.0054]], grad_fn=<PowBackward0>), V_pos_loss = 0.01916457898914814, Lv_loss = 0.0, Circular Tuning Loss = 1.1123522520065308\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.0019531250000000004, 0]\n",
      "x2 : [-2.0000000000000004, -1.9980468750000004]\n",
      "==============================\n",
      "2351) Lyapunov Risk = 0.8792258501052856, MSE = 0.022695766761898994, V_0_loss = tensor([[0.0055]], grad_fn=<PowBackward0>), V_pos_loss = 0.019267519935965538, Lv_loss = 0.0, Circular Tuning Loss = 1.1216851472854614\n",
      "2352) Lyapunov Risk = 0.8790623545646667, MSE = 0.022688785567879677, V_0_loss = tensor([[0.0055]], grad_fn=<PowBackward0>), V_pos_loss = 0.019205037504434586, Lv_loss = 0.0, Circular Tuning Loss = 1.1215310096740723\n",
      "2353) Lyapunov Risk = 0.878899097442627, MSE = 0.022691596299409866, V_0_loss = tensor([[0.0055]], grad_fn=<PowBackward0>), V_pos_loss = 0.01914226822555065, Lv_loss = 0.0, Circular Tuning Loss = 1.121376633644104\n",
      "2354) Lyapunov Risk = 0.8787362575531006, MSE = 0.022646592929959297, V_0_loss = tensor([[0.0055]], grad_fn=<PowBackward0>), V_pos_loss = 0.019079262390732765, Lv_loss = 0.0, Circular Tuning Loss = 1.1212223768234253\n",
      "2355) Lyapunov Risk = 0.8785734176635742, MSE = 0.02266986109316349, V_0_loss = tensor([[0.0055]], grad_fn=<PowBackward0>), V_pos_loss = 0.01901603490114212, Lv_loss = 0.0, Circular Tuning Loss = 1.1210684776306152\n",
      "2356) Lyapunov Risk = 0.8784102201461792, MSE = 0.02264186181128025, V_0_loss = tensor([[0.0055]], grad_fn=<PowBackward0>), V_pos_loss = 0.01895260438323021, Lv_loss = 0.0, Circular Tuning Loss = 1.1209146976470947\n",
      "2357) Lyapunov Risk = 0.8782472610473633, MSE = 0.02265174314379692, V_0_loss = tensor([[0.0055]], grad_fn=<PowBackward0>), V_pos_loss = 0.018889030441641808, Lv_loss = 0.0, Circular Tuning Loss = 1.120761513710022\n",
      "2358) Lyapunov Risk = 0.8780845403671265, MSE = 0.02264801412820816, V_0_loss = tensor([[0.0055]], grad_fn=<PowBackward0>), V_pos_loss = 0.01882534846663475, Lv_loss = 0.0, Circular Tuning Loss = 1.1206086874008179\n",
      "2359) Lyapunov Risk = 0.8779222369194031, MSE = 0.022661758586764336, V_0_loss = tensor([[0.0055]], grad_fn=<PowBackward0>), V_pos_loss = 0.01876155287027359, Lv_loss = 0.0, Circular Tuning Loss = 1.1204564571380615\n",
      "2360) Lyapunov Risk = 0.8777614831924438, MSE = 0.022629648447036743, V_0_loss = tensor([[0.0055]], grad_fn=<PowBackward0>), V_pos_loss = 0.018697701394557953, Lv_loss = 0.0, Circular Tuning Loss = 1.1203044652938843\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.0019531250000000004, 0]\n",
      "x2 : [-2.0000000000000004, -1.9980468750000004]\n",
      "==============================\n",
      "2361) Lyapunov Risk = 0.8824994564056396, MSE = 0.022670535370707512, V_0_loss = tensor([[0.0055]], grad_fn=<PowBackward0>), V_pos_loss = 0.018785282969474792, Lv_loss = 0.0, Circular Tuning Loss = 1.129528522491455\n",
      "2362) Lyapunov Risk = 0.8823385238647461, MSE = 0.02260008454322815, V_0_loss = tensor([[0.0055]], grad_fn=<PowBackward0>), V_pos_loss = 0.01871991902589798, Lv_loss = 0.0, Circular Tuning Loss = 1.129370927810669\n",
      "2363) Lyapunov Risk = 0.8821797370910645, MSE = 0.022643085569143295, V_0_loss = tensor([[0.0055]], grad_fn=<PowBackward0>), V_pos_loss = 0.018654219806194305, Lv_loss = 0.0, Circular Tuning Loss = 1.1292123794555664\n",
      "2364) Lyapunov Risk = 0.8820252418518066, MSE = 0.022603429853916168, V_0_loss = tensor([[0.0055]], grad_fn=<PowBackward0>), V_pos_loss = 0.018588274717330933, Lv_loss = 0.0, Circular Tuning Loss = 1.1290533542633057\n",
      "2365) Lyapunov Risk = 0.8818759322166443, MSE = 0.022617312148213387, V_0_loss = tensor([[0.0055]], grad_fn=<PowBackward0>), V_pos_loss = 0.0185221116989851, Lv_loss = 0.0, Circular Tuning Loss = 1.1288937330245972\n",
      "2366) Lyapunov Risk = 0.8817342519760132, MSE = 0.022594263777136803, V_0_loss = tensor([[0.0055]], grad_fn=<PowBackward0>), V_pos_loss = 0.01845584437251091, Lv_loss = 0.0, Circular Tuning Loss = 1.1287338733673096\n",
      "2367) Lyapunov Risk = 0.881603479385376, MSE = 0.02266748435795307, V_0_loss = tensor([[0.0055]], grad_fn=<PowBackward0>), V_pos_loss = 0.018389428034424782, Lv_loss = 0.0, Circular Tuning Loss = 1.1285735368728638\n",
      "2368) Lyapunov Risk = 0.8814863562583923, MSE = 0.02259620651602745, V_0_loss = tensor([[0.0055]], grad_fn=<PowBackward0>), V_pos_loss = 0.018322987481951714, Lv_loss = 0.0, Circular Tuning Loss = 1.1284130811691284\n",
      "2369) Lyapunov Risk = 0.8813871145248413, MSE = 0.022726409137248993, V_0_loss = tensor([[0.0055]], grad_fn=<PowBackward0>), V_pos_loss = 0.018256397917866707, Lv_loss = 0.0, Circular Tuning Loss = 1.128252625465393\n",
      "2370) Lyapunov Risk = 0.8813104033470154, MSE = 0.022646838799118996, V_0_loss = tensor([[0.0055]], grad_fn=<PowBackward0>), V_pos_loss = 0.018189841881394386, Lv_loss = 0.0, Circular Tuning Loss = 1.1280919313430786\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.0019531250000000004, 0]\n",
      "x2 : [-2.0000000000000004, -1.9980468750000004]\n",
      "==============================\n",
      "2371) Lyapunov Risk = 0.8860835433006287, MSE = 0.02278500609099865, V_0_loss = tensor([[0.0055]], grad_fn=<PowBackward0>), V_pos_loss = 0.01826154626905918, Lv_loss = 0.0, Circular Tuning Loss = 1.1371983289718628\n",
      "2372) Lyapunov Risk = 0.8860428333282471, MSE = 0.02267128974199295, V_0_loss = tensor([[0.0056]], grad_fn=<PowBackward0>), V_pos_loss = 0.018193315714597702, Lv_loss = 0.0, Circular Tuning Loss = 1.1370309591293335\n",
      "2373) Lyapunov Risk = 0.8859935998916626, MSE = 0.022876594215631485, V_0_loss = tensor([[0.0056]], grad_fn=<PowBackward0>), V_pos_loss = 0.018124597147107124, Lv_loss = 0.0, Circular Tuning Loss = 1.1368627548217773\n",
      "2374) Lyapunov Risk = 0.8859094977378845, MSE = 0.02269422449171543, V_0_loss = tensor([[0.0056]], grad_fn=<PowBackward0>), V_pos_loss = 0.01805570162832737, Lv_loss = 0.0, Circular Tuning Loss = 1.1366939544677734\n",
      "2375) Lyapunov Risk = 0.885741651058197, MSE = 0.022884037345647812, V_0_loss = tensor([[0.0056]], grad_fn=<PowBackward0>), V_pos_loss = 0.017986387014389038, Lv_loss = 0.0, Circular Tuning Loss = 1.1365243196487427\n",
      "2376) Lyapunov Risk = 0.8854715824127197, MSE = 0.022660445421934128, V_0_loss = tensor([[0.0056]], grad_fn=<PowBackward0>), V_pos_loss = 0.017916979268193245, Lv_loss = 0.0, Circular Tuning Loss = 1.1363544464111328\n",
      "2377) Lyapunov Risk = 0.8851015567779541, MSE = 0.022770142182707787, V_0_loss = tensor([[0.0056]], grad_fn=<PowBackward0>), V_pos_loss = 0.01784723810851574, Lv_loss = 0.0, Circular Tuning Loss = 1.1361842155456543\n",
      "2378) Lyapunov Risk = 0.8846948146820068, MSE = 0.02253819815814495, V_0_loss = tensor([[0.0056]], grad_fn=<PowBackward0>), V_pos_loss = 0.017777519300580025, Lv_loss = 0.0, Circular Tuning Loss = 1.1360139846801758\n",
      "2379) Lyapunov Risk = 0.8843241333961487, MSE = 0.02260269783437252, V_0_loss = tensor([[0.0056]], grad_fn=<PowBackward0>), V_pos_loss = 0.01770763099193573, Lv_loss = 0.0, Circular Tuning Loss = 1.1358436346054077\n",
      "2380) Lyapunov Risk = 0.8840528130531311, MSE = 0.02250305935740471, V_0_loss = tensor([[0.0056]], grad_fn=<PowBackward0>), V_pos_loss = 0.017637724056839943, Lv_loss = 0.0, Circular Tuning Loss = 1.1356735229492188\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.0019531250000000004, 0]\n",
      "x2 : [-2.0000000000000004, -1.9980468750000004]\n",
      "==============================\n",
      "2381) Lyapunov Risk = 0.8886527419090271, MSE = 0.02250172384083271, V_0_loss = tensor([[0.0056]], grad_fn=<PowBackward0>), V_pos_loss = 0.01769302412867546, Lv_loss = 0.0, Circular Tuning Loss = 1.1446586847305298\n",
      "2382) Lyapunov Risk = 0.8885613679885864, MSE = 0.022573431953787804, V_0_loss = tensor([[0.0056]], grad_fn=<PowBackward0>), V_pos_loss = 0.017621364444494247, Lv_loss = 0.0, Circular Tuning Loss = 1.1444827318191528\n",
      "2383) Lyapunov Risk = 0.8884879350662231, MSE = 0.02249925397336483, V_0_loss = tensor([[0.0056]], grad_fn=<PowBackward0>), V_pos_loss = 0.01754944585263729, Lv_loss = 0.0, Circular Tuning Loss = 1.1443064212799072\n",
      "2384) Lyapunov Risk = 0.8883779644966125, MSE = 0.022636035457253456, V_0_loss = tensor([[0.0056]], grad_fn=<PowBackward0>), V_pos_loss = 0.017477136105298996, Lv_loss = 0.0, Circular Tuning Loss = 1.1441293954849243\n",
      "2385) Lyapunov Risk = 0.8882016539573669, MSE = 0.02248932421207428, V_0_loss = tensor([[0.0056]], grad_fn=<PowBackward0>), V_pos_loss = 0.01740465685725212, Lv_loss = 0.0, Circular Tuning Loss = 1.1439523696899414\n",
      "2386) Lyapunov Risk = 0.8879604339599609, MSE = 0.02258598431944847, V_0_loss = tensor([[0.0056]], grad_fn=<PowBackward0>), V_pos_loss = 0.017331859096884727, Lv_loss = 0.0, Circular Tuning Loss = 1.1437748670578003\n",
      "2387) Lyapunov Risk = 0.8876875042915344, MSE = 0.02245585434138775, V_0_loss = tensor([[0.0056]], grad_fn=<PowBackward0>), V_pos_loss = 0.017258955165743828, Lv_loss = 0.0, Circular Tuning Loss = 1.14359712600708\n",
      "2388) Lyapunov Risk = 0.8874229192733765, MSE = 0.022498128935694695, V_0_loss = tensor([[0.0056]], grad_fn=<PowBackward0>), V_pos_loss = 0.017185857519507408, Lv_loss = 0.0, Circular Tuning Loss = 1.1434193849563599\n",
      "2389) Lyapunov Risk = 0.887198805809021, MSE = 0.022456128150224686, V_0_loss = tensor([[0.0056]], grad_fn=<PowBackward0>), V_pos_loss = 0.01711273565888405, Lv_loss = 0.0, Circular Tuning Loss = 1.1432416439056396\n",
      "2390) Lyapunov Risk = 0.8870229721069336, MSE = 0.022456463426351547, V_0_loss = tensor([[0.0056]], grad_fn=<PowBackward0>), V_pos_loss = 0.01703954115509987, Lv_loss = 0.0, Circular Tuning Loss = 1.1430641412734985\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.0019531250000000004, 0]\n",
      "x2 : [-2.0000000000000004, -1.9980468750000004]\n",
      "==============================\n",
      "2391) Lyapunov Risk = 0.8915734887123108, MSE = 0.02250189147889614, V_0_loss = tensor([[0.0057]], grad_fn=<PowBackward0>), V_pos_loss = 0.017077811062335968, Lv_loss = 0.0, Circular Tuning Loss = 1.1519302129745483\n",
      "2392) Lyapunov Risk = 0.8914347290992737, MSE = 0.022430457174777985, V_0_loss = tensor([[0.0057]], grad_fn=<PowBackward0>), V_pos_loss = 0.01700286567211151, Lv_loss = 0.0, Circular Tuning Loss = 1.1517462730407715\n",
      "2393) Lyapunov Risk = 0.8912796378135681, MSE = 0.022525284439325333, V_0_loss = tensor([[0.0057]], grad_fn=<PowBackward0>), V_pos_loss = 0.016927532851696014, Lv_loss = 0.0, Circular Tuning Loss = 1.1515614986419678\n",
      "2394) Lyapunov Risk = 0.8910977840423584, MSE = 0.022419648244976997, V_0_loss = tensor([[0.0057]], grad_fn=<PowBackward0>), V_pos_loss = 0.016851970925927162, Lv_loss = 0.0, Circular Tuning Loss = 1.1513761281967163\n",
      "2395) Lyapunov Risk = 0.8908888697624207, MSE = 0.022481651976704597, V_0_loss = tensor([[0.0057]], grad_fn=<PowBackward0>), V_pos_loss = 0.016776254400610924, Lv_loss = 0.0, Circular Tuning Loss = 1.151190161705017\n",
      "2396) Lyapunov Risk = 0.8906664848327637, MSE = 0.02240121178328991, V_0_loss = tensor([[0.0057]], grad_fn=<PowBackward0>), V_pos_loss = 0.016700400039553642, Lv_loss = 0.0, Circular Tuning Loss = 1.1510037183761597\n",
      "2397) Lyapunov Risk = 0.8904457688331604, MSE = 0.022441454231739044, V_0_loss = tensor([[0.0057]], grad_fn=<PowBackward0>), V_pos_loss = 0.016624407842755318, Lv_loss = 0.0, Circular Tuning Loss = 1.1508169174194336\n",
      "2398) Lyapunov Risk = 0.8902390003204346, MSE = 0.022397033870220184, V_0_loss = tensor([[0.0057]], grad_fn=<PowBackward0>), V_pos_loss = 0.016548361629247665, Lv_loss = 0.0, Circular Tuning Loss = 1.1506301164627075\n",
      "2399) Lyapunov Risk = 0.890049934387207, MSE = 0.022428641095757484, V_0_loss = tensor([[0.0057]], grad_fn=<PowBackward0>), V_pos_loss = 0.016472365707159042, Lv_loss = 0.0, Circular Tuning Loss = 1.1504428386688232\n",
      "2400) Lyapunov Risk = 0.8898751139640808, MSE = 0.02243281714618206, V_0_loss = tensor([[0.0057]], grad_fn=<PowBackward0>), V_pos_loss = 0.016396397724747658, Lv_loss = 0.0, Circular Tuning Loss = 1.1502554416656494\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.0019531250000000004, 0]\n",
      "x2 : [-2.0000000000000004, -1.9980468750000004]\n",
      "==============================\n",
      "2401) Lyapunov Risk = 0.8943327069282532, MSE = 0.02239750139415264, V_0_loss = tensor([[0.0057]], grad_fn=<PowBackward0>), V_pos_loss = 0.016418172046542168, Lv_loss = 0.0, Circular Tuning Loss = 1.159002661705017\n",
      "2402) Lyapunov Risk = 0.8941587805747986, MSE = 0.022440897300839424, V_0_loss = tensor([[0.0057]], grad_fn=<PowBackward0>), V_pos_loss = 0.016340618953108788, Lv_loss = 0.0, Circular Tuning Loss = 1.1588079929351807\n",
      "2403) Lyapunov Risk = 0.8939775228500366, MSE = 0.022378528490662575, V_0_loss = tensor([[0.0057]], grad_fn=<PowBackward0>), V_pos_loss = 0.016262825578451157, Lv_loss = 0.0, Circular Tuning Loss = 1.1586124897003174\n",
      "2404) Lyapunov Risk = 0.8937865495681763, MSE = 0.022408369928598404, V_0_loss = tensor([[0.0057]], grad_fn=<PowBackward0>), V_pos_loss = 0.01618478074669838, Lv_loss = 0.0, Circular Tuning Loss = 1.1584160327911377\n",
      "2405) Lyapunov Risk = 0.8935885429382324, MSE = 0.022355196997523308, V_0_loss = tensor([[0.0057]], grad_fn=<PowBackward0>), V_pos_loss = 0.016106609255075455, Lv_loss = 0.0, Circular Tuning Loss = 1.1582189798355103\n",
      "2406) Lyapunov Risk = 0.8933864831924438, MSE = 0.022384723648428917, V_0_loss = tensor([[0.0057]], grad_fn=<PowBackward0>), V_pos_loss = 0.016028324142098427, Lv_loss = 0.0, Circular Tuning Loss = 1.1580215692520142\n",
      "2407) Lyapunov Risk = 0.8931844830513, MSE = 0.02234629914164543, V_0_loss = tensor([[0.0057]], grad_fn=<PowBackward0>), V_pos_loss = 0.015949998050928116, Lv_loss = 0.0, Circular Tuning Loss = 1.1578236818313599\n",
      "2408) Lyapunov Risk = 0.8929861187934875, MSE = 0.022370731458067894, V_0_loss = tensor([[0.0058]], grad_fn=<PowBackward0>), V_pos_loss = 0.01587158441543579, Lv_loss = 0.0, Circular Tuning Loss = 1.1576259136199951\n",
      "2409) Lyapunov Risk = 0.8927931785583496, MSE = 0.022359555587172508, V_0_loss = tensor([[0.0058]], grad_fn=<PowBackward0>), V_pos_loss = 0.01579328067600727, Lv_loss = 0.0, Circular Tuning Loss = 1.1574281454086304\n",
      "2410) Lyapunov Risk = 0.8926052451133728, MSE = 0.022355886176228523, V_0_loss = tensor([[0.0058]], grad_fn=<PowBackward0>), V_pos_loss = 0.015714986249804497, Lv_loss = 0.0, Circular Tuning Loss = 1.1572306156158447\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.0019531250000000004, 0]\n",
      "x2 : [-2.0000000000000004, -1.9980468750000004]\n",
      "==============================\n",
      "2411) Lyapunov Risk = 0.8969781398773193, MSE = 0.022368386387825012, V_0_loss = tensor([[0.0058]], grad_fn=<PowBackward0>), V_pos_loss = 0.015720607712864876, Lv_loss = 0.0, Circular Tuning Loss = 1.165859580039978\n",
      "2412) Lyapunov Risk = 0.8967899084091187, MSE = 0.02231914922595024, V_0_loss = tensor([[0.0058]], grad_fn=<PowBackward0>), V_pos_loss = 0.015640607103705406, Lv_loss = 0.0, Circular Tuning Loss = 1.165655493736267\n",
      "2413) Lyapunov Risk = 0.8966008424758911, MSE = 0.022350924089550972, V_0_loss = tensor([[0.0058]], grad_fn=<PowBackward0>), V_pos_loss = 0.015560259111225605, Lv_loss = 0.0, Circular Tuning Loss = 1.1654510498046875\n",
      "2414) Lyapunov Risk = 0.8964098691940308, MSE = 0.022309323772788048, V_0_loss = tensor([[0.0058]], grad_fn=<PowBackward0>), V_pos_loss = 0.015479668974876404, Lv_loss = 0.0, Circular Tuning Loss = 1.1652461290359497\n",
      "2415) Lyapunov Risk = 0.8962163925170898, MSE = 0.02230919525027275, V_0_loss = tensor([[0.0058]], grad_fn=<PowBackward0>), V_pos_loss = 0.015398853458464146, Lv_loss = 0.0, Circular Tuning Loss = 1.1650406122207642\n",
      "2416) Lyapunov Risk = 0.8960206508636475, MSE = 0.022301703691482544, V_0_loss = tensor([[0.0058]], grad_fn=<PowBackward0>), V_pos_loss = 0.015317901037633419, Lv_loss = 0.0, Circular Tuning Loss = 1.164834976196289\n",
      "2417) Lyapunov Risk = 0.8958230018615723, MSE = 0.022308938205242157, V_0_loss = tensor([[0.0058]], grad_fn=<PowBackward0>), V_pos_loss = 0.015236795879900455, Lv_loss = 0.0, Circular Tuning Loss = 1.1646289825439453\n",
      "2418) Lyapunov Risk = 0.8956251740455627, MSE = 0.02228667587041855, V_0_loss = tensor([[0.0058]], grad_fn=<PowBackward0>), V_pos_loss = 0.01515563391149044, Lv_loss = 0.0, Circular Tuning Loss = 1.1644229888916016\n",
      "2419) Lyapunov Risk = 0.8954277038574219, MSE = 0.022323567420244217, V_0_loss = tensor([[0.0058]], grad_fn=<PowBackward0>), V_pos_loss = 0.015074447728693485, Lv_loss = 0.0, Circular Tuning Loss = 1.1642169952392578\n",
      "2420) Lyapunov Risk = 0.8952311277389526, MSE = 0.022293994203209877, V_0_loss = tensor([[0.0058]], grad_fn=<PowBackward0>), V_pos_loss = 0.014993301592767239, Lv_loss = 0.0, Circular Tuning Loss = 1.1640113592147827\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.020625000000000004, -0.010625000000000002]\n",
      "x2 : [-0.98937500000000023, -0.97937500000000022]\n",
      "==============================\n",
      "2421) Lyapunov Risk = 0.8948853015899658, MSE = 0.022301021963357925, V_0_loss = tensor([[0.0058]], grad_fn=<PowBackward0>), V_pos_loss = 0.014940867200493813, Lv_loss = 0.0, Circular Tuning Loss = 1.163370132446289\n",
      "2422) Lyapunov Risk = 0.8946893215179443, MSE = 0.022281639277935028, V_0_loss = tensor([[0.0058]], grad_fn=<PowBackward0>), V_pos_loss = 0.014858958311378956, Lv_loss = 0.0, Circular Tuning Loss = 1.1631624698638916\n",
      "2423) Lyapunov Risk = 0.894494354724884, MSE = 0.022271785885095596, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.014777075499296188, Lv_loss = 0.0, Circular Tuning Loss = 1.1629544496536255\n",
      "2424) Lyapunov Risk = 0.8943002223968506, MSE = 0.022261645644903183, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.014695125631988049, Lv_loss = 0.0, Circular Tuning Loss = 1.1627463102340698\n",
      "2425) Lyapunov Risk = 0.8941068053245544, MSE = 0.022240692749619484, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.014613291248679161, Lv_loss = 0.0, Circular Tuning Loss = 1.1625381708145142\n",
      "2426) Lyapunov Risk = 0.8939138650894165, MSE = 0.02225232869386673, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.014531601220369339, Lv_loss = 0.0, Circular Tuning Loss = 1.1623300313949585\n",
      "2427) Lyapunov Risk = 0.893721342086792, MSE = 0.02223130129277706, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.014449997805058956, Lv_loss = 0.0, Circular Tuning Loss = 1.162122130393982\n",
      "2428) Lyapunov Risk = 0.893528938293457, MSE = 0.022255033254623413, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.014368453994393349, Lv_loss = 0.0, Circular Tuning Loss = 1.1619142293930054\n",
      "2429) Lyapunov Risk = 0.8933369517326355, MSE = 0.022239917889237404, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.014287007041275501, Lv_loss = 0.0, Circular Tuning Loss = 1.1617069244384766\n",
      "2430) Lyapunov Risk = 0.8931452035903931, MSE = 0.022257454693317413, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.014205641113221645, Lv_loss = 0.0, Circular Tuning Loss = 1.1614998579025269\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.012812500000000001, -0.0028125000000000016]\n",
      "x2 : [-0.98937500000000023, -0.97937500000000022]\n",
      "==============================\n",
      "2431) Lyapunov Risk = 0.8928015828132629, MSE = 0.022237049415707588, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.014149741269648075, Lv_loss = 0.0, Circular Tuning Loss = 1.1608705520629883\n",
      "2432) Lyapunov Risk = 0.8926081657409668, MSE = 0.022229576483368874, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.014067742973566055, Lv_loss = 0.0, Circular Tuning Loss = 1.160662293434143\n",
      "2433) Lyapunov Risk = 0.8924151659011841, MSE = 0.02221890538930893, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.013985815457999706, Lv_loss = 0.0, Circular Tuning Loss = 1.1604541540145874\n",
      "2434) Lyapunov Risk = 0.8922226428985596, MSE = 0.022217165678739548, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.013904070481657982, Lv_loss = 0.0, Circular Tuning Loss = 1.1602461338043213\n",
      "2435) Lyapunov Risk = 0.8920308351516724, MSE = 0.02217717468738556, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.013822526670992374, Lv_loss = 0.0, Circular Tuning Loss = 1.1600384712219238\n",
      "2436) Lyapunov Risk = 0.891839861869812, MSE = 0.022217895835638046, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.013741209171712399, Lv_loss = 0.0, Circular Tuning Loss = 1.1598312854766846\n",
      "2437) Lyapunov Risk = 0.8916500210762024, MSE = 0.022168263792991638, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.013660094700753689, Lv_loss = 0.0, Circular Tuning Loss = 1.159624695777893\n",
      "2438) Lyapunov Risk = 0.8914613127708435, MSE = 0.022215088829398155, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.013579113408923149, Lv_loss = 0.0, Circular Tuning Loss = 1.1594187021255493\n",
      "2439) Lyapunov Risk = 0.8912746906280518, MSE = 0.022192228585481644, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.013498357497155666, Lv_loss = 0.0, Circular Tuning Loss = 1.1592133045196533\n",
      "2440) Lyapunov Risk = 0.891089916229248, MSE = 0.022216644138097763, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.013417779467999935, Lv_loss = 0.0, Circular Tuning Loss = 1.159008502960205\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.012812500000000001, -0.0028125000000000016]\n",
      "x2 : [-0.98937500000000023, -0.97937500000000022]\n",
      "==============================\n",
      "2441) Lyapunov Risk = 0.8907360434532166, MSE = 0.02219477668404579, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.013353729620575905, Lv_loss = 0.0, Circular Tuning Loss = 1.158364176750183\n",
      "2442) Lyapunov Risk = 0.8905557990074158, MSE = 0.02221427857875824, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.0132726626470685, Lv_loss = 0.0, Circular Tuning Loss = 1.158158779144287\n",
      "2443) Lyapunov Risk = 0.8903806209564209, MSE = 0.02217268943786621, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.013191690668463707, Lv_loss = 0.0, Circular Tuning Loss = 1.1579535007476807\n",
      "2444) Lyapunov Risk = 0.8902119994163513, MSE = 0.022224007174372673, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.013110718689858913, Lv_loss = 0.0, Circular Tuning Loss = 1.1577485799789429\n",
      "2445) Lyapunov Risk = 0.8900521993637085, MSE = 0.022155480459332466, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.013029900379478931, Lv_loss = 0.0, Circular Tuning Loss = 1.1575438976287842\n",
      "2446) Lyapunov Risk = 0.8899036049842834, MSE = 0.02224387414753437, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.012949113734066486, Lv_loss = 0.0, Circular Tuning Loss = 1.1573394536972046\n",
      "2447) Lyapunov Risk = 0.8897695541381836, MSE = 0.022186074405908585, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.012868567369878292, Lv_loss = 0.0, Circular Tuning Loss = 1.1571356058120728\n",
      "2448) Lyapunov Risk = 0.8896529078483582, MSE = 0.02229064516723156, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.012788044288754463, Lv_loss = 0.0, Circular Tuning Loss = 1.15693199634552\n",
      "2449) Lyapunov Risk = 0.8895559906959534, MSE = 0.022239087149500847, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.012707835994660854, Lv_loss = 0.0, Circular Tuning Loss = 1.1567291021347046\n",
      "2450) Lyapunov Risk = 0.8894744515419006, MSE = 0.022376399487257004, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.012627709656953812, Lv_loss = 0.0, Circular Tuning Loss = 1.1565266847610474\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.012812500000000001, -0.0028125000000000016]\n",
      "x2 : [-0.99718750000000023, -0.98718750000000022]\n",
      "==============================\n",
      "2451) Lyapunov Risk = 0.8892412185668945, MSE = 0.02228645794093609, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.012558029033243656, Lv_loss = 0.0, Circular Tuning Loss = 1.1559274196624756\n",
      "2452) Lyapunov Risk = 0.8891530632972717, MSE = 0.022436881437897682, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.012477174401283264, Lv_loss = 0.0, Circular Tuning Loss = 1.155724048614502\n",
      "2453) Lyapunov Risk = 0.889031171798706, MSE = 0.022320548072457314, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.012396590784192085, Lv_loss = 0.0, Circular Tuning Loss = 1.1555205583572388\n",
      "2454) Lyapunov Risk = 0.8888343572616577, MSE = 0.022435594350099564, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.012315905652940273, Lv_loss = 0.0, Circular Tuning Loss = 1.1553165912628174\n",
      "2455) Lyapunov Risk = 0.8885509371757507, MSE = 0.022263946011662483, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.012235546484589577, Lv_loss = 0.0, Circular Tuning Loss = 1.1551127433776855\n",
      "2456) Lyapunov Risk = 0.8881796598434448, MSE = 0.022335141897201538, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.012155109085142612, Lv_loss = 0.0, Circular Tuning Loss = 1.1549084186553955\n",
      "2457) Lyapunov Risk = 0.887773871421814, MSE = 0.022145647555589676, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.012074988335371017, Lv_loss = 0.0, Circular Tuning Loss = 1.1547044515609741\n",
      "2458) Lyapunov Risk = 0.8873946070671082, MSE = 0.022178588435053825, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.011994938366115093, Lv_loss = 0.0, Circular Tuning Loss = 1.1545006036758423\n",
      "2459) Lyapunov Risk = 0.8870959281921387, MSE = 0.022096671164035797, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.011915214359760284, Lv_loss = 0.0, Circular Tuning Loss = 1.1542969942092896\n",
      "2460) Lyapunov Risk = 0.8868944644927979, MSE = 0.022099541500210762, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.011835647746920586, Lv_loss = 0.0, Circular Tuning Loss = 1.1540937423706055\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.0039062500000000009, 0]\n",
      "x2 : [-0.75000000000000022, -0.74218750000000022]\n",
      "==============================\n",
      "2461) Lyapunov Risk = 0.8859032392501831, MSE = 0.0221504308283329, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.011722413823008537, Lv_loss = 0.0, Circular Tuning Loss = 1.152165412902832\n",
      "2462) Lyapunov Risk = 0.8858092427253723, MSE = 0.022095801308751106, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.011643517762422562, Lv_loss = 0.0, Circular Tuning Loss = 1.1519628763198853\n",
      "2463) Lyapunov Risk = 0.8857009410858154, MSE = 0.022203965112566948, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.011564759537577629, Lv_loss = 0.0, Circular Tuning Loss = 1.1517605781555176\n",
      "2464) Lyapunov Risk = 0.8855466842651367, MSE = 0.022117609158158302, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.011486372910439968, Lv_loss = 0.0, Circular Tuning Loss = 1.1515591144561768\n",
      "2465) Lyapunov Risk = 0.885335385799408, MSE = 0.02216629683971405, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.011408033780753613, Lv_loss = 0.0, Circular Tuning Loss = 1.1513581275939941\n",
      "2466) Lyapunov Risk = 0.8850804567337036, MSE = 0.022091025486588478, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.011330017820000648, Lv_loss = 0.0, Circular Tuning Loss = 1.151158094406128\n",
      "2467) Lyapunov Risk = 0.8848100900650024, MSE = 0.022103123366832733, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.011252084746956825, Lv_loss = 0.0, Circular Tuning Loss = 1.15095853805542\n",
      "2468) Lyapunov Risk = 0.8845552206039429, MSE = 0.022046353667974472, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.011174442246556282, Lv_loss = 0.0, Circular Tuning Loss = 1.1507601737976074\n",
      "2469) Lyapunov Risk = 0.8843362331390381, MSE = 0.022071553394198418, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.011097013019025326, Lv_loss = 0.0, Circular Tuning Loss = 1.1505622863769531\n",
      "2470) Lyapunov Risk = 0.8841552138328552, MSE = 0.02205238863825798, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.011019918136298656, Lv_loss = 0.0, Circular Tuning Loss = 1.1503649950027466\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.0078125000000000017, 0]\n",
      "x2 : [-0.99718750000000023, -0.98718750000000022]\n",
      "==============================\n",
      "2471) Lyapunov Risk = 0.883808434009552, MSE = 0.022068357095122337, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.010939277708530426, Lv_loss = 0.0, Circular Tuning Loss = 1.1497461795806885\n",
      "2472) Lyapunov Risk = 0.8836592435836792, MSE = 0.022066520527005196, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.01086171343922615, Lv_loss = 0.0, Circular Tuning Loss = 1.1495481729507446\n",
      "2473) Lyapunov Risk = 0.8835008144378662, MSE = 0.022068113088607788, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.010784304700791836, Lv_loss = 0.0, Circular Tuning Loss = 1.1493505239486694\n",
      "2474) Lyapunov Risk = 0.8833236694335938, MSE = 0.0220713559538126, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.01070689968764782, Lv_loss = 0.0, Circular Tuning Loss = 1.1491531133651733\n",
      "2475) Lyapunov Risk = 0.8831258416175842, MSE = 0.02203170768916607, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.010629784315824509, Lv_loss = 0.0, Circular Tuning Loss = 1.1489559412002563\n",
      "2476) Lyapunov Risk = 0.8829140663146973, MSE = 0.022076517343521118, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.010552946478128433, Lv_loss = 0.0, Circular Tuning Loss = 1.148759365081787\n",
      "2477) Lyapunov Risk = 0.8826980590820312, MSE = 0.021996013820171356, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.010476376861333847, Lv_loss = 0.0, Circular Tuning Loss = 1.1485635042190552\n",
      "2478) Lyapunov Risk = 0.8824869394302368, MSE = 0.022052999585866928, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.010399899445474148, Lv_loss = 0.0, Circular Tuning Loss = 1.1483678817749023\n",
      "2479) Lyapunov Risk = 0.8822876214981079, MSE = 0.022018546238541603, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.010323637165129185, Lv_loss = 0.0, Circular Tuning Loss = 1.148173213005066\n",
      "2480) Lyapunov Risk = 0.8821015954017639, MSE = 0.022007549181580544, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.010247539728879929, Lv_loss = 0.0, Circular Tuning Loss = 1.1479792594909668\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.0019531250000000004, 0]\n",
      "x2 : [-2.0000000000000004, -1.9980468750000004]\n",
      "==============================\n",
      "2481) Lyapunov Risk = 0.8860912919044495, MSE = 0.022048506885766983, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.010159950703382492, Lv_loss = 0.0, Circular Tuning Loss = 1.1560125350952148\n",
      "2482) Lyapunov Risk = 0.885916531085968, MSE = 0.021973537281155586, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.010082573629915714, Lv_loss = 0.0, Circular Tuning Loss = 1.155813217163086\n",
      "2483) Lyapunov Risk = 0.8857409358024597, MSE = 0.022028125822544098, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.010005014017224312, Lv_loss = 0.0, Circular Tuning Loss = 1.1556133031845093\n",
      "2484) Lyapunov Risk = 0.8855613470077515, MSE = 0.021989047527313232, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.009927386417984962, Lv_loss = 0.0, Circular Tuning Loss = 1.1554126739501953\n",
      "2485) Lyapunov Risk = 0.8853762745857239, MSE = 0.02198251150548458, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.009849636815488338, Lv_loss = 0.0, Circular Tuning Loss = 1.1552119255065918\n",
      "2486) Lyapunov Risk = 0.8851855993270874, MSE = 0.021997757256031036, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.009771906770765781, Lv_loss = 0.0, Circular Tuning Loss = 1.1550105810165405\n",
      "2487) Lyapunov Risk = 0.8849902153015137, MSE = 0.021980518475174904, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.00969410128891468, Lv_loss = 0.0, Circular Tuning Loss = 1.1548092365264893\n",
      "2488) Lyapunov Risk = 0.8847936391830444, MSE = 0.02196870557963848, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.009616565890610218, Lv_loss = 0.0, Circular Tuning Loss = 1.154607892036438\n",
      "2489) Lyapunov Risk = 0.8845981359481812, MSE = 0.022005517035722733, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.009539351798593998, Lv_loss = 0.0, Circular Tuning Loss = 1.1544067859649658\n",
      "2490) Lyapunov Risk = 0.8844048380851746, MSE = 0.02194844000041485, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.00946259405463934, Lv_loss = 0.0, Circular Tuning Loss = 1.1542062759399414\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.026837625177582741, -0.019104872204627317]\n",
      "x2 : [-1.9034375000000003, -1.8934375000000006]\n",
      "==============================\n",
      "2491) Lyapunov Risk = 0.8877360224723816, MSE = 0.02199687995016575, V_0_loss = tensor([[0.0063]], grad_fn=<PowBackward0>), V_pos_loss = 0.009359306655824184, Lv_loss = 0.0, Circular Tuning Loss = 1.160980224609375\n",
      "2492) Lyapunov Risk = 0.8875461220741272, MSE = 0.021939262747764587, V_0_loss = tensor([[0.0063]], grad_fn=<PowBackward0>), V_pos_loss = 0.009283240884542465, Lv_loss = 0.0, Circular Tuning Loss = 1.160775899887085\n",
      "2493) Lyapunov Risk = 0.8873729705810547, MSE = 0.02195005491375923, V_0_loss = tensor([[0.0063]], grad_fn=<PowBackward0>), V_pos_loss = 0.009221171960234642, Lv_loss = 0.0, Circular Tuning Loss = 1.1605716943740845\n",
      "2494) Lyapunov Risk = 0.8872266411781311, MSE = 0.021942894905805588, V_0_loss = tensor([[0.0063]], grad_fn=<PowBackward0>), V_pos_loss = 0.009183994494378567, Lv_loss = 0.0, Circular Tuning Loss = 1.1603814363479614\n",
      "2495) Lyapunov Risk = 0.8870841264724731, MSE = 0.021909628063440323, V_0_loss = tensor([[0.0063]], grad_fn=<PowBackward0>), V_pos_loss = 0.009149222634732723, Lv_loss = 0.0, Circular Tuning Loss = 1.1602059602737427\n",
      "2496) Lyapunov Risk = 0.8869439959526062, MSE = 0.021935196593403816, V_0_loss = tensor([[0.0063]], grad_fn=<PowBackward0>), V_pos_loss = 0.00911635160446167, Lv_loss = 0.0, Circular Tuning Loss = 1.1600439548492432\n",
      "2497) Lyapunov Risk = 0.8868058919906616, MSE = 0.02192232944071293, V_0_loss = tensor([[0.0063]], grad_fn=<PowBackward0>), V_pos_loss = 0.009085429832339287, Lv_loss = 0.0, Circular Tuning Loss = 1.159894347190857\n",
      "2498) Lyapunov Risk = 0.8866697549819946, MSE = 0.02191729098558426, V_0_loss = tensor([[0.0063]], grad_fn=<PowBackward0>), V_pos_loss = 0.009056147187948227, Lv_loss = 0.0, Circular Tuning Loss = 1.1597561836242676\n",
      "2499) Lyapunov Risk = 0.8865347504615784, MSE = 0.021949395537376404, V_0_loss = tensor([[0.0063]], grad_fn=<PowBackward0>), V_pos_loss = 0.009028410539031029, Lv_loss = 0.0, Circular Tuning Loss = 1.1596286296844482\n",
      "2500) Lyapunov Risk = 0.8864007592201233, MSE = 0.021917099133133888, V_0_loss = tensor([[0.0063]], grad_fn=<PowBackward0>), V_pos_loss = 0.00900196935981512, Lv_loss = 0.0, Circular Tuning Loss = 1.1595107316970825\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.0081782013272046535, 0]\n",
      "x2 : [-1.9190625000000003, -1.9090625000000006]\n",
      "==============================\n",
      "2501) Lyapunov Risk = 0.8898509740829468, MSE = 0.02193981595337391, V_0_loss = tensor([[0.0063]], grad_fn=<PowBackward0>), V_pos_loss = 0.008951186202466488, Lv_loss = 0.0, Circular Tuning Loss = 1.1665021181106567\n",
      "2502) Lyapunov Risk = 0.8897172212600708, MSE = 0.021918561309576035, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.008926997892558575, Lv_loss = 0.0, Circular Tuning Loss = 1.1663974523544312\n",
      "2503) Lyapunov Risk = 0.8895836472511292, MSE = 0.021914534270763397, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.008903613314032555, Lv_loss = 0.0, Circular Tuning Loss = 1.166299819946289\n",
      "2504) Lyapunov Risk = 0.8894506692886353, MSE = 0.0219254270195961, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.00888089556246996, Lv_loss = 0.0, Circular Tuning Loss = 1.1662083864212036\n",
      "2505) Lyapunov Risk = 0.8893182277679443, MSE = 0.02188020385801792, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.00885881669819355, Lv_loss = 0.0, Circular Tuning Loss = 1.1661227941513062\n",
      "2506) Lyapunov Risk = 0.8891865015029907, MSE = 0.021920526400208473, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.00883723795413971, Lv_loss = 0.0, Circular Tuning Loss = 1.1660418510437012\n",
      "2507) Lyapunov Risk = 0.889055609703064, MSE = 0.021882904693484306, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.008816144429147243, Lv_loss = 0.0, Circular Tuning Loss = 1.1659655570983887\n",
      "2508) Lyapunov Risk = 0.8889262080192566, MSE = 0.021908782422542572, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.008795429952442646, Lv_loss = 0.0, Circular Tuning Loss = 1.1658930778503418\n",
      "2509) Lyapunov Risk = 0.888798177242279, MSE = 0.02190207876265049, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.008775116875767708, Lv_loss = 0.0, Circular Tuning Loss = 1.1658241748809814\n",
      "2510) Lyapunov Risk = 0.8886723518371582, MSE = 0.021912826225161552, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.008755097165703773, Lv_loss = 0.0, Circular Tuning Loss = 1.1657580137252808\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.0075509467103563469, 0]\n",
      "x2 : [-1.7578125000000004, -1.7500000000000004]\n",
      "==============================\n",
      "2511) Lyapunov Risk = 0.8912830948829651, MSE = 0.021900078281760216, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.008710581809282303, Lv_loss = 0.0, Circular Tuning Loss = 1.1711146831512451\n",
      "2512) Lyapunov Risk = 0.8911592960357666, MSE = 0.02191033586859703, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.008691057562828064, Lv_loss = 0.0, Circular Tuning Loss = 1.1710500717163086\n",
      "2513) Lyapunov Risk = 0.8910382390022278, MSE = 0.021876297891139984, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.008671778254210949, Lv_loss = 0.0, Circular Tuning Loss = 1.170986294746399\n",
      "2514) Lyapunov Risk = 0.8909201622009277, MSE = 0.021919017657637596, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.008652699179947376, Lv_loss = 0.0, Circular Tuning Loss = 1.1709225177764893\n",
      "2515) Lyapunov Risk = 0.8908072113990784, MSE = 0.02184685692191124, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.008633832447230816, Lv_loss = 0.0, Circular Tuning Loss = 1.1708592176437378\n",
      "2516) Lyapunov Risk = 0.8906986713409424, MSE = 0.02193535678088665, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.008615086786448956, Lv_loss = 0.0, Circular Tuning Loss = 1.1707953214645386\n",
      "2517) Lyapunov Risk = 0.8905962705612183, MSE = 0.02185741253197193, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.008596503175795078, Lv_loss = 0.0, Circular Tuning Loss = 1.1707316637039185\n",
      "2518) Lyapunov Risk = 0.8905033469200134, MSE = 0.021947786211967468, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.008577978238463402, Lv_loss = 0.0, Circular Tuning Loss = 1.1706676483154297\n",
      "2519) Lyapunov Risk = 0.8904197216033936, MSE = 0.021900014951825142, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.008559583686292171, Lv_loss = 0.0, Circular Tuning Loss = 1.1706032752990723\n",
      "2520) Lyapunov Risk = 0.8903484344482422, MSE = 0.021979790180921555, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.008541216142475605, Lv_loss = 0.0, Circular Tuning Loss = 1.1705381870269775\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.0078125000000000017, 0]\n",
      "x2 : [-1.6328125000000004, -1.6250000000000004]\n",
      "==============================\n",
      "2521) Lyapunov Risk = 0.8924002051353455, MSE = 0.021922199055552483, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.008498801849782467, Lv_loss = 0.0, Circular Tuning Loss = 1.1746630668640137\n",
      "2522) Lyapunov Risk = 0.892346978187561, MSE = 0.022026479244232178, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.008480477146804333, Lv_loss = 0.0, Circular Tuning Loss = 1.1745942831039429\n",
      "2523) Lyapunov Risk = 0.892296552658081, MSE = 0.021930620074272156, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.008462183177471161, Lv_loss = 0.0, Circular Tuning Loss = 1.1745244264602661\n",
      "2524) Lyapunov Risk = 0.8922384977340698, MSE = 0.02209082804620266, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.008443820290267467, Lv_loss = 0.0, Circular Tuning Loss = 1.174452543258667\n",
      "2525) Lyapunov Risk = 0.892160952091217, MSE = 0.02192533016204834, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.008425517939031124, Lv_loss = 0.0, Circular Tuning Loss = 1.1743794679641724\n",
      "2526) Lyapunov Risk = 0.8920415639877319, MSE = 0.02212168648838997, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.008407119661569595, Lv_loss = 0.0, Circular Tuning Loss = 1.1743048429489136\n",
      "2527) Lyapunov Risk = 0.8918693661689758, MSE = 0.021915940567851067, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.008388803340494633, Lv_loss = 0.0, Circular Tuning Loss = 1.1742286682128906\n",
      "2528) Lyapunov Risk = 0.891640841960907, MSE = 0.022054653614759445, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.008370427414774895, Lv_loss = 0.0, Circular Tuning Loss = 1.174150824546814\n",
      "2529) Lyapunov Risk = 0.8913734555244446, MSE = 0.021872498095035553, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.008352101780474186, Lv_loss = 0.0, Circular Tuning Loss = 1.174072027206421\n",
      "2530) Lyapunov Risk = 0.8910952806472778, MSE = 0.02192992903292179, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.008333725854754448, Lv_loss = 0.0, Circular Tuning Loss = 1.173991322517395\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.0078125000000000017, 0]\n",
      "x2 : [-1.5000000000000004, -1.4921875000000004]\n",
      "==============================\n",
      "2531) Lyapunov Risk = 0.8923482894897461, MSE = 0.021803395822644234, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.008291891776025295, Lv_loss = 0.0, Circular Tuning Loss = 1.1769050359725952\n",
      "2532) Lyapunov Risk = 0.8921419978141785, MSE = 0.021805979311466217, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.008273465558886528, Lv_loss = 0.0, Circular Tuning Loss = 1.1768198013305664\n",
      "2533) Lyapunov Risk = 0.891993522644043, MSE = 0.021791834384202957, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.008254950866103172, Lv_loss = 0.0, Circular Tuning Loss = 1.176733136177063\n",
      "2534) Lyapunov Risk = 0.89189213514328, MSE = 0.021765772253274918, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.008236358873546124, Lv_loss = 0.0, Circular Tuning Loss = 1.1766448020935059\n",
      "2535) Lyapunov Risk = 0.8918179273605347, MSE = 0.021824073046445847, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.008217750117182732, Lv_loss = 0.0, Circular Tuning Loss = 1.1765549182891846\n",
      "2536) Lyapunov Risk = 0.8917487263679504, MSE = 0.021783605217933655, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.008199109695851803, Lv_loss = 0.0, Circular Tuning Loss = 1.1764636039733887\n",
      "2537) Lyapunov Risk = 0.8916646838188171, MSE = 0.02186632715165615, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.008180358447134495, Lv_loss = 0.0, Circular Tuning Loss = 1.1763710975646973\n",
      "2538) Lyapunov Risk = 0.8915553092956543, MSE = 0.021800220012664795, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.008161609061062336, Lv_loss = 0.0, Circular Tuning Loss = 1.1762769222259521\n",
      "2539) Lyapunov Risk = 0.8914171457290649, MSE = 0.021879158914089203, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.00814274325966835, Lv_loss = 0.0, Circular Tuning Loss = 1.1761817932128906\n",
      "2540) Lyapunov Risk = 0.8912548422813416, MSE = 0.021782876923680305, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.008123841136693954, Lv_loss = 0.0, Circular Tuning Loss = 1.1760857105255127\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0451734773582499, 1.0551734773582497]\n",
      "x2 : [-0.92515199152096617, -0.91515199152096616]\n",
      "==============================\n",
      "2541) Lyapunov Risk = 0.8927873373031616, MSE = 0.02184721827507019, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.00840615201741457, Lv_loss = 0.0, Circular Tuning Loss = 1.1791023015975952\n",
      "2542) Lyapunov Risk = 0.8926115036010742, MSE = 0.021730661392211914, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.008386322297155857, Lv_loss = 0.0, Circular Tuning Loss = 1.1790015697479248\n",
      "2543) Lyapunov Risk = 0.8924461603164673, MSE = 0.02179991826415062, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.00836622528731823, Lv_loss = 0.0, Circular Tuning Loss = 1.1788994073867798\n",
      "2544) Lyapunov Risk = 0.8922967314720154, MSE = 0.021714944392442703, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.008345912210643291, Lv_loss = 0.0, Circular Tuning Loss = 1.1787952184677124\n",
      "2545) Lyapunov Risk = 0.8921637535095215, MSE = 0.021744977682828903, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.008325415663421154, Lv_loss = 0.0, Circular Tuning Loss = 1.1786898374557495\n",
      "2546) Lyapunov Risk = 0.8920437693595886, MSE = 0.021752245724201202, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.008304811082780361, Lv_loss = 0.0, Circular Tuning Loss = 1.1785824298858643\n",
      "2547) Lyapunov Risk = 0.8919316530227661, MSE = 0.021718759089708328, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.008284118957817554, Lv_loss = 0.0, Circular Tuning Loss = 1.178473711013794\n",
      "2548) Lyapunov Risk = 0.8918213844299316, MSE = 0.021797053515911102, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.00826334673911333, Lv_loss = 0.0, Circular Tuning Loss = 1.1783632040023804\n",
      "2549) Lyapunov Risk = 0.8917080760002136, MSE = 0.021724291145801544, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.008242566138505936, Lv_loss = 0.0, Circular Tuning Loss = 1.1782513856887817\n",
      "2550) Lyapunov Risk = 0.8915891647338867, MSE = 0.021801471710205078, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.008221721276640892, Lv_loss = 0.0, Circular Tuning Loss = 1.178138256072998\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [0.11328125000000003, 0.11523437500000003]\n",
      "x2 : [1.9953760875093005, 1.9967892623906105]\n",
      "==============================\n",
      "2551) Lyapunov Risk = 0.8954411745071411, MSE = 0.02173694781959057, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.00817788764834404, Lv_loss = 0.0, Circular Tuning Loss = 1.1859411001205444\n",
      "2552) Lyapunov Risk = 0.8953087329864502, MSE = 0.021754831075668335, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.008157048374414444, Lv_loss = 0.0, Circular Tuning Loss = 1.1858257055282593\n",
      "2553) Lyapunov Risk = 0.8951717019081116, MSE = 0.02173161692917347, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.008136213757097721, Lv_loss = 0.0, Circular Tuning Loss = 1.1857095956802368\n",
      "2554) Lyapunov Risk = 0.8950316905975342, MSE = 0.02173166535794735, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.008115355856716633, Lv_loss = 0.0, Circular Tuning Loss = 1.1855921745300293\n",
      "2555) Lyapunov Risk = 0.8948915004730225, MSE = 0.021693360060453415, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.008094500750303268, Lv_loss = 0.0, Circular Tuning Loss = 1.1854740381240845\n",
      "2556) Lyapunov Risk = 0.8947529196739197, MSE = 0.021739795804023743, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.008073649369180202, Lv_loss = 0.0, Circular Tuning Loss = 1.1853548288345337\n",
      "2557) Lyapunov Risk = 0.894616961479187, MSE = 0.021676599979400635, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.008052864111959934, Lv_loss = 0.0, Circular Tuning Loss = 1.1852350234985352\n",
      "2558) Lyapunov Risk = 0.8944833278656006, MSE = 0.021737582981586456, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.00803207978606224, Lv_loss = 0.0, Circular Tuning Loss = 1.1851140260696411\n",
      "2559) Lyapunov Risk = 0.8943524360656738, MSE = 0.021696997806429863, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.008011325262486935, Lv_loss = 0.0, Circular Tuning Loss = 1.1849921941757202\n",
      "2560) Lyapunov Risk = 0.8942241072654724, MSE = 0.02170959860086441, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.0079905791208148, Lv_loss = 0.0, Circular Tuning Loss = 1.1848698854446411\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0451734773582499, 1.0551734773582497]\n",
      "x2 : [-0.92515199152096617, -0.91515199152096616]\n",
      "==============================\n",
      "2561) Lyapunov Risk = 0.8957452178001404, MSE = 0.021716494113206863, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.008256416767835617, Lv_loss = 0.0, Circular Tuning Loss = 1.1877714395523071\n",
      "2562) Lyapunov Risk = 0.895618736743927, MSE = 0.021659474819898605, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.008234919048845768, Lv_loss = 0.0, Circular Tuning Loss = 1.1876451969146729\n",
      "2563) Lyapunov Risk = 0.8954931497573853, MSE = 0.02172274701297283, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.00821326021105051, Lv_loss = 0.0, Circular Tuning Loss = 1.1875180006027222\n",
      "2564) Lyapunov Risk = 0.8953675031661987, MSE = 0.021639904007315636, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.00819146353751421, Lv_loss = 0.0, Circular Tuning Loss = 1.1873894929885864\n",
      "2565) Lyapunov Risk = 0.8952419757843018, MSE = 0.021697884425520897, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.008169533684849739, Lv_loss = 0.0, Circular Tuning Loss = 1.1872599124908447\n",
      "2566) Lyapunov Risk = 0.8951170444488525, MSE = 0.0216660313308239, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.008147578686475754, Lv_loss = 0.0, Circular Tuning Loss = 1.1871293783187866\n",
      "2567) Lyapunov Risk = 0.8949922919273376, MSE = 0.02167658321559429, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.008125550113618374, Lv_loss = 0.0, Circular Tuning Loss = 1.1869977712631226\n",
      "2568) Lyapunov Risk = 0.8948681354522705, MSE = 0.021689405664801598, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.008103473111987114, Lv_loss = 0.0, Circular Tuning Loss = 1.1868654489517212\n",
      "2569) Lyapunov Risk = 0.8947440981864929, MSE = 0.021687950938940048, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.00808137096464634, Lv_loss = 0.0, Circular Tuning Loss = 1.1867324113845825\n",
      "2570) Lyapunov Risk = 0.8946210145950317, MSE = 0.02167670987546444, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.008059259504079819, Lv_loss = 0.0, Circular Tuning Loss = 1.1865986585617065\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0451734773582499, 1.0551734773582497]\n",
      "x2 : [-0.92515199152096617, -0.91515199152096616]\n",
      "==============================\n",
      "2571) Lyapunov Risk = 0.8961195349693298, MSE = 0.021705664694309235, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.008315562270581722, Lv_loss = 0.0, Circular Tuning Loss = 1.1894503831863403\n",
      "2572) Lyapunov Risk = 0.8959985971450806, MSE = 0.021626988425850868, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.008292597718536854, Lv_loss = 0.0, Circular Tuning Loss = 1.1893128156661987\n",
      "2573) Lyapunov Risk = 0.8958796262741089, MSE = 0.021723488345742226, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.00826943013817072, Lv_loss = 0.0, Circular Tuning Loss = 1.189173936843872\n",
      "2574) Lyapunov Risk = 0.8957630395889282, MSE = 0.021605346351861954, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.008246107958257198, Lv_loss = 0.0, Circular Tuning Loss = 1.1890342235565186\n",
      "2575) Lyapunov Risk = 0.8956491351127625, MSE = 0.02171388454735279, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.008222582750022411, Lv_loss = 0.0, Circular Tuning Loss = 1.1888937950134277\n",
      "2576) Lyapunov Risk = 0.895540177822113, MSE = 0.021639486774802208, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.008198943920433521, Lv_loss = 0.0, Circular Tuning Loss = 1.188752293586731\n",
      "2577) Lyapunov Risk = 0.8954377174377441, MSE = 0.021706756204366684, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.008175129070878029, Lv_loss = 0.0, Circular Tuning Loss = 1.1886101961135864\n",
      "2578) Lyapunov Risk = 0.8953428268432617, MSE = 0.021683767437934875, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.008151243440806866, Lv_loss = 0.0, Circular Tuning Loss = 1.1884675025939941\n",
      "2579) Lyapunov Risk = 0.8952569365501404, MSE = 0.021738046780228615, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.008127239532768726, Lv_loss = 0.0, Circular Tuning Loss = 1.188324213027954\n",
      "2580) Lyapunov Risk = 0.8951796889305115, MSE = 0.02170283906161785, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.008103237487375736, Lv_loss = 0.0, Circular Tuning Loss = 1.1881803274154663\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [0.11424987284350387, 0.11721152031733262]\n",
      "x2 : [1.9946985801191621, 1.9967350747345844]\n",
      "==============================\n",
      "2581) Lyapunov Risk = 0.8990452289581299, MSE = 0.021789122372865677, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.00805665459483862, Lv_loss = 0.0, Circular Tuning Loss = 1.1958565711975098\n",
      "2582) Lyapunov Risk = 0.8989905118942261, MSE = 0.021687064319849014, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.008032716810703278, Lv_loss = 0.0, Circular Tuning Loss = 1.1957123279571533\n",
      "2583) Lyapunov Risk = 0.8989449143409729, MSE = 0.02187633141875267, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.008008712902665138, Lv_loss = 0.0, Circular Tuning Loss = 1.1955678462982178\n",
      "2584) Lyapunov Risk = 0.8989013433456421, MSE = 0.021673552691936493, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.007984763011336327, Lv_loss = 0.0, Circular Tuning Loss = 1.1954232454299927\n",
      "2585) Lyapunov Risk = 0.8988463282585144, MSE = 0.02196759358048439, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.007960757240653038, Lv_loss = 0.0, Circular Tuning Loss = 1.1952786445617676\n",
      "2586) Lyapunov Risk = 0.8987608551979065, MSE = 0.021679893136024475, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.00793683435767889, Lv_loss = 0.0, Circular Tuning Loss = 1.195133924484253\n",
      "2587) Lyapunov Risk = 0.8986260294914246, MSE = 0.02199619635939598, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.007912853732705116, Lv_loss = 0.0, Circular Tuning Loss = 1.1949889659881592\n",
      "2588) Lyapunov Risk = 0.8984313607215881, MSE = 0.021676480770111084, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.007888966239988804, Lv_loss = 0.0, Circular Tuning Loss = 1.1948438882827759\n",
      "2589) Lyapunov Risk = 0.898181140422821, MSE = 0.021904142573475838, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.007865062914788723, Lv_loss = 0.0, Circular Tuning Loss = 1.194698691368103\n",
      "2590) Lyapunov Risk = 0.8978981971740723, MSE = 0.021635234355926514, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.007841254584491253, Lv_loss = 0.0, Circular Tuning Loss = 1.194553256034851\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [0.11757685634236814, 0.11943264225677611]\n",
      "x2 : [1.9952980760711694, 1.9965409294208438]\n",
      "==============================\n",
      "2591) Lyapunov Risk = 0.9015328288078308, MSE = 0.021727507933974266, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.0077957771718502045, Lv_loss = 0.0, Circular Tuning Loss = 1.2021948099136353\n",
      "2592) Lyapunov Risk = 0.9012851715087891, MSE = 0.021588671952486038, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.007772207260131836, Lv_loss = 0.0, Circular Tuning Loss = 1.2020492553710938\n",
      "2593) Lyapunov Risk = 0.9010934233665466, MSE = 0.02158648520708084, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.007748784963041544, Lv_loss = 0.0, Circular Tuning Loss = 1.2019034624099731\n",
      "2594) Lyapunov Risk = 0.9009605646133423, MSE = 0.021607667207717896, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.007725538685917854, Lv_loss = 0.0, Circular Tuning Loss = 1.201757550239563\n",
      "2595) Lyapunov Risk = 0.9008718729019165, MSE = 0.02154768444597721, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.007702401839196682, Lv_loss = 0.0, Circular Tuning Loss = 1.2016116380691528\n",
      "2596) Lyapunov Risk = 0.9008045196533203, MSE = 0.021672111004590988, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.007679323200136423, Lv_loss = 0.0, Circular Tuning Loss = 1.2014659643173218\n",
      "2597) Lyapunov Risk = 0.9007352590560913, MSE = 0.021579772233963013, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.007656366564333439, Lv_loss = 0.0, Circular Tuning Loss = 1.2013204097747803\n",
      "2598) Lyapunov Risk = 0.9006458520889282, MSE = 0.021709688007831573, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.00763341598212719, Lv_loss = 0.0, Circular Tuning Loss = 1.2011750936508179\n",
      "2599) Lyapunov Risk = 0.9005277156829834, MSE = 0.02160792239010334, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.007610606029629707, Lv_loss = 0.0, Circular Tuning Loss = 1.2010300159454346\n",
      "2600) Lyapunov Risk = 0.9003791809082031, MSE = 0.021681586280465126, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.0075877816416323185, Lv_loss = 0.0, Circular Tuning Loss = 1.2008850574493408\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [0.11985156525376083, 0.12179297068085666]\n",
      "x2 : [1.9947184331211525, 1.9964066374574685]\n",
      "==============================\n",
      "2601) Lyapunov Risk = 0.9041014313697815, MSE = 0.021591071039438248, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.007544125895947218, Lv_loss = 0.0, Circular Tuning Loss = 1.208481788635254\n",
      "2602) Lyapunov Risk = 0.9039221405982971, MSE = 0.021599605679512024, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.007521468214690685, Lv_loss = 0.0, Circular Tuning Loss = 1.208337426185608\n",
      "2603) Lyapunov Risk = 0.90374755859375, MSE = 0.021562866866588593, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.0074989390559494495, Lv_loss = 0.0, Circular Tuning Loss = 1.208193063735962\n",
      "2604) Lyapunov Risk = 0.9035875201225281, MSE = 0.02155233733355999, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.007476432714611292, Lv_loss = 0.0, Circular Tuning Loss = 1.2080492973327637\n",
      "2605) Lyapunov Risk = 0.9034451842308044, MSE = 0.02154427580535412, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.0074540190398693085, Lv_loss = 0.0, Circular Tuning Loss = 1.2079055309295654\n",
      "2606) Lyapunov Risk = 0.9033200144767761, MSE = 0.02155679650604725, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.007431678008288145, Lv_loss = 0.0, Circular Tuning Loss = 1.2077622413635254\n",
      "2607) Lyapunov Risk = 0.903206467628479, MSE = 0.021558253094553947, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.007409403100609779, Lv_loss = 0.0, Circular Tuning Loss = 1.2076188325881958\n",
      "2608) Lyapunov Risk = 0.9030979871749878, MSE = 0.021565737202763557, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.007387207821011543, Lv_loss = 0.0, Circular Tuning Loss = 1.2074755430221558\n",
      "2609) Lyapunov Risk = 0.902988612651825, MSE = 0.02158520370721817, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.007365031633526087, Lv_loss = 0.0, Circular Tuning Loss = 1.2073326110839844\n",
      "2610) Lyapunov Risk = 0.9028742909431458, MSE = 0.021545983850955963, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.007342948578298092, Lv_loss = 0.0, Circular Tuning Loss = 1.2071897983551025\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0451734773582499, 1.0551734773582497]\n",
      "x2 : [-0.92515199152096617, -0.91515199152096616]\n",
      "==============================\n",
      "2611) Lyapunov Risk = 0.9042662382125854, MSE = 0.02160538360476494, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.007570876739919186, Lv_loss = 0.0, Circular Tuning Loss = 1.2098753452301025\n",
      "2612) Lyapunov Risk = 0.9041392803192139, MSE = 0.021489016711711884, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.007548047695308924, Lv_loss = 0.0, Circular Tuning Loss = 1.2097307443618774\n",
      "2613) Lyapunov Risk = 0.9040066003799438, MSE = 0.02162383496761322, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.0075250109657645226, Lv_loss = 0.0, Circular Tuning Loss = 1.2095856666564941\n",
      "2614) Lyapunov Risk = 0.9038689136505127, MSE = 0.02145874872803688, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.007501901593059301, Lv_loss = 0.0, Circular Tuning Loss = 1.2094402313232422\n",
      "2615) Lyapunov Risk = 0.9037278294563293, MSE = 0.021604804322123528, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.007478621788322926, Lv_loss = 0.0, Circular Tuning Loss = 1.2092950344085693\n",
      "2616) Lyapunov Risk = 0.9035860300064087, MSE = 0.021477434784173965, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.007455360610038042, Lv_loss = 0.0, Circular Tuning Loss = 1.2091491222381592\n",
      "2617) Lyapunov Risk = 0.9034443497657776, MSE = 0.021560275927186012, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.007432039827108383, Lv_loss = 0.0, Circular Tuning Loss = 1.20900297164917\n",
      "2618) Lyapunov Risk = 0.9033056497573853, MSE = 0.021516302600502968, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.007408709730952978, Lv_loss = 0.0, Circular Tuning Loss = 1.2088568210601807\n",
      "2619) Lyapunov Risk = 0.9031696319580078, MSE = 0.021513769403100014, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.007385318633168936, Lv_loss = 0.0, Circular Tuning Loss = 1.2087104320526123\n",
      "2620) Lyapunov Risk = 0.90303635597229, MSE = 0.021536847576498985, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.007361925672739744, Lv_loss = 0.0, Circular Tuning Loss = 1.2085641622543335\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0451734773582499, 1.0551734773582497]\n",
      "x2 : [-0.92515199152096617, -0.91515199152096616]\n",
      "==============================\n",
      "2621) Lyapunov Risk = 0.9044013023376465, MSE = 0.021485714241862297, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.007581500802189112, Lv_loss = 0.0, Circular Tuning Loss = 1.211228370666504\n",
      "2622) Lyapunov Risk = 0.9042705297470093, MSE = 0.0215073861181736, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.0075572398491203785, Lv_loss = 0.0, Circular Tuning Loss = 1.2110798358917236\n",
      "2623) Lyapunov Risk = 0.9041411876678467, MSE = 0.02149367146193981, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.0075327567756175995, Lv_loss = 0.0, Circular Tuning Loss = 1.2109304666519165\n",
      "2624) Lyapunov Risk = 0.9040133357048035, MSE = 0.021475238725543022, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.0075080678798258305, Lv_loss = 0.0, Circular Tuning Loss = 1.210781216621399\n",
      "2625) Lyapunov Risk = 0.903885543346405, MSE = 0.0215046014636755, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.007483205758035183, Lv_loss = 0.0, Circular Tuning Loss = 1.2106311321258545\n",
      "2626) Lyapunov Risk = 0.9037574529647827, MSE = 0.0214726310223341, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.007458204869180918, Lv_loss = 0.0, Circular Tuning Loss = 1.210480809211731\n",
      "2627) Lyapunov Risk = 0.9036287665367126, MSE = 0.021503908559679985, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.007433100137859583, Lv_loss = 0.0, Circular Tuning Loss = 1.2103303670883179\n",
      "2628) Lyapunov Risk = 0.903499960899353, MSE = 0.021492520347237587, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.007407895289361477, Lv_loss = 0.0, Circular Tuning Loss = 1.210179328918457\n",
      "2629) Lyapunov Risk = 0.9033718705177307, MSE = 0.021476274356245995, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.007382671814411879, Lv_loss = 0.0, Circular Tuning Loss = 1.2100279331207275\n",
      "2630) Lyapunov Risk = 0.9032440185546875, MSE = 0.021516848355531693, V_0_loss = tensor([[0.0059]], grad_fn=<PowBackward0>), V_pos_loss = 0.007357417140156031, Lv_loss = 0.0, Circular Tuning Loss = 1.209876298904419\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0451734773582499, 1.0551734773582497]\n",
      "x2 : [-0.92515199152096617, -0.91515199152096616]\n",
      "==============================\n",
      "2631) Lyapunov Risk = 0.9045789241790771, MSE = 0.021440813317894936, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.007567213382571936, Lv_loss = 0.0, Circular Tuning Loss = 1.2124829292297363\n",
      "2632) Lyapunov Risk = 0.9044504165649414, MSE = 0.021511122584342957, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.0075411805883049965, Lv_loss = 0.0, Circular Tuning Loss = 1.212328314781189\n",
      "2633) Lyapunov Risk = 0.9043228030204773, MSE = 0.02143239974975586, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.007515055127441883, Lv_loss = 0.0, Circular Tuning Loss = 1.2121723890304565\n",
      "2634) Lyapunov Risk = 0.9041963815689087, MSE = 0.02150307595729828, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.007488827686756849, Lv_loss = 0.0, Circular Tuning Loss = 1.2120157480239868\n",
      "2635) Lyapunov Risk = 0.9040716290473938, MSE = 0.02143528312444687, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.0074626002460718155, Lv_loss = 0.0, Circular Tuning Loss = 1.2118582725524902\n",
      "2636) Lyapunov Risk = 0.9039484262466431, MSE = 0.021505136042833328, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.007436305750161409, Lv_loss = 0.0, Circular Tuning Loss = 1.211700201034546\n",
      "2637) Lyapunov Risk = 0.9038281440734863, MSE = 0.02144014462828636, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.007410008460283279, Lv_loss = 0.0, Circular Tuning Loss = 1.2115416526794434\n",
      "2638) Lyapunov Risk = 0.9037110805511475, MSE = 0.021518008783459663, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.007383624091744423, Lv_loss = 0.0, Circular Tuning Loss = 1.2113827466964722\n",
      "2639) Lyapunov Risk = 0.9035995006561279, MSE = 0.021435532718896866, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.0073572867549955845, Lv_loss = 0.0, Circular Tuning Loss = 1.2112232446670532\n",
      "2640) Lyapunov Risk = 0.9034927487373352, MSE = 0.02154110185801983, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.007330936845391989, Lv_loss = 0.0, Circular Tuning Loss = 1.2110633850097656\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [0.13734402042770993, 0.14062500000000006]\n",
      "x2 : [1.9932184536859894, 1.9952785820663623]\n",
      "==============================\n",
      "2641) Lyapunov Risk = 0.9072264432907104, MSE = 0.021424734964966774, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.0072846794500947, Lv_loss = 0.0, Circular Tuning Loss = 1.2185274362564087\n",
      "2642) Lyapunov Risk = 0.9071366190910339, MSE = 0.021561993286013603, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.007258543744683266, Lv_loss = 0.0, Circular Tuning Loss = 1.2183663845062256\n",
      "2643) Lyapunov Risk = 0.9070597887039185, MSE = 0.021434111520648003, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.007232585921883583, Lv_loss = 0.0, Circular Tuning Loss = 1.2182046175003052\n",
      "2644) Lyapunov Risk = 0.9069957137107849, MSE = 0.021604087203741074, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.007206691429018974, Lv_loss = 0.0, Circular Tuning Loss = 1.2180432081222534\n",
      "2645) Lyapunov Risk = 0.9069464206695557, MSE = 0.021463030949234962, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.0071809845976531506, Lv_loss = 0.0, Circular Tuning Loss = 1.2178815603256226\n",
      "2646) Lyapunov Risk = 0.9069057703018188, MSE = 0.0216741431504488, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.007155285216867924, Lv_loss = 0.0, Circular Tuning Loss = 1.2177199125289917\n",
      "2647) Lyapunov Risk = 0.9068711996078491, MSE = 0.021512946113944054, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.0071297879330813885, Lv_loss = 0.0, Circular Tuning Loss = 1.2175581455230713\n",
      "2648) Lyapunov Risk = 0.9068273305892944, MSE = 0.02174910344183445, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.007104297634214163, Lv_loss = 0.0, Circular Tuning Loss = 1.2173967361450195\n",
      "2649) Lyapunov Risk = 0.9067608714103699, MSE = 0.02154778130352497, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.007079044356942177, Lv_loss = 0.0, Circular Tuning Loss = 1.2172350883483887\n",
      "2650) Lyapunov Risk = 0.9066450595855713, MSE = 0.02178630605340004, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.007053858134895563, Lv_loss = 0.0, Circular Tuning Loss = 1.217073917388916\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0451734773582499, 1.0551734773582497]\n",
      "x2 : [-0.92515199152096617, -0.91515199152096616]\n",
      "==============================\n",
      "2651) Lyapunov Risk = 0.9078817963600159, MSE = 0.021518390625715256, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.0072494810447096825, Lv_loss = 0.0, Circular Tuning Loss = 1.2196069955825806\n",
      "2652) Lyapunov Risk = 0.9076317548751831, MSE = 0.021708641201257706, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.007223696447908878, Lv_loss = 0.0, Circular Tuning Loss = 1.2194441556930542\n",
      "2653) Lyapunov Risk = 0.9073355197906494, MSE = 0.02143336459994316, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.00719795748591423, Lv_loss = 0.0, Circular Tuning Loss = 1.21928071975708\n",
      "2654) Lyapunov Risk = 0.9070272445678711, MSE = 0.021550601348280907, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.0071720401756465435, Lv_loss = 0.0, Circular Tuning Loss = 1.2191174030303955\n",
      "2655) Lyapunov Risk = 0.9067529439926147, MSE = 0.02136710286140442, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.00714613264426589, Lv_loss = 0.0, Circular Tuning Loss = 1.2189539670944214\n",
      "2656) Lyapunov Risk = 0.9065386652946472, MSE = 0.021426422521471977, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.007120106834918261, Lv_loss = 0.0, Circular Tuning Loss = 1.2187905311584473\n",
      "2657) Lyapunov Risk = 0.9063917398452759, MSE = 0.02139110304415226, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.007094104308634996, Lv_loss = 0.0, Circular Tuning Loss = 1.2186272144317627\n",
      "2658) Lyapunov Risk = 0.9062989950180054, MSE = 0.021385300904512405, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.007068120874464512, Lv_loss = 0.0, Circular Tuning Loss = 1.2184640169143677\n",
      "2659) Lyapunov Risk = 0.9062342047691345, MSE = 0.02147524245083332, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.0070421332493424416, Lv_loss = 0.0, Circular Tuning Loss = 1.218300700187683\n",
      "2660) Lyapunov Risk = 0.9061715602874756, MSE = 0.021380720660090446, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.007016208954155445, Lv_loss = 0.0, Circular Tuning Loss = 1.218137502670288\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [0.15039062500000006, 0.15234375000000006]\n",
      "x2 : [1.9929903939446194, 1.9943376494245177]\n",
      "==============================\n",
      "2661) Lyapunov Risk = 0.9098915457725525, MSE = 0.0215466246008873, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.006971183232963085, Lv_loss = 0.0, Circular Tuning Loss = 1.2255445718765259\n",
      "2662) Lyapunov Risk = 0.9097762703895569, MSE = 0.02134019508957863, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.006945414934307337, Lv_loss = 0.0, Circular Tuning Loss = 1.2253808975219727\n",
      "2663) Lyapunov Risk = 0.9096254110336304, MSE = 0.021564079448580742, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.0069196769036352634, Lv_loss = 0.0, Circular Tuning Loss = 1.2252179384231567\n",
      "2664) Lyapunov Risk = 0.9094491600990295, MSE = 0.02129334956407547, V_0_loss = tensor([[0.0060]], grad_fn=<PowBackward0>), V_pos_loss = 0.006894116289913654, Lv_loss = 0.0, Circular Tuning Loss = 1.2250549793243408\n",
      "2665) Lyapunov Risk = 0.9092585444450378, MSE = 0.021516738459467888, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.006868594326078892, Lv_loss = 0.0, Circular Tuning Loss = 1.2248923778533936\n",
      "2666) Lyapunov Risk = 0.9090712666511536, MSE = 0.021286601200699806, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.006843284238129854, Lv_loss = 0.0, Circular Tuning Loss = 1.2247298955917358\n",
      "2667) Lyapunov Risk = 0.9088997840881348, MSE = 0.02144285850226879, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.006818059366196394, Lv_loss = 0.0, Circular Tuning Loss = 1.2245678901672363\n",
      "2668) Lyapunov Risk = 0.9087514877319336, MSE = 0.021328860893845558, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.006792976055294275, Lv_loss = 0.0, Circular Tuning Loss = 1.2244060039520264\n",
      "2669) Lyapunov Risk = 0.9086232781410217, MSE = 0.02138391323387623, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.006768003571778536, Lv_loss = 0.0, Circular Tuning Loss = 1.2242445945739746\n",
      "2670) Lyapunov Risk = 0.908508837223053, MSE = 0.021389465779066086, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.006743149366229773, Lv_loss = 0.0, Circular Tuning Loss = 1.2240831851959229\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0451734773582499, 1.0551734773582497]\n",
      "x2 : [-0.92515199152096617, -0.91515199152096616]\n",
      "==============================\n",
      "2671) Lyapunov Risk = 0.9097598791122437, MSE = 0.021326949819922447, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.0069246054627001286, Lv_loss = 0.0, Circular Tuning Loss = 1.2265326976776123\n",
      "2672) Lyapunov Risk = 0.9096490740776062, MSE = 0.021425921469926834, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.0068990872241556644, Lv_loss = 0.0, Circular Tuning Loss = 1.2263697385787964\n",
      "2673) Lyapunov Risk = 0.9095315337181091, MSE = 0.021295510232448578, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.006873495876789093, Lv_loss = 0.0, Circular Tuning Loss = 1.226206660270691\n",
      "2674) Lyapunov Risk = 0.9094046354293823, MSE = 0.02143840678036213, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.006847787648439407, Lv_loss = 0.0, Circular Tuning Loss = 1.2260433435440063\n",
      "2675) Lyapunov Risk = 0.909267783164978, MSE = 0.021285325288772583, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.006822112947702408, Lv_loss = 0.0, Circular Tuning Loss = 1.225879430770874\n",
      "2676) Lyapunov Risk = 0.9091237187385559, MSE = 0.021433623507618904, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.006796369329094887, Lv_loss = 0.0, Circular Tuning Loss = 1.2257157564163208\n",
      "2677) Lyapunov Risk = 0.9089755415916443, MSE = 0.021293777972459793, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.006770715117454529, Lv_loss = 0.0, Circular Tuning Loss = 1.225551724433899\n",
      "2678) Lyapunov Risk = 0.9088268280029297, MSE = 0.021412178874015808, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.006745146121829748, Lv_loss = 0.0, Circular Tuning Loss = 1.225387692451477\n",
      "2679) Lyapunov Risk = 0.9086799621582031, MSE = 0.021303417161107063, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.006719679571688175, Lv_loss = 0.0, Circular Tuning Loss = 1.2252235412597656\n",
      "2680) Lyapunov Risk = 0.9085375070571899, MSE = 0.02137736789882183, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.006694276351481676, Lv_loss = 0.0, Circular Tuning Loss = 1.2250597476959229\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [0.16406250000000006, 0.17187500000000006]\n",
      "x2 : [1.9790572184328532, 1.9861583669617178]\n",
      "==============================\n",
      "2681) Lyapunov Risk = 0.9121087789535522, MSE = 0.021303214132785797, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.006650898139923811, Lv_loss = 0.0, Circular Tuning Loss = 1.2322858572006226\n",
      "2682) Lyapunov Risk = 0.9119746088981628, MSE = 0.021331090480089188, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.00662578409537673, Lv_loss = 0.0, Circular Tuning Loss = 1.232121229171753\n",
      "2683) Lyapunov Risk = 0.9118438959121704, MSE = 0.021312912926077843, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.0066007887944579124, Lv_loss = 0.0, Circular Tuning Loss = 1.2319567203521729\n",
      "2684) Lyapunov Risk = 0.9117155075073242, MSE = 0.021301889792084694, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.006575919222086668, Lv_loss = 0.0, Circular Tuning Loss = 1.2317924499511719\n",
      "2685) Lyapunov Risk = 0.911588728427887, MSE = 0.02133459597826004, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.006551198661327362, Lv_loss = 0.0, Circular Tuning Loss = 1.23162841796875\n",
      "2686) Lyapunov Risk = 0.9114626049995422, MSE = 0.02128678373992443, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.006526670418679714, Lv_loss = 0.0, Circular Tuning Loss = 1.2314647436141968\n",
      "2687) Lyapunov Risk = 0.9113370776176453, MSE = 0.021369928494095802, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.00650227814912796, Lv_loss = 0.0, Circular Tuning Loss = 1.231301188468933\n",
      "2688) Lyapunov Risk = 0.9112106561660767, MSE = 0.02126813307404518, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.00647802883759141, Lv_loss = 0.0, Circular Tuning Loss = 1.2311381101608276\n",
      "2689) Lyapunov Risk = 0.9110843539237976, MSE = 0.02139637991786003, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.006453919690102339, Lv_loss = 0.0, Circular Tuning Loss = 1.2309753894805908\n",
      "2690) Lyapunov Risk = 0.9109572172164917, MSE = 0.021237799897789955, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.00642996933311224, Lv_loss = 0.0, Circular Tuning Loss = 1.2308130264282227\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [0.17187500000000006, 0.17382812500000006]\n",
      "x2 : [1.9908433388101339, 1.9926010600155268]\n",
      "==============================\n",
      "2691) Lyapunov Risk = 0.9145843982696533, MSE = 0.021413074806332588, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.006388788111507893, Lv_loss = 0.0, Circular Tuning Loss = 1.2381281852722168\n",
      "2692) Lyapunov Risk = 0.9144590497016907, MSE = 0.021185724064707756, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.006365173030644655, Lv_loss = 0.0, Circular Tuning Loss = 1.2379655838012695\n",
      "2693) Lyapunov Risk = 0.9143329858779907, MSE = 0.02144063636660576, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.006341760046780109, Lv_loss = 0.0, Circular Tuning Loss = 1.23780357837677\n",
      "2694) Lyapunov Risk = 0.9142066240310669, MSE = 0.02115049958229065, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.006318488158285618, Lv_loss = 0.0, Circular Tuning Loss = 1.2376421689987183\n",
      "2695) Lyapunov Risk = 0.9140785932540894, MSE = 0.021460434421896935, V_0_loss = tensor([[0.0061]], grad_fn=<PowBackward0>), V_pos_loss = 0.006295333616435528, Lv_loss = 0.0, Circular Tuning Loss = 1.2374812364578247\n",
      "2696) Lyapunov Risk = 0.9139499664306641, MSE = 0.021142905578017235, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.006272345781326294, Lv_loss = 0.0, Circular Tuning Loss = 1.2373206615447998\n",
      "2697) Lyapunov Risk = 0.9138199090957642, MSE = 0.021468648687005043, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.006249517668038607, Lv_loss = 0.0, Circular Tuning Loss = 1.2371608018875122\n",
      "2698) Lyapunov Risk = 0.9136910438537598, MSE = 0.021146396175026894, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.006226843688637018, Lv_loss = 0.0, Circular Tuning Loss = 1.2370012998580933\n",
      "2699) Lyapunov Risk = 0.9135614037513733, MSE = 0.021462932229042053, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.006204296834766865, Lv_loss = 0.0, Circular Tuning Loss = 1.236842393875122\n",
      "2700) Lyapunov Risk = 0.9134317636489868, MSE = 0.021150272339582443, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.006181931588798761, Lv_loss = 0.0, Circular Tuning Loss = 1.2366836071014404\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [0.17968750000000006, 0.18164062500000006]\n",
      "x2 : [1.9897883279251007, 1.9919117456212136]\n",
      "==============================\n",
      "2701) Lyapunov Risk = 0.9170345664024353, MSE = 0.021442295983433723, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.006143082864582539, Lv_loss = 0.0, Circular Tuning Loss = 1.2439591884613037\n",
      "2702) Lyapunov Risk = 0.9169086217880249, MSE = 0.02114100567996502, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.006121091544628143, Lv_loss = 0.0, Circular Tuning Loss = 1.2438005208969116\n",
      "2703) Lyapunov Risk = 0.9167830348014832, MSE = 0.02143455110490322, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.0060992129147052765, Lv_loss = 0.0, Circular Tuning Loss = 1.2436423301696777\n",
      "2704) Lyapunov Risk = 0.9166600704193115, MSE = 0.021135974675416946, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.006077494006603956, Lv_loss = 0.0, Circular Tuning Loss = 1.2434844970703125\n",
      "2705) Lyapunov Risk = 0.9165388941764832, MSE = 0.02143862470984459, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.006055854726582766, Lv_loss = 0.0, Circular Tuning Loss = 1.2433274984359741\n",
      "2706) Lyapunov Risk = 0.9164221286773682, MSE = 0.021136995404958725, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.006034358404576778, Lv_loss = 0.0, Circular Tuning Loss = 1.2431708574295044\n",
      "2707) Lyapunov Risk = 0.9163085222244263, MSE = 0.02146145887672901, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.00601292634382844, Lv_loss = 0.0, Circular Tuning Loss = 1.2430146932601929\n",
      "2708) Lyapunov Risk = 0.9162029027938843, MSE = 0.021131008863449097, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.005991620011627674, Lv_loss = 0.0, Circular Tuning Loss = 1.24285888671875\n",
      "2709) Lyapunov Risk = 0.9161016345024109, MSE = 0.02150331623852253, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.005970359779894352, Lv_loss = 0.0, Circular Tuning Loss = 1.2427035570144653\n",
      "2710) Lyapunov Risk = 0.9160099029541016, MSE = 0.021114254370331764, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.005949229001998901, Lv_loss = 0.0, Circular Tuning Loss = 1.2425483465194702\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [0.24218750000000006, 0.25000000000000006]\n",
      "x2 : [1.9088292436859366, 1.9173499300453167]\n",
      "==============================\n",
      "2711) Lyapunov Risk = 0.9192410707473755, MSE = 0.021557364612817764, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.005912257824093103, Lv_loss = 0.0, Circular Tuning Loss = 1.249037742614746\n",
      "2712) Lyapunov Risk = 0.9191690683364868, MSE = 0.021084396168589592, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.005891469772905111, Lv_loss = 0.0, Circular Tuning Loss = 1.2488816976547241\n",
      "2713) Lyapunov Risk = 0.9191004037857056, MSE = 0.02164122834801674, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.0058706775307655334, Lv_loss = 0.0, Circular Tuning Loss = 1.2487263679504395\n",
      "2714) Lyapunov Risk = 0.9190431833267212, MSE = 0.02106623351573944, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.005850082729011774, Lv_loss = 0.0, Circular Tuning Loss = 1.2485710382461548\n",
      "2715) Lyapunov Risk = 0.9189772605895996, MSE = 0.02173105627298355, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.005829459056258202, Lv_loss = 0.0, Circular Tuning Loss = 1.248416543006897\n",
      "2716) Lyapunov Risk = 0.9189125299453735, MSE = 0.021061966195702553, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.005808993708342314, Lv_loss = 0.0, Circular Tuning Loss = 1.2482616901397705\n",
      "2717) Lyapunov Risk = 0.918819785118103, MSE = 0.021810073405504227, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.005788501817733049, Lv_loss = 0.0, Circular Tuning Loss = 1.24810791015625\n",
      "2718) Lyapunov Risk = 0.9187009334564209, MSE = 0.021045604720711708, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.005768188741058111, Lv_loss = 0.0, Circular Tuning Loss = 1.2479541301727295\n",
      "2719) Lyapunov Risk = 0.9185324907302856, MSE = 0.021820908412337303, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.005747821647673845, Lv_loss = 0.0, Circular Tuning Loss = 1.2478009462356567\n",
      "2720) Lyapunov Risk = 0.9183287620544434, MSE = 0.021004265174269676, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.005727621726691723, Lv_loss = 0.0, Circular Tuning Loss = 1.2476478815078735\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0451734773582499, 1.0551734773582497]\n",
      "x2 : [-0.92515199152096617, -0.91515199152096616]\n",
      "==============================\n",
      "2721) Lyapunov Risk = 0.9193258285522461, MSE = 0.021735904738307, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.005883411038666964, Lv_loss = 0.0, Circular Tuning Loss = 1.2499247789382935\n",
      "2722) Lyapunov Risk = 0.9190810918807983, MSE = 0.020944882184267044, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.005862593650817871, Lv_loss = 0.0, Circular Tuning Loss = 1.2497707605361938\n",
      "2723) Lyapunov Risk = 0.9188419580459595, MSE = 0.02161625400185585, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.005841554142534733, Lv_loss = 0.0, Circular Tuning Loss = 1.249617099761963\n",
      "2724) Lyapunov Risk = 0.9186371564865112, MSE = 0.020929012447595596, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.005820493213832378, Lv_loss = 0.0, Circular Tuning Loss = 1.2494627237319946\n",
      "2725) Lyapunov Risk = 0.9184712767601013, MSE = 0.021525826305150986, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.005799387115985155, Lv_loss = 0.0, Circular Tuning Loss = 1.249308466911316\n",
      "2726) Lyapunov Risk = 0.9183464050292969, MSE = 0.020972957834601402, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.0057782940566539764, Lv_loss = 0.0, Circular Tuning Loss = 1.2491533756256104\n",
      "2727) Lyapunov Risk = 0.918251633644104, MSE = 0.02149912156164646, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.005757191218435764, Lv_loss = 0.0, Circular Tuning Loss = 1.2489985227584839\n",
      "2728) Lyapunov Risk = 0.9181728959083557, MSE = 0.021043002605438232, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.005736126098781824, Lv_loss = 0.0, Circular Tuning Loss = 1.2488433122634888\n",
      "2729) Lyapunov Risk = 0.9180959463119507, MSE = 0.02150551974773407, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.005715168081223965, Lv_loss = 0.0, Circular Tuning Loss = 1.2486883401870728\n",
      "2730) Lyapunov Risk = 0.9180073142051697, MSE = 0.021091220900416374, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.005694229155778885, Lv_loss = 0.0, Circular Tuning Loss = 1.248533010482788\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0451734773582499, 1.0551734773582497]\n",
      "x2 : [-0.89808869765270238, -0.88808869765270237]\n",
      "==============================\n",
      "2731) Lyapunov Risk = 0.919041633605957, MSE = 0.021503454074263573, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.005838427692651749, Lv_loss = 0.0, Circular Tuning Loss = 1.2506364583969116\n",
      "2732) Lyapunov Risk = 0.9189070463180542, MSE = 0.021084440872073174, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.005816854070872068, Lv_loss = 0.0, Circular Tuning Loss = 1.2504792213439941\n",
      "2733) Lyapunov Risk = 0.9187448024749756, MSE = 0.02148081734776497, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.005795147269964218, Lv_loss = 0.0, Circular Tuning Loss = 1.2503217458724976\n",
      "2734) Lyapunov Risk = 0.9185603857040405, MSE = 0.02105366438627243, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.005773247219622135, Lv_loss = 0.0, Circular Tuning Loss = 1.2501637935638428\n",
      "2735) Lyapunov Risk = 0.9183663129806519, MSE = 0.02141796611249447, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.005751229356974363, Lv_loss = 0.0, Circular Tuning Loss = 1.2500054836273193\n",
      "2736) Lyapunov Risk = 0.9181748628616333, MSE = 0.021042868494987488, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.005729085765779018, Lv_loss = 0.0, Circular Tuning Loss = 1.2498466968536377\n",
      "2737) Lyapunov Risk = 0.9179970622062683, MSE = 0.021347658708691597, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.0057069286704063416, Lv_loss = 0.0, Circular Tuning Loss = 1.2496877908706665\n",
      "2738) Lyapunov Risk = 0.9178375005722046, MSE = 0.021070631220936775, V_0_loss = tensor([[0.0062]], grad_fn=<PowBackward0>), V_pos_loss = 0.005684711039066315, Lv_loss = 0.0, Circular Tuning Loss = 1.2495287656784058\n",
      "2739) Lyapunov Risk = 0.917697012424469, MSE = 0.021282965317368507, V_0_loss = tensor([[0.0063]], grad_fn=<PowBackward0>), V_pos_loss = 0.00566241517663002, Lv_loss = 0.0, Circular Tuning Loss = 1.2493698596954346\n",
      "2740) Lyapunov Risk = 0.9175710082054138, MSE = 0.021121161058545113, V_0_loss = tensor([[0.0063]], grad_fn=<PowBackward0>), V_pos_loss = 0.005640105810016394, Lv_loss = 0.0, Circular Tuning Loss = 1.2492105960845947\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0451734773582499, 1.0551734773582497]\n",
      "x2 : [-0.89808869765270238, -0.88808869765270237]\n",
      "==============================\n",
      "2741) Lyapunov Risk = 0.9185740947723389, MSE = 0.021227650344371796, V_0_loss = tensor([[0.0063]], grad_fn=<PowBackward0>), V_pos_loss = 0.005776898004114628, Lv_loss = 0.0, Circular Tuning Loss = 1.2512755393981934\n",
      "2742) Lyapunov Risk = 0.9184588193893433, MSE = 0.021153461188077927, V_0_loss = tensor([[0.0063]], grad_fn=<PowBackward0>), V_pos_loss = 0.005753903184086084, Lv_loss = 0.0, Circular Tuning Loss = 1.2511143684387207\n",
      "2743) Lyapunov Risk = 0.9183400273323059, MSE = 0.02119733765721321, V_0_loss = tensor([[0.0063]], grad_fn=<PowBackward0>), V_pos_loss = 0.00573077192530036, Lv_loss = 0.0, Circular Tuning Loss = 1.250952959060669\n",
      "2744) Lyapunov Risk = 0.9182151556015015, MSE = 0.021176928654313087, V_0_loss = tensor([[0.0063]], grad_fn=<PowBackward0>), V_pos_loss = 0.005707490257918835, Lv_loss = 0.0, Circular Tuning Loss = 1.2507911920547485\n",
      "2745) Lyapunov Risk = 0.9180827736854553, MSE = 0.021172218024730682, V_0_loss = tensor([[0.0063]], grad_fn=<PowBackward0>), V_pos_loss = 0.00568403210490942, Lv_loss = 0.0, Circular Tuning Loss = 1.25062894821167\n",
      "2746) Lyapunov Risk = 0.9179435968399048, MSE = 0.021199144423007965, V_0_loss = tensor([[0.0063]], grad_fn=<PowBackward0>), V_pos_loss = 0.005660471506416798, Lv_loss = 0.0, Circular Tuning Loss = 1.2504668235778809\n",
      "2747) Lyapunov Risk = 0.9177999496459961, MSE = 0.021149635314941406, V_0_loss = tensor([[0.0063]], grad_fn=<PowBackward0>), V_pos_loss = 0.005636816378682852, Lv_loss = 0.0, Circular Tuning Loss = 1.2503043413162231\n",
      "2748) Lyapunov Risk = 0.9176541566848755, MSE = 0.021216215565800667, V_0_loss = tensor([[0.0063]], grad_fn=<PowBackward0>), V_pos_loss = 0.005613104905933142, Lv_loss = 0.0, Circular Tuning Loss = 1.2501417398452759\n",
      "2749) Lyapunov Risk = 0.9175090193748474, MSE = 0.02111664228141308, V_0_loss = tensor([[0.0063]], grad_fn=<PowBackward0>), V_pos_loss = 0.0055893766693770885, Lv_loss = 0.0, Circular Tuning Loss = 1.2499792575836182\n",
      "2750) Lyapunov Risk = 0.917366087436676, MSE = 0.021228406578302383, V_0_loss = tensor([[0.0063]], grad_fn=<PowBackward0>), V_pos_loss = 0.005565623287111521, Lv_loss = 0.0, Circular Tuning Loss = 1.24981689453125\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0451734773582499, 1.0551734773582497]\n",
      "x2 : [-0.89808869765270238, -0.88808869765270237]\n",
      "==============================\n",
      "2751) Lyapunov Risk = 0.9183287024497986, MSE = 0.021077847108244896, V_0_loss = tensor([[0.0063]], grad_fn=<PowBackward0>), V_pos_loss = 0.005694561637938023, Lv_loss = 0.0, Circular Tuning Loss = 1.2518562078475952\n",
      "2752) Lyapunov Risk = 0.9181903600692749, MSE = 0.021221570670604706, V_0_loss = tensor([[0.0063]], grad_fn=<PowBackward0>), V_pos_loss = 0.005669998470693827, Lv_loss = 0.0, Circular Tuning Loss = 1.2516920566558838\n",
      "2753) Lyapunov Risk = 0.9180559515953064, MSE = 0.021051617339253426, V_0_loss = tensor([[0.0063]], grad_fn=<PowBackward0>), V_pos_loss = 0.005645213183015585, Lv_loss = 0.0, Circular Tuning Loss = 1.251527190208435\n",
      "2754) Lyapunov Risk = 0.9179244637489319, MSE = 0.02123178541660309, V_0_loss = tensor([[0.0063]], grad_fn=<PowBackward0>), V_pos_loss = 0.005620217882096767, Lv_loss = 0.0, Circular Tuning Loss = 1.2513619661331177\n",
      "2755) Lyapunov Risk = 0.9177964925765991, MSE = 0.021024877205491066, V_0_loss = tensor([[0.0063]], grad_fn=<PowBackward0>), V_pos_loss = 0.005595042835921049, Lv_loss = 0.0, Circular Tuning Loss = 1.2511965036392212\n",
      "2756) Lyapunov Risk = 0.9176702499389648, MSE = 0.021267423406243324, V_0_loss = tensor([[0.0063]], grad_fn=<PowBackward0>), V_pos_loss = 0.005569686181843281, Lv_loss = 0.0, Circular Tuning Loss = 1.251030683517456\n",
      "2757) Lyapunov Risk = 0.9175471663475037, MSE = 0.020996157079935074, V_0_loss = tensor([[0.0063]], grad_fn=<PowBackward0>), V_pos_loss = 0.0055442010052502155, Lv_loss = 0.0, Circular Tuning Loss = 1.2508645057678223\n",
      "2758) Lyapunov Risk = 0.9174259305000305, MSE = 0.021322013810276985, V_0_loss = tensor([[0.0063]], grad_fn=<PowBackward0>), V_pos_loss = 0.00551856542006135, Lv_loss = 0.0, Circular Tuning Loss = 1.2506985664367676\n",
      "2759) Lyapunov Risk = 0.9173094034194946, MSE = 0.02094648964703083, V_0_loss = tensor([[0.0063]], grad_fn=<PowBackward0>), V_pos_loss = 0.005492851138114929, Lv_loss = 0.0, Circular Tuning Loss = 1.2505320310592651\n",
      "2760) Lyapunov Risk = 0.9172003865242004, MSE = 0.02140638418495655, V_0_loss = tensor([[0.0063]], grad_fn=<PowBackward0>), V_pos_loss = 0.005467025097459555, Lv_loss = 0.0, Circular Tuning Loss = 1.2503658533096313\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0451734773582499, 1.0551734773582497]\n",
      "x2 : [-0.89808869765270238, -0.88808869765270237]\n",
      "==============================\n",
      "2761) Lyapunov Risk = 0.918183445930481, MSE = 0.020857354626059532, V_0_loss = tensor([[0.0063]], grad_fn=<PowBackward0>), V_pos_loss = 0.00558777991682291, Lv_loss = 0.0, Circular Tuning Loss = 1.2523690462112427\n",
      "2762) Lyapunov Risk = 0.9180970191955566, MSE = 0.021541312336921692, V_0_loss = tensor([[0.0063]], grad_fn=<PowBackward0>), V_pos_loss = 0.00556114362552762, Lv_loss = 0.0, Circular Tuning Loss = 1.2522003650665283\n",
      "2763) Lyapunov Risk = 0.9180413484573364, MSE = 0.020739931613206863, V_0_loss = tensor([[0.0063]], grad_fn=<PowBackward0>), V_pos_loss = 0.005534347612410784, Lv_loss = 0.0, Circular Tuning Loss = 1.2520312070846558\n",
      "2764) Lyapunov Risk = 0.9180135726928711, MSE = 0.021777819842100143, V_0_loss = tensor([[0.0063]], grad_fn=<PowBackward0>), V_pos_loss = 0.005507333669811487, Lv_loss = 0.0, Circular Tuning Loss = 1.251861572265625\n",
      "2765) Lyapunov Risk = 0.9180415868759155, MSE = 0.020601442083716393, V_0_loss = tensor([[0.0063]], grad_fn=<PowBackward0>), V_pos_loss = 0.005480263382196426, Lv_loss = 0.0, Circular Tuning Loss = 1.2516911029815674\n",
      "2766) Lyapunov Risk = 0.9181139469146729, MSE = 0.022148894146084785, V_0_loss = tensor([[0.0063]], grad_fn=<PowBackward0>), V_pos_loss = 0.005453034304082394, Lv_loss = 0.0, Circular Tuning Loss = 1.2515207529067993\n",
      "2767) Lyapunov Risk = 0.9182466864585876, MSE = 0.020486239343881607, V_0_loss = tensor([[0.0063]], grad_fn=<PowBackward0>), V_pos_loss = 0.005425911396741867, Lv_loss = 0.0, Circular Tuning Loss = 1.2513494491577148\n",
      "2768) Lyapunov Risk = 0.9183549880981445, MSE = 0.022565651684999466, V_0_loss = tensor([[0.0063]], grad_fn=<PowBackward0>), V_pos_loss = 0.005398597102612257, Lv_loss = 0.0, Circular Tuning Loss = 1.2511788606643677\n",
      "2769) Lyapunov Risk = 0.9184635877609253, MSE = 0.020430991426110268, V_0_loss = tensor([[0.0063]], grad_fn=<PowBackward0>), V_pos_loss = 0.005371399223804474, Lv_loss = 0.0, Circular Tuning Loss = 1.251007080078125\n",
      "2770) Lyapunov Risk = 0.9183365106582642, MSE = 0.022733377292752266, V_0_loss = tensor([[0.0064]], grad_fn=<PowBackward0>), V_pos_loss = 0.005344002041965723, Lv_loss = 0.0, Circular Tuning Loss = 1.2508362531661987\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [0.46875000000000011, 0.47656250000000011]\n",
      "x2 : [1.7373051411091545, 1.7421567416492219]\n",
      "==============================\n",
      "2771) Lyapunov Risk = 0.9206224679946899, MSE = 0.02045167051255703, V_0_loss = tensor([[0.0064]], grad_fn=<PowBackward0>), V_pos_loss = 0.00530267134308815, Lv_loss = 0.0, Circular Tuning Loss = 1.2559430599212646\n",
      "2772) Lyapunov Risk = 0.92006516456604, MSE = 0.022222822532057762, V_0_loss = tensor([[0.0064]], grad_fn=<PowBackward0>), V_pos_loss = 0.005275328643620014, Lv_loss = 0.0, Circular Tuning Loss = 1.255771517753601\n",
      "2773) Lyapunov Risk = 0.9195245504379272, MSE = 0.02069743163883686, V_0_loss = tensor([[0.0064]], grad_fn=<PowBackward0>), V_pos_loss = 0.005248214118182659, Lv_loss = 0.0, Circular Tuning Loss = 1.2555996179580688\n",
      "2774) Lyapunov Risk = 0.9191460013389587, MSE = 0.02136150747537613, V_0_loss = tensor([[0.0064]], grad_fn=<PowBackward0>), V_pos_loss = 0.005221106577664614, Lv_loss = 0.0, Circular Tuning Loss = 1.2554285526275635\n",
      "2775) Lyapunov Risk = 0.9189997315406799, MSE = 0.021300317719578743, V_0_loss = tensor([[0.0064]], grad_fn=<PowBackward0>), V_pos_loss = 0.005194328725337982, Lv_loss = 0.0, Circular Tuning Loss = 1.2552584409713745\n",
      "2776) Lyapunov Risk = 0.9189857244491577, MSE = 0.02081969566643238, V_0_loss = tensor([[0.0064]], grad_fn=<PowBackward0>), V_pos_loss = 0.005167676601558924, Lv_loss = 0.0, Circular Tuning Loss = 1.2550891637802124\n",
      "2777) Lyapunov Risk = 0.9189399480819702, MSE = 0.02178375795483589, V_0_loss = tensor([[0.0064]], grad_fn=<PowBackward0>), V_pos_loss = 0.005141125991940498, Lv_loss = 0.0, Circular Tuning Loss = 1.2549211978912354\n",
      "2778) Lyapunov Risk = 0.9187780022621155, MSE = 0.020649379119277, V_0_loss = tensor([[0.0064]], grad_fn=<PowBackward0>), V_pos_loss = 0.005114758387207985, Lv_loss = 0.0, Circular Tuning Loss = 1.2547532320022583\n",
      "2779) Lyapunov Risk = 0.9184828996658325, MSE = 0.021668318659067154, V_0_loss = tensor([[0.0064]], grad_fn=<PowBackward0>), V_pos_loss = 0.005088514648377895, Lv_loss = 0.0, Circular Tuning Loss = 1.2545865774154663\n",
      "2780) Lyapunov Risk = 0.9181851744651794, MSE = 0.020787715911865234, V_0_loss = tensor([[0.0064]], grad_fn=<PowBackward0>), V_pos_loss = 0.005062476731836796, Lv_loss = 0.0, Circular Tuning Loss = 1.254420280456543\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [0.27343750000000011, 0.28125000000000011]\n",
      "x2 : [1.9682205376647242, 1.9747201735872246]\n",
      "==============================\n",
      "2781) Lyapunov Risk = 0.9215611815452576, MSE = 0.021195299923419952, V_0_loss = tensor([[0.0064]], grad_fn=<PowBackward0>), V_pos_loss = 0.005023241508752108, Lv_loss = 0.0, Circular Tuning Loss = 1.2613962888717651\n",
      "2782) Lyapunov Risk = 0.921502947807312, MSE = 0.02120015025138855, V_0_loss = tensor([[0.0064]], grad_fn=<PowBackward0>), V_pos_loss = 0.004997566342353821, Lv_loss = 0.0, Circular Tuning Loss = 1.2612301111221313\n",
      "2783) Lyapunov Risk = 0.9214978218078613, MSE = 0.020916428416967392, V_0_loss = tensor([[0.0064]], grad_fn=<PowBackward0>), V_pos_loss = 0.004972056485712528, Lv_loss = 0.0, Circular Tuning Loss = 1.2610647678375244\n",
      "2784) Lyapunov Risk = 0.9214364290237427, MSE = 0.021478744223713875, V_0_loss = tensor([[0.0064]], grad_fn=<PowBackward0>), V_pos_loss = 0.00494674127548933, Lv_loss = 0.0, Circular Tuning Loss = 1.2609002590179443\n",
      "2785) Lyapunov Risk = 0.9212672710418701, MSE = 0.020893771201372147, V_0_loss = tensor([[0.0064]], grad_fn=<PowBackward0>), V_pos_loss = 0.0049215988256037235, Lv_loss = 0.0, Circular Tuning Loss = 1.260736107826233\n",
      "2786) Lyapunov Risk = 0.9210189580917358, MSE = 0.021310728043317795, V_0_loss = tensor([[0.0064]], grad_fn=<PowBackward0>), V_pos_loss = 0.004896668251603842, Lv_loss = 0.0, Circular Tuning Loss = 1.2605726718902588\n",
      "2787) Lyapunov Risk = 0.9207746386528015, MSE = 0.021064840257167816, V_0_loss = tensor([[0.0064]], grad_fn=<PowBackward0>), V_pos_loss = 0.004871943034231663, Lv_loss = 0.0, Circular Tuning Loss = 1.2604095935821533\n",
      "2788) Lyapunov Risk = 0.9205979704856873, MSE = 0.02095515839755535, V_0_loss = tensor([[0.0064]], grad_fn=<PowBackward0>), V_pos_loss = 0.004847371019423008, Lv_loss = 0.0, Circular Tuning Loss = 1.260246992111206\n",
      "2789) Lyapunov Risk = 0.9204914569854736, MSE = 0.021335691213607788, V_0_loss = tensor([[0.0064]], grad_fn=<PowBackward0>), V_pos_loss = 0.004822918679565191, Lv_loss = 0.0, Circular Tuning Loss = 1.2600852251052856\n",
      "2790) Lyapunov Risk = 0.9204057455062866, MSE = 0.020763736218214035, V_0_loss = tensor([[0.0064]], grad_fn=<PowBackward0>), V_pos_loss = 0.004798585548996925, Lv_loss = 0.0, Circular Tuning Loss = 1.2599234580993652\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.1855468750000004, 1.1875000000000004]\n",
      "x2 : [0.3247595264191645, 0.3281424381526975]\n",
      "==============================\n",
      "2791) Lyapunov Risk = 0.9209066033363342, MSE = 0.021424051374197006, V_0_loss = tensor([[0.0064]], grad_fn=<PowBackward0>), V_pos_loss = 0.004761743824928999, Lv_loss = 0.0, Circular Tuning Loss = 1.260115623474121\n",
      "2792) Lyapunov Risk = 0.9207437038421631, MSE = 0.020786434412002563, V_0_loss = tensor([[0.0064]], grad_fn=<PowBackward0>), V_pos_loss = 0.004737944342195988, Lv_loss = 0.0, Circular Tuning Loss = 1.2599525451660156\n",
      "2793) Lyapunov Risk = 0.9205536842346191, MSE = 0.021234044805169106, V_0_loss = tensor([[0.0064]], grad_fn=<PowBackward0>), V_pos_loss = 0.004714513197541237, Lv_loss = 0.0, Circular Tuning Loss = 1.259788990020752\n",
      "2794) Lyapunov Risk = 0.9203813076019287, MSE = 0.020995397120714188, V_0_loss = tensor([[0.0064]], grad_fn=<PowBackward0>), V_pos_loss = 0.004691505338996649, Lv_loss = 0.0, Circular Tuning Loss = 1.259624719619751\n",
      "2795) Lyapunov Risk = 0.920251190662384, MSE = 0.020954810082912445, V_0_loss = tensor([[0.0064]], grad_fn=<PowBackward0>), V_pos_loss = 0.004668849054723978, Lv_loss = 4.7525102786494244e-07, Circular Tuning Loss = 1.2594598531723022\n",
      "2796) Lyapunov Risk = 0.9201517105102539, MSE = 0.021252835169434547, V_0_loss = tensor([[0.0064]], grad_fn=<PowBackward0>), V_pos_loss = 0.004646515939384699, Lv_loss = 1.457501412005513e-06, Circular Tuning Loss = 1.2592945098876953\n",
      "2797) Lyapunov Risk = 0.9200548529624939, MSE = 0.020798319950699806, V_0_loss = tensor([[0.0064]], grad_fn=<PowBackward0>), V_pos_loss = 0.004624452441930771, Lv_loss = 2.3495515506510856e-06, Circular Tuning Loss = 1.2591289281845093\n",
      "2798) Lyapunov Risk = 0.919929563999176, MSE = 0.021338608115911484, V_0_loss = tensor([[0.0064]], grad_fn=<PowBackward0>), V_pos_loss = 0.004602653905749321, Lv_loss = 3.185790319548687e-06, Circular Tuning Loss = 1.2589629888534546\n",
      "2799) Lyapunov Risk = 0.9197800159454346, MSE = 0.020803282037377357, V_0_loss = tensor([[0.0064]], grad_fn=<PowBackward0>), V_pos_loss = 0.00458110636100173, Lv_loss = 3.995657607447356e-06, Circular Tuning Loss = 1.2587968111038208\n",
      "2800) Lyapunov Risk = 0.9196215867996216, MSE = 0.02121281810104847, V_0_loss = tensor([[0.0064]], grad_fn=<PowBackward0>), V_pos_loss = 0.00455985963344574, Lv_loss = 4.782771611644421e-06, Circular Tuning Loss = 1.2586307525634766\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.2500000000000004, 1.2519531250000004]\n",
      "x2 : [0.31122787948503267, 0.31461079121856561]\n",
      "==============================\n",
      "2801) Lyapunov Risk = 0.9202736020088196, MSE = 0.020935876294970512, V_0_loss = tensor([[0.0064]], grad_fn=<PowBackward0>), V_pos_loss = 0.004526976961642504, Lv_loss = 5.687788871000521e-06, Circular Tuning Loss = 1.259188175201416\n",
      "2802) Lyapunov Risk = 0.9201476573944092, MSE = 0.0210266076028347, V_0_loss = tensor([[0.0065]], grad_fn=<PowBackward0>), V_pos_loss = 0.004506547003984451, Lv_loss = 6.244891665119212e-06, Circular Tuning Loss = 1.259020209312439\n",
      "2803) Lyapunov Risk = 0.9200344085693359, MSE = 0.02109667658805847, V_0_loss = tensor([[0.0065]], grad_fn=<PowBackward0>), V_pos_loss = 0.004486574791371822, Lv_loss = 6.923661203472875e-06, Circular Tuning Loss = 1.2588512897491455\n",
      "2804) Lyapunov Risk = 0.9199159741401672, MSE = 0.020939825102686882, V_0_loss = tensor([[0.0065]], grad_fn=<PowBackward0>), V_pos_loss = 0.004467036575078964, Lv_loss = 7.12620749254711e-06, Circular Tuning Loss = 1.258681297302246\n",
      "2805) Lyapunov Risk = 0.9197828769683838, MSE = 0.02112821489572525, V_0_loss = tensor([[0.0065]], grad_fn=<PowBackward0>), V_pos_loss = 0.0044478788040578365, Lv_loss = 7.581920272059506e-06, Circular Tuning Loss = 1.258510708808899\n",
      "2806) Lyapunov Risk = 0.91963791847229, MSE = 0.020970499143004417, V_0_loss = tensor([[0.0065]], grad_fn=<PowBackward0>), V_pos_loss = 0.004429094027727842, Lv_loss = 7.574518349429127e-06, Circular Tuning Loss = 1.258339285850525\n",
      "2807) Lyapunov Risk = 0.9194914698600769, MSE = 0.021029174327850342, V_0_loss = tensor([[0.0065]], grad_fn=<PowBackward0>), V_pos_loss = 0.004410615190863609, Lv_loss = 7.81869312049821e-06, Circular Tuning Loss = 1.2581675052642822\n",
      "2808) Lyapunov Risk = 0.9193529486656189, MSE = 0.02107240818440914, V_0_loss = tensor([[0.0065]], grad_fn=<PowBackward0>), V_pos_loss = 0.004392403177917004, Lv_loss = 7.71256054576952e-06, Circular Tuning Loss = 1.2579954862594604\n",
      "2809) Lyapunov Risk = 0.9192262887954712, MSE = 0.02090098336338997, V_0_loss = tensor([[0.0065]], grad_fn=<PowBackward0>), V_pos_loss = 0.004374445881694555, Lv_loss = 7.746265509922523e-06, Circular Tuning Loss = 1.25782310962677\n",
      "2810) Lyapunov Risk = 0.9191043376922607, MSE = 0.021171042695641518, V_0_loss = tensor([[0.0065]], grad_fn=<PowBackward0>), V_pos_loss = 0.004356746096163988, Lv_loss = 7.566985004814342e-06, Circular Tuning Loss = 1.2576504945755005\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.2500000000000004, 1.2519531250000004]\n",
      "x2 : [0.32137661468563156, 0.3247595264191645]\n",
      "==============================\n",
      "2811) Lyapunov Risk = 0.9197837710380554, MSE = 0.020829804241657257, V_0_loss = tensor([[0.0065]], grad_fn=<PowBackward0>), V_pos_loss = 0.004327968694269657, Lv_loss = 7.429499419231433e-06, Circular Tuning Loss = 1.2582106590270996\n",
      "2812) Lyapunov Risk = 0.919650673866272, MSE = 0.02117607183754444, V_0_loss = tensor([[0.0065]], grad_fn=<PowBackward0>), V_pos_loss = 0.004311142489314079, Lv_loss = 7.054944944684394e-06, Circular Tuning Loss = 1.2580369710922241\n",
      "2813) Lyapunov Risk = 0.9195134043693542, MSE = 0.020853137597441673, V_0_loss = tensor([[0.0065]], grad_fn=<PowBackward0>), V_pos_loss = 0.004294820129871368, Lv_loss = 6.632581971643958e-06, Circular Tuning Loss = 1.2578623294830322\n",
      "2814) Lyapunov Risk = 0.9193750023841858, MSE = 0.02110588178038597, V_0_loss = tensor([[0.0065]], grad_fn=<PowBackward0>), V_pos_loss = 0.00427889684215188, Lv_loss = 6.004151600791374e-06, Circular Tuning Loss = 1.257686972618103\n",
      "2815) Lyapunov Risk = 0.9192425012588501, MSE = 0.02092881128191948, V_0_loss = tensor([[0.0065]], grad_fn=<PowBackward0>), V_pos_loss = 0.004263339564204216, Lv_loss = 5.447757303045364e-06, Circular Tuning Loss = 1.257511019706726\n",
      "2816) Lyapunov Risk = 0.9191148281097412, MSE = 0.02103492058813572, V_0_loss = tensor([[0.0065]], grad_fn=<PowBackward0>), V_pos_loss = 0.004248104523867369, Lv_loss = 4.634674951375928e-06, Circular Tuning Loss = 1.25733482837677\n",
      "2817) Lyapunov Risk = 0.9189904928207397, MSE = 0.020992808043956757, V_0_loss = tensor([[0.0065]], grad_fn=<PowBackward0>), V_pos_loss = 0.004233179613947868, Lv_loss = 3.964787083532428e-06, Circular Tuning Loss = 1.2571582794189453\n",
      "2818) Lyapunov Risk = 0.9188665151596069, MSE = 0.021000433713197708, V_0_loss = tensor([[0.0065]], grad_fn=<PowBackward0>), V_pos_loss = 0.004218517802655697, Lv_loss = 2.981320676553878e-06, Circular Tuning Loss = 1.2569819688796997\n",
      "2819) Lyapunov Risk = 0.91874098777771, MSE = 0.021003482863307, V_0_loss = tensor([[0.0065]], grad_fn=<PowBackward0>), V_pos_loss = 0.004204126540571451, Lv_loss = 2.215426320617553e-06, Circular Tuning Loss = 1.2568055391311646\n",
      "2820) Lyapunov Risk = 0.9186140894889832, MSE = 0.02101009711623192, V_0_loss = tensor([[0.0065]], grad_fn=<PowBackward0>), V_pos_loss = 0.004189960192888975, Lv_loss = 1.1190634268132271e-06, Circular Tuning Loss = 1.2566293478012085\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.1230468750000004, 1.1250000000000004]\n",
      "x2 : [0.3247595264191645, 0.3281424381526975]\n",
      "==============================\n",
      "2821) Lyapunov Risk = 0.918918788433075, MSE = 0.020960608497262, V_0_loss = tensor([[0.0065]], grad_fn=<PowBackward0>), V_pos_loss = 0.004165109246969223, Lv_loss = 3.309067153622891e-07, Circular Tuning Loss = 1.2564371824264526\n",
      "2822) Lyapunov Risk = 0.9187929630279541, MSE = 0.02105451375246048, V_0_loss = tensor([[0.0065]], grad_fn=<PowBackward0>), V_pos_loss = 0.004151704255491495, Lv_loss = 0.0, Circular Tuning Loss = 1.2562602758407593\n",
      "2823) Lyapunov Risk = 0.9186720848083496, MSE = 0.020901290699839592, V_0_loss = tensor([[0.0065]], grad_fn=<PowBackward0>), V_pos_loss = 0.004138773772865534, Lv_loss = 0.0, Circular Tuning Loss = 1.25608229637146\n",
      "2824) Lyapunov Risk = 0.918555736541748, MSE = 0.021128784865140915, V_0_loss = tensor([[0.0065]], grad_fn=<PowBackward0>), V_pos_loss = 0.004126221872866154, Lv_loss = 0.0, Circular Tuning Loss = 1.2559038400650024\n",
      "2825) Lyapunov Risk = 0.9184473156929016, MSE = 0.020845316350460052, V_0_loss = tensor([[0.0066]], grad_fn=<PowBackward0>), V_pos_loss = 0.004114056471735239, Lv_loss = 0.0, Circular Tuning Loss = 1.2557249069213867\n",
      "2826) Lyapunov Risk = 0.918350100517273, MSE = 0.02122066728770733, V_0_loss = tensor([[0.0066]], grad_fn=<PowBackward0>), V_pos_loss = 0.004102181177586317, Lv_loss = 0.0, Circular Tuning Loss = 1.255545973777771\n",
      "2827) Lyapunov Risk = 0.918265163898468, MSE = 0.02080405317246914, V_0_loss = tensor([[0.0066]], grad_fn=<PowBackward0>), V_pos_loss = 0.004090602044016123, Lv_loss = 0.0, Circular Tuning Loss = 1.2553669214248657\n",
      "2828) Lyapunov Risk = 0.9181953072547913, MSE = 0.021322710439562798, V_0_loss = tensor([[0.0066]], grad_fn=<PowBackward0>), V_pos_loss = 0.0040792422369122505, Lv_loss = 0.0, Circular Tuning Loss = 1.255187749862671\n",
      "2829) Lyapunov Risk = 0.9181459546089172, MSE = 0.020787933841347694, V_0_loss = tensor([[0.0066]], grad_fn=<PowBackward0>), V_pos_loss = 0.004068141337484121, Lv_loss = 0.0, Circular Tuning Loss = 1.2550090551376343\n",
      "2830) Lyapunov Risk = 0.918118417263031, MSE = 0.021433712914586067, V_0_loss = tensor([[0.0066]], grad_fn=<PowBackward0>), V_pos_loss = 0.004057202488183975, Lv_loss = 0.0, Circular Tuning Loss = 1.2548303604125977\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [0.36218750000000011, 0.37218750000000012]\n",
      "x2 : [1.9354380782878713, 1.9447863144176876]\n",
      "==============================\n",
      "2831) Lyapunov Risk = 0.9215290546417236, MSE = 0.02080799825489521, V_0_loss = tensor([[0.0066]], grad_fn=<PowBackward0>), V_pos_loss = 0.004035966470837593, Lv_loss = 0.0, Circular Tuning Loss = 1.2615267038345337\n",
      "2832) Lyapunov Risk = 0.9215456247329712, MSE = 0.02155768871307373, V_0_loss = tensor([[0.0066]], grad_fn=<PowBackward0>), V_pos_loss = 0.0040254476480185986, Lv_loss = 0.0, Circular Tuning Loss = 1.2613470554351807\n",
      "2833) Lyapunov Risk = 0.9215715527534485, MSE = 0.020864803344011307, V_0_loss = tensor([[0.0066]], grad_fn=<PowBackward0>), V_pos_loss = 0.004015171900391579, Lv_loss = 0.0, Circular Tuning Loss = 1.2611675262451172\n",
      "2834) Lyapunov Risk = 0.9215774536132812, MSE = 0.021690962836146355, V_0_loss = tensor([[0.0066]], grad_fn=<PowBackward0>), V_pos_loss = 0.004005005583167076, Lv_loss = 0.0, Circular Tuning Loss = 1.260988712310791\n",
      "2835) Lyapunov Risk = 0.9215343594551086, MSE = 0.020901286974549294, V_0_loss = tensor([[0.0066]], grad_fn=<PowBackward0>), V_pos_loss = 0.003995061386376619, Lv_loss = 0.0, Circular Tuning Loss = 1.260810375213623\n",
      "2836) Lyapunov Risk = 0.9213860630989075, MSE = 0.021740470081567764, V_0_loss = tensor([[0.0066]], grad_fn=<PowBackward0>), V_pos_loss = 0.003985180985182524, Lv_loss = 0.0, Circular Tuning Loss = 1.2606327533721924\n",
      "2837) Lyapunov Risk = 0.9211242198944092, MSE = 0.020850537344813347, V_0_loss = tensor([[0.0066]], grad_fn=<PowBackward0>), V_pos_loss = 0.003975503612309694, Lv_loss = 0.0, Circular Tuning Loss = 1.2604553699493408\n",
      "2838) Lyapunov Risk = 0.9207533001899719, MSE = 0.02158704772591591, V_0_loss = tensor([[0.0066]], grad_fn=<PowBackward0>), V_pos_loss = 0.003965833690017462, Lv_loss = 0.0, Circular Tuning Loss = 1.2602788209915161\n",
      "2839) Lyapunov Risk = 0.9203425645828247, MSE = 0.020757921040058136, V_0_loss = tensor([[0.0066]], grad_fn=<PowBackward0>), V_pos_loss = 0.003956368658691645, Lv_loss = 0.0, Circular Tuning Loss = 1.2601031064987183\n",
      "2840) Lyapunov Risk = 0.91997230052948, MSE = 0.021294206380844116, V_0_loss = tensor([[0.0066]], grad_fn=<PowBackward0>), V_pos_loss = 0.003946920856833458, Lv_loss = 0.0, Circular Tuning Loss = 1.2599282264709473\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0451734773582499, 1.0551734773582497]\n",
      "x2 : [-0.89808869765270238, -0.88808869765270237]\n",
      "==============================\n",
      "2841) Lyapunov Risk = 0.9206533432006836, MSE = 0.020793061703443527, V_0_loss = tensor([[0.0066]], grad_fn=<PowBackward0>), V_pos_loss = 0.004047323949635029, Lv_loss = 0.0, Circular Tuning Loss = 1.261741280555725\n",
      "2842) Lyapunov Risk = 0.920498788356781, MSE = 0.021046467125415802, V_0_loss = tensor([[0.0066]], grad_fn=<PowBackward0>), V_pos_loss = 0.00403768802061677, Lv_loss = 0.0, Circular Tuning Loss = 1.261567234992981\n",
      "2843) Lyapunov Risk = 0.920432984828949, MSE = 0.021009808406233788, V_0_loss = tensor([[0.0066]], grad_fn=<PowBackward0>), V_pos_loss = 0.004027804359793663, Lv_loss = 0.0, Circular Tuning Loss = 1.2613937854766846\n",
      "2844) Lyapunov Risk = 0.9204100370407104, MSE = 0.020893197506666183, V_0_loss = tensor([[0.0066]], grad_fn=<PowBackward0>), V_pos_loss = 0.004017841536551714, Lv_loss = 0.0, Circular Tuning Loss = 1.2612210512161255\n",
      "2845) Lyapunov Risk = 0.9203794002532959, MSE = 0.021263908594846725, V_0_loss = tensor([[0.0066]], grad_fn=<PowBackward0>), V_pos_loss = 0.004007627256214619, Lv_loss = 0.0, Circular Tuning Loss = 1.2610492706298828\n",
      "2846) Lyapunov Risk = 0.9203065037727356, MSE = 0.020781205967068672, V_0_loss = tensor([[0.0066]], grad_fn=<PowBackward0>), V_pos_loss = 0.003997331019490957, Lv_loss = 0.0, Circular Tuning Loss = 1.2608776092529297\n",
      "2847) Lyapunov Risk = 0.9201706647872925, MSE = 0.021392032504081726, V_0_loss = tensor([[0.0067]], grad_fn=<PowBackward0>), V_pos_loss = 0.003986750729382038, Lv_loss = 0.0, Circular Tuning Loss = 1.260707139968872\n",
      "2848) Lyapunov Risk = 0.9199840426445007, MSE = 0.020699191838502884, V_0_loss = tensor([[0.0067]], grad_fn=<PowBackward0>), V_pos_loss = 0.003976141568273306, Lv_loss = 0.0, Circular Tuning Loss = 1.2605372667312622\n",
      "2849) Lyapunov Risk = 0.9197694063186646, MSE = 0.021343756467103958, V_0_loss = tensor([[0.0067]], grad_fn=<PowBackward0>), V_pos_loss = 0.0039653778076171875, Lv_loss = 0.0, Circular Tuning Loss = 1.2603681087493896\n",
      "2850) Lyapunov Risk = 0.9195589423179626, MSE = 0.02069580927491188, V_0_loss = tensor([[0.0067]], grad_fn=<PowBackward0>), V_pos_loss = 0.003954598214477301, Lv_loss = 0.0, Circular Tuning Loss = 1.2601988315582275\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0451734773582499, 1.0551734773582497]\n",
      "x2 : [-0.89808869765270238, -0.88808869765270237]\n",
      "==============================\n",
      "2851) Lyapunov Risk = 0.9203171730041504, MSE = 0.021196234971284866, V_0_loss = tensor([[0.0067]], grad_fn=<PowBackward0>), V_pos_loss = 0.00405070511624217, Lv_loss = 0.0, Circular Tuning Loss = 1.262009859085083\n",
      "2852) Lyapunov Risk = 0.920162558555603, MSE = 0.020792527124285698, V_0_loss = tensor([[0.0067]], grad_fn=<PowBackward0>), V_pos_loss = 0.004039396997541189, Lv_loss = 0.0, Circular Tuning Loss = 1.261841058731079\n",
      "2853) Lyapunov Risk = 0.9200318455696106, MSE = 0.02102798782289028, V_0_loss = tensor([[0.0067]], grad_fn=<PowBackward0>), V_pos_loss = 0.004027831833809614, Lv_loss = 0.0, Circular Tuning Loss = 1.2616722583770752\n",
      "2854) Lyapunov Risk = 0.9199172854423523, MSE = 0.02096370980143547, V_0_loss = tensor([[0.0067]], grad_fn=<PowBackward0>), V_pos_loss = 0.0040160901844501495, Lv_loss = 0.0, Circular Tuning Loss = 1.2615034580230713\n",
      "2855) Lyapunov Risk = 0.9198082685470581, MSE = 0.020866533741354942, V_0_loss = tensor([[0.0067]], grad_fn=<PowBackward0>), V_pos_loss = 0.00400418508797884, Lv_loss = 0.0, Circular Tuning Loss = 1.261335015296936\n",
      "2856) Lyapunov Risk = 0.9196944832801819, MSE = 0.021120255813002586, V_0_loss = tensor([[0.0067]], grad_fn=<PowBackward0>), V_pos_loss = 0.003992084413766861, Lv_loss = 0.0, Circular Tuning Loss = 1.2611664533615112\n",
      "2857) Lyapunov Risk = 0.9195755124092102, MSE = 0.020750446245074272, V_0_loss = tensor([[0.0067]], grad_fn=<PowBackward0>), V_pos_loss = 0.003979858011007309, Lv_loss = 0.0, Circular Tuning Loss = 1.2609981298446655\n",
      "2858) Lyapunov Risk = 0.9194487929344177, MSE = 0.02121284231543541, V_0_loss = tensor([[0.0067]], grad_fn=<PowBackward0>), V_pos_loss = 0.0039674341678619385, Lv_loss = 0.0, Circular Tuning Loss = 1.260830044746399\n",
      "2859) Lyapunov Risk = 0.9193165898323059, MSE = 0.02069525048136711, V_0_loss = tensor([[0.0067]], grad_fn=<PowBackward0>), V_pos_loss = 0.003954920917749405, Lv_loss = 0.0, Circular Tuning Loss = 1.260662317276001\n",
      "2860) Lyapunov Risk = 0.9191778898239136, MSE = 0.02122391387820244, V_0_loss = tensor([[0.0067]], grad_fn=<PowBackward0>), V_pos_loss = 0.00394224189221859, Lv_loss = 0.0, Circular Tuning Loss = 1.2604951858520508\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0451734773582499, 1.0551734773582497]\n",
      "x2 : [-0.89808869765270238, -0.88808869765270237]\n",
      "==============================\n",
      "2861) Lyapunov Risk = 0.9199738502502441, MSE = 0.020701304078102112, V_0_loss = tensor([[0.0067]], grad_fn=<PowBackward0>), V_pos_loss = 0.004033379722386599, Lv_loss = 0.0, Circular Tuning Loss = 1.2623008489608765\n",
      "2862) Lyapunov Risk = 0.9198241829872131, MSE = 0.021145900711417198, V_0_loss = tensor([[0.0067]], grad_fn=<PowBackward0>), V_pos_loss = 0.0040199244394898415, Lv_loss = 0.0, Circular Tuning Loss = 1.2621333599090576\n",
      "2863) Lyapunov Risk = 0.9196760058403015, MSE = 0.0207718163728714, V_0_loss = tensor([[0.0067]], grad_fn=<PowBackward0>), V_pos_loss = 0.004006134811788797, Lv_loss = 0.0, Circular Tuning Loss = 1.2619657516479492\n",
      "2864) Lyapunov Risk = 0.9195311069488525, MSE = 0.02102045528590679, V_0_loss = tensor([[0.0067]], grad_fn=<PowBackward0>), V_pos_loss = 0.003992078825831413, Lv_loss = 0.0, Circular Tuning Loss = 1.2617977857589722\n",
      "2865) Lyapunov Risk = 0.9193936586380005, MSE = 0.02087712660431862, V_0_loss = tensor([[0.0067]], grad_fn=<PowBackward0>), V_pos_loss = 0.003977770917117596, Lv_loss = 0.0, Circular Tuning Loss = 1.2616297006607056\n",
      "2866) Lyapunov Risk = 0.9192624688148499, MSE = 0.020905135199427605, V_0_loss = tensor([[0.0067]], grad_fn=<PowBackward0>), V_pos_loss = 0.003963320050388575, Lv_loss = 0.0, Circular Tuning Loss = 1.261461853981018\n",
      "2867) Lyapunov Risk = 0.9191372394561768, MSE = 0.020984459668397903, V_0_loss = tensor([[0.0067]], grad_fn=<PowBackward0>), V_pos_loss = 0.003948746249079704, Lv_loss = 0.0, Circular Tuning Loss = 1.2612940073013306\n",
      "2868) Lyapunov Risk = 0.9190172553062439, MSE = 0.020812325179576874, V_0_loss = tensor([[0.0067]], grad_fn=<PowBackward0>), V_pos_loss = 0.003934413194656372, Lv_loss = 0.0, Circular Tuning Loss = 1.2611267566680908\n",
      "2869) Lyapunov Risk = 0.918898344039917, MSE = 0.021067114546895027, V_0_loss = tensor([[0.0067]], grad_fn=<PowBackward0>), V_pos_loss = 0.003920166287571192, Lv_loss = 0.0, Circular Tuning Loss = 1.2609602212905884\n",
      "2870) Lyapunov Risk = 0.9187785387039185, MSE = 0.020755896344780922, V_0_loss = tensor([[0.0067]], grad_fn=<PowBackward0>), V_pos_loss = 0.0039059577975422144, Lv_loss = 0.0, Circular Tuning Loss = 1.2607940435409546\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0451734773582499, 1.0551734773582497]\n",
      "x2 : [-0.89808869765270238, -0.88808869765270237]\n",
      "==============================\n",
      "2871) Lyapunov Risk = 0.9195790886878967, MSE = 0.021101806312799454, V_0_loss = tensor([[0.0067]], grad_fn=<PowBackward0>), V_pos_loss = 0.003992226906120777, Lv_loss = 0.0, Circular Tuning Loss = 1.2625738382339478\n",
      "2872) Lyapunov Risk = 0.9194552898406982, MSE = 0.020725777372717857, V_0_loss = tensor([[0.0068]], grad_fn=<PowBackward0>), V_pos_loss = 0.003977487329393625, Lv_loss = 0.0, Circular Tuning Loss = 1.2624081373214722\n",
      "2873) Lyapunov Risk = 0.9193264842033386, MSE = 0.02110403962433338, V_0_loss = tensor([[0.0068]], grad_fn=<PowBackward0>), V_pos_loss = 0.003962524700909853, Lv_loss = 0.0, Circular Tuning Loss = 1.2622421979904175\n",
      "2874) Lyapunov Risk = 0.9191956520080566, MSE = 0.0207260400056839, V_0_loss = tensor([[0.0068]], grad_fn=<PowBackward0>), V_pos_loss = 0.0039473590441048145, Lv_loss = 0.0, Circular Tuning Loss = 1.2620762586593628\n",
      "2875) Lyapunov Risk = 0.9190630912780762, MSE = 0.021079860627651215, V_0_loss = tensor([[0.0068]], grad_fn=<PowBackward0>), V_pos_loss = 0.0039320229552686214, Lv_loss = 0.0, Circular Tuning Loss = 1.2619107961654663\n",
      "2876) Lyapunov Risk = 0.9189304113388062, MSE = 0.020747631788253784, V_0_loss = tensor([[0.0068]], grad_fn=<PowBackward0>), V_pos_loss = 0.003916546702384949, Lv_loss = 0.0, Circular Tuning Loss = 1.2617452144622803\n",
      "2877) Lyapunov Risk = 0.9187978506088257, MSE = 0.021050283685326576, V_0_loss = tensor([[0.0068]], grad_fn=<PowBackward0>), V_pos_loss = 0.0039009428583085537, Lv_loss = 0.0, Circular Tuning Loss = 1.261579990386963\n",
      "2878) Lyapunov Risk = 0.9186658263206482, MSE = 0.02077857218682766, V_0_loss = tensor([[0.0068]], grad_fn=<PowBackward0>), V_pos_loss = 0.003885291051119566, Lv_loss = 0.0, Circular Tuning Loss = 1.2614150047302246\n",
      "2879) Lyapunov Risk = 0.9185344576835632, MSE = 0.021016141399741173, V_0_loss = tensor([[0.0068]], grad_fn=<PowBackward0>), V_pos_loss = 0.00386956799775362, Lv_loss = 0.0, Circular Tuning Loss = 1.261250615119934\n",
      "2880) Lyapunov Risk = 0.9184041619300842, MSE = 0.02080392837524414, V_0_loss = tensor([[0.0068]], grad_fn=<PowBackward0>), V_pos_loss = 0.0038538151420652866, Lv_loss = 0.0, Circular Tuning Loss = 1.2610862255096436\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0451734773582499, 1.0551734773582497]\n",
      "x2 : [-0.89808869765270238, -0.88808869765270237]\n",
      "==============================\n",
      "2881) Lyapunov Risk = 0.9191945195198059, MSE = 0.020981455221772194, V_0_loss = tensor([[0.0068]], grad_fn=<PowBackward0>), V_pos_loss = 0.003934885375201702, Lv_loss = 0.0, Circular Tuning Loss = 1.2628676891326904\n",
      "2882) Lyapunov Risk = 0.9190655946731567, MSE = 0.020808342844247818, V_0_loss = tensor([[0.0068]], grad_fn=<PowBackward0>), V_pos_loss = 0.003918527625501156, Lv_loss = 0.0, Circular Tuning Loss = 1.2627029418945312\n",
      "2883) Lyapunov Risk = 0.9189368486404419, MSE = 0.020964214578270912, V_0_loss = tensor([[0.0068]], grad_fn=<PowBackward0>), V_pos_loss = 0.0039019123651087284, Lv_loss = 0.0, Circular Tuning Loss = 1.262537956237793\n",
      "2884) Lyapunov Risk = 0.9188088774681091, MSE = 0.02080351859331131, V_0_loss = tensor([[0.0068]], grad_fn=<PowBackward0>), V_pos_loss = 0.0038851092103868723, Lv_loss = 0.0, Circular Tuning Loss = 1.2623729705810547\n",
      "2885) Lyapunov Risk = 0.9186840057373047, MSE = 0.020979730412364006, V_0_loss = tensor([[0.0068]], grad_fn=<PowBackward0>), V_pos_loss = 0.0038681719452142715, Lv_loss = 0.0, Circular Tuning Loss = 1.2622078657150269\n",
      "2886) Lyapunov Risk = 0.918562114238739, MSE = 0.020769214257597923, V_0_loss = tensor([[0.0068]], grad_fn=<PowBackward0>), V_pos_loss = 0.0038511110469698906, Lv_loss = 0.0, Circular Tuning Loss = 1.2620429992675781\n",
      "2887) Lyapunov Risk = 0.9184551239013672, MSE = 0.021074824035167694, V_0_loss = tensor([[0.0068]], grad_fn=<PowBackward0>), V_pos_loss = 0.003833991941064596, Lv_loss = 0.0, Circular Tuning Loss = 1.2618778944015503\n",
      "2888) Lyapunov Risk = 0.9183710813522339, MSE = 0.020658012479543686, V_0_loss = tensor([[0.0068]], grad_fn=<PowBackward0>), V_pos_loss = 0.0038167708553373814, Lv_loss = 0.0, Circular Tuning Loss = 1.2617132663726807\n",
      "2889) Lyapunov Risk = 0.9183965921401978, MSE = 0.021399037912487984, V_0_loss = tensor([[0.0068]], grad_fn=<PowBackward0>), V_pos_loss = 0.003799609374254942, Lv_loss = 0.0, Circular Tuning Loss = 1.261548638343811\n",
      "2890) Lyapunov Risk = 0.9185429811477661, MSE = 0.020408010110259056, V_0_loss = tensor([[0.0068]], grad_fn=<PowBackward0>), V_pos_loss = 0.003782366868108511, Lv_loss = 0.0, Circular Tuning Loss = 1.2613842487335205\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [0.47656250000000011, 0.48437500000000011]\n",
      "x2 : [1.933832502611835, 1.9381124446151983]\n",
      "==============================\n",
      "2891) Lyapunov Risk = 0.922411322593689, MSE = 0.022151023149490356, V_0_loss = tensor([[0.0068]], grad_fn=<PowBackward0>), V_pos_loss = 0.0037555645685642958, Lv_loss = 0.0, Circular Tuning Loss = 1.2681763172149658\n",
      "2892) Lyapunov Risk = 0.923133134841919, MSE = 0.020237483084201813, V_0_loss = tensor([[0.0068]], grad_fn=<PowBackward0>), V_pos_loss = 0.0037383760791271925, Lv_loss = 0.0, Circular Tuning Loss = 1.2680100202560425\n",
      "2893) Lyapunov Risk = 0.9240458607673645, MSE = 0.023368949070572853, V_0_loss = tensor([[0.0068]], grad_fn=<PowBackward0>), V_pos_loss = 0.0037212755996733904, Lv_loss = 0.0, Circular Tuning Loss = 1.267844557762146\n",
      "2894) Lyapunov Risk = 0.9246711730957031, MSE = 0.02031724713742733, V_0_loss = tensor([[0.0068]], grad_fn=<PowBackward0>), V_pos_loss = 0.003704228438436985, Lv_loss = 0.0, Circular Tuning Loss = 1.2676783800125122\n",
      "2895) Lyapunov Risk = 0.9244093894958496, MSE = 0.02366797626018524, V_0_loss = tensor([[0.0068]], grad_fn=<PowBackward0>), V_pos_loss = 0.0036872054915875196, Lv_loss = 0.0, Circular Tuning Loss = 1.2675130367279053\n",
      "2896) Lyapunov Risk = 0.9233213663101196, MSE = 0.020389901474118233, V_0_loss = tensor([[0.0068]], grad_fn=<PowBackward0>), V_pos_loss = 0.003670260775834322, Lv_loss = 0.0, Circular Tuning Loss = 1.267346978187561\n",
      "2897) Lyapunov Risk = 0.9221860766410828, MSE = 0.022096827626228333, V_0_loss = tensor([[0.0068]], grad_fn=<PowBackward0>), V_pos_loss = 0.0036533228121697903, Lv_loss = 0.0, Circular Tuning Loss = 1.2671817541122437\n",
      "2898) Lyapunov Risk = 0.9217023849487305, MSE = 0.02119433879852295, V_0_loss = tensor([[0.0068]], grad_fn=<PowBackward0>), V_pos_loss = 0.0036365706473588943, Lv_loss = 0.0, Circular Tuning Loss = 1.2670173645019531\n",
      "2899) Lyapunov Risk = 0.9217133522033691, MSE = 0.020828671753406525, V_0_loss = tensor([[0.0068]], grad_fn=<PowBackward0>), V_pos_loss = 0.003619777038693428, Lv_loss = 0.0, Circular Tuning Loss = 1.266853928565979\n",
      "2900) Lyapunov Risk = 0.9215735793113708, MSE = 0.022149061784148216, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0036032311618328094, Lv_loss = 0.0, Circular Tuning Loss = 1.2666923999786377\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [0.50390625000000022, 0.50585937500000022]\n",
      "x2 : [1.9339029922570909, 1.9354788790402593]\n",
      "==============================\n",
      "2901) Lyapunov Risk = 0.9244319200515747, MSE = 0.02033119462430477, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0035775352735072374, Lv_loss = 0.0, Circular Tuning Loss = 1.2735153436660767\n",
      "2902) Lyapunov Risk = 0.9240106344223022, MSE = 0.021654948592185974, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0035612822975963354, Lv_loss = 0.0, Circular Tuning Loss = 1.273352861404419\n",
      "2903) Lyapunov Risk = 0.9241523742675781, MSE = 0.020914526656270027, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.003545196959748864, Lv_loss = 0.0, Circular Tuning Loss = 1.273191213607788\n",
      "2904) Lyapunov Risk = 0.9245157241821289, MSE = 0.021186167374253273, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0035291635431349277, Lv_loss = 0.0, Circular Tuning Loss = 1.273030400276184\n",
      "2905) Lyapunov Risk = 0.9243364334106445, MSE = 0.021567752584815025, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0035133948549628258, Lv_loss = 0.0, Circular Tuning Loss = 1.2728707790374756\n",
      "2906) Lyapunov Risk = 0.9235020875930786, MSE = 0.020744066685438156, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0034975942689925432, Lv_loss = 0.0, Circular Tuning Loss = 1.2727121114730835\n",
      "2907) Lyapunov Risk = 0.9228344559669495, MSE = 0.021024459972977638, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0034820297732949257, Lv_loss = 0.0, Circular Tuning Loss = 1.2725543975830078\n",
      "2908) Lyapunov Risk = 0.9228619933128357, MSE = 0.020910874009132385, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.00346653675660491, Lv_loss = 0.0, Circular Tuning Loss = 1.2723971605300903\n",
      "2909) Lyapunov Risk = 0.92325359582901, MSE = 0.02097025327384472, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.003451102413237095, Lv_loss = 0.0, Circular Tuning Loss = 1.2722405195236206\n",
      "2910) Lyapunov Risk = 0.9233105778694153, MSE = 0.021342936903238297, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.003435941645875573, Lv_loss = 0.0, Circular Tuning Loss = 1.2720850706100464\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [0.52343750000000022, 0.53125000000000022]\n",
      "x2 : [1.9198081214636982, 1.9250482447263639]\n",
      "==============================\n",
      "2911) Lyapunov Risk = 0.9261894226074219, MSE = 0.020905962213873863, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0034119843039661646, Lv_loss = 0.0, Circular Tuning Loss = 1.2788013219833374\n",
      "2912) Lyapunov Risk = 0.9256196022033691, MSE = 0.020863840356469154, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0033970384392887354, Lv_loss = 0.0, Circular Tuning Loss = 1.2786449193954468\n",
      "2913) Lyapunov Risk = 0.9254752397537231, MSE = 0.020977720618247986, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0033821568358689547, Lv_loss = 0.0, Circular Tuning Loss = 1.2784886360168457\n",
      "2914) Lyapunov Risk = 0.925651490688324, MSE = 0.0207389984279871, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0033672975841909647, Lv_loss = 0.0, Circular Tuning Loss = 1.2783327102661133\n",
      "2915) Lyapunov Risk = 0.9256643056869507, MSE = 0.021198200061917305, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0033525903709232807, Lv_loss = 0.0, Circular Tuning Loss = 1.2781774997711182\n",
      "2916) Lyapunov Risk = 0.9253439903259277, MSE = 0.020830925554037094, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.003337772563099861, Lv_loss = 0.0, Circular Tuning Loss = 1.2780225276947021\n",
      "2917) Lyapunov Risk = 0.9249654412269592, MSE = 0.020819110795855522, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0033231046982109547, Lv_loss = 0.0, Circular Tuning Loss = 1.2778677940368652\n",
      "2918) Lyapunov Risk = 0.9248426556587219, MSE = 0.02106998674571514, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.003308489453047514, Lv_loss = 0.0, Circular Tuning Loss = 1.2777137756347656\n",
      "2919) Lyapunov Risk = 0.9249169826507568, MSE = 0.020597217604517937, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.003293819259852171, Lv_loss = 0.0, Circular Tuning Loss = 1.277559757232666\n",
      "2920) Lyapunov Risk = 0.9248244166374207, MSE = 0.021239614114165306, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0032792736310511827, Lv_loss = 0.0, Circular Tuning Loss = 1.277405858039856\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [0.55664062500000022, 0.55859375000000022]\n",
      "x2 : [1.9195106885337097, 1.9209766304147509]\n",
      "==============================\n",
      "2921) Lyapunov Risk = 0.927964985370636, MSE = 0.02070017345249653, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0032562650740146637, Lv_loss = 0.0, Circular Tuning Loss = 1.2841734886169434\n",
      "2922) Lyapunov Risk = 0.9276979565620422, MSE = 0.020831221714615822, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0032417618203908205, Lv_loss = 0.0, Circular Tuning Loss = 1.2840174436569214\n",
      "2923) Lyapunov Risk = 0.927635133266449, MSE = 0.02106337435543537, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0032273519318550825, Lv_loss = 0.0, Circular Tuning Loss = 1.2838612794876099\n",
      "2924) Lyapunov Risk = 0.9276678562164307, MSE = 0.020538929849863052, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.003212898736819625, Lv_loss = 0.0, Circular Tuning Loss = 1.2837048768997192\n",
      "2925) Lyapunov Risk = 0.9275233149528503, MSE = 0.021227896213531494, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.003198616672307253, Lv_loss = 0.0, Circular Tuning Loss = 1.2835488319396973\n",
      "2926) Lyapunov Risk = 0.9272750616073608, MSE = 0.020594893023371696, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.003184219589456916, Lv_loss = 0.0, Circular Tuning Loss = 1.2833924293518066\n",
      "2927) Lyapunov Risk = 0.9270591735839844, MSE = 0.020892426371574402, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0031699517276138067, Lv_loss = 0.0, Circular Tuning Loss = 1.2832363843917847\n",
      "2928) Lyapunov Risk = 0.9269983768463135, MSE = 0.020982583984732628, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.003155820071697235, Lv_loss = 0.0, Circular Tuning Loss = 1.2830798625946045\n",
      "2929) Lyapunov Risk = 0.9269591569900513, MSE = 0.020625513046979904, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0031417168211191893, Lv_loss = 0.0, Circular Tuning Loss = 1.2829233407974243\n",
      "2930) Lyapunov Risk = 0.9267784357070923, MSE = 0.021084055304527283, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.003127760486677289, Lv_loss = 0.0, Circular Tuning Loss = 1.2827668190002441\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [0.58789062500000022, 0.58984375000000022]\n",
      "x2 : [1.9099994738754329, 1.9116444787243025]\n",
      "==============================\n",
      "2931) Lyapunov Risk = 0.9299684762954712, MSE = 0.020673565566539764, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0031059046741575003, Lv_loss = 0.0, Circular Tuning Loss = 1.2894988059997559\n",
      "2932) Lyapunov Risk = 0.929827094078064, MSE = 0.02083173394203186, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.003092193976044655, Lv_loss = 0.0, Circular Tuning Loss = 1.2893399000167847\n",
      "2933) Lyapunov Risk = 0.9297623038291931, MSE = 0.020925596356391907, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.003078652545809746, Lv_loss = 0.0, Circular Tuning Loss = 1.2891807556152344\n",
      "2934) Lyapunov Risk = 0.9296558499336243, MSE = 0.020714236423373222, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0030651825945824385, Lv_loss = 0.0, Circular Tuning Loss = 1.2890218496322632\n",
      "2935) Lyapunov Risk = 0.9294717311859131, MSE = 0.020877808332443237, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.003051872132346034, Lv_loss = 0.0, Circular Tuning Loss = 1.2888630628585815\n",
      "2936) Lyapunov Risk = 0.9293006658554077, MSE = 0.020854821428656578, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.003038630122318864, Lv_loss = 0.0, Circular Tuning Loss = 1.2887048721313477\n",
      "2937) Lyapunov Risk = 0.9291910529136658, MSE = 0.02068067342042923, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0030255902092903852, Lv_loss = 0.0, Circular Tuning Loss = 1.2885464429855347\n",
      "2938) Lyapunov Risk = 0.9290872812271118, MSE = 0.020964015275239944, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0030126813799142838, Lv_loss = 0.0, Circular Tuning Loss = 1.2883883714675903\n",
      "2939) Lyapunov Risk = 0.9289481043815613, MSE = 0.020723899826407433, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0029997986275702715, Lv_loss = 0.0, Circular Tuning Loss = 1.288230538368225\n",
      "2940) Lyapunov Risk = 0.9287940859794617, MSE = 0.020788555964827538, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.002987048588693142, Lv_loss = 0.0, Circular Tuning Loss = 1.2880730628967285\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [0.61718750000000022, 0.62500000000000022]\n",
      "x2 : [1.8906669447742166, 1.8959895174007615]\n",
      "==============================\n",
      "2941) Lyapunov Risk = 0.9320061206817627, MSE = 0.020913155749440193, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.002966814674437046, Lv_loss = 0.0, Circular Tuning Loss = 1.2946875095367432\n",
      "2942) Lyapunov Risk = 0.9318944811820984, MSE = 0.020623544231057167, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.002954246709123254, Lv_loss = 0.0, Circular Tuning Loss = 1.2945282459259033\n",
      "2943) Lyapunov Risk = 0.9317581057548523, MSE = 0.020940903574228287, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.002941790269687772, Lv_loss = 0.0, Circular Tuning Loss = 1.294369101524353\n",
      "2944) Lyapunov Risk = 0.9316062927246094, MSE = 0.0207161046564579, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0029293885454535484, Lv_loss = 0.0, Circular Tuning Loss = 1.2942101955413818\n",
      "2945) Lyapunov Risk = 0.9314714670181274, MSE = 0.020737456157803535, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.002917094621807337, Lv_loss = 0.0, Circular Tuning Loss = 1.2940517663955688\n",
      "2946) Lyapunov Risk = 0.9313578009605408, MSE = 0.020909197628498077, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0029048598371446133, Lv_loss = 0.0, Circular Tuning Loss = 1.2938933372497559\n",
      "2947) Lyapunov Risk = 0.9312351942062378, MSE = 0.02064000628888607, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0028927105013281107, Lv_loss = 0.0, Circular Tuning Loss = 1.293735146522522\n",
      "2948) Lyapunov Risk = 0.931093156337738, MSE = 0.02088519185781479, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.002880666172131896, Lv_loss = 0.0, Circular Tuning Loss = 1.2935770750045776\n",
      "2949) Lyapunov Risk = 0.930952787399292, MSE = 0.0207508634775877, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.002868718234822154, Lv_loss = 0.0, Circular Tuning Loss = 1.2934192419052124\n",
      "2950) Lyapunov Risk = 0.9308277368545532, MSE = 0.02072260156273842, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0028568096458911896, Lv_loss = 0.0, Circular Tuning Loss = 1.2932615280151367\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [0.96875000000000022, 0.97656250000000022]\n",
      "x2 : [1.6018940718660328, 1.6118940718660326]\n",
      "==============================\n",
      "2951) Lyapunov Risk = 0.9334321618080139, MSE = 0.02086752839386463, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.002837772248312831, Lv_loss = 0.0, Circular Tuning Loss = 1.2987332344055176\n",
      "2952) Lyapunov Risk = 0.9332984089851379, MSE = 0.020672332495450974, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.002825947478413582, Lv_loss = 0.0, Circular Tuning Loss = 1.2985738515853882\n",
      "2953) Lyapunov Risk = 0.9331607818603516, MSE = 0.020810555666685104, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0028141785878688097, Lv_loss = 0.0, Circular Tuning Loss = 1.2984145879745483\n",
      "2954) Lyapunov Risk = 0.9330310225486755, MSE = 0.020758308470249176, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0028024334460496902, Lv_loss = 0.0, Circular Tuning Loss = 1.298255205154419\n",
      "2955) Lyapunov Risk = 0.9329060316085815, MSE = 0.0207106601446867, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0027906629256904125, Lv_loss = 0.0, Circular Tuning Loss = 1.298095941543579\n",
      "2956) Lyapunov Risk = 0.932774543762207, MSE = 0.020805085077881813, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0027789075393229723, Lv_loss = 0.0, Circular Tuning Loss = 1.2979369163513184\n",
      "2957) Lyapunov Risk = 0.9326370358467102, MSE = 0.020723553374409676, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0027671463321894407, Lv_loss = 0.0, Circular Tuning Loss = 1.297777771949768\n",
      "2958) Lyapunov Risk = 0.9325035214424133, MSE = 0.020740879699587822, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0027554098051041365, Lv_loss = 0.0, Circular Tuning Loss = 1.2976186275482178\n",
      "2959) Lyapunov Risk = 0.9323767423629761, MSE = 0.020791301503777504, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0027437324170023203, Lv_loss = 0.0, Circular Tuning Loss = 1.297459602355957\n",
      "2960) Lyapunov Risk = 0.9322491884231567, MSE = 0.02070208452641964, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.002732100198045373, Lv_loss = 0.0, Circular Tuning Loss = 1.2973003387451172\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [0.93750000000000022, 0.94531250000000022]\n",
      "x2 : [1.6501195450187907, 1.6601195450187904]\n",
      "==============================\n",
      "2961) Lyapunov Risk = 0.9349579215049744, MSE = 0.02077633887529373, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.002713683294132352, Lv_loss = 0.0, Circular Tuning Loss = 1.3029899597167969\n",
      "2962) Lyapunov Risk = 0.9348227381706238, MSE = 0.020730450749397278, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.002702160272747278, Lv_loss = 0.0, Circular Tuning Loss = 1.302828311920166\n",
      "2963) Lyapunov Risk = 0.9346909523010254, MSE = 0.02070527896285057, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0026906379498541355, Lv_loss = 0.0, Circular Tuning Loss = 1.3026669025421143\n",
      "2964) Lyapunov Risk = 0.9345620274543762, MSE = 0.020776426419615746, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0026791186537593603, Lv_loss = 0.0, Circular Tuning Loss = 1.3025051355361938\n",
      "2965) Lyapunov Risk = 0.9344311952590942, MSE = 0.02067435532808304, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.002667589345946908, Lv_loss = 0.0, Circular Tuning Loss = 1.3023433685302734\n",
      "2966) Lyapunov Risk = 0.9342978000640869, MSE = 0.020759109407663345, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0026560965925455093, Lv_loss = 0.0, Circular Tuning Loss = 1.302181601524353\n",
      "2967) Lyapunov Risk = 0.9341644048690796, MSE = 0.020717523992061615, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.00264460570178926, Lv_loss = 0.0, Circular Tuning Loss = 1.302019715309143\n",
      "2968) Lyapunov Risk = 0.9340337514877319, MSE = 0.020699134096503258, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0026331052649766207, Lv_loss = 0.0, Circular Tuning Loss = 1.3018577098846436\n",
      "2969) Lyapunov Risk = 0.9339039921760559, MSE = 0.020762186497449875, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0026216276455670595, Lv_loss = 0.0, Circular Tuning Loss = 1.3016955852508545\n",
      "2970) Lyapunov Risk = 0.9337724447250366, MSE = 0.020680716261267662, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0026101896073669195, Lv_loss = 0.0, Circular Tuning Loss = 1.3015334606170654\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [0.96875000000000022, 0.97656250000000022]\n",
      "x2 : [1.6501195450187907, 1.6601195450187904]\n",
      "==============================\n",
      "2971) Lyapunov Risk = 0.9365456700325012, MSE = 0.020738553255796432, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0025923135690391064, Lv_loss = 0.0, Circular Tuning Loss = 1.3073514699935913\n",
      "2972) Lyapunov Risk = 0.9364124536514282, MSE = 0.020701397210359573, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0025810343213379383, Lv_loss = 0.0, Circular Tuning Loss = 1.3071869611740112\n",
      "2973) Lyapunov Risk = 0.9362804293632507, MSE = 0.020693637430667877, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0025697697419673204, Lv_loss = 0.0, Circular Tuning Loss = 1.3070224523544312\n",
      "2974) Lyapunov Risk = 0.9361485838890076, MSE = 0.020721539855003357, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.002558475360274315, Lv_loss = 0.0, Circular Tuning Loss = 1.3068580627441406\n",
      "2975) Lyapunov Risk = 0.9360158443450928, MSE = 0.020680133253335953, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0025471460539847612, Lv_loss = 0.0, Circular Tuning Loss = 1.3066937923431396\n",
      "2976) Lyapunov Risk = 0.935882568359375, MSE = 0.02070680633187294, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0025358344428241253, Lv_loss = 0.0, Circular Tuning Loss = 1.3065295219421387\n",
      "2977) Lyapunov Risk = 0.9357497096061707, MSE = 0.020704148337244987, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0025245018769055605, Lv_loss = 0.0, Circular Tuning Loss = 1.3063653707504272\n",
      "2978) Lyapunov Risk = 0.9356177449226379, MSE = 0.020682144910097122, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0025132254231721163, Lv_loss = 0.0, Circular Tuning Loss = 1.306201457977295\n",
      "2979) Lyapunov Risk = 0.9354857206344604, MSE = 0.020717402920126915, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0025019512977451086, Lv_loss = 0.0, Circular Tuning Loss = 1.3060375452041626\n",
      "2980) Lyapunov Risk = 0.9353531002998352, MSE = 0.020683782175183296, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0024906801991164684, Lv_loss = 0.0, Circular Tuning Loss = 1.3058738708496094\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [0.79968750000000022, 0.80968750000000023]\n",
      "x2 : [1.8146430590176013, 1.8234619694140441]\n",
      "==============================\n",
      "2981) Lyapunov Risk = 0.9384676814079285, MSE = 0.020693793892860413, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.002473231637850404, Lv_loss = 0.0, Circular Tuning Loss = 1.3123363256454468\n",
      "2982) Lyapunov Risk = 0.9383339285850525, MSE = 0.02068978361785412, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0024620580952614546, Lv_loss = 0.0, Circular Tuning Loss = 1.3121699094772339\n",
      "2983) Lyapunov Risk = 0.9382002949714661, MSE = 0.020670773461461067, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.002450894098728895, Lv_loss = 0.0, Circular Tuning Loss = 1.3120033740997314\n",
      "2984) Lyapunov Risk = 0.9380667805671692, MSE = 0.020695243030786514, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0024397526867687702, Lv_loss = 0.0, Circular Tuning Loss = 1.311836838722229\n",
      "2985) Lyapunov Risk = 0.9379332065582275, MSE = 0.020659714937210083, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0024285807739943266, Lv_loss = 0.0, Circular Tuning Loss = 1.3116705417633057\n",
      "2986) Lyapunov Risk = 0.9377995729446411, MSE = 0.02069878578186035, V_0_loss = tensor([[0.0069]], grad_fn=<PowBackward0>), V_pos_loss = 0.0024174097925424576, Lv_loss = 0.0, Circular Tuning Loss = 1.3115043640136719\n",
      "2987) Lyapunov Risk = 0.9376660585403442, MSE = 0.02066519856452942, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.0024062348529696465, Lv_loss = 0.0, Circular Tuning Loss = 1.3113383054733276\n",
      "2988) Lyapunov Risk = 0.9375327825546265, MSE = 0.020705468952655792, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.0023950706236064434, Lv_loss = 0.0, Circular Tuning Loss = 1.3111722469329834\n",
      "2989) Lyapunov Risk = 0.9374002814292908, MSE = 0.020659683272242546, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.0023839096538722515, Lv_loss = 0.0, Circular Tuning Loss = 1.3110063076019287\n",
      "2990) Lyapunov Risk = 0.9372692108154297, MSE = 0.020735016092658043, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.002372815739363432, Lv_loss = 0.0, Circular Tuning Loss = 1.3108406066894531\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [0.86218750000000022, 0.87218750000000023]\n",
      "x2 : [1.7838592407352363, 1.7925613075600406]\n",
      "==============================\n",
      "2991) Lyapunov Risk = 0.9403541684150696, MSE = 0.0206139013171196, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.0023558256216347218, Lv_loss = 0.0, Circular Tuning Loss = 1.317244529724121\n",
      "2992) Lyapunov Risk = 0.9402282238006592, MSE = 0.02078613080084324, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.0023448457941412926, Lv_loss = 0.0, Circular Tuning Loss = 1.3170759677886963\n",
      "2993) Lyapunov Risk = 0.9401087164878845, MSE = 0.020539743825793266, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.002333858283236623, Lv_loss = 0.0, Circular Tuning Loss = 1.3169071674346924\n",
      "2994) Lyapunov Risk = 0.939995527267456, MSE = 0.020867744460701942, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.002323018154129386, Lv_loss = 0.0, Circular Tuning Loss = 1.3167386054992676\n",
      "2995) Lyapunov Risk = 0.9398913383483887, MSE = 0.020468810573220253, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.002312220400199294, Lv_loss = 0.0, Circular Tuning Loss = 1.3165699243545532\n",
      "2996) Lyapunov Risk = 0.9397883415222168, MSE = 0.02095409855246544, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.0023015541955828667, Lv_loss = 0.0, Circular Tuning Loss = 1.3164013624191284\n",
      "2997) Lyapunov Risk = 0.9397014379501343, MSE = 0.020431434735655785, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00229092501103878, Lv_loss = 0.0, Circular Tuning Loss = 1.3162328004837036\n",
      "2998) Lyapunov Risk = 0.9396098852157593, MSE = 0.021042443811893463, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.0022804068867117167, Lv_loss = 0.0, Circular Tuning Loss = 1.316064476966858\n",
      "2999) Lyapunov Risk = 0.9395318627357483, MSE = 0.02041587606072426, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.0022698999382555485, Lv_loss = 0.0, Circular Tuning Loss = 1.3158962726593018\n",
      "3000) Lyapunov Risk = 0.9394418001174927, MSE = 0.021120918914675713, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.0022595138289034367, Lv_loss = 0.0, Circular Tuning Loss = 1.3157284259796143\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.2480468750000004, 1.2500000000000004]\n",
      "x2 : [0.21650635094610968, 0.21819780681287615]\n",
      "==============================\n",
      "3001) Lyapunov Risk = 0.9399440288543701, MSE = 0.02040073834359646, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.0022435642313212156, Lv_loss = 0.0, Circular Tuning Loss = 1.3158843517303467\n",
      "3002) Lyapunov Risk = 0.9398247003555298, MSE = 0.021153109148144722, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.002233632607385516, Lv_loss = 0.0, Circular Tuning Loss = 1.3157153129577637\n",
      "3003) Lyapunov Risk = 0.9397071599960327, MSE = 0.020381594076752663, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.0022239787504076958, Lv_loss = 0.0, Circular Tuning Loss = 1.315544843673706\n",
      "3004) Lyapunov Risk = 0.9395523071289062, MSE = 0.021150702610611916, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.0022146415431052446, Lv_loss = 0.0, Circular Tuning Loss = 1.3153740167617798\n",
      "3005) Lyapunov Risk = 0.9394003748893738, MSE = 0.020365172997117043, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.0022055229637771845, Lv_loss = 0.0, Circular Tuning Loss = 1.315202236175537\n",
      "3006) Lyapunov Risk = 0.9392149448394775, MSE = 0.021103575825691223, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.002196677029132843, Lv_loss = 0.0, Circular Tuning Loss = 1.3150303363800049\n",
      "3007) Lyapunov Risk = 0.9390377998352051, MSE = 0.020381277427077293, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.0021879910491406918, Lv_loss = 0.0, Circular Tuning Loss = 1.3148573637008667\n",
      "3008) Lyapunov Risk = 0.9388450384140015, MSE = 0.021015550941228867, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.0021795521024614573, Lv_loss = 0.0, Circular Tuning Loss = 1.3146846294403076\n",
      "3009) Lyapunov Risk = 0.9386714696884155, MSE = 0.02042333036661148, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.0021712302695959806, Lv_loss = 0.0, Circular Tuning Loss = 1.3145108222961426\n",
      "3010) Lyapunov Risk = 0.9384911060333252, MSE = 0.020913202315568924, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.002163111697882414, Lv_loss = 0.0, Circular Tuning Loss = 1.314337134361267\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.3750000000000004, 1.3759765625000004]\n",
      "x2 : [0.20466615987874431, 0.20635307354567933]\n",
      "==============================\n",
      "3011) Lyapunov Risk = 0.9393040537834167, MSE = 0.02046213671565056, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.0021497108973562717, Lv_loss = 0.0, Circular Tuning Loss = 1.3152475357055664\n",
      "3012) Lyapunov Risk = 0.939143717288971, MSE = 0.02082999050617218, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.002142133889719844, Lv_loss = 0.0, Circular Tuning Loss = 1.3150715827941895\n",
      "3013) Lyapunov Risk = 0.938997745513916, MSE = 0.020503900945186615, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.0021348821464926004, Lv_loss = 0.0, Circular Tuning Loss = 1.3148943185806274\n",
      "3014) Lyapunov Risk = 0.9388497471809387, MSE = 0.02075658179819584, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.002128009917214513, Lv_loss = 0.0, Circular Tuning Loss = 1.3147162199020386\n",
      "3015) Lyapunov Risk = 0.9387073516845703, MSE = 0.020566314458847046, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00212151394225657, Lv_loss = 0.0, Circular Tuning Loss = 1.3145369291305542\n",
      "3016) Lyapunov Risk = 0.9385682940483093, MSE = 0.020685268566012383, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.002115280134603381, Lv_loss = 0.0, Circular Tuning Loss = 1.3143573999404907\n",
      "3017) Lyapunov Risk = 0.9384323954582214, MSE = 0.02063419111073017, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.0021092386450618505, Lv_loss = 0.0, Circular Tuning Loss = 1.3141775131225586\n",
      "3018) Lyapunov Risk = 0.9382988810539246, MSE = 0.020634200423955917, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.002103387610986829, Lv_loss = 0.0, Circular Tuning Loss = 1.3139972686767578\n",
      "3019) Lyapunov Risk = 0.9381669163703918, MSE = 0.020675262436270714, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.002097704680636525, Lv_loss = 0.0, Circular Tuning Loss = 1.3138169050216675\n",
      "3020) Lyapunov Risk = 0.9380365014076233, MSE = 0.02059839479625225, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.002092161448672414, Lv_loss = 0.0, Circular Tuning Loss = 1.3136361837387085\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.3759765625000004, 1.3769531250000004]\n",
      "x2 : [0.20297470401197781, 0.2046617384762863]\n",
      "==============================\n",
      "3021) Lyapunov Risk = 0.9388707280158997, MSE = 0.020690549165010452, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.002081576967611909, Lv_loss = 0.0, Circular Tuning Loss = 1.31453537940979\n",
      "3022) Lyapunov Risk = 0.9387453198432922, MSE = 0.02055937796831131, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.002076685195788741, Lv_loss = 0.0, Circular Tuning Loss = 1.3143534660339355\n",
      "3023) Lyapunov Risk = 0.9386227130889893, MSE = 0.02072818949818611, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.0020723051857203245, Lv_loss = 0.0, Circular Tuning Loss = 1.3141711950302124\n",
      "3024) Lyapunov Risk = 0.9385024905204773, MSE = 0.020517295226454735, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.0020682658068835735, Lv_loss = 0.0, Circular Tuning Loss = 1.313988447189331\n",
      "3025) Lyapunov Risk = 0.9383851885795593, MSE = 0.020785527303814888, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.0020645814947783947, Lv_loss = 0.0, Circular Tuning Loss = 1.3138055801391602\n",
      "3026) Lyapunov Risk = 0.9382706880569458, MSE = 0.0204782672226429, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.0020611498039215803, Lv_loss = 0.0, Circular Tuning Loss = 1.3136227130889893\n",
      "3027) Lyapunov Risk = 0.9381576776504517, MSE = 0.02085024118423462, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.0020579961128532887, Lv_loss = 0.0, Circular Tuning Loss = 1.3134398460388184\n",
      "3028) Lyapunov Risk = 0.9380548596382141, MSE = 0.0204320065677166, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.002055024029687047, Lv_loss = 0.0, Circular Tuning Loss = 1.3132566213607788\n",
      "3029) Lyapunov Risk = 0.9379522800445557, MSE = 0.02093259058892727, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.002052278956398368, Lv_loss = 0.0, Circular Tuning Loss = 1.3130735158920288\n",
      "3030) Lyapunov Risk = 0.937869131565094, MSE = 0.020372629165649414, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.002049665665253997, Lv_loss = 0.0, Circular Tuning Loss = 1.3128902912139893\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.020086738679125, 1.0300867386791248]\n",
      "x2 : [-0.8845570507185706, -0.87455705071857059]\n",
      "==============================\n",
      "3031) Lyapunov Risk = 0.9384155869483948, MSE = 0.02103499509394169, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.002103509148582816, Lv_loss = 0.0, Circular Tuning Loss = 1.314141035079956\n",
      "3032) Lyapunov Risk = 0.9383571147918701, MSE = 0.020313618704676628, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.0021008553449064493, Lv_loss = 0.0, Circular Tuning Loss = 1.313957691192627\n",
      "3033) Lyapunov Risk = 0.9382846355438232, MSE = 0.021145885810256004, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.0020980217959731817, Lv_loss = 0.0, Circular Tuning Loss = 1.3137743473052979\n",
      "3034) Lyapunov Risk = 0.9382315874099731, MSE = 0.02028796263039112, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.002094948897138238, Lv_loss = 0.0, Circular Tuning Loss = 1.3135907649993896\n",
      "3035) Lyapunov Risk = 0.9381530284881592, MSE = 0.021231934428215027, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.0020917418878525496, Lv_loss = 0.0, Circular Tuning Loss = 1.313407301902771\n",
      "3036) Lyapunov Risk = 0.9380854368209839, MSE = 0.020294442772865295, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.0020882890094071627, Lv_loss = 0.0, Circular Tuning Loss = 1.3132233619689941\n",
      "3037) Lyapunov Risk = 0.9379742741584778, MSE = 0.021276874467730522, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.0020847031846642494, Lv_loss = 0.0, Circular Tuning Loss = 1.3130402565002441\n",
      "3038) Lyapunov Risk = 0.9378565549850464, MSE = 0.020303573459386826, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.0020809154957532883, Lv_loss = 0.0, Circular Tuning Loss = 1.3128567934036255\n",
      "3039) Lyapunov Risk = 0.937684178352356, MSE = 0.02124619297683239, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.0020770300179719925, Lv_loss = 0.0, Circular Tuning Loss = 1.3126739263534546\n",
      "3040) Lyapunov Risk = 0.937502384185791, MSE = 0.02029920183122158, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.002072986215353012, Lv_loss = 0.0, Circular Tuning Loss = 1.3124908208847046\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.020086738679125, 1.0300867386791248]\n",
      "x2 : [-0.8845570507185706, -0.87455705071857059]\n",
      "==============================\n",
      "3041) Lyapunov Risk = 0.9379090070724487, MSE = 0.021141041070222855, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.0021242285147309303, Lv_loss = 0.0, Circular Tuning Loss = 1.3137307167053223\n",
      "3042) Lyapunov Risk = 0.9377077221870422, MSE = 0.020296243950724602, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0021196678280830383, Lv_loss = 0.0, Circular Tuning Loss = 1.3135477304458618\n",
      "3043) Lyapunov Risk = 0.9374871253967285, MSE = 0.021011486649513245, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.002114869887009263, Lv_loss = 0.0, Circular Tuning Loss = 1.3133646249771118\n",
      "3044) Lyapunov Risk = 0.9372814893722534, MSE = 0.02034800499677658, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0021097937133163214, Lv_loss = 0.0, Circular Tuning Loss = 1.3131810426712036\n",
      "3045) Lyapunov Risk = 0.9370865225791931, MSE = 0.02082516998052597, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.002104455605149269, Lv_loss = 0.0, Circular Tuning Loss = 1.3129976987838745\n",
      "3046) Lyapunov Risk = 0.9369070529937744, MSE = 0.020486081019043922, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.002098929136991501, Lv_loss = 0.0, Circular Tuning Loss = 1.312814474105835\n",
      "3047) Lyapunov Risk = 0.9367619156837463, MSE = 0.0205890741199255, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.002093191258609295, Lv_loss = 0.0, Circular Tuning Loss = 1.312631368637085\n",
      "3048) Lyapunov Risk = 0.936646580696106, MSE = 0.020679719746112823, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0020872815512120724, Lv_loss = 0.0, Circular Tuning Loss = 1.312448501586914\n",
      "3049) Lyapunov Risk = 0.9365474581718445, MSE = 0.020439844578504562, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0020812409929931164, Lv_loss = 0.0, Circular Tuning Loss = 1.3122659921646118\n",
      "3050) Lyapunov Risk = 0.9364515542984009, MSE = 0.020813914015889168, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0020753578282892704, Lv_loss = 0.0, Circular Tuning Loss = 1.3120839595794678\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.020086738679125, 1.0300867386791248]\n",
      "x2 : [-0.8845570507185706, -0.87455705071857059]\n",
      "==============================\n",
      "3051) Lyapunov Risk = 0.9369701743125916, MSE = 0.020396482199430466, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.002123421523720026, Lv_loss = 0.0, Circular Tuning Loss = 1.3133232593536377\n",
      "3052) Lyapunov Risk = 0.9368534088134766, MSE = 0.020816916599869728, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.002117485972121358, Lv_loss = 0.0, Circular Tuning Loss = 1.3131426572799683\n",
      "3053) Lyapunov Risk = 0.9367252588272095, MSE = 0.02043004333972931, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0021114537958055735, Lv_loss = 0.0, Circular Tuning Loss = 1.3129626512527466\n",
      "3054) Lyapunov Risk = 0.9365900754928589, MSE = 0.020741667598485947, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0021053601521998644, Lv_loss = 0.0, Circular Tuning Loss = 1.3127834796905518\n",
      "3055) Lyapunov Risk = 0.9364491701126099, MSE = 0.020482370629906654, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0020991412457078695, Lv_loss = 0.0, Circular Tuning Loss = 1.3126046657562256\n",
      "3056) Lyapunov Risk = 0.936305046081543, MSE = 0.02066710963845253, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0020928354933857918, Lv_loss = 0.0, Circular Tuning Loss = 1.3124266862869263\n",
      "3057) Lyapunov Risk = 0.936161458492279, MSE = 0.02052043005824089, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00208651483990252, Lv_loss = 0.0, Circular Tuning Loss = 1.3122493028640747\n",
      "3058) Lyapunov Risk = 0.9360230565071106, MSE = 0.02061975747346878, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0020801667124032974, Lv_loss = 0.0, Circular Tuning Loss = 1.3120726346969604\n",
      "3059) Lyapunov Risk = 0.9358922839164734, MSE = 0.020542925223708153, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0020737897139042616, Lv_loss = 0.0, Circular Tuning Loss = 1.3118966817855835\n",
      "3060) Lyapunov Risk = 0.9357685446739197, MSE = 0.020586058497428894, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.002067502588033676, Lv_loss = 0.0, Circular Tuning Loss = 1.3117212057113647\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.020086738679125, 1.0300867386791248]\n",
      "x2 : [-0.8845570507185706, -0.87455705071857059]\n",
      "==============================\n",
      "3061) Lyapunov Risk = 0.9362752437591553, MSE = 0.02057092823088169, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.002113670576363802, Lv_loss = 0.0, Circular Tuning Loss = 1.3129677772521973\n",
      "3062) Lyapunov Risk = 0.936159074306488, MSE = 0.020531103014945984, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0021073417738080025, Lv_loss = 0.0, Circular Tuning Loss = 1.3127939701080322\n",
      "3063) Lyapunov Risk = 0.9360430240631104, MSE = 0.020619472488760948, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0021008451003581285, Lv_loss = 0.0, Circular Tuning Loss = 1.3126202821731567\n",
      "3064) Lyapunov Risk = 0.9359266757965088, MSE = 0.02047792077064514, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0020941949915140867, Lv_loss = 0.0, Circular Tuning Loss = 1.31244695186615\n",
      "3065) Lyapunov Risk = 0.9358094930648804, MSE = 0.02066805399954319, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.002087398199364543, Lv_loss = 0.0, Circular Tuning Loss = 1.3122740983963013\n",
      "3066) Lyapunov Risk = 0.9356911778450012, MSE = 0.020442306995391846, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.002080457517877221, Lv_loss = 0.0, Circular Tuning Loss = 1.3121017217636108\n",
      "3067) Lyapunov Risk = 0.9355707168579102, MSE = 0.020695311948657036, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0020733834244310856, Lv_loss = 0.0, Circular Tuning Loss = 1.3119300603866577\n",
      "3068) Lyapunov Risk = 0.9354488253593445, MSE = 0.020431268960237503, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.002066172892227769, Lv_loss = 0.0, Circular Tuning Loss = 1.3117585182189941\n",
      "3069) Lyapunov Risk = 0.9353249669075012, MSE = 0.020690111443400383, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0020588659681379795, Lv_loss = 0.0, Circular Tuning Loss = 1.3115875720977783\n",
      "3070) Lyapunov Risk = 0.9351999759674072, MSE = 0.02044060081243515, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0020514612551778555, Lv_loss = 0.0, Circular Tuning Loss = 1.3114169836044312\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.020086738679125, 1.0300867386791248]\n",
      "x2 : [-0.8845570507185706, -0.87455705071857059]\n",
      "==============================\n",
      "3071) Lyapunov Risk = 0.9356862306594849, MSE = 0.02066023461520672, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.002094393130391836, Lv_loss = 0.0, Circular Tuning Loss = 1.3126403093338013\n",
      "3072) Lyapunov Risk = 0.9355621933937073, MSE = 0.020451927557587624, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.002086467109620571, Lv_loss = 0.0, Circular Tuning Loss = 1.312469482421875\n",
      "3073) Lyapunov Risk = 0.9354386329650879, MSE = 0.020634856075048447, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0020783289801329374, Lv_loss = 0.0, Circular Tuning Loss = 1.3122984170913696\n",
      "3074) Lyapunov Risk = 0.9353155493736267, MSE = 0.020460665225982666, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.002070026006549597, Lv_loss = 0.0, Circular Tuning Loss = 1.3121274709701538\n",
      "3075) Lyapunov Risk = 0.9351921081542969, MSE = 0.02061440795660019, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.002061558421701193, Lv_loss = 0.0, Circular Tuning Loss = 1.3119564056396484\n",
      "3076) Lyapunov Risk = 0.9350696206092834, MSE = 0.02046736516058445, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0020529713947325945, Lv_loss = 0.0, Circular Tuning Loss = 1.3117852210998535\n",
      "3077) Lyapunov Risk = 0.9349471926689148, MSE = 0.020607318729162216, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.002044274937361479, Lv_loss = 0.0, Circular Tuning Loss = 1.3116141557693481\n",
      "3078) Lyapunov Risk = 0.9348257184028625, MSE = 0.020466862246394157, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.002035485114902258, Lv_loss = 0.0, Circular Tuning Loss = 1.3114428520202637\n",
      "3079) Lyapunov Risk = 0.9347044229507446, MSE = 0.020609868690371513, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.002026644768193364, Lv_loss = 0.0, Circular Tuning Loss = 1.3112719058990479\n",
      "3080) Lyapunov Risk = 0.9345839023590088, MSE = 0.020459389314055443, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0020177403930574656, Lv_loss = 0.0, Circular Tuning Loss = 1.3111004829406738\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.020086738679125, 1.0300867386791248]\n",
      "x2 : [-0.8845570507185706, -0.87455705071857059]\n",
      "==============================\n",
      "3081) Lyapunov Risk = 0.9350775480270386, MSE = 0.020614610984921455, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0020572165958583355, Lv_loss = 0.0, Circular Tuning Loss = 1.312329649925232\n",
      "3082) Lyapunov Risk = 0.934959352016449, MSE = 0.020433880388736725, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0020478027872741222, Lv_loss = 0.0, Circular Tuning Loss = 1.312157392501831\n",
      "3083) Lyapunov Risk = 0.9348425269126892, MSE = 0.020630570128560066, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0020381773356348276, Lv_loss = 0.0, Circular Tuning Loss = 1.3119845390319824\n",
      "3084) Lyapunov Risk = 0.9347270727157593, MSE = 0.02040594443678856, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0020283316262066364, Lv_loss = 0.0, Circular Tuning Loss = 1.311811089515686\n",
      "3085) Lyapunov Risk = 0.934612512588501, MSE = 0.020653467625379562, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0020183005835860968, Lv_loss = 0.0, Circular Tuning Loss = 1.311637282371521\n",
      "3086) Lyapunov Risk = 0.9344990253448486, MSE = 0.02039041370153427, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.002008080715313554, Lv_loss = 0.0, Circular Tuning Loss = 1.3114629983901978\n",
      "3087) Lyapunov Risk = 0.9343873858451843, MSE = 0.02067805826663971, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0019977185875177383, Lv_loss = 0.0, Circular Tuning Loss = 1.3112884759902954\n",
      "3088) Lyapunov Risk = 0.9342782497406006, MSE = 0.020378390327095985, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.001987182069569826, Lv_loss = 0.0, Circular Tuning Loss = 1.311113953590393\n",
      "3089) Lyapunov Risk = 0.9341724514961243, MSE = 0.020706720650196075, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.001976531930267811, Lv_loss = 0.0, Circular Tuning Loss = 1.3109394311904907\n",
      "3090) Lyapunov Risk = 0.9340737462043762, MSE = 0.020351046696305275, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0019657495431602, Lv_loss = 0.0, Circular Tuning Loss = 1.3107644319534302\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.020086738679125, 1.0300867386791248]\n",
      "x2 : [-0.8845570507185706, -0.87455705071857059]\n",
      "==============================\n",
      "3091) Lyapunov Risk = 0.9345875382423401, MSE = 0.020762551575899124, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.002000704174861312, Lv_loss = 0.0, Circular Tuning Loss = 1.311978816986084\n",
      "3092) Lyapunov Risk = 0.9345110058784485, MSE = 0.020292578265070915, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0019892556592822075, Lv_loss = 0.0, Circular Tuning Loss = 1.311802864074707\n",
      "3093) Lyapunov Risk = 0.9344429969787598, MSE = 0.02087470330297947, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0019775331020355225, Lv_loss = 0.0, Circular Tuning Loss = 1.3116260766983032\n",
      "3094) Lyapunov Risk = 0.9343917369842529, MSE = 0.02023223601281643, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0019656086806207895, Lv_loss = 0.0, Circular Tuning Loss = 1.311448574066162\n",
      "3095) Lyapunov Risk = 0.9343562126159668, MSE = 0.02102748490869999, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0019534751772880554, Lv_loss = 0.0, Circular Tuning Loss = 1.3112709522247314\n",
      "3096) Lyapunov Risk = 0.9343386888504028, MSE = 0.020185241475701332, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0019411880057305098, Lv_loss = 0.0, Circular Tuning Loss = 1.3110926151275635\n",
      "3097) Lyapunov Risk = 0.9343537092208862, MSE = 0.02122713066637516, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0019288189942017198, Lv_loss = 0.0, Circular Tuning Loss = 1.310914158821106\n",
      "3098) Lyapunov Risk = 0.9343730211257935, MSE = 0.020148593932390213, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.001916396664455533, Lv_loss = 0.0, Circular Tuning Loss = 1.3107352256774902\n",
      "3099) Lyapunov Risk = 0.9344016313552856, MSE = 0.021433401852846146, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0019039338221773505, Lv_loss = 0.0, Circular Tuning Loss = 1.3105570077896118\n",
      "3100) Lyapunov Risk = 0.9343940019607544, MSE = 0.020131481811404228, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0018914855318143964, Lv_loss = 0.0, Circular Tuning Loss = 1.3103781938552856\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.973336135700658, 1.9749898801227186]\n",
      "x2 : [-0.27147866661602038, -0.2706329386826371]\n",
      "==============================\n",
      "3101) Lyapunov Risk = 0.9376212358474731, MSE = 0.02153979241847992, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0018744198605418205, Lv_loss = 0.0, Circular Tuning Loss = 1.3159326314926147\n",
      "3102) Lyapunov Risk = 0.9374762773513794, MSE = 0.0201230701059103, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0018619460752233863, Lv_loss = 0.0, Circular Tuning Loss = 1.3157514333724976\n",
      "3103) Lyapunov Risk = 0.9372490048408508, MSE = 0.021445786580443382, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0018494357354938984, Lv_loss = 0.0, Circular Tuning Loss = 1.3155698776245117\n",
      "3104) Lyapunov Risk = 0.9369277954101562, MSE = 0.020119506865739822, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0018369308672845364, Lv_loss = 0.0, Circular Tuning Loss = 1.315387487411499\n",
      "3105) Lyapunov Risk = 0.9365741014480591, MSE = 0.021129241213202477, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0018246816471219063, Lv_loss = 0.0, Circular Tuning Loss = 1.3152052164077759\n",
      "3106) Lyapunov Risk = 0.9362320899963379, MSE = 0.020185744389891624, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0018127002986148, Lv_loss = 0.0, Circular Tuning Loss = 1.3150230646133423\n",
      "3107) Lyapunov Risk = 0.9359513521194458, MSE = 0.02074904553592205, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0018008316401392221, Lv_loss = 9.986828786168189e-08, Circular Tuning Loss = 1.3148415088653564\n",
      "3108) Lyapunov Risk = 0.9357556104660034, MSE = 0.02037116326391697, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0017890790477395058, Lv_loss = 1.0825780236700666e-06, Circular Tuning Loss = 1.3146600723266602\n",
      "3109) Lyapunov Risk = 0.9356338381767273, MSE = 0.020463645458221436, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.001777446479536593, Lv_loss = 2.0896507066936465e-06, Circular Tuning Loss = 1.3144794702529907\n",
      "3110) Lyapunov Risk = 0.9355657696723938, MSE = 0.020624427124857903, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0017659161239862442, Lv_loss = 3.1245995160134044e-06, Circular Tuning Loss = 1.3142991065979004\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.5029296875000004, 1.5039062500000004]\n",
      "x2 : [0.20974052747904376, 0.21143198334581023]\n",
      "==============================\n",
      "3111) Lyapunov Risk = 0.936843991279602, MSE = 0.020278707146644592, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0017502384725958109, Lv_loss = 4.046601134177763e-06, Circular Tuning Loss = 1.3159371614456177\n",
      "3112) Lyapunov Risk = 0.9367952942848206, MSE = 0.020825618878006935, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0017391896108165383, Lv_loss = 4.983268809155561e-06, Circular Tuning Loss = 1.31575608253479\n",
      "3113) Lyapunov Risk = 0.936728298664093, MSE = 0.02018553577363491, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.0017284513451159, Lv_loss = 5.7751403801376e-06, Circular Tuning Loss = 1.315574288368225\n",
      "3114) Lyapunov Risk = 0.9366316795349121, MSE = 0.02092086710035801, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.0017180138966068625, Lv_loss = 6.5707881731214e-06, Circular Tuning Loss = 1.3153927326202393\n",
      "3115) Lyapunov Risk = 0.9365034103393555, MSE = 0.020156076177954674, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.0017078248783946037, Lv_loss = 7.276243195519783e-06, Circular Tuning Loss = 1.3152105808258057\n",
      "3116) Lyapunov Risk = 0.9363530874252319, MSE = 0.020887264981865883, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.0016979050124064088, Lv_loss = 7.957639354572166e-06, Circular Tuning Loss = 1.3150285482406616\n",
      "3117) Lyapunov Risk = 0.9361863732337952, MSE = 0.020187651738524437, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.001688199583441019, Lv_loss = 8.594274731876794e-06, Circular Tuning Loss = 1.314846158027649\n",
      "3118) Lyapunov Risk = 0.9360173344612122, MSE = 0.020754793658852577, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.0016787402564659715, Lv_loss = 9.16721091925865e-06, Circular Tuning Loss = 1.3146638870239258\n",
      "3119) Lyapunov Risk = 0.9358571171760559, MSE = 0.02027195319533348, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.0016695823287591338, Lv_loss = 9.727244105306454e-06, Circular Tuning Loss = 1.314481496810913\n",
      "3120) Lyapunov Risk = 0.9357083439826965, MSE = 0.02058785781264305, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.0016609006561338902, Lv_loss = 1.0218326679023448e-05, Circular Tuning Loss = 1.3142997026443481\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.7705078125000004, 1.7714843750000004]\n",
      "x2 : [0.054126587736527419, 0.05496609432916344]\n",
      "==============================\n",
      "3121) Lyapunov Risk = 0.9378467798233032, MSE = 0.02040308155119419, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.0016485940432175994, Lv_loss = 1.0679787010303698e-05, Circular Tuning Loss = 1.3178377151489258\n",
      "3122) Lyapunov Risk = 0.9377342462539673, MSE = 0.020407646894454956, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.0016406105132773519, Lv_loss = 1.1068756066379137e-05, Circular Tuning Loss = 1.3176552057266235\n",
      "3123) Lyapunov Risk = 0.9376369714736938, MSE = 0.020551353693008423, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.0016329002100974321, Lv_loss = 1.1392928172426764e-05, Circular Tuning Loss = 1.3174725770950317\n",
      "3124) Lyapunov Risk = 0.9375445246696472, MSE = 0.020292598754167557, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.0016254624351859093, Lv_loss = 1.1634228030743543e-05, Circular Tuning Loss = 1.3172898292541504\n",
      "3125) Lyapunov Risk = 0.9374504685401917, MSE = 0.020645871758461, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.0016182558611035347, Lv_loss = 1.1796096259786282e-05, Circular Tuning Loss = 1.3171072006225586\n",
      "3126) Lyapunov Risk = 0.9373574256896973, MSE = 0.02023898810148239, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.001611177809536457, Lv_loss = 1.1917572010133881e-05, Circular Tuning Loss = 1.3169244527816772\n",
      "3127) Lyapunov Risk = 0.9372540712356567, MSE = 0.020695585757493973, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.0016042476054280996, Lv_loss = 1.2002173207292799e-05, Circular Tuning Loss = 1.3167420625686646\n",
      "3128) Lyapunov Risk = 0.9371477961540222, MSE = 0.02022629603743553, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.0015974156558513641, Lv_loss = 1.2147518646088429e-05, Circular Tuning Loss = 1.3165593147277832\n",
      "3129) Lyapunov Risk = 0.937031090259552, MSE = 0.020690344274044037, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.0015907501801848412, Lv_loss = 1.2262339623703156e-05, Circular Tuning Loss = 1.3163774013519287\n",
      "3130) Lyapunov Risk = 0.9369118213653564, MSE = 0.020243151113390923, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.001584322308190167, Lv_loss = 1.2319004781602416e-05, Circular Tuning Loss = 1.3161958456039429\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.9677734375000004, 1.9687500000000004]\n",
      "x2 : [0, 0.00084270088773948993]\n",
      "==============================\n",
      "3131) Lyapunov Risk = 0.9398940205574036, MSE = 0.02064020000398159, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.0015743833500891924, Lv_loss = 1.2270121260371525e-05, Circular Tuning Loss = 1.3214044570922852\n",
      "3132) Lyapunov Risk = 0.9397732615470886, MSE = 0.020268740132451057, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.0015685035614296794, Lv_loss = 1.210991740663303e-05, Circular Tuning Loss = 1.321221947669983\n",
      "3133) Lyapunov Risk = 0.9396496415138245, MSE = 0.02058427967131138, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.0015628215624019504, Lv_loss = 1.1953355169680435e-05, Circular Tuning Loss = 1.3210395574569702\n",
      "3134) Lyapunov Risk = 0.9395301938056946, MSE = 0.020297937095165253, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.0015572826378047466, Lv_loss = 1.1795165846706368e-05, Circular Tuning Loss = 1.320857286453247\n",
      "3135) Lyapunov Risk = 0.9394092559814453, MSE = 0.02053873799741268, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.0015519094886258245, Lv_loss = 1.1481440196803305e-05, Circular Tuning Loss = 1.320675253868103\n",
      "3136) Lyapunov Risk = 0.9392923712730408, MSE = 0.020326461642980576, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.0015466714976355433, Lv_loss = 1.100162262446247e-05, Circular Tuning Loss = 1.320493459701538\n",
      "3137) Lyapunov Risk = 0.9391751289367676, MSE = 0.02050718665122986, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.001541585079394281, Lv_loss = 1.0437331184220966e-05, Circular Tuning Loss = 1.3203119039535522\n",
      "3138) Lyapunov Risk = 0.939061164855957, MSE = 0.02034710720181465, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0015366405714303255, Lv_loss = 9.861718353931792e-06, Circular Tuning Loss = 1.3201305866241455\n",
      "3139) Lyapunov Risk = 0.9389479756355286, MSE = 0.02048863284289837, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0015318276127800345, Lv_loss = 9.244065950042568e-06, Circular Tuning Loss = 1.3199498653411865\n",
      "3140) Lyapunov Risk = 0.9388371706008911, MSE = 0.020352106541395187, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0015271097654476762, Lv_loss = 8.573058039473835e-06, Circular Tuning Loss = 1.3197698593139648\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.6191406250000004, 1.6201171875000004]\n",
      "x2 : [-0.00084572793338324093, -3.902734630118895e-06]\n",
      "==============================\n",
      "3141) Lyapunov Risk = 0.940386176109314, MSE = 0.0204841997474432, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0015187944518402219, Lv_loss = 7.80925893195672e-06, Circular Tuning Loss = 1.3220843076705933\n",
      "3142) Lyapunov Risk = 0.9402770400047302, MSE = 0.02033189870417118, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0015143412165343761, Lv_loss = 6.906690941832494e-06, Circular Tuning Loss = 1.3219034671783447\n",
      "3143) Lyapunov Risk = 0.9401679635047913, MSE = 0.020500997081398964, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.001510075991973281, Lv_loss = 5.810996299260296e-06, Circular Tuning Loss = 1.321722388267517\n",
      "3144) Lyapunov Risk = 0.9400606155395508, MSE = 0.020301496610045433, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0015059631550684571, Lv_loss = 4.612937118508853e-06, Circular Tuning Loss = 1.321541428565979\n",
      "3145) Lyapunov Risk = 0.9399536848068237, MSE = 0.02052672766149044, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.001502006663940847, Lv_loss = 3.4671816138143186e-06, Circular Tuning Loss = 1.321360468864441\n",
      "3146) Lyapunov Risk = 0.9398475885391235, MSE = 0.020273413509130478, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0014981718268245459, Lv_loss = 2.435162059555296e-06, Circular Tuning Loss = 1.321179747581482\n",
      "3147) Lyapunov Risk = 0.9397436380386353, MSE = 0.02056276984512806, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.001494463300332427, Lv_loss = 1.3188864613766782e-06, Circular Tuning Loss = 1.3209993839263916\n",
      "3148) Lyapunov Risk = 0.9396414756774902, MSE = 0.020246315747499466, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0014908459270372987, Lv_loss = 2.2018467404905095e-07, Circular Tuning Loss = 1.3208192586898804\n",
      "3149) Lyapunov Risk = 0.9395424127578735, MSE = 0.020607750862836838, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.001487301429733634, Lv_loss = 0.0, Circular Tuning Loss = 1.3206400871276855\n",
      "3150) Lyapunov Risk = 0.9394435286521912, MSE = 0.020216818898916245, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0014838047791272402, Lv_loss = 0.0, Circular Tuning Loss = 1.3204609155654907\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.6875000000000004, 1.6884765625000004]\n",
      "x2 : [-0.00084572793338324093, 0]\n",
      "==============================\n",
      "3151) Lyapunov Risk = 0.9412473440170288, MSE = 0.020650062710046768, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0014768412802368402, Lv_loss = 0.0, Circular Tuning Loss = 1.3232591152191162\n",
      "3152) Lyapunov Risk = 0.9411532282829285, MSE = 0.020176365971565247, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.001473588403314352, Lv_loss = 0.0, Circular Tuning Loss = 1.323079228401184\n",
      "3153) Lyapunov Risk = 0.9410802125930786, MSE = 0.02072853408753872, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0014705308713018894, Lv_loss = 0.0, Circular Tuning Loss = 1.3228994607925415\n",
      "3154) Lyapunov Risk = 0.9410110116004944, MSE = 0.020113030448555946, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0014675944112241268, Lv_loss = 0.0, Circular Tuning Loss = 1.3227195739746094\n",
      "3155) Lyapunov Risk = 0.940966010093689, MSE = 0.0208633691072464, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0014648294309154153, Lv_loss = 0.0, Circular Tuning Loss = 1.3225399255752563\n",
      "3156) Lyapunov Risk = 0.9409264922142029, MSE = 0.02004692330956459, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.001462149783037603, Lv_loss = 0.0, Circular Tuning Loss = 1.3223601579666138\n",
      "3157) Lyapunov Risk = 0.9409046173095703, MSE = 0.021032651886343956, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0014595502289012074, Lv_loss = 0.0, Circular Tuning Loss = 1.3221806287765503\n",
      "3158) Lyapunov Risk = 0.9408722519874573, MSE = 0.01999759115278721, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.001457018544897437, Lv_loss = 0.0, Circular Tuning Loss = 1.3220018148422241\n",
      "3159) Lyapunov Risk = 0.9408572912216187, MSE = 0.021192677319049835, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0014545742888003588, Lv_loss = 0.0, Circular Tuning Loss = 1.3218235969543457\n",
      "3160) Lyapunov Risk = 0.9407985210418701, MSE = 0.01997186802327633, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0014522154815495014, Lv_loss = 0.0, Circular Tuning Loss = 1.321645736694336\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.9990234375000004, 2.0000000000000004]\n",
      "x2 : [0, 0.00084572793338324093]\n",
      "==============================\n",
      "3161) Lyapunov Risk = 0.9439514875411987, MSE = 0.02129512093961239, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.001446488662622869, Lv_loss = 0.0, Circular Tuning Loss = 1.3270341157913208\n",
      "3162) Lyapunov Risk = 0.9438360333442688, MSE = 0.019962960854172707, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.001444334047846496, Lv_loss = 0.0, Circular Tuning Loss = 1.3268550634384155\n",
      "3163) Lyapunov Risk = 0.9437180161476135, MSE = 0.021285071969032288, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0014423002721741796, Lv_loss = 0.0, Circular Tuning Loss = 1.3266764879226685\n",
      "3164) Lyapunov Risk = 0.9435054659843445, MSE = 0.01997927576303482, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0014403549721464515, Lv_loss = 0.0, Circular Tuning Loss = 1.326497197151184\n",
      "3165) Lyapunov Risk = 0.9432704448699951, MSE = 0.021094588562846184, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0014384997775778174, Lv_loss = 0.0, Circular Tuning Loss = 1.326318383216858\n",
      "3166) Lyapunov Risk = 0.9429898262023926, MSE = 0.02005091682076454, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0014367148978635669, Lv_loss = 0.0, Circular Tuning Loss = 1.3261395692825317\n",
      "3167) Lyapunov Risk = 0.9427335858345032, MSE = 0.02078559808433056, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0014349365374073386, Lv_loss = 0.0, Circular Tuning Loss = 1.325960636138916\n",
      "3168) Lyapunov Risk = 0.9425004720687866, MSE = 0.020183943212032318, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.001433136290870607, Lv_loss = 0.0, Circular Tuning Loss = 1.3257817029953003\n",
      "3169) Lyapunov Risk = 0.9423171281814575, MSE = 0.020516306161880493, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.001431367825716734, Lv_loss = 0.0, Circular Tuning Loss = 1.3256031274795532\n",
      "3170) Lyapunov Risk = 0.9421636462211609, MSE = 0.020339345559477806, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0014296002918854356, Lv_loss = 0.0, Circular Tuning Loss = 1.3254246711730957\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.9939925211822487, 1.9956205928331348]\n",
      "x2 : [-0.10571599167290512, -0.10487026373952188]\n",
      "==============================\n",
      "3171) Lyapunov Risk = 0.9452094435691833, MSE = 0.020317351445555687, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.00142435054294765, Lv_loss = 3.917065896530403e-06, Circular Tuning Loss = 1.3307472467422485\n",
      "3172) Lyapunov Risk = 0.9451068043708801, MSE = 0.020495755597949028, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0014224413316696882, Lv_loss = 2.270439381391043e-06, Circular Tuning Loss = 1.3305670022964478\n",
      "3173) Lyapunov Risk = 0.9450138807296753, MSE = 0.02020537108182907, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0014204373583197594, Lv_loss = 5.516313308362442e-07, Circular Tuning Loss = 1.3303859233856201\n",
      "3174) Lyapunov Risk = 0.9449248313903809, MSE = 0.020603785291314125, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0014183594612404704, Lv_loss = 0.0, Circular Tuning Loss = 1.330204963684082\n",
      "3175) Lyapunov Risk = 0.9448300004005432, MSE = 0.02015228196978569, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.001416202518157661, Lv_loss = 0.0, Circular Tuning Loss = 1.3300234079360962\n",
      "3176) Lyapunov Risk = 0.9447346329689026, MSE = 0.020669106394052505, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0014139956329017878, Lv_loss = 0.0, Circular Tuning Loss = 1.3298426866531372\n",
      "3177) Lyapunov Risk = 0.9446249008178711, MSE = 0.020130783319473267, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0014117351965978742, Lv_loss = 0.0, Circular Tuning Loss = 1.3296616077423096\n",
      "3178) Lyapunov Risk = 0.9445158243179321, MSE = 0.020702749490737915, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0014094851212576032, Lv_loss = 0.0, Circular Tuning Loss = 1.3294813632965088\n",
      "3179) Lyapunov Risk = 0.9443854093551636, MSE = 0.02013055607676506, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0014071952318772674, Lv_loss = 0.0, Circular Tuning Loss = 1.329301357269287\n",
      "3180) Lyapunov Risk = 0.9442520141601562, MSE = 0.020680589601397514, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.001404877402819693, Lv_loss = 0.0, Circular Tuning Loss = 1.3291219472885132\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0075433693395626, 1.0175433693395624]\n",
      "x2 : [-0.8845570507185706, -0.87455705071857059]\n",
      "==============================\n",
      "3181) Lyapunov Risk = 0.944614827632904, MSE = 0.020152663812041283, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 0.0014345030067488551, Lv_loss = 0.0, Circular Tuning Loss = 1.330170750617981\n",
      "3182) Lyapunov Risk = 0.9444665312767029, MSE = 0.020597849041223526, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 0.0014318568864837289, Lv_loss = 0.0, Circular Tuning Loss = 1.3299915790557861\n",
      "3183) Lyapunov Risk = 0.9443174004554749, MSE = 0.020194320008158684, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 0.0014290004037320614, Lv_loss = 0.0, Circular Tuning Loss = 1.3298118114471436\n",
      "3184) Lyapunov Risk = 0.9441789388656616, MSE = 0.02051665261387825, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 0.0014260003808885813, Lv_loss = 0.0, Circular Tuning Loss = 1.329632043838501\n",
      "3185) Lyapunov Risk = 0.9440428614616394, MSE = 0.020232539623975754, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 0.0014228270156309009, Lv_loss = 0.0, Circular Tuning Loss = 1.3294520378112793\n",
      "3186) Lyapunov Risk = 0.9439159631729126, MSE = 0.020476119592785835, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 0.0014195567928254604, Lv_loss = 0.0, Circular Tuning Loss = 1.3292720317840576\n",
      "3187) Lyapunov Risk = 0.9437919855117798, MSE = 0.0202492568641901, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 0.0014161848230287433, Lv_loss = 0.0, Circular Tuning Loss = 1.329092025756836\n",
      "3188) Lyapunov Risk = 0.9436731934547424, MSE = 0.02047993429005146, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 0.0014127667527645826, Lv_loss = 0.0, Circular Tuning Loss = 1.3289122581481934\n",
      "3189) Lyapunov Risk = 0.9435542225837708, MSE = 0.02024371735751629, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 0.0014092606725171208, Lv_loss = 0.0, Circular Tuning Loss = 1.3287326097488403\n",
      "3190) Lyapunov Risk = 0.9434397220611572, MSE = 0.020504390820860863, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 0.0014057070948183537, Lv_loss = 0.0, Circular Tuning Loss = 1.328553557395935\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [0.49218750000000011, 0.50000000000000011]\n",
      "x2 : [-0.99718750000000023, -0.98718750000000022]\n",
      "==============================\n",
      "3191) Lyapunov Risk = 0.9431522488594055, MSE = 0.02021772786974907, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 0.0014203944010660052, Lv_loss = 0.0, Circular Tuning Loss = 1.3281952142715454\n",
      "3192) Lyapunov Risk = 0.9430395364761353, MSE = 0.020539280027151108, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 0.0014167827321216464, Lv_loss = 0.0, Circular Tuning Loss = 1.3280161619186401\n",
      "3193) Lyapunov Risk = 0.9429264068603516, MSE = 0.02019134908914566, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 0.0014130849158391356, Lv_loss = 0.0, Circular Tuning Loss = 1.3278366327285767\n",
      "3194) Lyapunov Risk = 0.942814826965332, MSE = 0.0205841064453125, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 0.0014093852369114757, Lv_loss = 0.0, Circular Tuning Loss = 1.327656865119934\n",
      "3195) Lyapunov Risk = 0.9427016973495483, MSE = 0.020166097208857536, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 0.001405641552992165, Lv_loss = 0.0, Circular Tuning Loss = 1.3274768590927124\n",
      "3196) Lyapunov Risk = 0.9425895810127258, MSE = 0.020622266456484795, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 0.00140191032551229, Lv_loss = 0.0, Circular Tuning Loss = 1.3272969722747803\n",
      "3197) Lyapunov Risk = 0.9424737095832825, MSE = 0.0201457217335701, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 0.0013981678057461977, Lv_loss = 0.0, Circular Tuning Loss = 1.3271169662475586\n",
      "3198) Lyapunov Risk = 0.9423569440841675, MSE = 0.020644469186663628, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 0.0013944478705525398, Lv_loss = 0.0, Circular Tuning Loss = 1.326937198638916\n",
      "3199) Lyapunov Risk = 0.9422355890274048, MSE = 0.020138423889875412, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 0.001390732591971755, Lv_loss = 0.0, Circular Tuning Loss = 1.326757788658142\n",
      "3200) Lyapunov Risk = 0.9421127438545227, MSE = 0.020646093413233757, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 0.001387050491757691, Lv_loss = 0.0, Circular Tuning Loss = 1.326578974723816\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [0.49218750000000011, 0.50000000000000011]\n",
      "x2 : [-0.99718750000000023, -0.98718750000000022]\n",
      "==============================\n",
      "3201) Lyapunov Risk = 0.941813051700592, MSE = 0.02014421671628952, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 0.0014016691129654646, Lv_loss = 0.0, Circular Tuning Loss = 1.3262252807617188\n",
      "3202) Lyapunov Risk = 0.9416844248771667, MSE = 0.020624851807951927, V_0_loss = tensor([[0.0077]], grad_fn=<PowBackward0>), V_pos_loss = 0.001397936837747693, Lv_loss = 0.0, Circular Tuning Loss = 1.3260464668273926\n",
      "3203) Lyapunov Risk = 0.9415568113327026, MSE = 0.02016332745552063, V_0_loss = tensor([[0.0077]], grad_fn=<PowBackward0>), V_pos_loss = 0.0013941667275503278, Lv_loss = 0.0, Circular Tuning Loss = 1.325866937637329\n",
      "3204) Lyapunov Risk = 0.9414312243461609, MSE = 0.02060994878411293, V_0_loss = tensor([[0.0077]], grad_fn=<PowBackward0>), V_pos_loss = 0.0013903891667723656, Lv_loss = 0.0, Circular Tuning Loss = 1.325687289237976\n",
      "3205) Lyapunov Risk = 0.9413068890571594, MSE = 0.020178161561489105, V_0_loss = tensor([[0.0077]], grad_fn=<PowBackward0>), V_pos_loss = 0.0013865857617929578, Lv_loss = 0.0, Circular Tuning Loss = 1.3255070447921753\n",
      "3206) Lyapunov Risk = 0.9411836266517639, MSE = 0.020600158721208572, V_0_loss = tensor([[0.0077]], grad_fn=<PowBackward0>), V_pos_loss = 0.00138278107624501, Lv_loss = 0.0, Circular Tuning Loss = 1.3253270387649536\n",
      "3207) Lyapunov Risk = 0.9410634636878967, MSE = 0.020180966705083847, V_0_loss = tensor([[0.0077]], grad_fn=<PowBackward0>), V_pos_loss = 0.0013789749937132, Lv_loss = 0.0, Circular Tuning Loss = 1.325147032737732\n",
      "3208) Lyapunov Risk = 0.9409428834915161, MSE = 0.0205998495221138, V_0_loss = tensor([[0.0077]], grad_fn=<PowBackward0>), V_pos_loss = 0.0013751924270763993, Lv_loss = 0.0, Circular Tuning Loss = 1.3249672651290894\n",
      "3209) Lyapunov Risk = 0.940826416015625, MSE = 0.020175214856863022, V_0_loss = tensor([[0.0077]], grad_fn=<PowBackward0>), V_pos_loss = 0.0013714346569031477, Lv_loss = 0.0, Circular Tuning Loss = 1.3247874975204468\n",
      "3210) Lyapunov Risk = 0.940708577632904, MSE = 0.020614895969629288, V_0_loss = tensor([[0.0077]], grad_fn=<PowBackward0>), V_pos_loss = 0.0013677156530320644, Lv_loss = 0.0, Circular Tuning Loss = 1.324608564376831\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0075433693395626, 1.0175433693395624]\n",
      "x2 : [-0.8777912272515046, -0.86779122725150459]\n",
      "==============================\n",
      "3211) Lyapunov Risk = 0.9410852193832397, MSE = 0.020167862996459007, V_0_loss = tensor([[0.0077]], grad_fn=<PowBackward0>), V_pos_loss = 0.0013911171117797494, Lv_loss = 0.0, Circular Tuning Loss = 1.3256118297576904\n",
      "3212) Lyapunov Risk = 0.9409679770469666, MSE = 0.020630236715078354, V_0_loss = tensor([[0.0077]], grad_fn=<PowBackward0>), V_pos_loss = 0.0013871564297005534, Lv_loss = 0.0, Circular Tuning Loss = 1.3254332542419434\n",
      "3213) Lyapunov Risk = 0.9408544301986694, MSE = 0.02015998214483261, V_0_loss = tensor([[0.0077]], grad_fn=<PowBackward0>), V_pos_loss = 0.0013830113457515836, Lv_loss = 0.0, Circular Tuning Loss = 1.325254201889038\n",
      "3214) Lyapunov Risk = 0.9407390356063843, MSE = 0.02065066434442997, V_0_loss = tensor([[0.0077]], grad_fn=<PowBackward0>), V_pos_loss = 0.0013787182979285717, Lv_loss = 0.0, Circular Tuning Loss = 1.3250755071640015\n",
      "3215) Lyapunov Risk = 0.9406275153160095, MSE = 0.020148616284132004, V_0_loss = tensor([[0.0077]], grad_fn=<PowBackward0>), V_pos_loss = 0.001374293235130608, Lv_loss = 0.0, Circular Tuning Loss = 1.3248964548110962\n",
      "3216) Lyapunov Risk = 0.9405136704444885, MSE = 0.02067725360393524, V_0_loss = tensor([[0.0077]], grad_fn=<PowBackward0>), V_pos_loss = 0.0013697621179744601, Lv_loss = 0.0, Circular Tuning Loss = 1.3247178792953491\n",
      "3217) Lyapunov Risk = 0.9404025673866272, MSE = 0.020138775929808617, V_0_loss = tensor([[0.0077]], grad_fn=<PowBackward0>), V_pos_loss = 0.0013651481131091714, Lv_loss = 0.0, Circular Tuning Loss = 1.3245394229888916\n",
      "3218) Lyapunov Risk = 0.9402880668640137, MSE = 0.020704837515950203, V_0_loss = tensor([[0.0077]], grad_fn=<PowBackward0>), V_pos_loss = 0.0013604670530185103, Lv_loss = 0.0, Circular Tuning Loss = 1.3243615627288818\n",
      "3219) Lyapunov Risk = 0.940176248550415, MSE = 0.020130453631281853, V_0_loss = tensor([[0.0077]], grad_fn=<PowBackward0>), V_pos_loss = 0.0013557362835854292, Lv_loss = 0.0, Circular Tuning Loss = 1.3241839408874512\n",
      "3220) Lyapunov Risk = 0.9400618076324463, MSE = 0.020732441917061806, V_0_loss = tensor([[0.0077]], grad_fn=<PowBackward0>), V_pos_loss = 0.0013509753625839949, Lv_loss = 0.0, Circular Tuning Loss = 1.3240069150924683\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [0.49218750000000011, 0.50000000000000011]\n",
      "x2 : [-0.99718750000000023, -0.98718750000000022]\n",
      "==============================\n",
      "3221) Lyapunov Risk = 0.9397661685943604, MSE = 0.020116597414016724, V_0_loss = tensor([[0.0077]], grad_fn=<PowBackward0>), V_pos_loss = 0.0013639500830322504, Lv_loss = 0.0, Circular Tuning Loss = 1.323656678199768\n",
      "3222) Lyapunov Risk = 0.9396426677703857, MSE = 0.020748157054185867, V_0_loss = tensor([[0.0078]], grad_fn=<PowBackward0>), V_pos_loss = 0.0013590971939265728, Lv_loss = 0.0, Circular Tuning Loss = 1.3234800100326538\n",
      "3223) Lyapunov Risk = 0.9395186901092529, MSE = 0.02011452615261078, V_0_loss = tensor([[0.0078]], grad_fn=<PowBackward0>), V_pos_loss = 0.0013542273081839085, Lv_loss = 0.0, Circular Tuning Loss = 1.3233023881912231\n",
      "3224) Lyapunov Risk = 0.9393848776817322, MSE = 0.020750457420945168, V_0_loss = tensor([[0.0078]], grad_fn=<PowBackward0>), V_pos_loss = 0.0013493264559656382, Lv_loss = 0.0, Circular Tuning Loss = 1.3231250047683716\n",
      "3225) Lyapunov Risk = 0.9392502307891846, MSE = 0.020120900124311447, V_0_loss = tensor([[0.0078]], grad_fn=<PowBackward0>), V_pos_loss = 0.0013443807838484645, Lv_loss = 0.0, Circular Tuning Loss = 1.3229469060897827\n",
      "3226) Lyapunov Risk = 0.9391034841537476, MSE = 0.020724091678857803, V_0_loss = tensor([[0.0078]], grad_fn=<PowBackward0>), V_pos_loss = 0.0013393720146268606, Lv_loss = 0.0, Circular Tuning Loss = 1.3227688074111938\n",
      "3227) Lyapunov Risk = 0.9389579892158508, MSE = 0.02013362944126129, V_0_loss = tensor([[0.0078]], grad_fn=<PowBackward0>), V_pos_loss = 0.0013343269238248467, Lv_loss = 0.0, Circular Tuning Loss = 1.322590708732605\n",
      "3228) Lyapunov Risk = 0.9388047456741333, MSE = 0.02066952735185623, V_0_loss = tensor([[0.0078]], grad_fn=<PowBackward0>), V_pos_loss = 0.001329264254309237, Lv_loss = 0.0, Circular Tuning Loss = 1.3224128484725952\n",
      "3229) Lyapunov Risk = 0.938644289970398, MSE = 0.02016833983361721, V_0_loss = tensor([[0.0078]], grad_fn=<PowBackward0>), V_pos_loss = 0.001324298675172031, Lv_loss = 0.0, Circular Tuning Loss = 1.3222352266311646\n",
      "3230) Lyapunov Risk = 0.9384849071502686, MSE = 0.02057177945971489, V_0_loss = tensor([[0.0078]], grad_fn=<PowBackward0>), V_pos_loss = 0.0013193225022405386, Lv_loss = 0.0, Circular Tuning Loss = 1.3220579624176025\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0075433693395626, 1.0175433693395624]\n",
      "x2 : [-0.8777912272515046, -0.86779122725150459]\n",
      "==============================\n",
      "3231) Lyapunov Risk = 0.938814640045166, MSE = 0.0202418752014637, V_0_loss = tensor([[0.0078]], grad_fn=<PowBackward0>), V_pos_loss = 0.0013387809740379453, Lv_loss = 0.0, Circular Tuning Loss = 1.323054552078247\n",
      "3232) Lyapunov Risk = 0.9386643171310425, MSE = 0.020437920466065407, V_0_loss = tensor([[0.0078]], grad_fn=<PowBackward0>), V_pos_loss = 0.0013334742980077863, Lv_loss = 0.0, Circular Tuning Loss = 1.3228771686553955\n",
      "3233) Lyapunov Risk = 0.9385254383087158, MSE = 0.02034711465239525, V_0_loss = tensor([[0.0078]], grad_fn=<PowBackward0>), V_pos_loss = 0.0013280061539262533, Lv_loss = 0.0, Circular Tuning Loss = 1.3226994276046753\n",
      "3234) Lyapunov Risk = 0.9383992552757263, MSE = 0.020309947431087494, V_0_loss = tensor([[0.0078]], grad_fn=<PowBackward0>), V_pos_loss = 0.001322306809015572, Lv_loss = 0.0, Circular Tuning Loss = 1.3225215673446655\n",
      "3235) Lyapunov Risk = 0.9382827877998352, MSE = 0.020455261692404747, V_0_loss = tensor([[0.0078]], grad_fn=<PowBackward0>), V_pos_loss = 0.0013164137490093708, Lv_loss = 0.0, Circular Tuning Loss = 1.322343349456787\n",
      "3236) Lyapunov Risk = 0.9381720423698425, MSE = 0.02022136002779007, V_0_loss = tensor([[0.0078]], grad_fn=<PowBackward0>), V_pos_loss = 0.0013103917008265853, Lv_loss = 0.0, Circular Tuning Loss = 1.3221654891967773\n",
      "3237) Lyapunov Risk = 0.9380671381950378, MSE = 0.02055547572672367, V_0_loss = tensor([[0.0078]], grad_fn=<PowBackward0>), V_pos_loss = 0.0013042597565799952, Lv_loss = 0.0, Circular Tuning Loss = 1.3219876289367676\n",
      "3238) Lyapunov Risk = 0.9379624724388123, MSE = 0.02017294242978096, V_0_loss = tensor([[0.0078]], grad_fn=<PowBackward0>), V_pos_loss = 0.0012980721658095717, Lv_loss = 0.0, Circular Tuning Loss = 1.3218101263046265\n",
      "3239) Lyapunov Risk = 0.9378648400306702, MSE = 0.0206446535885334, V_0_loss = tensor([[0.0078]], grad_fn=<PowBackward0>), V_pos_loss = 0.0012917802669107914, Lv_loss = 0.0, Circular Tuning Loss = 1.3216333389282227\n",
      "3240) Lyapunov Risk = 0.9377670288085938, MSE = 0.020146077498793602, V_0_loss = tensor([[0.0078]], grad_fn=<PowBackward0>), V_pos_loss = 0.001285439939238131, Lv_loss = 0.0, Circular Tuning Loss = 1.3214571475982666\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0075433693395626, 1.0175433693395624]\n",
      "x2 : [-0.8777912272515046, -0.86779122725150459]\n",
      "==============================\n",
      "3241) Lyapunov Risk = 0.938161313533783, MSE = 0.020710831508040428, V_0_loss = tensor([[0.0078]], grad_fn=<PowBackward0>), V_pos_loss = 0.0013014685828238726, Lv_loss = 0.0, Circular Tuning Loss = 1.3224420547485352\n",
      "3242) Lyapunov Risk = 0.9380751252174377, MSE = 0.020129747688770294, V_0_loss = tensor([[0.0078]], grad_fn=<PowBackward0>), V_pos_loss = 0.0012946536298841238, Lv_loss = 0.0, Circular Tuning Loss = 1.3222661018371582\n",
      "3243) Lyapunov Risk = 0.9379968643188477, MSE = 0.020759114995598793, V_0_loss = tensor([[0.0079]], grad_fn=<PowBackward0>), V_pos_loss = 0.0012876326218247414, Lv_loss = 0.0, Circular Tuning Loss = 1.322089672088623\n",
      "3244) Lyapunov Risk = 0.937923014163971, MSE = 0.020147042348980904, V_0_loss = tensor([[0.0079]], grad_fn=<PowBackward0>), V_pos_loss = 0.0012804974103346467, Lv_loss = 0.0, Circular Tuning Loss = 1.3219131231307983\n",
      "3245) Lyapunov Risk = 0.9378589391708374, MSE = 0.020789625123143196, V_0_loss = tensor([[0.0079]], grad_fn=<PowBackward0>), V_pos_loss = 0.001273216214030981, Lv_loss = 0.0, Circular Tuning Loss = 1.3217365741729736\n",
      "3246) Lyapunov Risk = 0.9377989172935486, MSE = 0.020219827070832253, V_0_loss = tensor([[0.0079]], grad_fn=<PowBackward0>), V_pos_loss = 0.0012658523628488183, Lv_loss = 0.0, Circular Tuning Loss = 1.321560025215149\n",
      "3247) Lyapunov Risk = 0.9377422332763672, MSE = 0.020790399983525276, V_0_loss = tensor([[0.0079]], grad_fn=<PowBackward0>), V_pos_loss = 0.0012584031792357564, Lv_loss = 0.0, Circular Tuning Loss = 1.3213841915130615\n",
      "3248) Lyapunov Risk = 0.9376794099807739, MSE = 0.02035437524318695, V_0_loss = tensor([[0.0079]], grad_fn=<PowBackward0>), V_pos_loss = 0.0012509168591350317, Lv_loss = 0.0, Circular Tuning Loss = 1.3212084770202637\n",
      "3249) Lyapunov Risk = 0.9376072883605957, MSE = 0.02072269655764103, V_0_loss = tensor([[0.0079]], grad_fn=<PowBackward0>), V_pos_loss = 0.001243353239260614, Lv_loss = 0.0, Circular Tuning Loss = 1.3210334777832031\n",
      "3250) Lyapunov Risk = 0.9375158548355103, MSE = 0.02052622102200985, V_0_loss = tensor([[0.0079]], grad_fn=<PowBackward0>), V_pos_loss = 0.0012356475926935673, Lv_loss = 0.0, Circular Tuning Loss = 1.3208587169647217\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [0.43359375000000011, 0.43750000000000011]\n",
      "x2 : [-0.75000000000000022, -0.74218750000000022]\n",
      "==============================\n",
      "3251) Lyapunov Risk = 0.9365930557250977, MSE = 0.02056637592613697, V_0_loss = tensor([[0.0079]], grad_fn=<PowBackward0>), V_pos_loss = 0.0012249688152223825, Lv_loss = 0.0, Circular Tuning Loss = 1.319339632987976\n",
      "3252) Lyapunov Risk = 0.9364503026008606, MSE = 0.020706789568066597, V_0_loss = tensor([[0.0079]], grad_fn=<PowBackward0>), V_pos_loss = 0.0012170642148703337, Lv_loss = 0.0, Circular Tuning Loss = 1.3191661834716797\n",
      "3253) Lyapunov Risk = 0.9362822771072388, MSE = 0.020345034077763557, V_0_loss = tensor([[0.0079]], grad_fn=<PowBackward0>), V_pos_loss = 0.0012090676464140415, Lv_loss = 0.0, Circular Tuning Loss = 1.3189938068389893\n",
      "3254) Lyapunov Risk = 0.9360970258712769, MSE = 0.02085818536579609, V_0_loss = tensor([[0.0079]], grad_fn=<PowBackward0>), V_pos_loss = 0.0012009689817205071, Lv_loss = 0.0, Circular Tuning Loss = 1.3188223838806152\n",
      "3255) Lyapunov Risk = 0.9358834028244019, MSE = 0.02015075273811817, V_0_loss = tensor([[0.0079]], grad_fn=<PowBackward0>), V_pos_loss = 0.0011928669409826398, Lv_loss = 0.0, Circular Tuning Loss = 1.3186516761779785\n",
      "3256) Lyapunov Risk = 0.9356582164764404, MSE = 0.020892895758152008, V_0_loss = tensor([[0.0079]], grad_fn=<PowBackward0>), V_pos_loss = 0.0011846899287775159, Lv_loss = 0.0, Circular Tuning Loss = 1.3184818029403687\n",
      "3257) Lyapunov Risk = 0.9354240298271179, MSE = 0.02006434090435505, V_0_loss = tensor([[0.0079]], grad_fn=<PowBackward0>), V_pos_loss = 0.0011765887029469013, Lv_loss = 0.0, Circular Tuning Loss = 1.3183132410049438\n",
      "3258) Lyapunov Risk = 0.9352042078971863, MSE = 0.02079032175242901, V_0_loss = tensor([[0.0079]], grad_fn=<PowBackward0>), V_pos_loss = 0.0011684749042615294, Lv_loss = 0.0, Circular Tuning Loss = 1.3181453943252563\n",
      "3259) Lyapunov Risk = 0.9349965453147888, MSE = 0.020115269348025322, V_0_loss = tensor([[0.0079]], grad_fn=<PowBackward0>), V_pos_loss = 0.0011605211766436696, Lv_loss = 0.0, Circular Tuning Loss = 1.3179785013198853\n",
      "3260) Lyapunov Risk = 0.9348236322402954, MSE = 0.020589031279087067, V_0_loss = tensor([[0.0079]], grad_fn=<PowBackward0>), V_pos_loss = 0.0011526182061061263, Lv_loss = 0.0, Circular Tuning Loss = 1.317812442779541\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0012716846697813, 1.0112716846697811]\n",
      "x2 : [-0.8777912272515046, -0.86779122725150459]\n",
      "==============================\n",
      "3261) Lyapunov Risk = 0.9351498484611511, MSE = 0.020281914621591568, V_0_loss = tensor([[0.0079]], grad_fn=<PowBackward0>), V_pos_loss = 0.0011642787139862776, Lv_loss = 0.0, Circular Tuning Loss = 1.3187745809555054\n",
      "3262) Lyapunov Risk = 0.9350387454032898, MSE = 0.020370779559016228, V_0_loss = tensor([[0.0079]], grad_fn=<PowBackward0>), V_pos_loss = 0.0011560256825760007, Lv_loss = 0.0, Circular Tuning Loss = 1.3186089992523193\n",
      "3263) Lyapunov Risk = 0.9349469542503357, MSE = 0.020496157929301262, V_0_loss = tensor([[0.0079]], grad_fn=<PowBackward0>), V_pos_loss = 0.001147592207416892, Lv_loss = 0.0, Circular Tuning Loss = 1.3184431791305542\n",
      "3264) Lyapunov Risk = 0.9348596930503845, MSE = 0.020211437717080116, V_0_loss = tensor([[0.0079]], grad_fn=<PowBackward0>), V_pos_loss = 0.0011390234576538205, Lv_loss = 0.0, Circular Tuning Loss = 1.3182772397994995\n",
      "3265) Lyapunov Risk = 0.9347660541534424, MSE = 0.020674074068665504, V_0_loss = tensor([[0.0079]], grad_fn=<PowBackward0>), V_pos_loss = 0.0011303279316052794, Lv_loss = 0.0, Circular Tuning Loss = 1.3181113004684448\n",
      "3266) Lyapunov Risk = 0.9346509575843811, MSE = 0.020128430798649788, V_0_loss = tensor([[0.0079]], grad_fn=<PowBackward0>), V_pos_loss = 0.0011215885169804096, Lv_loss = 0.0, Circular Tuning Loss = 1.3179454803466797\n",
      "3267) Lyapunov Risk = 0.9345144629478455, MSE = 0.02074459008872509, V_0_loss = tensor([[0.0079]], grad_fn=<PowBackward0>), V_pos_loss = 0.001112722442485392, Lv_loss = 0.0, Circular Tuning Loss = 1.3177798986434937\n",
      "3268) Lyapunov Risk = 0.9343504905700684, MSE = 0.020117519423365593, V_0_loss = tensor([[0.0079]], grad_fn=<PowBackward0>), V_pos_loss = 0.0011037725489586592, Lv_loss = 0.0, Circular Tuning Loss = 1.3176146745681763\n",
      "3269) Lyapunov Risk = 0.9341756701469421, MSE = 0.02067720517516136, V_0_loss = tensor([[0.0079]], grad_fn=<PowBackward0>), V_pos_loss = 0.0010947728296741843, Lv_loss = 0.0, Circular Tuning Loss = 1.3174500465393066\n",
      "3270) Lyapunov Risk = 0.9339953064918518, MSE = 0.02016841247677803, V_0_loss = tensor([[0.0079]], grad_fn=<PowBackward0>), V_pos_loss = 0.0010857299203053117, Lv_loss = 0.0, Circular Tuning Loss = 1.3172858953475952\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0012716846697813, 1.0112716846697811]\n",
      "x2 : [-0.8777912272515046, -0.86779122725150459]\n",
      "==============================\n",
      "3271) Lyapunov Risk = 0.9342905879020691, MSE = 0.020528491586446762, V_0_loss = tensor([[0.0079]], grad_fn=<PowBackward0>), V_pos_loss = 0.0010937059996649623, Lv_loss = 0.0, Circular Tuning Loss = 1.3182390928268433\n",
      "3272) Lyapunov Risk = 0.9341367483139038, MSE = 0.020260240882635117, V_0_loss = tensor([[0.0079]], grad_fn=<PowBackward0>), V_pos_loss = 0.0010840645991265774, Lv_loss = 0.0, Circular Tuning Loss = 1.318074107170105\n",
      "3273) Lyapunov Risk = 0.933999240398407, MSE = 0.020386312156915665, V_0_loss = tensor([[0.0079]], grad_fn=<PowBackward0>), V_pos_loss = 0.0010742164449766278, Lv_loss = 0.0, Circular Tuning Loss = 1.3179091215133667\n",
      "3274) Lyapunov Risk = 0.9338741898536682, MSE = 0.02037467435002327, V_0_loss = tensor([[0.0079]], grad_fn=<PowBackward0>), V_pos_loss = 0.0010642552515491843, Lv_loss = 0.0, Circular Tuning Loss = 1.3177436590194702\n",
      "3275) Lyapunov Risk = 0.9337579011917114, MSE = 0.020285574719309807, V_0_loss = tensor([[0.0079]], grad_fn=<PowBackward0>), V_pos_loss = 0.001054249587468803, Lv_loss = 0.0, Circular Tuning Loss = 1.3175779581069946\n",
      "3276) Lyapunov Risk = 0.9336462616920471, MSE = 0.020487090572714806, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0010442233178764582, Lv_loss = 0.0, Circular Tuning Loss = 1.317412257194519\n",
      "3277) Lyapunov Risk = 0.933535099029541, MSE = 0.020221902057528496, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0010341963497921824, Lv_loss = 0.0, Circular Tuning Loss = 1.3172463178634644\n",
      "3278) Lyapunov Risk = 0.9334218502044678, MSE = 0.020569831132888794, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0010242086136713624, Lv_loss = 0.0, Circular Tuning Loss = 1.3170808553695679\n",
      "3279) Lyapunov Risk = 0.933300793170929, MSE = 0.020188797265291214, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.001014277688227594, Lv_loss = 0.0, Circular Tuning Loss = 1.31691575050354\n",
      "3280) Lyapunov Risk = 0.9331730604171753, MSE = 0.02059531956911087, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0010043377988040447, Lv_loss = 0.0, Circular Tuning Loss = 1.3167508840560913\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0012716846697813, 1.0112716846697811]\n",
      "x2 : [-0.8777912272515046, -0.86779122725150459]\n",
      "==============================\n",
      "3281) Lyapunov Risk = 0.9334925413131714, MSE = 0.020184673368930817, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0010089360876008868, Lv_loss = 0.0, Circular Tuning Loss = 1.317693829536438\n",
      "3282) Lyapunov Risk = 0.9333497881889343, MSE = 0.020558740943670273, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0009986223885789514, Lv_loss = 0.0, Circular Tuning Loss = 1.3175287246704102\n",
      "3283) Lyapunov Risk = 0.9332047700881958, MSE = 0.020208654925227165, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0009881799342110753, Lv_loss = 0.0, Circular Tuning Loss = 1.3173627853393555\n",
      "3284) Lyapunov Risk = 0.9330602288246155, MSE = 0.020503560081124306, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.000977642834186554, Lv_loss = 0.0, Circular Tuning Loss = 1.3171966075897217\n",
      "3285) Lyapunov Risk = 0.9329201579093933, MSE = 0.02024717442691326, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0009670471190474927, Lv_loss = 0.0, Circular Tuning Loss = 1.3170301914215088\n",
      "3286) Lyapunov Risk = 0.9327847957611084, MSE = 0.02045399323105812, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0009562519262544811, Lv_loss = 0.0, Circular Tuning Loss = 1.3168641328811646\n",
      "3287) Lyapunov Risk = 0.9326523542404175, MSE = 0.020292872563004494, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0009453181992284954, Lv_loss = 0.0, Circular Tuning Loss = 1.3166980743408203\n",
      "3288) Lyapunov Risk = 0.9325219988822937, MSE = 0.020410684868693352, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0009342196863144636, Lv_loss = 0.0, Circular Tuning Loss = 1.3165326118469238\n",
      "3289) Lyapunov Risk = 0.9323938488960266, MSE = 0.020335698500275612, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0009229759452864528, Lv_loss = 0.0, Circular Tuning Loss = 1.3163671493530273\n",
      "3290) Lyapunov Risk = 0.932267427444458, MSE = 0.020378366112709045, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0009116633445955813, Lv_loss = 0.0, Circular Tuning Loss = 1.3162022829055786\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0012716846697813, 1.0112716846697811]\n",
      "x2 : [-0.8727912272515046, -0.86602540378443871]\n",
      "==============================\n",
      "3291) Lyapunov Risk = 0.932587742805481, MSE = 0.020363733172416687, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0009120931499637663, Lv_loss = 0.0, Circular Tuning Loss = 1.3171230554580688\n",
      "3292) Lyapunov Risk = 0.9324632287025452, MSE = 0.02034086547791958, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0009003127925097942, Lv_loss = 0.0, Circular Tuning Loss = 1.3169578313827515\n",
      "3293) Lyapunov Risk = 0.9323398470878601, MSE = 0.020390987396240234, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0008884553099051118, Lv_loss = 0.0, Circular Tuning Loss = 1.3167924880981445\n",
      "3294) Lyapunov Risk = 0.9322167038917542, MSE = 0.02030947245657444, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0008765142410993576, Lv_loss = 0.0, Circular Tuning Loss = 1.3166269063949585\n",
      "3295) Lyapunov Risk = 0.9320935606956482, MSE = 0.020417306572198868, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0008645046036690474, Lv_loss = 0.0, Circular Tuning Loss = 1.3164613246917725\n",
      "3296) Lyapunov Risk = 0.9319708347320557, MSE = 0.020292388275265694, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0008524557342752814, Lv_loss = 0.0, Circular Tuning Loss = 1.3162956237792969\n",
      "3297) Lyapunov Risk = 0.9318475127220154, MSE = 0.02044512890279293, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0008403893443755805, Lv_loss = 0.0, Circular Tuning Loss = 1.3161300420761108\n",
      "3298) Lyapunov Risk = 0.931725025177002, MSE = 0.02028081752359867, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0008283607894554734, Lv_loss = 0.0, Circular Tuning Loss = 1.315964698791504\n",
      "3299) Lyapunov Risk = 0.93160480260849, MSE = 0.0204637311398983, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0008164243772625923, Lv_loss = 0.0, Circular Tuning Loss = 1.3157994747161865\n",
      "3300) Lyapunov Risk = 0.9314864277839661, MSE = 0.02026551589369774, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0008042309200391173, Lv_loss = 0.0, Circular Tuning Loss = 1.3156346082687378\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0000000000000002, 1.0062716846697812]\n",
      "x2 : [-0.8727912272515046, -0.86602540378443871]\n",
      "==============================\n",
      "3301) Lyapunov Risk = 0.9318022727966309, MSE = 0.020473957061767578, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0008013623883016407, Lv_loss = 0.0, Circular Tuning Loss = 1.3165351152420044\n",
      "3302) Lyapunov Risk = 0.9316847324371338, MSE = 0.020244330167770386, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.000788144941907376, Lv_loss = 0.0, Circular Tuning Loss = 1.3163695335388184\n",
      "3303) Lyapunov Risk = 0.9315678477287292, MSE = 0.020494554191827774, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0007745295879431069, Lv_loss = 0.0, Circular Tuning Loss = 1.3162034749984741\n",
      "3304) Lyapunov Risk = 0.9314517974853516, MSE = 0.020227055996656418, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0007605782011523843, Lv_loss = 0.0, Circular Tuning Loss = 1.3160370588302612\n",
      "3305) Lyapunov Risk = 0.9313368201255798, MSE = 0.02052444964647293, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0007463411893695593, Lv_loss = 0.0, Circular Tuning Loss = 1.3158702850341797\n",
      "3306) Lyapunov Risk = 0.9312235116958618, MSE = 0.02020869590342045, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0007318602874875069, Lv_loss = 0.0, Circular Tuning Loss = 1.3157033920288086\n",
      "3307) Lyapunov Risk = 0.9311268329620361, MSE = 0.02058883011341095, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0007172224577516317, Lv_loss = 0.0, Circular Tuning Loss = 1.3155368566513062\n",
      "3308) Lyapunov Risk = 0.9310399889945984, MSE = 0.020149175077676773, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0007023939397186041, Lv_loss = 0.0, Circular Tuning Loss = 1.315369963645935\n",
      "3309) Lyapunov Risk = 0.9309830665588379, MSE = 0.020732015371322632, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0006874845130369067, Lv_loss = 0.0, Circular Tuning Loss = 1.3152035474777222\n",
      "3310) Lyapunov Risk = 0.9309487342834473, MSE = 0.020062999799847603, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0006724648410454392, Lv_loss = 0.0, Circular Tuning Loss = 1.3150370121002197\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0000000000000002, 1.0062716846697812]\n",
      "x2 : [-0.8727912272515046, -0.86602540378443871]\n",
      "==============================\n",
      "3311) Lyapunov Risk = 0.9313886165618896, MSE = 0.02096753753721714, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.000663812446873635, Lv_loss = 0.0, Circular Tuning Loss = 1.3159217834472656\n",
      "3312) Lyapunov Risk = 0.9314342737197876, MSE = 0.019978569820523262, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0006482084281742573, Lv_loss = 0.0, Circular Tuning Loss = 1.3157540559768677\n",
      "3313) Lyapunov Risk = 0.9316069483757019, MSE = 0.02134951390326023, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0006324675632640719, Lv_loss = 0.0, Circular Tuning Loss = 1.3155862092971802\n",
      "3314) Lyapunov Risk = 0.9317966103553772, MSE = 0.01992187462747097, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0006166154053062201, Lv_loss = 0.0, Circular Tuning Loss = 1.3154178857803345\n",
      "3315) Lyapunov Risk = 0.9321523308753967, MSE = 0.021889381110668182, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0006007312913425267, Lv_loss = 0.0, Circular Tuning Loss = 1.3152499198913574\n",
      "3316) Lyapunov Risk = 0.9323795437812805, MSE = 0.019940026104450226, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0005849269800819457, Lv_loss = 3.0610675594289205e-07, Circular Tuning Loss = 1.3150818347930908\n",
      "3317) Lyapunov Risk = 0.9325345754623413, MSE = 0.022274820134043694, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0005691166734322906, Lv_loss = 0.0, Circular Tuning Loss = 1.3149142265319824\n",
      "3318) Lyapunov Risk = 0.9322519898414612, MSE = 0.019951799884438515, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0005534027586691082, Lv_loss = 4.721441655419767e-07, Circular Tuning Loss = 1.3147467374801636\n",
      "3319) Lyapunov Risk = 0.931715190410614, MSE = 0.021918578073382378, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0005373911699280143, Lv_loss = 0.0, Circular Tuning Loss = 1.3145798444747925\n",
      "3320) Lyapunov Risk = 0.9308716058731079, MSE = 0.01993950456380844, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0005212283576838672, Lv_loss = 0.0, Circular Tuning Loss = 1.314413070678711\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [0.49218750000000011, 0.50000000000000011]\n",
      "x2 : [-1.0000000000000002, -0.99218750000000022]\n",
      "==============================\n",
      "3321) Lyapunov Risk = 0.9300176501274109, MSE = 0.020960744470357895, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.000511501042637974, Lv_loss = 0.0, Circular Tuning Loss = 1.3140949010849\n",
      "3322) Lyapunov Risk = 0.929550051689148, MSE = 0.020211312919855118, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.000494612380862236, Lv_loss = 0.0, Circular Tuning Loss = 1.3139264583587646\n",
      "3323) Lyapunov Risk = 0.9293946623802185, MSE = 0.020234011113643646, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.00047741091111674905, Lv_loss = 0.0, Circular Tuning Loss = 1.3137569427490234\n",
      "3324) Lyapunov Risk = 0.9294780492782593, MSE = 0.02080187015235424, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.00045995533582754433, Lv_loss = 0.0, Circular Tuning Loss = 1.313585877418518\n",
      "3325) Lyapunov Risk = 0.9296412467956543, MSE = 0.01995895802974701, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.00044225051533430815, Lv_loss = 0.0, Circular Tuning Loss = 1.313413381576538\n",
      "3326) Lyapunov Risk = 0.9297789931297302, MSE = 0.02128791995346546, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.00042448192834854126, Lv_loss = 0.0, Circular Tuning Loss = 1.3132405281066895\n",
      "3327) Lyapunov Risk = 0.9296746850013733, MSE = 0.01992461457848549, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0004066588298883289, Lv_loss = 0.0, Circular Tuning Loss = 1.3130673170089722\n",
      "3328) Lyapunov Risk = 0.929437518119812, MSE = 0.021205296739935875, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.00038887487608008087, Lv_loss = 0.0, Circular Tuning Loss = 1.3128937482833862\n",
      "3329) Lyapunov Risk = 0.9290371537208557, MSE = 0.02000574953854084, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0003711527388077229, Lv_loss = 0.0, Circular Tuning Loss = 1.3127199411392212\n",
      "3330) Lyapunov Risk = 0.928686261177063, MSE = 0.02069971151649952, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0003540061297826469, Lv_loss = 0.0, Circular Tuning Loss = 1.3125466108322144\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0000000000000002, 1.0062716846697812]\n",
      "x2 : [-0.8727912272515046, -0.86602540378443871]\n",
      "==============================\n",
      "3331) Lyapunov Risk = 0.9288474321365356, MSE = 0.02025875262916088, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0003380896814633161, Lv_loss = 0.0, Circular Tuning Loss = 1.3134090900421143\n",
      "3332) Lyapunov Risk = 0.9287254214286804, MSE = 0.020259084179997444, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.00032416239264421165, Lv_loss = 0.0, Circular Tuning Loss = 1.3132398128509521\n",
      "3333) Lyapunov Risk = 0.9287014603614807, MSE = 0.020630447193980217, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.00031313017825596035, Lv_loss = 0.0, Circular Tuning Loss = 1.3130784034729004\n",
      "3334) Lyapunov Risk = 0.9287230372428894, MSE = 0.020037248730659485, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.00030467190663330257, Lv_loss = 0.0, Circular Tuning Loss = 1.312927484512329\n",
      "3335) Lyapunov Risk = 0.9287418127059937, MSE = 0.020936666056513786, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.00029836760950274765, Lv_loss = 0.0, Circular Tuning Loss = 1.312789797782898\n",
      "3336) Lyapunov Risk = 0.9286618828773499, MSE = 0.019980259239673615, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002937592507805675, Lv_loss = 0.0, Circular Tuning Loss = 1.3126660585403442\n",
      "3337) Lyapunov Risk = 0.9284957647323608, MSE = 0.020922262221574783, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.00029031012672930956, Lv_loss = 0.0, Circular Tuning Loss = 1.3125567436218262\n",
      "3338) Lyapunov Risk = 0.9282530546188354, MSE = 0.02005006931722164, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002877276565413922, Lv_loss = 0.0, Circular Tuning Loss = 1.3124593496322632\n",
      "3339) Lyapunov Risk = 0.9280192852020264, MSE = 0.02063223347067833, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.000285949936369434, Lv_loss = 0.0, Circular Tuning Loss = 1.3123735189437866\n",
      "3340) Lyapunov Risk = 0.9278280735015869, MSE = 0.02022191509604454, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002848502481356263, Lv_loss = 0.0, Circular Tuning Loss = 1.3122973442077637\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0175781250000004, -1.0156250000000004]\n",
      "x2 : [0.47360764269461492, 0.47529909856138142]\n",
      "==============================\n",
      "3341) Lyapunov Risk = 0.9274950623512268, MSE = 0.02033471316099167, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002837137726601213, Lv_loss = 0.0, Circular Tuning Loss = 1.3106824159622192\n",
      "3342) Lyapunov Risk = 0.9274133443832397, MSE = 0.020481504499912262, V_0_loss = tensor([[0.0080]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002837919455487281, Lv_loss = 0.0, Circular Tuning Loss = 1.3106231689453125\n",
      "3343) Lyapunov Risk = 0.927359938621521, MSE = 0.020135976374149323, V_0_loss = tensor([[0.0079]], grad_fn=<PowBackward0>), V_pos_loss = 0.00028435070998966694, Lv_loss = 0.0, Circular Tuning Loss = 1.3105705976486206\n",
      "3344) Lyapunov Risk = 0.9273059368133545, MSE = 0.0206854697316885, V_0_loss = tensor([[0.0079]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002853703626897186, Lv_loss = 0.0, Circular Tuning Loss = 1.3105241060256958\n",
      "3345) Lyapunov Risk = 0.9272204041481018, MSE = 0.020072048529982567, V_0_loss = tensor([[0.0079]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002867695002350956, Lv_loss = 0.0, Circular Tuning Loss = 1.310482382774353\n",
      "3346) Lyapunov Risk = 0.9270915985107422, MSE = 0.020714273676276207, V_0_loss = tensor([[0.0079]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002885649155359715, Lv_loss = 0.0, Circular Tuning Loss = 1.3104451894760132\n",
      "3347) Lyapunov Risk = 0.9269261956214905, MSE = 0.020114095881581306, V_0_loss = tensor([[0.0079]], grad_fn=<PowBackward0>), V_pos_loss = 0.00029065340640954673, Lv_loss = 0.0, Circular Tuning Loss = 1.3104113340377808\n",
      "3348) Lyapunov Risk = 0.9267559051513672, MSE = 0.020557934418320656, V_0_loss = tensor([[0.0079]], grad_fn=<PowBackward0>), V_pos_loss = 0.000293030112516135, Lv_loss = 0.0, Circular Tuning Loss = 1.3103805780410767\n",
      "3349) Lyapunov Risk = 0.9266021847724915, MSE = 0.02022603526711464, V_0_loss = tensor([[0.0079]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002956167154479772, Lv_loss = 0.0, Circular Tuning Loss = 1.3103516101837158\n",
      "3350) Lyapunov Risk = 0.9264693856239319, MSE = 0.020371444523334503, V_0_loss = tensor([[0.0079]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002984382736030966, Lv_loss = 0.0, Circular Tuning Loss = 1.3103245496749878\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0175781250000004, -1.0156250000000004]\n",
      "x2 : [0.47360764269461492, 0.47529909856138142]\n",
      "==============================\n",
      "3351) Lyapunov Risk = 0.926170825958252, MSE = 0.020381325855851173, V_0_loss = tensor([[0.0078]], grad_fn=<PowBackward0>), V_pos_loss = 0.0003007643681485206, Lv_loss = 0.0, Circular Tuning Loss = 1.3087608814239502\n",
      "3352) Lyapunov Risk = 0.9260743856430054, MSE = 0.02024371549487114, V_0_loss = tensor([[0.0078]], grad_fn=<PowBackward0>), V_pos_loss = 0.000303993234410882, Lv_loss = 0.0, Circular Tuning Loss = 1.308734655380249\n",
      "3353) Lyapunov Risk = 0.9259809255599976, MSE = 0.020492883399128914, V_0_loss = tensor([[0.0078]], grad_fn=<PowBackward0>), V_pos_loss = 0.0003073492262046784, Lv_loss = 0.0, Circular Tuning Loss = 1.3087067604064941\n",
      "3354) Lyapunov Risk = 0.9258794188499451, MSE = 0.020196793600916862, V_0_loss = tensor([[0.0078]], grad_fn=<PowBackward0>), V_pos_loss = 0.0003104262286797166, Lv_loss = 0.0, Circular Tuning Loss = 1.3086751699447632\n",
      "3355) Lyapunov Risk = 0.9257661700248718, MSE = 0.020504359155893326, V_0_loss = tensor([[0.0078]], grad_fn=<PowBackward0>), V_pos_loss = 0.0003130486875306815, Lv_loss = 0.0, Circular Tuning Loss = 1.3086390495300293\n",
      "3356) Lyapunov Risk = 0.9256479144096375, MSE = 0.020210711285471916, V_0_loss = tensor([[0.0078]], grad_fn=<PowBackward0>), V_pos_loss = 0.00031514413421973586, Lv_loss = 0.0, Circular Tuning Loss = 1.3085981607437134\n",
      "3357) Lyapunov Risk = 0.9255253672599792, MSE = 0.020456504076719284, V_0_loss = tensor([[0.0078]], grad_fn=<PowBackward0>), V_pos_loss = 0.0003167303802911192, Lv_loss = 0.0, Circular Tuning Loss = 1.3085519075393677\n",
      "3358) Lyapunov Risk = 0.9254019260406494, MSE = 0.020265860483050346, V_0_loss = tensor([[0.0078]], grad_fn=<PowBackward0>), V_pos_loss = 0.0003177264879923314, Lv_loss = 0.0, Circular Tuning Loss = 1.308499813079834\n",
      "3359) Lyapunov Risk = 0.9252841472625732, MSE = 0.02036145329475403, V_0_loss = tensor([[0.0077]], grad_fn=<PowBackward0>), V_pos_loss = 0.0003181454085279256, Lv_loss = 0.0, Circular Tuning Loss = 1.3084425926208496\n",
      "3360) Lyapunov Risk = 0.9251735210418701, MSE = 0.02034568414092064, V_0_loss = tensor([[0.0077]], grad_fn=<PowBackward0>), V_pos_loss = 0.00031800635042600334, Lv_loss = 0.0, Circular Tuning Loss = 1.3083796501159668\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0488281250000004, -1.0468750000000004]\n",
      "x2 : [0.41948105495808752, 0.42117251082485396]\n",
      "==============================\n",
      "3361) Lyapunov Risk = 0.9248949885368347, MSE = 0.020274275913834572, V_0_loss = tensor([[0.0077]], grad_fn=<PowBackward0>), V_pos_loss = 0.00031664816197007895, Lv_loss = 0.0, Circular Tuning Loss = 1.3068000078201294\n",
      "3362) Lyapunov Risk = 0.9247953295707703, MSE = 0.02042640745639801, V_0_loss = tensor([[0.0077]], grad_fn=<PowBackward0>), V_pos_loss = 0.0003156554594170302, Lv_loss = 0.0, Circular Tuning Loss = 1.306728482246399\n",
      "3363) Lyapunov Risk = 0.924694299697876, MSE = 0.02022818848490715, V_0_loss = tensor([[0.0077]], grad_fn=<PowBackward0>), V_pos_loss = 0.00031439284794032574, Lv_loss = 0.0, Circular Tuning Loss = 1.306653380393982\n",
      "3364) Lyapunov Risk = 0.9245895147323608, MSE = 0.020460378378629684, V_0_loss = tensor([[0.0077]], grad_fn=<PowBackward0>), V_pos_loss = 0.00031296830275096, Lv_loss = 0.0, Circular Tuning Loss = 1.3065760135650635\n",
      "3365) Lyapunov Risk = 0.9244810938835144, MSE = 0.020227301865816116, V_0_loss = tensor([[0.0077]], grad_fn=<PowBackward0>), V_pos_loss = 0.0003114115388598293, Lv_loss = 0.0, Circular Tuning Loss = 1.3064963817596436\n",
      "3366) Lyapunov Risk = 0.9243684411048889, MSE = 0.020440759137272835, V_0_loss = tensor([[0.0077]], grad_fn=<PowBackward0>), V_pos_loss = 0.000309792987536639, Lv_loss = 0.0, Circular Tuning Loss = 1.306415319442749\n",
      "3367) Lyapunov Risk = 0.9242532253265381, MSE = 0.020258933305740356, V_0_loss = tensor([[0.0077]], grad_fn=<PowBackward0>), V_pos_loss = 0.00030821250402368605, Lv_loss = 0.0, Circular Tuning Loss = 1.3063331842422485\n",
      "3368) Lyapunov Risk = 0.9241389036178589, MSE = 0.020370200276374817, V_0_loss = tensor([[0.0077]], grad_fn=<PowBackward0>), V_pos_loss = 0.00030674514709971845, Lv_loss = 0.0, Circular Tuning Loss = 1.3062509298324585\n",
      "3369) Lyapunov Risk = 0.9240284562110901, MSE = 0.020323337987065315, V_0_loss = tensor([[0.0077]], grad_fn=<PowBackward0>), V_pos_loss = 0.00030538602732121944, Lv_loss = 0.0, Circular Tuning Loss = 1.3061686754226685\n",
      "3370) Lyapunov Risk = 0.9239223003387451, MSE = 0.020298216491937637, V_0_loss = tensor([[0.0077]], grad_fn=<PowBackward0>), V_pos_loss = 0.0003041613381356001, Lv_loss = 0.0, Circular Tuning Loss = 1.3060871362686157\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0332031250000004, -1.0312591768784634]\n",
      "x2 : [0.42455542255838696, 0.42624687842515341]\n",
      "==============================\n",
      "3371) Lyapunov Risk = 0.9236329793930054, MSE = 0.020388269796967506, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 0.0003024031757377088, Lv_loss = 0.0, Circular Tuning Loss = 1.304470181465149\n",
      "3372) Lyapunov Risk = 0.923529326915741, MSE = 0.020266782492399216, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 0.0003015195543412119, Lv_loss = 0.0, Circular Tuning Loss = 1.3043909072875977\n",
      "3373) Lyapunov Risk = 0.9234245419502258, MSE = 0.020408300682902336, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 0.000300805812003091, Lv_loss = 0.0, Circular Tuning Loss = 1.304313063621521\n",
      "3374) Lyapunov Risk = 0.9233188033103943, MSE = 0.02026183530688286, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 0.0003002276935148984, Lv_loss = 0.0, Circular Tuning Loss = 1.3042360544204712\n",
      "3375) Lyapunov Risk = 0.923213005065918, MSE = 0.020397480577230453, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002997778356075287, Lv_loss = 0.0, Circular Tuning Loss = 1.3041603565216064\n",
      "3376) Lyapunov Risk = 0.9231071472167969, MSE = 0.02027519792318344, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002994365058839321, Lv_loss = 0.0, Circular Tuning Loss = 1.3040848970413208\n",
      "3377) Lyapunov Risk = 0.9230028390884399, MSE = 0.020375829190015793, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 0.00029919747612439096, Lv_loss = 0.0, Circular Tuning Loss = 1.304010033607483\n",
      "3378) Lyapunov Risk = 0.922900378704071, MSE = 0.020296115428209305, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 0.00029903335962444544, Lv_loss = 0.0, Circular Tuning Loss = 1.3039352893829346\n",
      "3379) Lyapunov Risk = 0.9228004217147827, MSE = 0.020353741943836212, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002989436616189778, Lv_loss = 0.0, Circular Tuning Loss = 1.3038609027862549\n",
      "3380) Lyapunov Risk = 0.9227042198181152, MSE = 0.02032105252146721, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002989188942592591, Lv_loss = 0.0, Circular Tuning Loss = 1.3037865161895752\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0566406250000004, -1.0546875000000004]\n",
      "x2 : [0.42624687842515341, 0.42793833429191991]\n",
      "==============================\n",
      "3381) Lyapunov Risk = 0.9224585890769958, MSE = 0.020338261500000954, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 0.00029826804529875517, Lv_loss = 0.0, Circular Tuning Loss = 1.3022502660751343\n",
      "3382) Lyapunov Risk = 0.9223759174346924, MSE = 0.02036215551197529, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 0.00029834677116014063, Lv_loss = 0.0, Circular Tuning Loss = 1.302175760269165\n",
      "3383) Lyapunov Risk = 0.9223027229309082, MSE = 0.020336449146270752, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002984659222420305, Lv_loss = 0.0, Circular Tuning Loss = 1.3021007776260376\n",
      "3384) Lyapunov Risk = 0.9222427606582642, MSE = 0.020401865243911743, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002986229083035141, Lv_loss = 0.0, Circular Tuning Loss = 1.3020249605178833\n",
      "3385) Lyapunov Risk = 0.922200083732605, MSE = 0.020370393991470337, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002987950574606657, Lv_loss = 0.0, Circular Tuning Loss = 1.3019483089447021\n",
      "3386) Lyapunov Risk = 0.9221806526184082, MSE = 0.020441921427845955, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002989930799230933, Lv_loss = 0.0, Circular Tuning Loss = 1.3018710613250732\n",
      "3387) Lyapunov Risk = 0.9221928119659424, MSE = 0.02045190893113613, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.00029919680673629045, Lv_loss = 0.0, Circular Tuning Loss = 1.3017925024032593\n",
      "3388) Lyapunov Risk = 0.9222419857978821, MSE = 0.020499667152762413, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.00029904517577961087, Lv_loss = 0.0, Circular Tuning Loss = 1.301712155342102\n",
      "3389) Lyapunov Risk = 0.9223229289054871, MSE = 0.020589934661984444, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.00029832415748387575, Lv_loss = 0.0, Circular Tuning Loss = 1.301629662513733\n",
      "3390) Lyapunov Risk = 0.9224164485931396, MSE = 0.020568808540701866, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.00029698730213567615, Lv_loss = 0.0, Circular Tuning Loss = 1.3015449047088623\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0644531250000004, -1.0625000000000004]\n",
      "x2 : [0.40594940802395563, 0.40764086389072213]\n",
      "==============================\n",
      "3391) Lyapunov Risk = 0.9223359823226929, MSE = 0.02076411060988903, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002944385341834277, Lv_loss = 0.0, Circular Tuning Loss = 1.3000041246414185\n",
      "3392) Lyapunov Risk = 0.9223365783691406, MSE = 0.020586835220456123, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002920717524830252, Lv_loss = 0.0, Circular Tuning Loss = 1.2999159097671509\n",
      "3393) Lyapunov Risk = 0.922204315662384, MSE = 0.020885057747364044, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002892719057854265, Lv_loss = 0.0, Circular Tuning Loss = 1.2998260259628296\n",
      "3394) Lyapunov Risk = 0.9219181537628174, MSE = 0.02041816897690296, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.000286103313555941, Lv_loss = 0.0, Circular Tuning Loss = 1.299734354019165\n",
      "3395) Lyapunov Risk = 0.9215287566184998, MSE = 0.02081344835460186, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002826266863849014, Lv_loss = 0.0, Circular Tuning Loss = 1.2996416091918945\n",
      "3396) Lyapunov Risk = 0.9211161732673645, MSE = 0.020143065601587296, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00027892112848348916, Lv_loss = 0.0, Circular Tuning Loss = 1.2995474338531494\n",
      "3397) Lyapunov Risk = 0.9207980036735535, MSE = 0.020648393779993057, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002749851264525205, Lv_loss = 0.0, Circular Tuning Loss = 1.2994524240493774\n",
      "3398) Lyapunov Risk = 0.9206181764602661, MSE = 0.02006266452372074, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00027081905864179134, Lv_loss = 0.0, Circular Tuning Loss = 1.29935622215271\n",
      "3399) Lyapunov Risk = 0.9205743074417114, MSE = 0.020572328940033913, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00026645438629202545, Lv_loss = 0.0, Circular Tuning Loss = 1.2992594242095947\n",
      "3400) Lyapunov Risk = 0.920587956905365, MSE = 0.020202701911330223, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00026182152214460075, Lv_loss = 0.0, Circular Tuning Loss = 1.2991609573364258\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.7500000000000004, 1.7509306512307559]\n",
      "x2 : [0.43132124602545285, 0.43301270189221935]\n",
      "==============================\n",
      "3401) Lyapunov Risk = 0.9225600361824036, MSE = 0.020518049597740173, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002563921734690666, Lv_loss = 1.4929622693671263e-07, Circular Tuning Loss = 1.3022269010543823\n",
      "3402) Lyapunov Risk = 0.9224714040756226, MSE = 0.020358135923743248, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00025149821885861456, Lv_loss = 2.355953938604216e-06, Circular Tuning Loss = 1.3021247386932373\n",
      "3403) Lyapunov Risk = 0.9223012924194336, MSE = 0.02034580148756504, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00024666255922056735, Lv_loss = 4.518900368566392e-06, Circular Tuning Loss = 1.3020211458206177\n",
      "3404) Lyapunov Risk = 0.9220911264419556, MSE = 0.020425723865628242, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00024198890605475754, Lv_loss = 6.693054729112191e-06, Circular Tuning Loss = 1.3019163608551025\n",
      "3405) Lyapunov Risk = 0.921897292137146, MSE = 0.020157184451818466, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002376238553551957, Lv_loss = 8.811264706309885e-06, Circular Tuning Loss = 1.3018112182617188\n",
      "3406) Lyapunov Risk = 0.9217658638954163, MSE = 0.020474417135119438, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00023368204711005092, Lv_loss = 1.0889746590692084e-05, Circular Tuning Loss = 1.3017069101333618\n",
      "3407) Lyapunov Risk = 0.9216925501823425, MSE = 0.020087353885173798, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00023012282326817513, Lv_loss = 1.2914458238810766e-05, Circular Tuning Loss = 1.3016033172607422\n",
      "3408) Lyapunov Risk = 0.9216564297676086, MSE = 0.020529691129922867, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002269894612254575, Lv_loss = 1.4860059309285134e-05, Circular Tuning Loss = 1.301501989364624\n",
      "3409) Lyapunov Risk = 0.9216105341911316, MSE = 0.02011185698211193, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00022423792688641697, Lv_loss = 1.676842657616362e-05, Circular Tuning Loss = 1.3014030456542969\n",
      "3410) Lyapunov Risk = 0.9215297698974609, MSE = 0.020518949255347252, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00022189097944647074, Lv_loss = 1.8586339137982577e-05, Circular Tuning Loss = 1.3013064861297607\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0644531250000004, -1.0625000000000004]\n",
      "x2 : [0.38903484935629085, 0.39072630522305729]\n",
      "==============================\n",
      "3411) Lyapunov Risk = 0.9212439060211182, MSE = 0.02015100233256817, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00021933697280474007, Lv_loss = 2.0347282770671882e-05, Circular Tuning Loss = 1.2997545003890991\n",
      "3412) Lyapunov Risk = 0.9210919141769409, MSE = 0.020415902137756348, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002175571717089042, Lv_loss = 2.2078780602896586e-05, Circular Tuning Loss = 1.2996649742126465\n",
      "3413) Lyapunov Risk = 0.9209362268447876, MSE = 0.02018551528453827, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00021592418488580734, Lv_loss = 2.3800799681339413e-05, Circular Tuning Loss = 1.2995778322219849\n",
      "3414) Lyapunov Risk = 0.9208048582077026, MSE = 0.020284214988350868, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002144348545698449, Lv_loss = 2.5474311769357882e-05, Circular Tuning Loss = 1.2994933128356934\n",
      "3415) Lyapunov Risk = 0.920707643032074, MSE = 0.020259594544768333, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00021305459085851908, Lv_loss = 2.7122885512653738e-05, Circular Tuning Loss = 1.2994108200073242\n",
      "3416) Lyapunov Risk = 0.9206374287605286, MSE = 0.020196540281176567, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00021177464805077761, Lv_loss = 2.874976780731231e-05, Circular Tuning Loss = 1.2993298768997192\n",
      "3417) Lyapunov Risk = 0.920577347278595, MSE = 0.020345542579889297, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002105905005009845, Lv_loss = 3.0343950129463337e-05, Circular Tuning Loss = 1.2992507219314575\n",
      "3418) Lyapunov Risk = 0.9205077886581421, MSE = 0.020153557881712914, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020947877783328295, Lv_loss = 3.193407610524446e-05, Circular Tuning Loss = 1.2991725206375122\n",
      "3419) Lyapunov Risk = 0.9204234480857849, MSE = 0.020390456542372704, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020845365361310542, Lv_loss = 3.34860997099895e-05, Circular Tuning Loss = 1.299095630645752\n",
      "3420) Lyapunov Risk = 0.9203189015388489, MSE = 0.02012258768081665, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002074672665912658, Lv_loss = 3.504595588310622e-05, Circular Tuning Loss = 1.2990190982818604\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.7902322683924323, 1.7933681107273229]\n",
      "x2 : [0.86940831551797171, 0.8727912272515046]\n",
      "==============================\n",
      "3421) Lyapunov Risk = 0.9229707717895508, MSE = 0.020384715870022774, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020607408077921718, Lv_loss = 3.648481288109906e-05, Circular Tuning Loss = 1.3036576509475708\n",
      "3422) Lyapunov Risk = 0.9228605628013611, MSE = 0.02009754814207554, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002052550989901647, Lv_loss = 3.7945308577036485e-05, Circular Tuning Loss = 1.3035815954208374\n",
      "3423) Lyapunov Risk = 0.9227632284164429, MSE = 0.020363889634609222, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002045529254246503, Lv_loss = 3.932579420506954e-05, Circular Tuning Loss = 1.3035054206848145\n",
      "3424) Lyapunov Risk = 0.9226722717285156, MSE = 0.02009527012705803, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020393848535604775, Lv_loss = 4.065735629410483e-05, Circular Tuning Loss = 1.3034288883209229\n",
      "3425) Lyapunov Risk = 0.9225915670394897, MSE = 0.02034970372915268, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020341020717751235, Lv_loss = 4.1934945329558104e-05, Circular Tuning Loss = 1.3033521175384521\n",
      "3426) Lyapunov Risk = 0.9225088357925415, MSE = 0.020113181322813034, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020294857677072287, Lv_loss = 4.3161740904906765e-05, Circular Tuning Loss = 1.3032748699188232\n",
      "3427) Lyapunov Risk = 0.9224259257316589, MSE = 0.020335163921117783, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020254582341294736, Lv_loss = 4.4554166379384696e-05, Circular Tuning Loss = 1.3031970262527466\n",
      "3428) Lyapunov Risk = 0.9223331809043884, MSE = 0.02012322098016739, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020218704594299197, Lv_loss = 4.632182026398368e-05, Circular Tuning Loss = 1.303118109703064\n",
      "3429) Lyapunov Risk = 0.9222366809844971, MSE = 0.02031184546649456, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002018696250161156, Lv_loss = 4.827012890018523e-05, Circular Tuning Loss = 1.3030387163162231\n",
      "3430) Lyapunov Risk = 0.9221333265304565, MSE = 0.020124008879065514, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020158877305220813, Lv_loss = 4.9915390263777226e-05, Circular Tuning Loss = 1.3029581308364868\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0078125000000004, -1.0058740105776398]\n",
      "x2 : [0.49897948069611214, 0.50067093656287864]\n",
      "==============================\n",
      "3431) Lyapunov Risk = 0.9218608736991882, MSE = 0.020277613773941994, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002008801675401628, Lv_loss = 5.161201988812536e-05, Circular Tuning Loss = 1.301406979560852\n",
      "3432) Lyapunov Risk = 0.9217594265937805, MSE = 0.020148079842329025, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020064931595698, Lv_loss = 5.322571087162942e-05, Circular Tuning Loss = 1.3013242483139038\n",
      "3433) Lyapunov Risk = 0.9216633439064026, MSE = 0.020223693922162056, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002004239067900926, Lv_loss = 5.48597818124108e-05, Circular Tuning Loss = 1.30124032497406\n",
      "3434) Lyapunov Risk = 0.9215725660324097, MSE = 0.020185280591249466, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020020993542857468, Lv_loss = 5.6381035392405465e-05, Circular Tuning Loss = 1.3011549711227417\n",
      "3435) Lyapunov Risk = 0.9214864373207092, MSE = 0.020170899108052254, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020000104268547148, Lv_loss = 5.7801094953902066e-05, Circular Tuning Loss = 1.3010680675506592\n",
      "3436) Lyapunov Risk = 0.9214023947715759, MSE = 0.020219234749674797, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019979581702500582, Lv_loss = 5.926925950916484e-05, Circular Tuning Loss = 1.3009798526763916\n",
      "3437) Lyapunov Risk = 0.9213180541992188, MSE = 0.02013949304819107, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001996034407056868, Lv_loss = 6.059689985704608e-05, Circular Tuning Loss = 1.3008902072906494\n",
      "3438) Lyapunov Risk = 0.9212316274642944, MSE = 0.020240947604179382, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001994177291635424, Lv_loss = 6.20522623648867e-05, Circular Tuning Loss = 1.3007992506027222\n",
      "3439) Lyapunov Risk = 0.921142578125, MSE = 0.02012585662305355, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019924092339351773, Lv_loss = 6.331388431135565e-05, Circular Tuning Loss = 1.3007069826126099\n",
      "3440) Lyapunov Risk = 0.9210510849952698, MSE = 0.020242827013134956, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019905841327272356, Lv_loss = 6.468639185186476e-05, Circular Tuning Loss = 1.3006134033203125\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0156250000000004, -1.0136718750000004]\n",
      "x2 : [0.49897948069611214, 0.50067093656287864]\n",
      "==============================\n",
      "3441) Lyapunov Risk = 0.9207993745803833, MSE = 0.020122217014431953, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019841900211758912, Lv_loss = 6.572462734766304e-05, Circular Tuning Loss = 1.2990785837173462\n",
      "3442) Lyapunov Risk = 0.920706570148468, MSE = 0.02023700624704361, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019821473688352853, Lv_loss = 6.700400990666822e-05, Circular Tuning Loss = 1.2989822626113892\n",
      "3443) Lyapunov Risk = 0.9206144213676453, MSE = 0.02011626586318016, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019800006703007966, Lv_loss = 6.820153066655621e-05, Circular Tuning Loss = 1.2988848686218262\n",
      "3444) Lyapunov Risk = 0.9205231070518494, MSE = 0.0202201958745718, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019777033594436944, Lv_loss = 6.946108624106273e-05, Circular Tuning Loss = 1.2987860441207886\n",
      "3445) Lyapunov Risk = 0.9204328060150146, MSE = 0.020125120878219604, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019752717344090343, Lv_loss = 7.070101128192618e-05, Circular Tuning Loss = 1.2986857891082764\n",
      "3446) Lyapunov Risk = 0.9203438758850098, MSE = 0.020198898389935493, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.000197276720427908, Lv_loss = 7.189581810962409e-05, Circular Tuning Loss = 1.2985844612121582\n",
      "3447) Lyapunov Risk = 0.9202553629875183, MSE = 0.020137473940849304, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019701443670783192, Lv_loss = 7.310353248612955e-05, Circular Tuning Loss = 1.2984817028045654\n",
      "3448) Lyapunov Risk = 0.9201672673225403, MSE = 0.020176786929368973, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019674452778417617, Lv_loss = 7.422314956784248e-05, Circular Tuning Loss = 1.2983778715133667\n",
      "3449) Lyapunov Risk = 0.9200789928436279, MSE = 0.02015063539147377, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019646539294626564, Lv_loss = 7.543139508925378e-05, Circular Tuning Loss = 1.298272967338562\n",
      "3450) Lyapunov Risk = 0.9199904799461365, MSE = 0.020154966041445732, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001961763045983389, Lv_loss = 7.656333036720753e-05, Circular Tuning Loss = 1.2981667518615723\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.8012077165645495, 1.8027756377319948]\n",
      "x2 : [0.86602540378443871, 0.86771685965120526]\n",
      "==============================\n",
      "3451) Lyapunov Risk = 0.9226877689361572, MSE = 0.02016383595764637, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019543815869838, Lv_loss = 8.899870590539649e-05, Circular Tuning Loss = 1.3027892112731934\n",
      "3452) Lyapunov Risk = 0.9225992560386658, MSE = 0.020124852657318115, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019520710338838398, Lv_loss = 9.015337855089456e-05, Circular Tuning Loss = 1.3026801347732544\n",
      "3453) Lyapunov Risk = 0.922511100769043, MSE = 0.0201755128800869, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019502805662341416, Lv_loss = 9.123751078732312e-05, Circular Tuning Loss = 1.302570104598999\n",
      "3454) Lyapunov Risk = 0.9224227666854858, MSE = 0.02009534277021885, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019489481928758323, Lv_loss = 9.1994421381969e-05, Circular Tuning Loss = 1.3024587631225586\n",
      "3455) Lyapunov Risk = 0.9223341345787048, MSE = 0.02018457092344761, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019480165792629123, Lv_loss = 9.283004328608513e-05, Circular Tuning Loss = 1.3023459911346436\n",
      "3456) Lyapunov Risk = 0.9222453236579895, MSE = 0.020081743597984314, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.000194749838556163, Lv_loss = 9.342736302642152e-05, Circular Tuning Loss = 1.3022323846817017\n",
      "3457) Lyapunov Risk = 0.9221566915512085, MSE = 0.020192798227071762, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001947375712916255, Lv_loss = 9.396966197527945e-05, Circular Tuning Loss = 1.302117943763733\n",
      "3458) Lyapunov Risk = 0.9220677018165588, MSE = 0.02007780782878399, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019475910812616348, Lv_loss = 9.423653682461008e-05, Circular Tuning Loss = 1.3020025491714478\n",
      "3459) Lyapunov Risk = 0.9219789505004883, MSE = 0.020191393792629242, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001948140561580658, Lv_loss = 9.439401765121147e-05, Circular Tuning Loss = 1.301885962486267\n",
      "3460) Lyapunov Risk = 0.9218899011611938, MSE = 0.02007455565035343, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001949028082890436, Lv_loss = 9.44246567087248e-05, Circular Tuning Loss = 1.3017685413360596\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.983952205528579, 1.9852166380961931]\n",
      "x2 : [0.24272391688099015, 0.24356964481437338]\n",
      "==============================\n",
      "3461) Lyapunov Risk = 0.92448490858078, MSE = 0.020181000232696533, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019458041060715914, Lv_loss = 9.41991966101341e-05, Circular Tuning Loss = 1.3062469959259033\n",
      "3462) Lyapunov Risk = 0.9243977069854736, MSE = 0.02006579376757145, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019476431771181524, Lv_loss = 9.411165956407785e-05, Circular Tuning Loss = 1.3061267137527466\n",
      "3463) Lyapunov Risk = 0.9243108034133911, MSE = 0.02017461508512497, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019501544011291116, Lv_loss = 9.382908319821581e-05, Circular Tuning Loss = 1.3060046434402466\n",
      "3464) Lyapunov Risk = 0.9242236614227295, MSE = 0.020062683150172234, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019532829173840582, Lv_loss = 9.350937034469098e-05, Circular Tuning Loss = 1.305881142616272\n",
      "3465) Lyapunov Risk = 0.9241368174552917, MSE = 0.02016698569059372, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019569369032979012, Lv_loss = 9.292810864280909e-05, Circular Tuning Loss = 1.3057562112808228\n",
      "3466) Lyapunov Risk = 0.9240501523017883, MSE = 0.02006436511874199, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019610693561844528, Lv_loss = 9.24100968404673e-05, Circular Tuning Loss = 1.305630087852478\n",
      "3467) Lyapunov Risk = 0.9239639043807983, MSE = 0.020164448767900467, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019656216318253428, Lv_loss = 9.163226786768064e-05, Circular Tuning Loss = 1.3055027723312378\n",
      "3468) Lyapunov Risk = 0.92387855052948, MSE = 0.020064350217580795, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019705420709215105, Lv_loss = 9.103438787860796e-05, Circular Tuning Loss = 1.3053743839263916\n",
      "3469) Lyapunov Risk = 0.9237945675849915, MSE = 0.020169811323285103, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019756883557420224, Lv_loss = 9.013466478791088e-05, Circular Tuning Loss = 1.305245041847229\n",
      "3470) Lyapunov Risk = 0.9237139225006104, MSE = 0.020039647817611694, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019809685181826353, Lv_loss = 8.94898475962691e-05, Circular Tuning Loss = 1.305114507675171\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.8012077165645495, 1.8027756377319948]\n",
      "x2 : [0.86602540378443871, 0.86771685965120526]\n",
      "==============================\n",
      "3471) Lyapunov Risk = 0.9263923168182373, MSE = 0.02020668052136898, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019819082808680832, Lv_loss = 9.73345449892804e-05, Circular Tuning Loss = 1.3096613883972168\n",
      "3472) Lyapunov Risk = 0.9263231158256531, MSE = 0.019976507872343063, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019880195031873882, Lv_loss = 9.610991401132196e-05, Circular Tuning Loss = 1.309528112411499\n",
      "3473) Lyapunov Risk = 0.9262633919715881, MSE = 0.020289544016122818, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.000199484929908067, Lv_loss = 9.398795373272151e-05, Circular Tuning Loss = 1.3093942403793335\n",
      "3474) Lyapunov Risk = 0.9262187480926514, MSE = 0.0199002493172884, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002002303663175553, Lv_loss = 9.239456994691864e-05, Circular Tuning Loss = 1.3092594146728516\n",
      "3475) Lyapunov Risk = 0.9261963367462158, MSE = 0.020435279235243797, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020096871594432741, Lv_loss = 8.992127550300211e-05, Circular Tuning Loss = 1.3091237545013428\n",
      "3476) Lyapunov Risk = 0.9261944890022278, MSE = 0.01983046531677246, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020167835464235395, Lv_loss = 8.827167039271444e-05, Circular Tuning Loss = 1.3089872598648071\n",
      "3477) Lyapunov Risk = 0.9262478351593018, MSE = 0.020665958523750305, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002023484412347898, Lv_loss = 8.553348015993834e-05, Circular Tuning Loss = 1.3088499307632446\n",
      "3478) Lyapunov Risk = 0.9263197779655457, MSE = 0.019760604947805405, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020295995636843145, Lv_loss = 8.397400233661756e-05, Circular Tuning Loss = 1.3087115287780762\n",
      "3479) Lyapunov Risk = 0.9264414310455322, MSE = 0.020962929353117943, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020351177954580635, Lv_loss = 8.113676449283957e-05, Circular Tuning Loss = 1.3085724115371704\n",
      "3480) Lyapunov Risk = 0.9265206456184387, MSE = 0.019715920090675354, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020401565416250378, Lv_loss = 8.250505197793245e-05, Circular Tuning Loss = 1.3084324598312378\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.8012077165645495, 1.8027756377319948]\n",
      "x2 : [0.86602540378443871, 0.86771685965120526]\n",
      "==============================\n",
      "3481) Lyapunov Risk = 0.9292957782745361, MSE = 0.02117163874208927, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020401255460456014, Lv_loss = 8.086515299510211e-05, Circular Tuning Loss = 1.3129401206970215\n",
      "3482) Lyapunov Risk = 0.9291651844978333, MSE = 0.019684193655848503, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020451431919354945, Lv_loss = 8.44462847453542e-05, Circular Tuning Loss = 1.3127985000610352\n",
      "3483) Lyapunov Risk = 0.9289035797119141, MSE = 0.021034322679042816, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020502565894275904, Lv_loss = 7.473173172911629e-05, Circular Tuning Loss = 1.3126559257507324\n",
      "3484) Lyapunov Risk = 0.9285066723823547, MSE = 0.019680161029100418, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020550840417854488, Lv_loss = 7.194688805611804e-05, Circular Tuning Loss = 1.3125132322311401\n",
      "3485) Lyapunov Risk = 0.9281534552574158, MSE = 0.0205746628344059, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020591217617038637, Lv_loss = 6.811168714193627e-05, Circular Tuning Loss = 1.3123699426651\n",
      "3486) Lyapunov Risk = 0.9279056787490845, MSE = 0.01984439045190811, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020625043543986976, Lv_loss = 6.489890802185982e-05, Circular Tuning Loss = 1.3122258186340332\n",
      "3487) Lyapunov Risk = 0.9278163909912109, MSE = 0.020178716629743576, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002064879663521424, Lv_loss = 6.321908585960045e-05, Circular Tuning Loss = 1.31208074092865\n",
      "3488) Lyapunov Risk = 0.9278506636619568, MSE = 0.020173974335193634, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020665758347604424, Lv_loss = 6.292632315307856e-05, Circular Tuning Loss = 1.3119348287582397\n",
      "3489) Lyapunov Risk = 0.927926242351532, MSE = 0.020020272582769394, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020674828556366265, Lv_loss = 6.269849109230563e-05, Circular Tuning Loss = 1.3117882013320923\n",
      "3490) Lyapunov Risk = 0.9279574155807495, MSE = 0.020426347851753235, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020678207511082292, Lv_loss = 6.249868602026254e-05, Circular Tuning Loss = 1.3116410970687866\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0156250000000004, -1.0146484375000004]\n",
      "x2 : [0.43132124602545285, 0.43301270189221935]\n",
      "==============================\n",
      "3491) Lyapunov Risk = 0.9276790618896484, MSE = 0.01999579183757305, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020629458595067263, Lv_loss = 6.221740477485582e-05, Circular Tuning Loss = 1.3099547624588013\n",
      "3492) Lyapunov Risk = 0.9274944067001343, MSE = 0.020372023805975914, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020622173906303942, Lv_loss = 6.209532875800505e-05, Circular Tuning Loss = 1.3098067045211792\n",
      "3493) Lyapunov Risk = 0.9272481799125671, MSE = 0.020044470205903053, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002060902479570359, Lv_loss = 6.202346412464976e-05, Circular Tuning Loss = 1.3096585273742676\n",
      "3494) Lyapunov Risk = 0.9270243048667908, MSE = 0.020071372389793396, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020591822976712137, Lv_loss = 6.19689526502043e-05, Circular Tuning Loss = 1.3095099925994873\n",
      "3495) Lyapunov Risk = 0.9268791079521179, MSE = 0.02019299380481243, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020569573098327965, Lv_loss = 6.19539205217734e-05, Circular Tuning Loss = 1.3093611001968384\n",
      "3496) Lyapunov Risk = 0.9268149733543396, MSE = 0.01982622966170311, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020544743165373802, Lv_loss = 6.195493187988177e-05, Circular Tuning Loss = 1.3092120885849\n",
      "3497) Lyapunov Risk = 0.9267959594726562, MSE = 0.020387254655361176, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020516387303359807, Lv_loss = 6.198472692631185e-05, Circular Tuning Loss = 1.3090627193450928\n",
      "3498) Lyapunov Risk = 0.9267582893371582, MSE = 0.019740551710128784, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002048709720838815, Lv_loss = 6.202670192578807e-05, Circular Tuning Loss = 1.3089134693145752\n",
      "3499) Lyapunov Risk = 0.9266769886016846, MSE = 0.020436614751815796, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020454601326491684, Lv_loss = 6.209221464814618e-05, Circular Tuning Loss = 1.3087642192840576\n",
      "3500) Lyapunov Risk = 0.9265395998954773, MSE = 0.019777849316596985, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020422339730430394, Lv_loss = 6.216572364792228e-05, Circular Tuning Loss = 1.3086153268814087\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.4960937500000004, 1.4980468750000004]\n",
      "x2 : [0.45838453989371658, 0.46007599576048308]\n",
      "==============================\n",
      "3501) Lyapunov Risk = 0.9274774789810181, MSE = 0.020277973264455795, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020341627532616258, Lv_loss = 6.212404696270823e-05, Circular Tuning Loss = 1.309885025024414\n",
      "3502) Lyapunov Risk = 0.9273391962051392, MSE = 0.019891701638698578, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020315793517511338, Lv_loss = 6.215827306732535e-05, Circular Tuning Loss = 1.3097363710403442\n",
      "3503) Lyapunov Risk = 0.9272392988204956, MSE = 0.020070824772119522, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002029707538895309, Lv_loss = 6.214500172063708e-05, Circular Tuning Loss = 1.3095879554748535\n",
      "3504) Lyapunov Risk = 0.9271709322929382, MSE = 0.020030291751027107, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020285065693315119, Lv_loss = 6.208104605320841e-05, Circular Tuning Loss = 1.309439778327942\n",
      "3505) Lyapunov Risk = 0.9271155595779419, MSE = 0.019941166043281555, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020278595911804587, Lv_loss = 6.19808561168611e-05, Circular Tuning Loss = 1.3092917203903198\n",
      "3506) Lyapunov Risk = 0.9270505309104919, MSE = 0.020114833489060402, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020276794384699315, Lv_loss = 6.184269295772538e-05, Circular Tuning Loss = 1.3091440200805664\n",
      "3507) Lyapunov Risk = 0.926965594291687, MSE = 0.019927071407437325, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002027972077485174, Lv_loss = 6.167725950945169e-05, Circular Tuning Loss = 1.3089966773986816\n",
      "3508) Lyapunov Risk = 0.9268633723258972, MSE = 0.020081110298633575, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002028665621764958, Lv_loss = 6.148194370325655e-05, Circular Tuning Loss = 1.308849573135376\n",
      "3509) Lyapunov Risk = 0.9267560839653015, MSE = 0.019993707537651062, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020296717411838472, Lv_loss = 6.1269078287296e-05, Circular Tuning Loss = 1.308702826499939\n",
      "3510) Lyapunov Risk = 0.9266579747200012, MSE = 0.019962448626756668, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002031060284934938, Lv_loss = 6.102907718741335e-05, Circular Tuning Loss = 1.3085564374923706\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.90136718750000022, -0.90039062500000022]\n",
      "x2 : [0.64063049604605515, 0.64257812500000022]\n",
      "==============================\n",
      "3511) Lyapunov Risk = 0.9263710379600525, MSE = 0.020098766312003136, V_0_loss = tensor([[0.0070]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020281746401451528, Lv_loss = 6.064193803467788e-05, Circular Tuning Loss = 1.3069181442260742\n",
      "3512) Lyapunov Risk = 0.9262963533401489, MSE = 0.01986647956073284, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020301027689129114, Lv_loss = 6.036720878910273e-05, Circular Tuning Loss = 1.3067723512649536\n",
      "3513) Lyapunov Risk = 0.926231324672699, MSE = 0.020181847736239433, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020322503405623138, Lv_loss = 6.008659693179652e-05, Circular Tuning Loss = 1.306626796722412\n",
      "3514) Lyapunov Risk = 0.926161527633667, MSE = 0.019802788272500038, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002034741046372801, Lv_loss = 5.9789901570184156e-05, Circular Tuning Loss = 1.306481957435608\n",
      "3515) Lyapunov Risk = 0.9260903596878052, MSE = 0.020223427563905716, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020373123697936535, Lv_loss = 5.949564729235135e-05, Circular Tuning Loss = 1.3063368797302246\n",
      "3516) Lyapunov Risk = 0.9260125160217285, MSE = 0.01978791132569313, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020395791216287762, Lv_loss = 5.9216094086878e-05, Circular Tuning Loss = 1.3061920404434204\n",
      "3517) Lyapunov Risk = 0.9259406328201294, MSE = 0.020225765183568, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002041104162344709, Lv_loss = 5.897947630728595e-05, Circular Tuning Loss = 1.306046962738037\n",
      "3518) Lyapunov Risk = 0.9258705377578735, MSE = 0.019808776676654816, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002041807456407696, Lv_loss = 5.878473893972114e-05, Circular Tuning Loss = 1.3059015274047852\n",
      "3519) Lyapunov Risk = 0.9258165955543518, MSE = 0.020218802616000175, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002041400148300454, Lv_loss = 5.865635830559768e-05, Circular Tuning Loss = 1.3057554960250854\n",
      "3520) Lyapunov Risk = 0.9257725477218628, MSE = 0.01983974687755108, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020402442896738648, Lv_loss = 5.856602729181759e-05, Circular Tuning Loss = 1.3056093454360962\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.7500000000000004, 1.7574452098460429]\n",
      "x2 : [0.42624687842515341, 0.43301270189221935]\n",
      "==============================\n",
      "3521) Lyapunov Risk = 0.9277023077011108, MSE = 0.020248299464583397, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020336506713647395, Lv_loss = 0.00011635757982730865, Circular Tuning Loss = 1.3084542751312256\n",
      "3522) Lyapunov Risk = 0.9276899099349976, MSE = 0.019841456785798073, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020313853747211397, Lv_loss = 0.0001162484913947992, Circular Tuning Loss = 1.3083065748214722\n",
      "3523) Lyapunov Risk = 0.9276952743530273, MSE = 0.020338207483291626, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002028576418524608, Lv_loss = 0.00011615589028224349, Circular Tuning Loss = 1.3081578016281128\n",
      "3524) Lyapunov Risk = 0.9277045726776123, MSE = 0.019819196313619614, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020257409778423607, Lv_loss = 0.00011600227298913524, Circular Tuning Loss = 1.3080085515975952\n",
      "3525) Lyapunov Risk = 0.9277245402336121, MSE = 0.020479079335927963, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020224075706209987, Lv_loss = 0.00011588921915972605, Circular Tuning Loss = 1.3078585863113403\n",
      "3526) Lyapunov Risk = 0.9277313947677612, MSE = 0.019793199375271797, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020190325449220836, Lv_loss = 0.00011572492076084018, Circular Tuning Loss = 1.3077083826065063\n",
      "3527) Lyapunov Risk = 0.9277305006980896, MSE = 0.02062438242137432, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020152753859292716, Lv_loss = 0.0001156094585894607, Circular Tuning Loss = 1.3075577020645142\n",
      "3528) Lyapunov Risk = 0.9277083873748779, MSE = 0.01975088380277157, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020115214283578098, Lv_loss = 0.00011543693108251318, Circular Tuning Loss = 1.307407021522522\n",
      "3529) Lyapunov Risk = 0.9276702404022217, MSE = 0.020744413137435913, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020074014901183546, Lv_loss = 0.00011532142525538802, Circular Tuning Loss = 1.3072562217712402\n",
      "3530) Lyapunov Risk = 0.9277236461639404, MSE = 0.019654078409075737, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020026773563586175, Lv_loss = 0.00011517033271957189, Circular Tuning Loss = 1.3071047067642212\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.7500000000000004, 1.7574452098460429]\n",
      "x2 : [0.42624687842515341, 0.43301270189221935]\n",
      "==============================\n",
      "3531) Lyapunov Risk = 0.9296643137931824, MSE = 0.020966891199350357, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001993180048884824, Lv_loss = 0.00017158358241431415, Circular Tuning Loss = 1.309924840927124\n",
      "3532) Lyapunov Risk = 0.929719090461731, MSE = 0.019553273916244507, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019883560889866203, Lv_loss = 0.00017389476124662906, Circular Tuning Loss = 1.309771180152893\n",
      "3533) Lyapunov Risk = 0.9296506643295288, MSE = 0.021135561168193817, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001983738475246355, Lv_loss = 0.00017078127712011337, Circular Tuning Loss = 1.309617042541504\n",
      "3534) Lyapunov Risk = 0.9295839667320251, MSE = 0.01949033886194229, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001979270891752094, Lv_loss = 0.00017815124010667205, Circular Tuning Loss = 1.309462070465088\n",
      "3535) Lyapunov Risk = 0.9293405413627625, MSE = 0.021077316254377365, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019750774663407356, Lv_loss = 0.00016936234897002578, Circular Tuning Loss = 1.3093068599700928\n",
      "3536) Lyapunov Risk = 0.9290860891342163, MSE = 0.019480513408780098, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019709652406163514, Lv_loss = 0.00017250582459382713, Circular Tuning Loss = 1.30915105342865\n",
      "3537) Lyapunov Risk = 0.9286952018737793, MSE = 0.02072134055197239, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001967060670722276, Lv_loss = 0.00016746848996262997, Circular Tuning Loss = 1.308995246887207\n",
      "3538) Lyapunov Risk = 0.9283593893051147, MSE = 0.019584255293011665, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019633426563814282, Lv_loss = 0.00016636267537251115, Circular Tuning Loss = 1.3088394403457642\n",
      "3539) Lyapunov Risk = 0.928067684173584, MSE = 0.020208066329360008, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001959910587174818, Lv_loss = 0.00016521157522220165, Circular Tuning Loss = 1.3086833953857422\n",
      "3540) Lyapunov Risk = 0.9278944730758667, MSE = 0.019893765449523926, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019570128642953932, Lv_loss = 0.00016392290126532316, Circular Tuning Loss = 1.308527946472168\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0039062500000004, -1.0029296875000004]\n",
      "x2 : [0.46515036336078253, 0.46684181922754897]\n",
      "==============================\n",
      "3541) Lyapunov Risk = 0.9276686906814575, MSE = 0.019753918051719666, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019501270435284823, Lv_loss = 0.00016217646771110594, Circular Tuning Loss = 1.3068609237670898\n",
      "3542) Lyapunov Risk = 0.9277382493019104, MSE = 0.020347343757748604, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019476638408377767, Lv_loss = 0.00016075359599199146, Circular Tuning Loss = 1.3067063093185425\n",
      "3543) Lyapunov Risk = 0.9277834892272949, MSE = 0.019566735252738, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019456278823781759, Lv_loss = 0.00015924220497254282, Circular Tuning Loss = 1.3065520524978638\n",
      "3544) Lyapunov Risk = 0.9277544617652893, MSE = 0.020541680976748466, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019437195442151278, Lv_loss = 0.00015777112275827676, Circular Tuning Loss = 1.3063982725143433\n",
      "3545) Lyapunov Risk = 0.927655041217804, MSE = 0.01956123299896717, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001942059607245028, Lv_loss = 0.00015631751739419997, Circular Tuning Loss = 1.3062450885772705\n",
      "3546) Lyapunov Risk = 0.9274792075157166, MSE = 0.020419251173734665, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001940487854881212, Lv_loss = 0.00015472587256226689, Circular Tuning Loss = 1.306092381477356\n",
      "3547) Lyapunov Risk = 0.9272624254226685, MSE = 0.0196842048317194, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001939291541930288, Lv_loss = 0.0001531593588879332, Circular Tuning Loss = 1.3059403896331787\n",
      "3548) Lyapunov Risk = 0.9270888566970825, MSE = 0.020044898614287376, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019378153956495225, Lv_loss = 0.00015166672528721392, Circular Tuning Loss = 1.3057886362075806\n",
      "3549) Lyapunov Risk = 0.9269886612892151, MSE = 0.019947942346334457, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019361628801561892, Lv_loss = 0.000150213876622729, Circular Tuning Loss = 1.3056374788284302\n",
      "3550) Lyapunov Risk = 0.9269530177116394, MSE = 0.019742902368307114, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001934250321937725, Lv_loss = 0.00014882697723805904, Circular Tuning Loss = 1.3054864406585693\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.4980468750000004, 1.5000000000000004]\n",
      "x2 : [0.48544783376198031, 0.48713928962874675]\n",
      "==============================\n",
      "3551) Lyapunov Risk = 0.9280269145965576, MSE = 0.02020425722002983, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001927595876622945, Lv_loss = 0.00014724086213391274, Circular Tuning Loss = 1.306764006614685\n",
      "3552) Lyapunov Risk = 0.9279798269271851, MSE = 0.01964353583753109, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019258559041190892, Lv_loss = 0.0001458519691368565, Circular Tuning Loss = 1.3066127300262451\n",
      "3553) Lyapunov Risk = 0.9278961420059204, MSE = 0.0202406607568264, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019244285067543387, Lv_loss = 0.00014441183884628117, Circular Tuning Loss = 1.3064618110656738\n",
      "3554) Lyapunov Risk = 0.9277760982513428, MSE = 0.019690250977873802, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019234874343965203, Lv_loss = 0.00014286364603322, Circular Tuning Loss = 1.3063113689422607\n",
      "3555) Lyapunov Risk = 0.9276552200317383, MSE = 0.020077481865882874, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019227122538723052, Lv_loss = 0.00014128632028587162, Circular Tuning Loss = 1.3061609268188477\n",
      "3556) Lyapunov Risk = 0.9275444149971008, MSE = 0.01983092725276947, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019221693219151348, Lv_loss = 0.00013965765538159758, Circular Tuning Loss = 1.3060109615325928\n",
      "3557) Lyapunov Risk = 0.9274600744247437, MSE = 0.019863156601786613, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019213712948840111, Lv_loss = 0.0001380819594487548, Circular Tuning Loss = 1.305861234664917\n",
      "3558) Lyapunov Risk = 0.9273975491523743, MSE = 0.020010538399219513, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019203979172743857, Lv_loss = 0.00013655210204888135, Circular Tuning Loss = 1.3057116270065308\n",
      "3559) Lyapunov Risk = 0.9273394346237183, MSE = 0.0197340939193964, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019193612388335168, Lv_loss = 0.0001350468082819134, Circular Tuning Loss = 1.3055622577667236\n",
      "3560) Lyapunov Risk = 0.9272693991661072, MSE = 0.02008613385260105, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019180466188117862, Lv_loss = 0.00013359691365621984, Circular Tuning Loss = 1.3054126501083374\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0078125000000004, -1.0068359375000004]\n",
      "x2 : [0.45838453989371658, 0.46007599576048308]\n",
      "==============================\n",
      "3561) Lyapunov Risk = 0.9269914031028748, MSE = 0.019728748127818108, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.000191258528502658, Lv_loss = 0.00013185400166548789, Circular Tuning Loss = 1.3037643432617188\n",
      "3562) Lyapunov Risk = 0.9268980622291565, MSE = 0.02002486027777195, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019110464199911803, Lv_loss = 0.00013045142986811697, Circular Tuning Loss = 1.303615689277649\n",
      "3563) Lyapunov Risk = 0.9268057346343994, MSE = 0.01981498673558235, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001909516577143222, Lv_loss = 0.00012906033953186125, Circular Tuning Loss = 1.3034671545028687\n",
      "3564) Lyapunov Risk = 0.9267228841781616, MSE = 0.019895557314157486, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019078158948104829, Lv_loss = 0.00012772894115187228, Circular Tuning Loss = 1.303318977355957\n",
      "3565) Lyapunov Risk = 0.9266500473022461, MSE = 0.019935082644224167, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019060607883147895, Lv_loss = 0.00012644393427763134, Circular Tuning Loss = 1.3031712770462036\n",
      "3566) Lyapunov Risk = 0.926581859588623, MSE = 0.019793443381786346, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019042482017539442, Lv_loss = 0.0001251846260856837, Circular Tuning Loss = 1.3030238151550293\n",
      "3567) Lyapunov Risk = 0.926511287689209, MSE = 0.020001111552119255, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019023034838028252, Lv_loss = 0.00012395922385621816, Circular Tuning Loss = 1.3028764724731445\n",
      "3568) Lyapunov Risk = 0.9264341592788696, MSE = 0.019760562106966972, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019004040223080665, Lv_loss = 0.00012272903404664248, Circular Tuning Loss = 1.3027297258377075\n",
      "3569) Lyapunov Risk = 0.9263515472412109, MSE = 0.01997869648039341, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001898357004392892, Lv_loss = 0.00012153560237493366, Circular Tuning Loss = 1.30258309841156\n",
      "3570) Lyapunov Risk = 0.9262676239013672, MSE = 0.019800299778580666, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00018963409820571542, Lv_loss = 0.00012036071711918339, Circular Tuning Loss = 1.30243718624115\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.84472656250000022, -0.84375000000000022]\n",
      "x2 : [0.75000000000000022, 0.75195312500000022]\n",
      "==============================\n",
      "3571) Lyapunov Risk = 0.9260129928588867, MSE = 0.019903788343071938, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00018901262956205755, Lv_loss = 0.00011897235526703298, Circular Tuning Loss = 1.3009108304977417\n",
      "3572) Lyapunov Risk = 0.9259378910064697, MSE = 0.01988617330789566, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00018880958668887615, Lv_loss = 0.00011786361574195325, Circular Tuning Loss = 1.3007657527923584\n",
      "3573) Lyapunov Risk = 0.9258675575256348, MSE = 0.019815951585769653, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001886072423076257, Lv_loss = 0.0001167747686849907, Circular Tuning Loss = 1.3006213903427124\n",
      "3574) Lyapunov Risk = 0.9257978796958923, MSE = 0.019947469234466553, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00018840271513909101, Lv_loss = 0.00011570612696232274, Circular Tuning Loss = 1.3004772663116455\n",
      "3575) Lyapunov Risk = 0.9257254600524902, MSE = 0.019771991297602654, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00018820456170942634, Lv_loss = 0.00011464337876532227, Circular Tuning Loss = 1.3003336191177368\n",
      "3576) Lyapunov Risk = 0.9256489872932434, MSE = 0.01995541714131832, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00018799968529492617, Lv_loss = 0.00011361755605321378, Circular Tuning Loss = 1.3001905679702759\n",
      "3577) Lyapunov Risk = 0.9255689382553101, MSE = 0.01978425681591034, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00018780262325890362, Lv_loss = 0.00011259818711550906, Circular Tuning Loss = 1.3000478744506836\n",
      "3578) Lyapunov Risk = 0.9254888296127319, MSE = 0.019914191216230392, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001875890593510121, Lv_loss = 0.00011164144234498963, Circular Tuning Loss = 1.29990553855896\n",
      "3579) Lyapunov Risk = 0.9254105687141418, MSE = 0.019829947501420975, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001873375877039507, Lv_loss = 0.0001107980206143111, Circular Tuning Loss = 1.299763560295105\n",
      "3580) Lyapunov Risk = 0.9253354668617249, MSE = 0.019850192591547966, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00018700079817790538, Lv_loss = 0.00011017209180863574, Circular Tuning Loss = 1.2996217012405396\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.84472656250000022, -0.84375000000000022]\n",
      "x2 : [0.75000000000000022, 0.75195312500000022]\n",
      "==============================\n",
      "3581) Lyapunov Risk = 0.9250926375389099, MSE = 0.019878093153238297, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001861608325270936, Lv_loss = 0.00010955277684843168, Circular Tuning Loss = 1.2981079816818237\n",
      "3582) Lyapunov Risk = 0.9250205159187317, MSE = 0.019810736179351807, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00018563361663836986, Lv_loss = 0.00010940846550511196, Circular Tuning Loss = 1.297966718673706\n",
      "3583) Lyapunov Risk = 0.9249476790428162, MSE = 0.0198921300470829, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00018501606245990843, Lv_loss = 0.00010949827992590144, Circular Tuning Loss = 1.2978253364562988\n",
      "3584) Lyapunov Risk = 0.9248740673065186, MSE = 0.019796963781118393, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00018432213983032852, Lv_loss = 0.00010979393846355379, Circular Tuning Loss = 1.2976841926574707\n",
      "3585) Lyapunov Risk = 0.9247992038726807, MSE = 0.01988166570663452, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00018355820793658495, Lv_loss = 0.00011028740846086293, Circular Tuning Loss = 1.2975428104400635\n",
      "3586) Lyapunov Risk = 0.9247242212295532, MSE = 0.019807903096079826, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00018274267495144159, Lv_loss = 0.00011093481589341536, Circular Tuning Loss = 1.2974021434783936\n",
      "3587) Lyapunov Risk = 0.9246492981910706, MSE = 0.01985548622906208, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00018187446403317153, Lv_loss = 0.00011172554513905197, Circular Tuning Loss = 1.2972614765167236\n",
      "3588) Lyapunov Risk = 0.9245750904083252, MSE = 0.01983051747083664, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001809776877053082, Lv_loss = 0.00011260025348747149, Circular Tuning Loss = 1.2971209287643433\n",
      "3589) Lyapunov Risk = 0.924501359462738, MSE = 0.01983235962688923, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00018005484889727086, Lv_loss = 0.00011355869355611503, Circular Tuning Loss = 1.2969805002212524\n",
      "3590) Lyapunov Risk = 0.9244282245635986, MSE = 0.019847480580210686, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00017912560724653304, Lv_loss = 0.00011455638741608709, Circular Tuning Loss = 1.2968404293060303\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.84472656250000022, -0.84375000000000022]\n",
      "x2 : [0.75000000000000022, 0.75195312500000022]\n",
      "==============================\n",
      "3591) Lyapunov Risk = 0.9241882562637329, MSE = 0.019813746213912964, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00017780532652977854, Lv_loss = 0.00011534398072399199, Circular Tuning Loss = 1.2953368425369263\n",
      "3592) Lyapunov Risk = 0.9241161942481995, MSE = 0.019862186163663864, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00017689226660877466, Lv_loss = 0.00011635971895884722, Circular Tuning Loss = 1.2951972484588623\n",
      "3593) Lyapunov Risk = 0.9240442514419556, MSE = 0.019788434728980064, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00017603157903067768, Lv_loss = 0.00011731491395039484, Circular Tuning Loss = 1.295058012008667\n",
      "3594) Lyapunov Risk = 0.9239717721939087, MSE = 0.01985926181077957, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00017522020789328963, Lv_loss = 0.00011822332453448325, Circular Tuning Loss = 1.2949188947677612\n",
      "3595) Lyapunov Risk = 0.9238992929458618, MSE = 0.0197836235165596, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001744795881677419, Lv_loss = 0.00011902372352778912, Circular Tuning Loss = 1.2947808504104614\n",
      "3596) Lyapunov Risk = 0.9238265156745911, MSE = 0.019853997975587845, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001738332211971283, Lv_loss = 0.00011967914178967476, Circular Tuning Loss = 1.2946434020996094\n",
      "3597) Lyapunov Risk = 0.9237536787986755, MSE = 0.019795557484030724, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001732732926029712, Lv_loss = 0.00012018973211525008, Circular Tuning Loss = 1.2945072650909424\n",
      "3598) Lyapunov Risk = 0.9236807823181152, MSE = 0.019843028858304024, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00017278498853556812, Lv_loss = 0.00012057563435519114, Circular Tuning Loss = 1.2943722009658813\n",
      "3599) Lyapunov Risk = 0.9236083030700684, MSE = 0.0198048148304224, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00017235823906958103, Lv_loss = 0.0001208763278555125, Circular Tuning Loss = 1.2942383289337158\n",
      "3600) Lyapunov Risk = 0.9235358238220215, MSE = 0.01982814073562622, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001719740394037217, Lv_loss = 0.00012115603021811694, Circular Tuning Loss = 1.2941056489944458\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.81250000000000022, -0.81152343750000022]\n",
      "x2 : [0.7617328922093628, 0.76367187500000022]\n",
      "==============================\n",
      "3601) Lyapunov Risk = 0.9232759475708008, MSE = 0.01980605721473694, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00017125639715231955, Lv_loss = 0.00012114257697248831, Circular Tuning Loss = 1.2925773859024048\n",
      "3602) Lyapunov Risk = 0.9232040643692017, MSE = 0.019824227318167686, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00017095412476919591, Lv_loss = 0.00012136036093579605, Circular Tuning Loss = 1.292447566986084\n",
      "3603) Lyapunov Risk = 0.9231324195861816, MSE = 0.019792595878243446, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00017066614236682653, Lv_loss = 0.00012159754987806082, Circular Tuning Loss = 1.2923188209533691\n",
      "3604) Lyapunov Risk = 0.9230607748031616, MSE = 0.019818967208266258, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001703732123132795, Lv_loss = 0.00012192015128675848, Circular Tuning Loss = 1.2921911478042603\n",
      "3605) Lyapunov Risk = 0.9229891896247864, MSE = 0.019783655181527138, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001700743450783193, Lv_loss = 0.0001223146973643452, Circular Tuning Loss = 1.2920641899108887\n",
      "3606) Lyapunov Risk = 0.9229177832603455, MSE = 0.019817743450403214, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016977210179902613, Lv_loss = 0.00012277041969355196, Circular Tuning Loss = 1.2919385433197021\n",
      "3607) Lyapunov Risk = 0.922846257686615, MSE = 0.019786130636930466, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016947129915934056, Lv_loss = 0.00012326780415605754, Circular Tuning Loss = 1.2918132543563843\n",
      "3608) Lyapunov Risk = 0.9227747321128845, MSE = 0.01981986127793789, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016917206812649965, Lv_loss = 0.00012380574480630457, Circular Tuning Loss = 1.2916890382766724\n",
      "3609) Lyapunov Risk = 0.9227033853530884, MSE = 0.019787775352597237, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016887596575543284, Lv_loss = 0.00012437961413525045, Circular Tuning Loss = 1.2915655374526978\n",
      "3610) Lyapunov Risk = 0.9226321578025818, MSE = 0.019814597442746162, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016858457820490003, Lv_loss = 0.0001249955384992063, Circular Tuning Loss = 1.29144287109375\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.81250000000000022, -0.81152343750000022]\n",
      "x2 : [0.75976562500000022, 0.76171875000000022]\n",
      "==============================\n",
      "3611) Lyapunov Risk = 0.9223747849464417, MSE = 0.019781986251473427, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016793484974186867, Lv_loss = 0.00012536486610770226, Circular Tuning Loss = 1.2899285554885864\n",
      "3612) Lyapunov Risk = 0.9223040342330933, MSE = 0.01981603167951107, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001676562096690759, Lv_loss = 0.0001260265416931361, Circular Tuning Loss = 1.2898074388504028\n",
      "3613) Lyapunov Risk = 0.922234058380127, MSE = 0.01975894905626774, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016738205158617347, Lv_loss = 0.00012669904390349984, Circular Tuning Loss = 1.2896872758865356\n",
      "3614) Lyapunov Risk = 0.9221649169921875, MSE = 0.019830983132123947, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001671172067290172, Lv_loss = 0.00012739452358800918, Circular Tuning Loss = 1.2895679473876953\n",
      "3615) Lyapunov Risk = 0.9221019744873047, MSE = 0.019708862528204918, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016685432638041675, Lv_loss = 0.000128111380035989, Circular Tuning Loss = 1.2894489765167236\n",
      "3616) Lyapunov Risk = 0.9220492839813232, MSE = 0.019918978214263916, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001666036550886929, Lv_loss = 0.0001288577914237976, Circular Tuning Loss = 1.2893309593200684\n",
      "3617) Lyapunov Risk = 0.9220393300056458, MSE = 0.019581258296966553, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016633409541100264, Lv_loss = 0.00012962447362951934, Circular Tuning Loss = 1.2892131805419922\n",
      "3618) Lyapunov Risk = 0.9220808744430542, MSE = 0.020184636116027832, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001660733250901103, Lv_loss = 0.00013044188381172717, Circular Tuning Loss = 1.2890961170196533\n",
      "3619) Lyapunov Risk = 0.9222487807273865, MSE = 0.019406339153647423, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.000165791847393848, Lv_loss = 0.00013124982069712132, Circular Tuning Loss = 1.288979172706604\n",
      "3620) Lyapunov Risk = 0.9225729703903198, MSE = 0.02074909582734108, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016553167370148003, Lv_loss = 0.00013210054021328688, Circular Tuning Loss = 1.2888624668121338\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.1875000000000004, -1.1855468750000004]\n",
      "x2 : [0.025371838001497227, 0.02706329386826371]\n",
      "==============================\n",
      "3621) Lyapunov Risk = 0.9230677485466003, MSE = 0.019305521622300148, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016491091810166836, Lv_loss = 0.0001533066388219595, Circular Tuning Loss = 1.2875518798828125\n",
      "3622) Lyapunov Risk = 0.9238234758377075, MSE = 0.021695146337151527, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016467789828311652, Lv_loss = 0.00013340250006876886, Circular Tuning Loss = 1.28743577003479\n",
      "3623) Lyapunov Risk = 0.9245914816856384, MSE = 0.019404293969273567, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016446506197098643, Lv_loss = 0.0002238205197500065, Circular Tuning Loss = 1.2873202562332153\n",
      "3624) Lyapunov Risk = 0.9250997304916382, MSE = 0.02250550501048565, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.000164259850862436, Lv_loss = 0.00013484506052918732, Circular Tuning Loss = 1.2872041463851929\n",
      "3625) Lyapunov Risk = 0.9250568747520447, MSE = 0.019463755190372467, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001640579430386424, Lv_loss = 0.00025493366410955787, Circular Tuning Loss = 1.2870887517929077\n",
      "3626) Lyapunov Risk = 0.9241282939910889, MSE = 0.02205762267112732, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016385548224207014, Lv_loss = 0.00013628011220134795, Circular Tuning Loss = 1.286972165107727\n",
      "3627) Lyapunov Risk = 0.9227439165115356, MSE = 0.01928681507706642, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001636524684727192, Lv_loss = 0.00016262011195067316, Circular Tuning Loss = 1.2868558168411255\n",
      "3628) Lyapunov Risk = 0.9215635061264038, MSE = 0.020426297560334206, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016346550546586514, Lv_loss = 0.000137653827550821, Circular Tuning Loss = 1.2867393493652344\n",
      "3629) Lyapunov Risk = 0.9210875630378723, MSE = 0.019750945270061493, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016328437777701765, Lv_loss = 0.00013825483620166779, Circular Tuning Loss = 1.286622166633606\n",
      "3630) Lyapunov Risk = 0.9212661981582642, MSE = 0.019477177411317825, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016314109961967915, Lv_loss = 0.00013879944162908942, Circular Tuning Loss = 1.2865052223205566\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.4980468750000004, 1.5000000000000004]\n",
      "x2 : [0.48883074549551325, 0.49052220136227975]\n",
      "==============================\n",
      "3631) Lyapunov Risk = 0.9228067398071289, MSE = 0.020724140107631683, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016266298189293593, Lv_loss = 0.0001390415127389133, Circular Tuning Loss = 1.2877811193466187\n",
      "3632) Lyapunov Risk = 0.9231633543968201, MSE = 0.01930101215839386, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016259370022453368, Lv_loss = 0.00015432726650033146, Circular Tuning Loss = 1.2876635789871216\n",
      "3633) Lyapunov Risk = 0.9231182336807251, MSE = 0.021060297265648842, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016257692186627537, Lv_loss = 0.0001393976854160428, Circular Tuning Loss = 1.2875454425811768\n",
      "3634) Lyapunov Risk = 0.9226229786872864, MSE = 0.01932510919868946, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001626082230359316, Lv_loss = 0.0001428050163667649, Circular Tuning Loss = 1.2874274253845215\n",
      "3635) Lyapunov Risk = 0.9220397472381592, MSE = 0.020311249420046806, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016267184400931, Lv_loss = 0.00013911834685131907, Circular Tuning Loss = 1.2873088121414185\n",
      "3636) Lyapunov Risk = 0.921687126159668, MSE = 0.019663454964756966, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001627549499971792, Lv_loss = 0.00013879951438866556, Circular Tuning Loss = 1.2871893644332886\n",
      "3637) Lyapunov Risk = 0.9216375946998596, MSE = 0.019631966948509216, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001628788304515183, Lv_loss = 0.00013838769518770278, Circular Tuning Loss = 1.2870702743530273\n",
      "3638) Lyapunov Risk = 0.9218038320541382, MSE = 0.020264536142349243, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.000163041302585043, Lv_loss = 0.00013787818897981197, Circular Tuning Loss = 1.2869513034820557\n",
      "3639) Lyapunov Risk = 0.9220005869865417, MSE = 0.01936463825404644, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016320639406330884, Lv_loss = 0.00013745126489084214, Circular Tuning Loss = 1.2868316173553467\n",
      "3640) Lyapunov Risk = 0.9220431447029114, MSE = 0.020609812811017036, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001633873034734279, Lv_loss = 0.00013657206727657467, Circular Tuning Loss = 1.2867119312286377\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0068359375000004, -1.0058618511856541]\n",
      "x2 : [0.45838453989371658, 0.46007599576048308]\n",
      "==============================\n",
      "3641) Lyapunov Risk = 0.9216592311859131, MSE = 0.019371196627616882, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016321301518473774, Lv_loss = 0.00013553811004385352, Circular Tuning Loss = 1.2851470708847046\n",
      "3642) Lyapunov Risk = 0.921347439289093, MSE = 0.020272739231586456, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001634043437661603, Lv_loss = 0.0001348403748124838, Circular Tuning Loss = 1.285027265548706\n",
      "3643) Lyapunov Risk = 0.9210729598999023, MSE = 0.019593991339206696, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016357821004930884, Lv_loss = 0.00013410061364993453, Circular Tuning Loss = 1.2849066257476807\n",
      "3644) Lyapunov Risk = 0.9209352135658264, MSE = 0.019795162603259087, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016377971041947603, Lv_loss = 0.00013334426330402493, Circular Tuning Loss = 1.2847867012023926\n",
      "3645) Lyapunov Risk = 0.920894205570221, MSE = 0.01991119794547558, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016394864360336214, Lv_loss = 0.00013260699051897973, Circular Tuning Loss = 1.2846660614013672\n",
      "3646) Lyapunov Risk = 0.9209089279174805, MSE = 0.019543133676052094, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001640869304537773, Lv_loss = 0.00013188474986236542, Circular Tuning Loss = 1.2845450639724731\n",
      "3647) Lyapunov Risk = 0.9209430813789368, MSE = 0.020192258059978485, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001642319984966889, Lv_loss = 0.00013120213407091796, Circular Tuning Loss = 1.2844245433807373\n",
      "3648) Lyapunov Risk = 0.9209216833114624, MSE = 0.01944579742848873, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016434415010735393, Lv_loss = 0.0001305342448176816, Circular Tuning Loss = 1.2843035459518433\n",
      "3649) Lyapunov Risk = 0.9208283424377441, MSE = 0.02021106518805027, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016445777146145701, Lv_loss = 0.00012992708070669323, Circular Tuning Loss = 1.2841830253601074\n",
      "3650) Lyapunov Risk = 0.9206744432449341, MSE = 0.01951133832335472, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016453521675430238, Lv_loss = 0.00012932647950947285, Circular Tuning Loss = 1.2840619087219238\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.978030326583212, 1.9794831127871608]\n",
      "x2 : [0.25625556381512204, 0.25710129174850527]\n",
      "==============================\n",
      "3651) Lyapunov Risk = 0.9230086207389832, MSE = 0.019987717270851135, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016426527872681618, Lv_loss = 0.00012847954349126667, Circular Tuning Loss = 1.288165807723999\n",
      "3652) Lyapunov Risk = 0.9228854775428772, MSE = 0.01965511217713356, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001643319264985621, Lv_loss = 0.00012773253547493368, Circular Tuning Loss = 1.2880429029464722\n",
      "3653) Lyapunov Risk = 0.9228001236915588, MSE = 0.019794819876551628, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016441851039417088, Lv_loss = 0.00012683575914707035, Circular Tuning Loss = 1.287919282913208\n",
      "3654) Lyapunov Risk = 0.9227277636528015, MSE = 0.019768398255109787, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016448904352728277, Lv_loss = 0.00012582600174937397, Circular Tuning Loss = 1.287794589996338\n",
      "3655) Lyapunov Risk = 0.9226669073104858, MSE = 0.01967317797243595, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016453467833343893, Lv_loss = 0.0001247530453838408, Circular Tuning Loss = 1.2876683473587036\n",
      "3656) Lyapunov Risk = 0.922614336013794, MSE = 0.019877318292856216, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001645718002691865, Lv_loss = 0.00012362710549496114, Circular Tuning Loss = 1.2875412702560425\n",
      "3657) Lyapunov Risk = 0.9225629568099976, MSE = 0.01959790661931038, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016458284517284483, Lv_loss = 0.00012244266690686345, Circular Tuning Loss = 1.2874130010604858\n",
      "3658) Lyapunov Risk = 0.9225345253944397, MSE = 0.019988616928458214, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016461593622807413, Lv_loss = 0.00012119060556869954, Circular Tuning Loss = 1.2872847318649292\n",
      "3659) Lyapunov Risk = 0.9224848747253418, MSE = 0.019536253064870834, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016462928033433855, Lv_loss = 0.00011985074525000528, Circular Tuning Loss = 1.2871557474136353\n",
      "3660) Lyapunov Risk = 0.9224417209625244, MSE = 0.020054373890161514, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001646552118472755, Lv_loss = 0.00011847239511553198, Circular Tuning Loss = 1.2870266437530518\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.81250000000000022, -0.81152343750000022]\n",
      "x2 : [0.81054687500000022, 0.81250000000000022]\n",
      "==============================\n",
      "3661) Lyapunov Risk = 0.9222190976142883, MSE = 0.019531922414898872, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001643050491111353, Lv_loss = 0.00011679210001602769, Circular Tuning Loss = 1.285630464553833\n",
      "3662) Lyapunov Risk = 0.922146201133728, MSE = 0.020032702013850212, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016432291886303574, Lv_loss = 0.00011535124940564856, Circular Tuning Loss = 1.2855008840560913\n",
      "3663) Lyapunov Risk = 0.9220414161682129, MSE = 0.019559934735298157, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016431565745733678, Lv_loss = 0.00011389352584956214, Circular Tuning Loss = 1.2853710651397705\n",
      "3664) Lyapunov Risk = 0.921959638595581, MSE = 0.0199434794485569, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016432604752480984, Lv_loss = 0.00011242747859796509, Circular Tuning Loss = 1.2852413654327393\n",
      "3665) Lyapunov Risk = 0.921862781047821, MSE = 0.019602112472057343, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016430825053248554, Lv_loss = 0.00011095423542428762, Circular Tuning Loss = 1.2851110696792603\n",
      "3666) Lyapunov Risk = 0.9217731952667236, MSE = 0.019819587469100952, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016427485388703644, Lv_loss = 0.00010948713315883651, Circular Tuning Loss = 1.2849804162979126\n",
      "3667) Lyapunov Risk = 0.9216938614845276, MSE = 0.019704295322299004, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016421766486018896, Lv_loss = 0.00010801498865475878, Circular Tuning Loss = 1.2848492860794067\n",
      "3668) Lyapunov Risk = 0.9216260313987732, MSE = 0.019707614555954933, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001641455601202324, Lv_loss = 0.00010655716323526576, Circular Tuning Loss = 1.2847175598144531\n",
      "3669) Lyapunov Risk = 0.92156583070755, MSE = 0.019813381135463715, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001640607661101967, Lv_loss = 0.00010511999425943941, Circular Tuning Loss = 1.28458571434021\n",
      "3670) Lyapunov Risk = 0.9215080142021179, MSE = 0.019635263830423355, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016395644342992455, Lv_loss = 0.0001037026522681117, Circular Tuning Loss = 1.2844536304473877\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.84765625000000022, -0.8466801774534165]\n",
      "x2 : [0.69335937500000022, 0.69531250000000022]\n",
      "==============================\n",
      "3671) Lyapunov Risk = 0.9212479591369629, MSE = 0.019867239519953728, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016349484212696552, Lv_loss = 0.00010207345621893182, Circular Tuning Loss = 1.2828936576843262\n",
      "3672) Lyapunov Risk = 0.9211742281913757, MSE = 0.01963072456419468, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016336965200025588, Lv_loss = 0.00010064854723168537, Circular Tuning Loss = 1.2827614545822144\n",
      "3673) Lyapunov Risk = 0.9210968017578125, MSE = 0.019815044477581978, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016324390890076756, Lv_loss = 9.921698074322194e-05, Circular Tuning Loss = 1.282629132270813\n",
      "3674) Lyapunov Risk = 0.9210208654403687, MSE = 0.019677648320794106, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016311074432451278, Lv_loss = 9.778255480341613e-05, Circular Tuning Loss = 1.2824965715408325\n",
      "3675) Lyapunov Risk = 0.9209482073783875, MSE = 0.019737649708986282, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016297600814141333, Lv_loss = 9.636215690989047e-05, Circular Tuning Loss = 1.2823642492294312\n",
      "3676) Lyapunov Risk = 0.9208806753158569, MSE = 0.019749650731682777, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016284064622595906, Lv_loss = 9.494296682532877e-05, Circular Tuning Loss = 1.2822318077087402\n",
      "3677) Lyapunov Risk = 0.9208181500434875, MSE = 0.019668802618980408, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016270078776869923, Lv_loss = 9.351457265438512e-05, Circular Tuning Loss = 1.2820994853973389\n",
      "3678) Lyapunov Risk = 0.9207563996315002, MSE = 0.019818123430013657, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016256484377663583, Lv_loss = 9.206063259625807e-05, Circular Tuning Loss = 1.2819669246673584\n",
      "3679) Lyapunov Risk = 0.9206920862197876, MSE = 0.01963604800403118, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001624308933969587, Lv_loss = 9.057269926415756e-05, Circular Tuning Loss = 1.2818347215652466\n",
      "3680) Lyapunov Risk = 0.9206238985061646, MSE = 0.01983259618282318, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016230483015533537, Lv_loss = 8.906951552489772e-05, Circular Tuning Loss = 1.2817023992538452\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.80664062500000022, -0.80566406250000022]\n",
      "x2 : [0.78125000000000022, 0.78320312500000022]\n",
      "==============================\n",
      "3681) Lyapunov Risk = 0.9203864336013794, MSE = 0.019643375650048256, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001618351088836789, Lv_loss = 8.736598101677373e-05, Circular Tuning Loss = 1.2802438735961914\n",
      "3682) Lyapunov Risk = 0.9203131794929504, MSE = 0.019800890237092972, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016171981405932456, Lv_loss = 8.58397179399617e-05, Circular Tuning Loss = 1.2801119089126587\n",
      "3683) Lyapunov Risk = 0.9202404022216797, MSE = 0.019670933485031128, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016160808445420116, Lv_loss = 8.429372974205762e-05, Circular Tuning Loss = 1.279980182647705\n",
      "3684) Lyapunov Risk = 0.9201699495315552, MSE = 0.01974533684551716, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001615102228242904, Lv_loss = 8.271895785583183e-05, Circular Tuning Loss = 1.2798486948013306\n",
      "3685) Lyapunov Risk = 0.9201010465621948, MSE = 0.019704211503267288, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001614240900380537, Lv_loss = 8.110452472465113e-05, Circular Tuning Loss = 1.2797170877456665\n",
      "3686) Lyapunov Risk = 0.9200333952903748, MSE = 0.019711825996637344, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016135460464283824, Lv_loss = 7.94538136688061e-05, Circular Tuning Loss = 1.279585838317871\n",
      "3687) Lyapunov Risk = 0.9199667572975159, MSE = 0.0197436660528183, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001612996420590207, Lv_loss = 7.777507562423125e-05, Circular Tuning Loss = 1.2794549465179443\n",
      "3688) Lyapunov Risk = 0.91990065574646, MSE = 0.01968328468501568, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001612490596016869, Lv_loss = 7.608540909131989e-05, Circular Tuning Loss = 1.2793240547180176\n",
      "3689) Lyapunov Risk = 0.9198353886604309, MSE = 0.0197792686522007, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016121004591695964, Lv_loss = 7.438127795467153e-05, Circular Tuning Loss = 1.2791935205459595\n",
      "3690) Lyapunov Risk = 0.9197683930397034, MSE = 0.019657470285892487, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016116922779474407, Lv_loss = 7.267788168974221e-05, Circular Tuning Loss = 1.27906334400177\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.84472656250000022, -0.84375000000000022]\n",
      "x2 : [0.71875000000000022, 0.72070312500000022]\n",
      "==============================\n",
      "3691) Lyapunov Risk = 0.9195249080657959, MSE = 0.01978928968310356, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001607945596333593, Lv_loss = 7.081083458615467e-05, Circular Tuning Loss = 1.2775627374649048\n",
      "3692) Lyapunov Risk = 0.9194546341896057, MSE = 0.01965826377272606, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016076097381301224, Lv_loss = 6.90918168402277e-05, Circular Tuning Loss = 1.2774335145950317\n",
      "3693) Lyapunov Risk = 0.9193851351737976, MSE = 0.01976311020553112, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016073444567155093, Lv_loss = 6.736713839927688e-05, Circular Tuning Loss = 1.2773042917251587\n",
      "3694) Lyapunov Risk = 0.9193150997161865, MSE = 0.01967398077249527, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016071168647613376, Lv_loss = 6.564150680787861e-05, Circular Tuning Loss = 1.2771756649017334\n",
      "3695) Lyapunov Risk = 0.919245719909668, MSE = 0.019725888967514038, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016068802506197244, Lv_loss = 6.392932118615136e-05, Circular Tuning Loss = 1.277046799659729\n",
      "3696) Lyapunov Risk = 0.9191777110099792, MSE = 0.019713321700692177, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001606588193681091, Lv_loss = 6.222965021152049e-05, Circular Tuning Loss = 1.2769184112548828\n",
      "3697) Lyapunov Risk = 0.9191108345985413, MSE = 0.01969282701611519, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016062390932347625, Lv_loss = 6.054209734429605e-05, Circular Tuning Loss = 1.2767902612686157\n",
      "3698) Lyapunov Risk = 0.919044017791748, MSE = 0.01974281668663025, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001605833531357348, Lv_loss = 5.8858367992797866e-05, Circular Tuning Loss = 1.2766624689102173\n",
      "3699) Lyapunov Risk = 0.9189763069152832, MSE = 0.019680744037032127, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001605409343028441, Lv_loss = 5.7180397561751306e-05, Circular Tuning Loss = 1.2765347957611084\n",
      "3700) Lyapunov Risk = 0.9189077019691467, MSE = 0.019738100469112396, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016049246187321842, Lv_loss = 5.5518703447887674e-05, Circular Tuning Loss = 1.276407241821289\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.82910156250000022, -0.82812500000000022]\n",
      "x2 : [0.75000000000000022, 0.75195312500000022]\n",
      "==============================\n",
      "3701) Lyapunov Risk = 0.9186738729476929, MSE = 0.019689882174134254, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016010215040296316, Lv_loss = 5.375292312237434e-05, Circular Tuning Loss = 1.2749465703964233\n",
      "3702) Lyapunov Risk = 0.918605387210846, MSE = 0.01972068101167679, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016005006909836084, Lv_loss = 5.2110535762039945e-05, Circular Tuning Loss = 1.27482008934021\n",
      "3703) Lyapunov Risk = 0.9185370802879333, MSE = 0.019698800519108772, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001599998795427382, Lv_loss = 5.046925798524171e-05, Circular Tuning Loss = 1.2746937274932861\n",
      "3704) Lyapunov Risk = 0.9184693098068237, MSE = 0.019697632640600204, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015995332796592265, Lv_loss = 4.882392386207357e-05, Circular Tuning Loss = 1.2745678424835205\n",
      "3705) Lyapunov Risk = 0.9184017777442932, MSE = 0.019713720306754112, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015991207328625023, Lv_loss = 4.716989496955648e-05, Circular Tuning Loss = 1.2744420766830444\n",
      "3706) Lyapunov Risk = 0.9183342456817627, MSE = 0.019688846543431282, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001598710659891367, Lv_loss = 4.552157406578772e-05, Circular Tuning Loss = 1.2743170261383057\n",
      "3707) Lyapunov Risk = 0.9182664752006531, MSE = 0.019720135256648064, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015982803597580642, Lv_loss = 4.387428271002136e-05, Circular Tuning Loss = 1.2741920948028564\n",
      "3708) Lyapunov Risk = 0.9181985259056091, MSE = 0.019694188609719276, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015977787552401423, Lv_loss = 4.2245817894581705e-05, Circular Tuning Loss = 1.2740674018859863\n",
      "3709) Lyapunov Risk = 0.9181302785873413, MSE = 0.019709020853042603, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001597194350324571, Lv_loss = 4.0633181924931705e-05, Circular Tuning Loss = 1.2739428281784058\n",
      "3710) Lyapunov Risk = 0.9180625677108765, MSE = 0.01970531791448593, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015965659986250103, Lv_loss = 3.9030641346471384e-05, Circular Tuning Loss = 1.2738186120986938\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.84472656250000022, -0.84375000000000022]\n",
      "x2 : [0.71875000000000022, 0.72070312500000022]\n",
      "==============================\n",
      "3711) Lyapunov Risk = 0.9178242087364197, MSE = 0.019688831642270088, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001592288026586175, Lv_loss = 3.749429015442729e-05, Circular Tuning Loss = 1.2723385095596313\n",
      "3712) Lyapunov Risk = 0.9177584052085876, MSE = 0.019727779552340508, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015910097863525152, Lv_loss = 3.6259458283893764e-05, Circular Tuning Loss = 1.2722150087356567\n",
      "3713) Lyapunov Risk = 0.9176929593086243, MSE = 0.019661173224449158, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001589407620485872, Lv_loss = 3.5206197935622185e-05, Circular Tuning Loss = 1.2720924615859985\n",
      "3714) Lyapunov Risk = 0.917627215385437, MSE = 0.01973903924226761, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015875491953920573, Lv_loss = 3.43112951668445e-05, Circular Tuning Loss = 1.2719699144363403\n",
      "3715) Lyapunov Risk = 0.9175611734390259, MSE = 0.019655466079711914, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015855045057833195, Lv_loss = 3.354579894221388e-05, Circular Tuning Loss = 1.2718479633331299\n",
      "3716) Lyapunov Risk = 0.9174948334693909, MSE = 0.019739139825105667, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015832905774004757, Lv_loss = 3.290976383141242e-05, Circular Tuning Loss = 1.271726131439209\n",
      "3717) Lyapunov Risk = 0.9174286127090454, MSE = 0.019665641710162163, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015809597971383482, Lv_loss = 3.236876000300981e-05, Circular Tuning Loss = 1.2716047763824463\n",
      "3718) Lyapunov Risk = 0.9173626899719238, MSE = 0.019728830084204674, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015784458082634956, Lv_loss = 3.193727388861589e-05, Circular Tuning Loss = 1.2714836597442627\n",
      "3719) Lyapunov Risk = 0.9172973036766052, MSE = 0.019673336297273636, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015757561777718365, Lv_loss = 3.15865472657606e-05, Circular Tuning Loss = 1.2713626623153687\n",
      "3720) Lyapunov Risk = 0.9172324538230896, MSE = 0.01971978135406971, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015728958533145487, Lv_loss = 3.132423444185406e-05, Circular Tuning Loss = 1.2712419033050537\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.9394114652915744, 1.9409438122896538]\n",
      "x2 : [0.32391379848578128, 0.3247595264191645]\n",
      "==============================\n",
      "3721) Lyapunov Risk = 0.9194763898849487, MSE = 0.019669486209750175, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001566561550134793, Lv_loss = 3.10596551571507e-05, Circular Tuning Loss = 1.275024652481079\n",
      "3722) Lyapunov Risk = 0.9194120168685913, MSE = 0.019714944064617157, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015637076285202056, Lv_loss = 3.0732728191651404e-05, Circular Tuning Loss = 1.274902582168579\n",
      "3723) Lyapunov Risk = 0.9193480014801025, MSE = 0.019658047705888748, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015609928232152015, Lv_loss = 3.0262441214290448e-05, Circular Tuning Loss = 1.2747796773910522\n",
      "3724) Lyapunov Risk = 0.9192848801612854, MSE = 0.01972576230764389, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015584015636704862, Lv_loss = 2.9682416425202973e-05, Circular Tuning Loss = 1.2746562957763672\n",
      "3725) Lyapunov Risk = 0.9192226529121399, MSE = 0.019640065729618073, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001555924245622009, Lv_loss = 2.896500336646568e-05, Circular Tuning Loss = 1.2745318412780762\n",
      "3726) Lyapunov Risk = 0.9191625714302063, MSE = 0.019757362082600594, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015535912825725973, Lv_loss = 2.8145032047177665e-05, Circular Tuning Loss = 1.2744070291519165\n",
      "3727) Lyapunov Risk = 0.9191053509712219, MSE = 0.019618285819888115, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015513549442403018, Lv_loss = 2.721067903621588e-05, Circular Tuning Loss = 1.2742819786071777\n",
      "3728) Lyapunov Risk = 0.9190518260002136, MSE = 0.01980401948094368, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015492219245061278, Lv_loss = 2.621613566589076e-05, Circular Tuning Loss = 1.2741559743881226\n",
      "3729) Lyapunov Risk = 0.9190055131912231, MSE = 0.019585205242037773, V_0_loss = tensor([[0.0071]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015471976075787097, Lv_loss = 2.5116116376011632e-05, Circular Tuning Loss = 1.274030089378357\n",
      "3730) Lyapunov Risk = 0.9189675450325012, MSE = 0.019868338480591774, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001545238628750667, Lv_loss = 2.3976021111593582e-05, Circular Tuning Loss = 1.273903489112854\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.87597656250000022, -0.87500000000000022]\n",
      "x2 : [0.62500000000000022, 0.62695312500000022]\n",
      "==============================\n",
      "3731) Lyapunov Risk = 0.9187355637550354, MSE = 0.019544629380106926, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015401560813188553, Lv_loss = 2.266066803713329e-05, Circular Tuning Loss = 1.2723207473754883\n",
      "3732) Lyapunov Risk = 0.9187346696853638, MSE = 0.01998375914990902, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001538358919788152, Lv_loss = 2.1381174519774504e-05, Circular Tuning Loss = 1.2721939086914062\n",
      "3733) Lyapunov Risk = 0.9187595844268799, MSE = 0.01950896717607975, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015367119340226054, Lv_loss = 1.9970211724285036e-05, Circular Tuning Loss = 1.2720671892166138\n",
      "3734) Lyapunov Risk = 0.9188195466995239, MSE = 0.020151406526565552, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001535061455797404, Lv_loss = 1.8608472601044923e-05, Circular Tuning Loss = 1.2719403505325317\n",
      "3735) Lyapunov Risk = 0.9189140200614929, MSE = 0.01951061375439167, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015336350770667195, Lv_loss = 1.7103215213865042e-05, Circular Tuning Loss = 1.2718136310577393\n",
      "3736) Lyapunov Risk = 0.9190424084663391, MSE = 0.020369186997413635, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015321777027565986, Lv_loss = 1.5691361113567837e-05, Circular Tuning Loss = 1.2716864347457886\n",
      "3737) Lyapunov Risk = 0.9191734194755554, MSE = 0.01955762319266796, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015309473383240402, Lv_loss = 1.4076110346650239e-05, Circular Tuning Loss = 1.2715601921081543\n",
      "3738) Lyapunov Risk = 0.9192681908607483, MSE = 0.02055434137582779, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015297539357561618, Lv_loss = 1.2571761544677429e-05, Circular Tuning Loss = 1.2714334726333618\n",
      "3739) Lyapunov Risk = 0.9192413091659546, MSE = 0.01960027404129505, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.000152878652443178, Lv_loss = 1.0829151506186463e-05, Circular Tuning Loss = 1.2713077068328857\n",
      "3740) Lyapunov Risk = 0.9190449714660645, MSE = 0.020470380783081055, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001527771382825449, Lv_loss = 9.320436220150441e-06, Circular Tuning Loss = 1.2711814641952515\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.87597656250000022, -0.87500000000000022]\n",
      "x2 : [0.62500000000000022, 0.62695312500000022]\n",
      "==============================\n",
      "3741) Lyapunov Risk = 0.918479323387146, MSE = 0.01959368586540222, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015237649495247751, Lv_loss = 7.638264833076391e-06, Circular Tuning Loss = 1.2696086168289185\n",
      "3742) Lyapunov Risk = 0.9180585145950317, MSE = 0.02003789320588112, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015229376731440425, Lv_loss = 6.1812575040676165e-06, Circular Tuning Loss = 1.2694830894470215\n",
      "3743) Lyapunov Risk = 0.9177087545394897, MSE = 0.019655395299196243, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015222305955830961, Lv_loss = 4.8934393817035016e-06, Circular Tuning Loss = 1.2693581581115723\n",
      "3744) Lyapunov Risk = 0.917529821395874, MSE = 0.019603921100497246, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015215935127343982, Lv_loss = 3.7317829537641956e-06, Circular Tuning Loss = 1.2692331075668335\n",
      "3745) Lyapunov Risk = 0.9175232648849487, MSE = 0.019913095980882645, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015210072160698473, Lv_loss = 2.5712986371217994e-06, Circular Tuning Loss = 1.2691084146499634\n",
      "3746) Lyapunov Risk = 0.9176070690155029, MSE = 0.019465601071715355, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015205700765363872, Lv_loss = 1.4332189266497153e-06, Circular Tuning Loss = 1.268984317779541\n",
      "3747) Lyapunov Risk = 0.9176759719848633, MSE = 0.02012566290795803, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015201199857983738, Lv_loss = 7.253933631545806e-07, Circular Tuning Loss = 1.26885986328125\n",
      "3748) Lyapunov Risk = 0.9176506996154785, MSE = 0.0195149052888155, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015198352048173547, Lv_loss = 4.6837408262945246e-07, Circular Tuning Loss = 1.268736481666565\n",
      "3749) Lyapunov Risk = 0.9175163507461548, MSE = 0.020025620236992836, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015195303421933204, Lv_loss = 2.2895187612448353e-07, Circular Tuning Loss = 1.2686127424240112\n",
      "3750) Lyapunov Risk = 0.9173179864883423, MSE = 0.019622109830379486, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015193564468063414, Lv_loss = 6.41915463006626e-08, Circular Tuning Loss = 1.2684894800186157\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.9718264673879902, 1.9734566754808682]\n",
      "x2 : [0.3247595264191645, 0.32560525435254772]\n",
      "==============================\n",
      "3751) Lyapunov Risk = 0.9195365905761719, MSE = 0.019710702821612358, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015159750182647258, Lv_loss = 0.0, Circular Tuning Loss = 1.2724635601043701\n",
      "3752) Lyapunov Risk = 0.9194166660308838, MSE = 0.019795924425125122, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015160908515099436, Lv_loss = 0.0, Circular Tuning Loss = 1.2723389863967896\n",
      "3753) Lyapunov Risk = 0.9193680286407471, MSE = 0.019486060366034508, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001516405027359724, Lv_loss = 0.0, Circular Tuning Loss = 1.2722134590148926\n",
      "3754) Lyapunov Risk = 0.9193558096885681, MSE = 0.019961828365921974, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015166703087743372, Lv_loss = 0.0, Circular Tuning Loss = 1.2720869779586792\n",
      "3755) Lyapunov Risk = 0.9193323254585266, MSE = 0.01945178210735321, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001516770280431956, Lv_loss = 0.0, Circular Tuning Loss = 1.2719606161117554\n",
      "3756) Lyapunov Risk = 0.9192676544189453, MSE = 0.019954076036810875, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015165751392487437, Lv_loss = 0.0, Circular Tuning Loss = 1.2718335390090942\n",
      "3757) Lyapunov Risk = 0.9191641807556152, MSE = 0.019545624032616615, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001516296761110425, Lv_loss = 0.0, Circular Tuning Loss = 1.2717068195343018\n",
      "3758) Lyapunov Risk = 0.9190467000007629, MSE = 0.019771428778767586, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.000151586122228764, Lv_loss = 0.0, Circular Tuning Loss = 1.271579623222351\n",
      "3759) Lyapunov Risk = 0.9189433455467224, MSE = 0.019705094397068024, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015153171261772513, Lv_loss = 0.0, Circular Tuning Loss = 1.2714524269104004\n",
      "3760) Lyapunov Risk = 0.9188693761825562, MSE = 0.01957254856824875, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001514722971478477, Lv_loss = 0.0, Circular Tuning Loss = 1.2713251113891602\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.9663731788719616, 1.967719818140534]\n",
      "x2 : [0.33744544541991317, 0.33829117335329639]\n",
      "==============================\n",
      "3761) Lyapunov Risk = 0.9211974143981934, MSE = 0.019862845540046692, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015108943625818938, Lv_loss = 0.0, Circular Tuning Loss = 1.2752424478530884\n",
      "3762) Lyapunov Risk = 0.9211560487747192, MSE = 0.019465235993266106, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015105183410923928, Lv_loss = 0.0, Circular Tuning Loss = 1.275113582611084\n",
      "3763) Lyapunov Risk = 0.9211016297340393, MSE = 0.01992296427488327, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001510337897343561, Lv_loss = 0.0, Circular Tuning Loss = 1.2749837636947632\n",
      "3764) Lyapunov Risk = 0.9210253357887268, MSE = 0.019474785774946213, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015104567864909768, Lv_loss = 0.0, Circular Tuning Loss = 1.2748534679412842\n",
      "3765) Lyapunov Risk = 0.9209319353103638, MSE = 0.019840057939291, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001510738511569798, Lv_loss = 0.0, Circular Tuning Loss = 1.2747223377227783\n",
      "3766) Lyapunov Risk = 0.9208353757858276, MSE = 0.01957351341843605, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001511240698164329, Lv_loss = 0.0, Circular Tuning Loss = 1.2745909690856934\n",
      "3767) Lyapunov Risk = 0.9207480549812317, MSE = 0.019688067957758904, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015119275485631078, Lv_loss = 0.0, Circular Tuning Loss = 1.2744592428207397\n",
      "3768) Lyapunov Risk = 0.9206767082214355, MSE = 0.019717484712600708, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015128203085623682, Lv_loss = 0.0, Circular Tuning Loss = 1.2743275165557861\n",
      "3769) Lyapunov Risk = 0.9206182956695557, MSE = 0.019564051181077957, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015139373135752976, Lv_loss = 0.0, Circular Tuning Loss = 1.274195671081543\n",
      "3770) Lyapunov Risk = 0.9205641746520996, MSE = 0.019828910008072853, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001515170297352597, Lv_loss = 0.0, Circular Tuning Loss = 1.2740634679794312\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.8691233575366795, 1.8720814844236777]\n",
      "x2 : [0.43132124602545285, 0.43301270189221935]\n",
      "==============================\n",
      "3771) Lyapunov Risk = 0.9226171970367432, MSE = 0.019507084041833878, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015134467685129493, Lv_loss = 1.8830240151146427e-05, Circular Tuning Loss = 1.2773919105529785\n",
      "3772) Lyapunov Risk = 0.9225459694862366, MSE = 0.019840393215417862, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001515356998424977, Lv_loss = 1.76393714355072e-05, Circular Tuning Loss = 1.2772581577301025\n",
      "3773) Lyapunov Risk = 0.9224660396575928, MSE = 0.019513480365276337, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001517792697995901, Lv_loss = 1.635878834349569e-05, Circular Tuning Loss = 1.2771238088607788\n",
      "3774) Lyapunov Risk = 0.9223818182945251, MSE = 0.019778205081820488, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.000152059510583058, Lv_loss = 1.4996014215284958e-05, Circular Tuning Loss = 1.2769888639450073\n",
      "3775) Lyapunov Risk = 0.922297477722168, MSE = 0.019570238888263702, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015237531624734402, Lv_loss = 1.3564210348704364e-05, Circular Tuning Loss = 1.2768534421920776\n",
      "3776) Lyapunov Risk = 0.9222164154052734, MSE = 0.019696474075317383, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015271088341251016, Lv_loss = 1.2074948244844563e-05, Circular Tuning Loss = 1.2767176628112793\n",
      "3777) Lyapunov Risk = 0.9221407771110535, MSE = 0.019656993448734283, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001530558947706595, Lv_loss = 1.0540961739025079e-05, Circular Tuning Loss = 1.276581883430481\n",
      "3778) Lyapunov Risk = 0.9220699667930603, MSE = 0.01962260529398918, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015341521066147834, Lv_loss = 8.965525012172293e-06, Circular Tuning Loss = 1.276445984840393\n",
      "3779) Lyapunov Risk = 0.9220014214515686, MSE = 0.019724225625395775, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015378119132947177, Lv_loss = 7.357753929682076e-06, Circular Tuning Loss = 1.2763099670410156\n",
      "3780) Lyapunov Risk = 0.9219328761100769, MSE = 0.01957016810774803, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001541481469757855, Lv_loss = 5.728326868847944e-06, Circular Tuning Loss = 1.2761740684509277\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.8346892619987329, 1.8356199132294884]\n",
      "x2 : [0.43132124602545285, 0.43301270189221935]\n",
      "==============================\n",
      "3781) Lyapunov Risk = 0.9238113164901733, MSE = 0.019751600921154022, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015418905240949243, Lv_loss = 4.067984718858497e-06, Circular Tuning Loss = 1.2792304754257202\n",
      "3782) Lyapunov Risk = 0.9237367510795593, MSE = 0.01954120770096779, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015459113637916744, Lv_loss = 2.3247919216373703e-06, Circular Tuning Loss = 1.279092788696289\n",
      "3783) Lyapunov Risk = 0.9236592054367065, MSE = 0.019752262160182, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001550232118461281, Lv_loss = 5.32527735686017e-07, Circular Tuning Loss = 1.2789543867111206\n",
      "3784) Lyapunov Risk = 0.9235789179801941, MSE = 0.01954720914363861, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015548891678918153, Lv_loss = 0.0, Circular Tuning Loss = 1.2788156270980835\n",
      "3785) Lyapunov Risk = 0.9234969615936279, MSE = 0.01972750574350357, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015598407480865717, Lv_loss = 0.0, Circular Tuning Loss = 1.2786762714385986\n",
      "3786) Lyapunov Risk = 0.9234148859977722, MSE = 0.019583100453019142, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001565113925607875, Lv_loss = 0.0, Circular Tuning Loss = 1.2785367965698242\n",
      "3787) Lyapunov Risk = 0.9233336448669434, MSE = 0.019689690321683884, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015706202248111367, Lv_loss = 0.0, Circular Tuning Loss = 1.2783973217010498\n",
      "3788) Lyapunov Risk = 0.9232534766197205, MSE = 0.019625691697001457, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015763577539473772, Lv_loss = 0.0, Circular Tuning Loss = 1.2782577276229858\n",
      "3789) Lyapunov Risk = 0.9231741428375244, MSE = 0.019648149609565735, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015823013382032514, Lv_loss = 0.0, Circular Tuning Loss = 1.2781181335449219\n",
      "3790) Lyapunov Risk = 0.9230955839157104, MSE = 0.0196574367582798, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015884637832641602, Lv_loss = 0.0, Circular Tuning Loss = 1.277978777885437\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.9149743242851516, 1.9164533877286507]\n",
      "x2 : [0.42962979015868641, 0.43047551809206963]\n",
      "==============================\n",
      "3791) Lyapunov Risk = 0.9252301454544067, MSE = 0.019611231982707977, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015914352843537927, Lv_loss = 0.0, Circular Tuning Loss = 1.281561255455017\n",
      "3792) Lyapunov Risk = 0.925147294998169, MSE = 0.01966930367052555, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015981559408828616, Lv_loss = 0.0, Circular Tuning Loss = 1.2814195156097412\n",
      "3793) Lyapunov Risk = 0.9250634908676147, MSE = 0.019596247002482414, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001605544675840065, Lv_loss = 0.0, Circular Tuning Loss = 1.2812772989273071\n",
      "3794) Lyapunov Risk = 0.9249787330627441, MSE = 0.019676122814416885, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016137097554747015, Lv_loss = 0.0, Circular Tuning Loss = 1.281133770942688\n",
      "3795) Lyapunov Risk = 0.9248932600021362, MSE = 0.019598962739109993, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016226117440965027, Lv_loss = 0.0, Circular Tuning Loss = 1.2809892892837524\n",
      "3796) Lyapunov Risk = 0.924807071685791, MSE = 0.019678642973303795, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016319812857545912, Lv_loss = 0.0, Circular Tuning Loss = 1.2808431386947632\n",
      "3797) Lyapunov Risk = 0.9247203469276428, MSE = 0.019609786570072174, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001641904964344576, Lv_loss = 0.0, Circular Tuning Loss = 1.2806960344314575\n",
      "3798) Lyapunov Risk = 0.9246333241462708, MSE = 0.019668515771627426, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016524085367564112, Lv_loss = 0.0, Circular Tuning Loss = 1.2805469036102295\n",
      "3799) Lyapunov Risk = 0.9245461821556091, MSE = 0.01962009258568287, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016634634812362492, Lv_loss = 0.0, Circular Tuning Loss = 1.2803963422775269\n",
      "3800) Lyapunov Risk = 0.9244590997695923, MSE = 0.01965225674211979, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016749094356782734, Lv_loss = 0.0, Circular Tuning Loss = 1.2802437543869019\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.9242772677906221, 1.9254546244061643]\n",
      "x2 : [0.48544783376198031, 0.48713928962874675]\n",
      "==============================\n",
      "3801) Lyapunov Risk = 0.9266575574874878, MSE = 0.019631510600447655, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001682955917203799, Lv_loss = 1.7594989003555384e-06, Circular Tuning Loss = 1.2839393615722656\n",
      "3802) Lyapunov Risk = 0.9265660643577576, MSE = 0.01963038370013237, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016949704149737954, Lv_loss = 0.0, Circular Tuning Loss = 1.2837799787521362\n",
      "3803) Lyapunov Risk = 0.9264737963676453, MSE = 0.019649408757686615, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00017071518232114613, Lv_loss = 0.0, Circular Tuning Loss = 1.2836178541183472\n",
      "3804) Lyapunov Risk = 0.9263808131217957, MSE = 0.019615614786744118, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00017194313113577664, Lv_loss = 0.0, Circular Tuning Loss = 1.2834532260894775\n",
      "3805) Lyapunov Risk = 0.9262874126434326, MSE = 0.019664445891976357, V_0_loss = tensor([[0.0072]], grad_fn=<PowBackward0>), V_pos_loss = 0.00017319538164883852, Lv_loss = 0.0, Circular Tuning Loss = 1.2832869291305542\n",
      "3806) Lyapunov Risk = 0.9261936545372009, MSE = 0.019610119983553886, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00017446905258111656, Lv_loss = 0.0, Circular Tuning Loss = 1.2831194400787354\n",
      "3807) Lyapunov Risk = 0.9260991215705872, MSE = 0.019674845039844513, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00017576779646333307, Lv_loss = 0.0, Circular Tuning Loss = 1.282950758934021\n",
      "3808) Lyapunov Risk = 0.9260040521621704, MSE = 0.01960884779691696, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001770996896084398, Lv_loss = 0.0, Circular Tuning Loss = 1.2827814817428589\n",
      "3809) Lyapunov Risk = 0.9259082674980164, MSE = 0.019677527248859406, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00017845440015662462, Lv_loss = 0.0, Circular Tuning Loss = 1.2826114892959595\n",
      "3810) Lyapunov Risk = 0.925812304019928, MSE = 0.019608568400144577, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001798343291739002, Lv_loss = 0.0, Circular Tuning Loss = 1.28244149684906\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.6113727827950388, 1.6131406047441663]\n",
      "x2 : [0.649519052838329, 0.652901964571862]\n",
      "==============================\n",
      "3811) Lyapunov Risk = 0.9271421432495117, MSE = 0.019675958901643753, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00018085743067786098, Lv_loss = 7.638965371370432e-07, Circular Tuning Loss = 1.2844040393829346\n",
      "3812) Lyapunov Risk = 0.9270431995391846, MSE = 0.01960163190960884, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00018236521282233298, Lv_loss = 0.0, Circular Tuning Loss = 1.2842319011688232\n",
      "3813) Lyapunov Risk = 0.9269437193870544, MSE = 0.019680719822645187, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00018397034727968276, Lv_loss = 0.0, Circular Tuning Loss = 1.2840602397918701\n",
      "3814) Lyapunov Risk = 0.9268441796302795, MSE = 0.019598113372921944, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00018566535436548293, Lv_loss = 0.0, Circular Tuning Loss = 1.2838890552520752\n",
      "3815) Lyapunov Risk = 0.9267441034317017, MSE = 0.0196845605969429, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00018742882821243256, Lv_loss = 0.0, Circular Tuning Loss = 1.283718466758728\n",
      "3816) Lyapunov Risk = 0.9266435503959656, MSE = 0.019598528742790222, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001892653963295743, Lv_loss = 0.0, Circular Tuning Loss = 1.2835488319396973\n",
      "3817) Lyapunov Risk = 0.9265426397323608, MSE = 0.019692201167345047, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019116414478048682, Lv_loss = 0.0, Circular Tuning Loss = 1.2833800315856934\n",
      "3818) Lyapunov Risk = 0.9264412522315979, MSE = 0.019600244238972664, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001931250444613397, Lv_loss = 0.0, Circular Tuning Loss = 1.283212423324585\n",
      "3819) Lyapunov Risk = 0.926339328289032, MSE = 0.01970066875219345, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019514939049258828, Lv_loss = 0.0, Circular Tuning Loss = 1.2830458879470825\n",
      "3820) Lyapunov Risk = 0.9262375831604004, MSE = 0.019598636776208878, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019723385048564523, Lv_loss = 0.0, Circular Tuning Loss = 1.2828806638717651\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.8394218142324981, 1.841606173047069]\n",
      "x2 : [0.64782759697156256, 0.649519052838329]\n",
      "==============================\n",
      "3821) Lyapunov Risk = 0.9282544851303101, MSE = 0.019707389175891876, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001989277807297185, Lv_loss = 0.0, Circular Tuning Loss = 1.2862499952316284\n",
      "3822) Lyapunov Risk = 0.9281502366065979, MSE = 0.019581520929932594, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020110719196964055, Lv_loss = 0.0, Circular Tuning Loss = 1.2860838174819946\n",
      "3823) Lyapunov Risk = 0.9280462265014648, MSE = 0.019721275195479393, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002033370838034898, Lv_loss = 0.0, Circular Tuning Loss = 1.2859182357788086\n",
      "3824) Lyapunov Risk = 0.9279419779777527, MSE = 0.019562331959605217, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002056294761132449, Lv_loss = 0.0, Circular Tuning Loss = 1.2857534885406494\n",
      "3825) Lyapunov Risk = 0.9278380274772644, MSE = 0.01974584348499775, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020798131299670786, Lv_loss = 0.0, Circular Tuning Loss = 1.285589337348938\n",
      "3826) Lyapunov Risk = 0.9277377128601074, MSE = 0.01953580044209957, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00021038379054516554, Lv_loss = 0.0, Circular Tuning Loss = 1.2854257822036743\n",
      "3827) Lyapunov Risk = 0.9276414513587952, MSE = 0.0198047012090683, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00021286439732648432, Lv_loss = 0.0, Circular Tuning Loss = 1.2852630615234375\n",
      "3828) Lyapunov Risk = 0.9275691509246826, MSE = 0.019457021728157997, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00021535278938245028, Lv_loss = 0.0, Circular Tuning Loss = 1.2851006984710693\n",
      "3829) Lyapunov Risk = 0.9275218844413757, MSE = 0.019979987293481827, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00021788674348499626, Lv_loss = 0.0, Circular Tuning Loss = 1.2849390506744385\n",
      "3830) Lyapunov Risk = 0.9275274872779846, MSE = 0.019322296604514122, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00022047104721423239, Lv_loss = 0.0, Circular Tuning Loss = 1.284778356552124\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0000000000000002, 1.0062716846697812]\n",
      "x2 : [-0.8727912272515046, -0.86602540378443871]\n",
      "==============================\n",
      "3831) Lyapunov Risk = 0.9280059337615967, MSE = 0.020323876291513443, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00022266396263148636, Lv_loss = 0.0, Circular Tuning Loss = 1.2855900526046753\n",
      "3832) Lyapunov Risk = 0.9282547235488892, MSE = 0.01917337067425251, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002253631391795352, Lv_loss = 2.126198887708597e-05, Circular Tuning Loss = 1.2854294776916504\n",
      "3833) Lyapunov Risk = 0.9287102222442627, MSE = 0.02103964239358902, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00022804175387136638, Lv_loss = 0.0, Circular Tuning Loss = 1.2852665185928345\n",
      "3834) Lyapunov Risk = 0.9294636249542236, MSE = 0.019147798418998718, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00023073071497492492, Lv_loss = 0.00011423996329540387, Circular Tuning Loss = 1.2851026058197021\n",
      "3835) Lyapunov Risk = 0.9309589862823486, MSE = 0.022496413439512253, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002333746524527669, Lv_loss = 0.0, Circular Tuning Loss = 1.2849366664886475\n",
      "3836) Lyapunov Risk = 0.9330456852912903, MSE = 0.019603710621595383, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002360038342885673, Lv_loss = 0.00036468630423769355, Circular Tuning Loss = 1.284769058227539\n",
      "3837) Lyapunov Risk = 0.9351022839546204, MSE = 0.024625878781080246, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00023843384406063706, Lv_loss = 0.0, Circular Tuning Loss = 1.284597635269165\n",
      "3838) Lyapunov Risk = 0.9358259439468384, MSE = 0.020143836736679077, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00024066904734354466, Lv_loss = 0.0005170496297068894, Circular Tuning Loss = 1.2844232320785522\n",
      "3839) Lyapunov Risk = 0.9331992268562317, MSE = 0.02380295656621456, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002426580904284492, Lv_loss = 0.0, Circular Tuning Loss = 1.2842447757720947\n",
      "3840) Lyapunov Risk = 0.9289276003837585, MSE = 0.019191408529877663, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002444195852149278, Lv_loss = 0.00011263648775639012, Circular Tuning Loss = 1.2840632200241089\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.83789062500000022, -0.83691406250000022]\n",
      "x2 : [0.76562500000000022, 0.76757812500000022]\n",
      "==============================\n",
      "3841) Lyapunov Risk = 0.9264073371887207, MSE = 0.019783109426498413, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00024551074602641165, Lv_loss = 0.0, Circular Tuning Loss = 1.282588243484497\n",
      "3842) Lyapunov Risk = 0.9274593591690063, MSE = 0.020958516746759415, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00024697609478607774, Lv_loss = 0.0, Circular Tuning Loss = 1.2824031114578247\n",
      "3843) Lyapunov Risk = 0.9295907020568848, MSE = 0.019252922385931015, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002483550924807787, Lv_loss = 0.00023885161499492824, Circular Tuning Loss = 1.2822167873382568\n",
      "3844) Lyapunov Risk = 0.9297602772712708, MSE = 0.022439267486333847, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00024959625443443656, Lv_loss = 0.0, Circular Tuning Loss = 1.282029151916504\n",
      "3845) Lyapunov Risk = 0.9276828765869141, MSE = 0.01914217323064804, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.00025066183297894895, Lv_loss = 9.86540544545278e-05, Circular Tuning Loss = 1.2818396091461182\n",
      "3846) Lyapunov Risk = 0.92588871717453, MSE = 0.019823916256427765, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.00025156090850941837, Lv_loss = 0.0, Circular Tuning Loss = 1.2816485166549683\n",
      "3847) Lyapunov Risk = 0.9264811277389526, MSE = 0.020612698048353195, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.00025240631657652557, Lv_loss = 0.0, Circular Tuning Loss = 1.2814574241638184\n",
      "3848) Lyapunov Risk = 0.9277764558792114, MSE = 0.019153738394379616, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.00025321627617813647, Lv_loss = 0.00015632603026460856, Circular Tuning Loss = 1.2812663316726685\n",
      "3849) Lyapunov Risk = 0.9273760914802551, MSE = 0.02138189971446991, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.00025382719468325377, Lv_loss = 0.0, Circular Tuning Loss = 1.2810741662979126\n",
      "3850) Lyapunov Risk = 0.9258390069007874, MSE = 0.01925422064960003, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002542720758356154, Lv_loss = 1.483432060922496e-05, Circular Tuning Loss = 1.280882477760315\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.83691406250000022, -0.83593750000000022]\n",
      "x2 : [0.81250000000000022, 0.81445312500000022]\n",
      "==============================\n",
      "3851) Lyapunov Risk = 0.9252978563308716, MSE = 0.019437817856669426, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002539709967095405, Lv_loss = 0.0, Circular Tuning Loss = 1.2794997692108154\n",
      "3852) Lyapunov Risk = 0.9261710047721863, MSE = 0.020836099982261658, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.00025402920437045395, Lv_loss = 0.0, Circular Tuning Loss = 1.279309630393982\n",
      "3853) Lyapunov Risk = 0.9264624118804932, MSE = 0.019133439287543297, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.00025387536152265966, Lv_loss = 9.82380734058097e-05, Circular Tuning Loss = 1.2791208028793335\n",
      "3854) Lyapunov Risk = 0.925536036491394, MSE = 0.020498432219028473, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.00025344471214339137, Lv_loss = 0.0, Circular Tuning Loss = 1.278933048248291\n",
      "3855) Lyapunov Risk = 0.9248502254486084, MSE = 0.019617559388279915, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002528778277337551, Lv_loss = 0.0, Circular Tuning Loss = 1.278747320175171\n",
      "3856) Lyapunov Risk = 0.9252068400382996, MSE = 0.019261544570326805, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.00025217581423930824, Lv_loss = 1.425977188773686e-05, Circular Tuning Loss = 1.2785634994506836\n",
      "3857) Lyapunov Risk = 0.9256084561347961, MSE = 0.020743513479828835, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002513724029995501, Lv_loss = 0.0, Circular Tuning Loss = 1.2783817052841187\n",
      "3858) Lyapunov Risk = 0.9251911640167236, MSE = 0.01919577457010746, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.00025056899175979197, Lv_loss = 3.404524613870308e-05, Circular Tuning Loss = 1.2782025337219238\n",
      "3859) Lyapunov Risk = 0.9245431423187256, MSE = 0.019884707406163216, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002497214009054005, Lv_loss = 0.0, Circular Tuning Loss = 1.2780259847640991\n",
      "3860) Lyapunov Risk = 0.9245359897613525, MSE = 0.019980084151029587, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.000248871510848403, Lv_loss = 0.0, Circular Tuning Loss = 1.2778522968292236\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.1718750000000004, -1.1708984375000004]\n",
      "x2 : [0.011840191067365374, 0.013531646934131855]\n",
      "==============================\n",
      "3861) Lyapunov Risk = 0.9248271584510803, MSE = 0.019259415566921234, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.00024754778132773936, Lv_loss = 2.574019890744239e-05, Circular Tuning Loss = 1.2764893770217896\n",
      "3862) Lyapunov Risk = 0.9247023463249207, MSE = 0.020424015820026398, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.00024678563931956887, Lv_loss = 0.0, Circular Tuning Loss = 1.2763222455978394\n",
      "3863) Lyapunov Risk = 0.9242242574691772, MSE = 0.019402334466576576, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002461336553096771, Lv_loss = 0.0, Circular Tuning Loss = 1.2761588096618652\n",
      "3864) Lyapunov Risk = 0.924038290977478, MSE = 0.019605346024036407, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.00024558999575674534, Lv_loss = 0.0, Circular Tuning Loss = 1.2759993076324463\n",
      "3865) Lyapunov Risk = 0.9241883754730225, MSE = 0.0201413556933403, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002451459877192974, Lv_loss = 0.0, Circular Tuning Loss = 1.2758437395095825\n",
      "3866) Lyapunov Risk = 0.9241952300071716, MSE = 0.019318323582410812, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002447822771500796, Lv_loss = 8.952438292908482e-06, Circular Tuning Loss = 1.275691270828247\n",
      "3867) Lyapunov Risk = 0.9238998889923096, MSE = 0.020061638206243515, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002445057616569102, Lv_loss = 0.0, Circular Tuning Loss = 1.2755423784255981\n",
      "3868) Lyapunov Risk = 0.923655092716217, MSE = 0.01961825229227543, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 0.00024433783255517483, Lv_loss = 0.0, Circular Tuning Loss = 1.275396704673767\n",
      "3869) Lyapunov Risk = 0.9236732125282288, MSE = 0.019487963989377022, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 0.00024425878655165434, Lv_loss = 0.0, Circular Tuning Loss = 1.2752541303634644\n",
      "3870) Lyapunov Risk = 0.9237331748008728, MSE = 0.02013442851603031, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 0.00024427162134088576, Lv_loss = 0.0, Circular Tuning Loss = 1.275114893913269\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.0039062500000004, -1.0029296875000004]\n",
      "x2 : [0.44485289295958474, 0.44654434882635119]\n",
      "==============================\n",
      "3871) Lyapunov Risk = 0.9234060645103455, MSE = 0.01939702220261097, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002436901704641059, Lv_loss = 1.952904824520374e-07, Circular Tuning Loss = 1.2735658884048462\n",
      "3872) Lyapunov Risk = 0.9231677055358887, MSE = 0.019850920885801315, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 0.00024349361774511635, Lv_loss = 0.0, Circular Tuning Loss = 1.2734321355819702\n",
      "3873) Lyapunov Risk = 0.9230782985687256, MSE = 0.01976034790277481, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 0.00024320081865880638, Lv_loss = 0.0, Circular Tuning Loss = 1.2733007669448853\n",
      "3874) Lyapunov Risk = 0.9231064319610596, MSE = 0.01948518306016922, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002428152074571699, Lv_loss = 0.0, Circular Tuning Loss = 1.273171305656433\n",
      "3875) Lyapunov Risk = 0.9230582118034363, MSE = 0.02003897912800312, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.000242362599237822, Lv_loss = 0.0, Circular Tuning Loss = 1.273044228553772\n",
      "3876) Lyapunov Risk = 0.9228746294975281, MSE = 0.01950002834200859, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.00024189939722418785, Lv_loss = 0.0, Circular Tuning Loss = 1.2729190587997437\n",
      "3877) Lyapunov Risk = 0.9227256178855896, MSE = 0.019730158150196075, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.000241423724219203, Lv_loss = 0.0, Circular Tuning Loss = 1.2727962732315063\n",
      "3878) Lyapunov Risk = 0.9226832389831543, MSE = 0.01980893313884735, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.000240935361944139, Lv_loss = 0.0, Circular Tuning Loss = 1.272675633430481\n",
      "3879) Lyapunov Risk = 0.9226658344268799, MSE = 0.01950203999876976, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002404387923888862, Lv_loss = 0.0, Circular Tuning Loss = 1.2725566625595093\n",
      "3880) Lyapunov Risk = 0.9225751757621765, MSE = 0.019927028566598892, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.00023986658197827637, Lv_loss = 0.0, Circular Tuning Loss = 1.272439956665039\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.78125000000000022, -0.78027343750000022]\n",
      "x2 : [0.78027343750000022, 0.78125000000000022]\n",
      "==============================\n",
      "3881) Lyapunov Risk = 0.9222500920295715, MSE = 0.01956428587436676, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.00023874003090895712, Lv_loss = 0.0, Circular Tuning Loss = 1.2709864377975464\n",
      "3882) Lyapunov Risk = 0.922147274017334, MSE = 0.019687531515955925, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.00023805888486094773, Lv_loss = 0.0, Circular Tuning Loss = 1.2708734273910522\n",
      "3883) Lyapunov Risk = 0.9221056699752808, MSE = 0.01981182023882866, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.00023733190027996898, Lv_loss = 0.0, Circular Tuning Loss = 1.2707618474960327\n",
      "3884) Lyapunov Risk = 0.922055721282959, MSE = 0.019535137340426445, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.00023657275596633554, Lv_loss = 0.0, Circular Tuning Loss = 1.2706515789031982\n",
      "3885) Lyapunov Risk = 0.9219523668289185, MSE = 0.01983295939862728, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.00023578412947244942, Lv_loss = 0.0, Circular Tuning Loss = 1.2705426216125488\n",
      "3886) Lyapunov Risk = 0.9218350648880005, MSE = 0.019625980406999588, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.000234985796851106, Lv_loss = 0.0, Circular Tuning Loss = 1.270434856414795\n",
      "3887) Lyapunov Risk = 0.9217578172683716, MSE = 0.019627971574664116, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002341690706089139, Lv_loss = 0.0, Circular Tuning Loss = 1.2703276872634888\n",
      "3888) Lyapunov Risk = 0.9217073917388916, MSE = 0.019811058416962624, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.00023333456192631274, Lv_loss = 0.0, Circular Tuning Loss = 1.2702215909957886\n",
      "3889) Lyapunov Risk = 0.9216359257698059, MSE = 0.019568171352148056, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.00023246381897479296, Lv_loss = 0.0, Circular Tuning Loss = 1.2701159715652466\n",
      "3890) Lyapunov Risk = 0.9215363264083862, MSE = 0.019774150103330612, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.00023151577624958009, Lv_loss = 0.0, Circular Tuning Loss = 1.270011305809021\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.80566406250000022, -0.80468750000000022]\n",
      "x2 : [0.76562500000000022, 0.76660156250000022]\n",
      "==============================\n",
      "3891) Lyapunov Risk = 0.9212756752967834, MSE = 0.019677652046084404, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.00023002858506515622, Lv_loss = 0.0, Circular Tuning Loss = 1.2685917615890503\n",
      "3892) Lyapunov Risk = 0.9212031960487366, MSE = 0.01963205449283123, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.00022896041627973318, Lv_loss = 0.0, Circular Tuning Loss = 1.2684886455535889\n",
      "3893) Lyapunov Risk = 0.9211382269859314, MSE = 0.019775982946157455, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.00022783596068620682, Lv_loss = 0.0, Circular Tuning Loss = 1.268385887145996\n",
      "3894) Lyapunov Risk = 0.9210605025291443, MSE = 0.01960514858365059, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.00022666729637421668, Lv_loss = 0.0, Circular Tuning Loss = 1.2682836055755615\n",
      "3895) Lyapunov Risk = 0.9209722876548767, MSE = 0.0197246503084898, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.00022546242689713836, Lv_loss = 0.0, Circular Tuning Loss = 1.2681814432144165\n",
      "3896) Lyapunov Risk = 0.9208871722221375, MSE = 0.019688302651047707, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.00022422659094445407, Lv_loss = 0.0, Circular Tuning Loss = 1.2680799961090088\n",
      "3897) Lyapunov Risk = 0.9208133220672607, MSE = 0.019623473286628723, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.00022295888629741967, Lv_loss = 0.0, Circular Tuning Loss = 1.2679780721664429\n",
      "3898) Lyapunov Risk = 0.9207407236099243, MSE = 0.019754499197006226, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.000221660069655627, Lv_loss = 0.0, Circular Tuning Loss = 1.2678762674331665\n",
      "3899) Lyapunov Risk = 0.9206603765487671, MSE = 0.019636183977127075, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.00022034165158402175, Lv_loss = 0.0, Circular Tuning Loss = 1.267773985862732\n",
      "3900) Lyapunov Risk = 0.9205775856971741, MSE = 0.019691163673996925, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002190009254263714, Lv_loss = 0.0, Circular Tuning Loss = 1.267671823501587\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.89062500000000022, -0.88964843750000022]\n",
      "x2 : [0.65429687500000022, 0.65625000000000022]\n",
      "==============================\n",
      "3901) Lyapunov Risk = 0.9203342199325562, MSE = 0.019722411409020424, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00021719869982916862, Lv_loss = 0.0, Circular Tuning Loss = 1.2662248611450195\n",
      "3902) Lyapunov Risk = 0.9202585220336914, MSE = 0.01963336206972599, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002158306015189737, Lv_loss = 0.0, Circular Tuning Loss = 1.2661222219467163\n",
      "3903) Lyapunov Risk = 0.9201806783676147, MSE = 0.019730495288968086, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00021444671438075602, Lv_loss = 0.0, Circular Tuning Loss = 1.2660191059112549\n",
      "3904) Lyapunov Risk = 0.9201008677482605, MSE = 0.019665652886033058, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0002130568609572947, Lv_loss = 0.0, Circular Tuning Loss = 1.2659156322479248\n",
      "3905) Lyapunov Risk = 0.9200226068496704, MSE = 0.019660642370581627, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00021166211809031665, Lv_loss = 0.0, Circular Tuning Loss = 1.2658116817474365\n",
      "3906) Lyapunov Risk = 0.9199464321136475, MSE = 0.019726479426026344, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00021026933973189443, Lv_loss = 0.0, Circular Tuning Loss = 1.265707015991211\n",
      "3907) Lyapunov Risk = 0.919869065284729, MSE = 0.01963683031499386, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020888452127110213, Lv_loss = 0.0, Circular Tuning Loss = 1.2656018733978271\n",
      "3908) Lyapunov Risk = 0.9197898507118225, MSE = 0.019715536385774612, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020750443218275905, Lv_loss = 0.0, Circular Tuning Loss = 1.265496015548706\n",
      "3909) Lyapunov Risk = 0.9197114706039429, MSE = 0.019690290093421936, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020613541710190475, Lv_loss = 0.0, Circular Tuning Loss = 1.2653894424438477\n",
      "3910) Lyapunov Risk = 0.9196351766586304, MSE = 0.01965867541730404, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020477436191868037, Lv_loss = 0.0, Circular Tuning Loss = 1.265282154083252\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.5919267413546354, 1.5954623852528904]\n",
      "x2 : [0.86264249205090571, 0.86602540378443871]\n",
      "==============================\n",
      "3911) Lyapunov Risk = 0.9211082458496094, MSE = 0.01972857676446438, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020301173208281398, Lv_loss = 0.0, Circular Tuning Loss = 1.2675766944885254\n",
      "3912) Lyapunov Risk = 0.9210308194160461, MSE = 0.01963990367949009, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020178100385237485, Lv_loss = 0.0, Circular Tuning Loss = 1.2674683332443237\n",
      "3913) Lyapunov Risk = 0.9209520220756531, MSE = 0.019696276634931564, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00020063990086782724, Lv_loss = 0.0, Circular Tuning Loss = 1.267359733581543\n",
      "3914) Lyapunov Risk = 0.9208745360374451, MSE = 0.01968175359070301, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019958690972998738, Lv_loss = 0.0, Circular Tuning Loss = 1.267250895500183\n",
      "3915) Lyapunov Risk = 0.9207982420921326, MSE = 0.01964828185737133, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019862636690959334, Lv_loss = 5.8077965547909116e-08, Circular Tuning Loss = 1.2671418190002441\n",
      "3916) Lyapunov Risk = 0.9207220077514648, MSE = 0.01971203088760376, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001977373322006315, Lv_loss = 3.606539564771083e-07, Circular Tuning Loss = 1.267032504081726\n",
      "3917) Lyapunov Risk = 0.9206454157829285, MSE = 0.019652359187602997, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019686475570779294, Lv_loss = 7.099088747963833e-07, Circular Tuning Loss = 1.266922950744629\n",
      "3918) Lyapunov Risk = 0.9205688834190369, MSE = 0.01968998834490776, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001959698274731636, Lv_loss = 1.0537897878748481e-06, Circular Tuning Loss = 1.2668122053146362\n",
      "3919) Lyapunov Risk = 0.9204932451248169, MSE = 0.019685473293066025, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019503272778820246, Lv_loss = 1.4158837302602478e-06, Circular Tuning Loss = 1.2667008638381958\n",
      "3920) Lyapunov Risk = 0.9204179644584656, MSE = 0.019659806042909622, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019406084902584553, Lv_loss = 1.7881199028124684e-06, Circular Tuning Loss = 1.266588568687439\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.584855453558125, 1.5883910974563802]\n",
      "x2 : [0.86264249205090571, 0.86602540378443871]\n",
      "==============================\n",
      "3921) Lyapunov Risk = 0.9218648672103882, MSE = 0.019697537645697594, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019266424351371825, Lv_loss = 2.6599368538882118e-06, Circular Tuning Loss = 1.2688260078430176\n",
      "3922) Lyapunov Risk = 0.921789288520813, MSE = 0.019653962925076485, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00019172107568010688, Lv_loss = 3.985895546065876e-06, Circular Tuning Loss = 1.2687122821807861\n",
      "3923) Lyapunov Risk = 0.9217138886451721, MSE = 0.019676653668284416, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001908311533043161, Lv_loss = 5.104326191940345e-06, Circular Tuning Loss = 1.2685983180999756\n",
      "3924) Lyapunov Risk = 0.921639621257782, MSE = 0.019670585170388222, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001899487106129527, Lv_loss = 6.129345365479821e-06, Circular Tuning Loss = 1.2684836387634277\n",
      "3925) Lyapunov Risk = 0.9215656518936157, MSE = 0.019653625786304474, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00018907403864432126, Lv_loss = 7.052748969726963e-06, Circular Tuning Loss = 1.2683682441711426\n",
      "3926) Lyapunov Risk = 0.9214916825294495, MSE = 0.019680028781294823, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001882206415757537, Lv_loss = 7.906676728453021e-06, Circular Tuning Loss = 1.268251895904541\n",
      "3927) Lyapunov Risk = 0.9214179515838623, MSE = 0.019664505496621132, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00018736900528892875, Lv_loss = 8.689265087014064e-06, Circular Tuning Loss = 1.268134593963623\n",
      "3928) Lyapunov Risk = 0.9213445782661438, MSE = 0.019672490656375885, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00018650641140993685, Lv_loss = 9.432499609829392e-06, Circular Tuning Loss = 1.2680163383483887\n",
      "3929) Lyapunov Risk = 0.921271800994873, MSE = 0.019681405276060104, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00018563619232736528, Lv_loss = 1.0133737305295654e-05, Circular Tuning Loss = 1.2678974866867065\n",
      "3930) Lyapunov Risk = 0.9211985468864441, MSE = 0.019662579521536827, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00018477179401088506, Lv_loss = 1.0750699402706232e-05, Circular Tuning Loss = 1.267777442932129\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.2207031250000004, -1.2187586360652816]\n",
      "x2 : [-0.02706329386826371, -0.025371838001497227]\n",
      "==============================\n",
      "3931) Lyapunov Risk = 0.9211780428886414, MSE = 0.019673168659210205, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00018354272469878197, Lv_loss = 1.1308799003018066e-05, Circular Tuning Loss = 1.2666348218917847\n",
      "3932) Lyapunov Risk = 0.9211049675941467, MSE = 0.019682785496115685, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001827034866437316, Lv_loss = 1.1836445082735736e-05, Circular Tuning Loss = 1.266513466835022\n",
      "3933) Lyapunov Risk = 0.9210323095321655, MSE = 0.01966254971921444, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001818789605749771, Lv_loss = 1.2328555385465734e-05, Circular Tuning Loss = 1.2663915157318115\n",
      "3934) Lyapunov Risk = 0.9209597706794739, MSE = 0.01970175839960575, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00018106563948094845, Lv_loss = 1.2747910659527406e-05, Circular Tuning Loss = 1.2662690877914429\n",
      "3935) Lyapunov Risk = 0.9208868145942688, MSE = 0.0196746364235878, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00018026820907834917, Lv_loss = 1.3090997526887804e-05, Circular Tuning Loss = 1.266145944595337\n",
      "3936) Lyapunov Risk = 0.9208140969276428, MSE = 0.019685493782162666, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001794864801922813, Lv_loss = 1.3372956345847342e-05, Circular Tuning Loss = 1.2660225629806519\n",
      "3937) Lyapunov Risk = 0.920741856098175, MSE = 0.019688261672854424, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00017872291209641844, Lv_loss = 1.3615501302410848e-05, Circular Tuning Loss = 1.2658987045288086\n",
      "3938) Lyapunov Risk = 0.9206697344779968, MSE = 0.019661037251353264, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00017796702741179615, Lv_loss = 1.3848931303073186e-05, Circular Tuning Loss = 1.2657744884490967\n",
      "3939) Lyapunov Risk = 0.9205977320671082, MSE = 0.019691623747348785, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00017721937911119312, Lv_loss = 1.4066385119804181e-05, Circular Tuning Loss = 1.2656501531600952\n",
      "3940) Lyapunov Risk = 0.9205254912376404, MSE = 0.01965942606329918, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00017648110224399716, Lv_loss = 1.4261595424613915e-05, Circular Tuning Loss = 1.265525221824646\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.7262812094883322, 1.7301751283127627]\n",
      "x2 : [0.85925958031737282, 0.86602540378443871]\n",
      "==============================\n",
      "3941) Lyapunov Risk = 0.9223909378051758, MSE = 0.019680052995681763, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00017540818953420967, Lv_loss = 2.1500331058632582e-05, Circular Tuning Loss = 1.2685518264770508\n",
      "3942) Lyapunov Risk = 0.9223185777664185, MSE = 0.019665153697133064, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00017477991059422493, Lv_loss = 2.1292185920174234e-05, Circular Tuning Loss = 1.268426537513733\n",
      "3943) Lyapunov Risk = 0.9222463369369507, MSE = 0.01966691017150879, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00017423118697479367, Lv_loss = 2.08072397072101e-05, Circular Tuning Loss = 1.2683011293411255\n",
      "3944) Lyapunov Risk = 0.9221741557121277, MSE = 0.019674738869071007, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00017375475727021694, Lv_loss = 2.0103285351069644e-05, Circular Tuning Loss = 1.268175721168518\n",
      "3945) Lyapunov Risk = 0.9221020340919495, MSE = 0.01966179721057415, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00017334443691652268, Lv_loss = 1.919613714562729e-05, Circular Tuning Loss = 1.2680500745773315\n",
      "3946) Lyapunov Risk = 0.9220296144485474, MSE = 0.019677408039569855, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00017299610772170126, Lv_loss = 1.8094437109539285e-05, Circular Tuning Loss = 1.2679243087768555\n",
      "3947) Lyapunov Risk = 0.9219574332237244, MSE = 0.019664378836750984, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00017270815442316234, Lv_loss = 1.6794660041341558e-05, Circular Tuning Loss = 1.267798900604248\n",
      "3948) Lyapunov Risk = 0.9218850135803223, MSE = 0.019672144204378128, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00017247263167519122, Lv_loss = 1.531055931991432e-05, Circular Tuning Loss = 1.2676732540130615\n",
      "3949) Lyapunov Risk = 0.9218126535415649, MSE = 0.019663700833916664, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00017228611977770925, Lv_loss = 1.3678996765520424e-05, Circular Tuning Loss = 1.267547607421875\n",
      "3950) Lyapunov Risk = 0.9217402935028076, MSE = 0.019666993990540504, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001721433800412342, Lv_loss = 1.1920185897906777e-05, Circular Tuning Loss = 1.2674219608306885\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.2363281250000004, -1.2343750000000004]\n",
      "x2 : [-0.054126587736527419, -0.05243513186976094]\n",
      "==============================\n",
      "3951) Lyapunov Risk = 0.9217437505722046, MSE = 0.01966083236038685, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00017169232887681574, Lv_loss = 1.0045780982181896e-05, Circular Tuning Loss = 1.2663265466690063\n",
      "3952) Lyapunov Risk = 0.9216713309288025, MSE = 0.019685063511133194, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001716148544801399, Lv_loss = 8.121024620777462e-06, Circular Tuning Loss = 1.2662005424499512\n",
      "3953) Lyapunov Risk = 0.921599268913269, MSE = 0.019668009132146835, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00017155363457277417, Lv_loss = 6.135740022727987e-06, Circular Tuning Loss = 1.2660748958587646\n",
      "3954) Lyapunov Risk = 0.9215272665023804, MSE = 0.01970043033361435, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00017151591600850224, Lv_loss = 4.416546744323568e-06, Circular Tuning Loss = 1.2659493684768677\n",
      "3955) Lyapunov Risk = 0.9214553833007812, MSE = 0.019665826112031937, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00017149174527730793, Lv_loss = 3.5014006698474986e-06, Circular Tuning Loss = 1.2658240795135498\n",
      "3956) Lyapunov Risk = 0.9213836789131165, MSE = 0.01969880610704422, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001714552636258304, Lv_loss = 2.606087946332991e-06, Circular Tuning Loss = 1.2656984329223633\n",
      "3957) Lyapunov Risk = 0.9213123321533203, MSE = 0.019655223935842514, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00017136272799689323, Lv_loss = 1.7623394796828507e-06, Circular Tuning Loss = 1.2655730247497559\n",
      "3958) Lyapunov Risk = 0.9212406277656555, MSE = 0.01968362368643284, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00017122080316767097, Lv_loss = 1.0456425343363662e-06, Circular Tuning Loss = 1.2654472589492798\n",
      "3959) Lyapunov Risk = 0.9211690425872803, MSE = 0.01966134086251259, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00017102310084737837, Lv_loss = 5.888033456358244e-07, Circular Tuning Loss = 1.2653213739395142\n",
      "3960) Lyapunov Risk = 0.9210976958274841, MSE = 0.019666528329253197, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001707763149170205, Lv_loss = 2.67783036633773e-07, Circular Tuning Loss = 1.2651954889297485\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.8012077165645495, 1.8027756377319948]\n",
      "x2 : [0.86602540378443871, 0.86771685965120526]\n",
      "==============================\n",
      "3961) Lyapunov Risk = 0.9231774210929871, MSE = 0.01967461407184601, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00017013428441714495, Lv_loss = 7.061262152774361e-08, Circular Tuning Loss = 1.2686728239059448\n",
      "3962) Lyapunov Risk = 0.9231060147285461, MSE = 0.01965271309018135, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001698680134722963, Lv_loss = 0.0, Circular Tuning Loss = 1.2685463428497314\n",
      "3963) Lyapunov Risk = 0.9230344295501709, MSE = 0.01968376338481903, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016963458620011806, Lv_loss = 0.0, Circular Tuning Loss = 1.2684195041656494\n",
      "3964) Lyapunov Risk = 0.9229629039764404, MSE = 0.019654277712106705, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016943755326792598, Lv_loss = 0.0, Circular Tuning Loss = 1.2682926654815674\n",
      "3965) Lyapunov Risk = 0.9228915572166443, MSE = 0.019674811512231827, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016925600357353687, Lv_loss = 0.0, Circular Tuning Loss = 1.2681655883789062\n",
      "3966) Lyapunov Risk = 0.9228200912475586, MSE = 0.01966473087668419, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016909070836845785, Lv_loss = 0.0, Circular Tuning Loss = 1.2680381536483765\n",
      "3967) Lyapunov Risk = 0.9227489233016968, MSE = 0.019656961783766747, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016894162399694324, Lv_loss = 0.0, Circular Tuning Loss = 1.2679105997085571\n",
      "3968) Lyapunov Risk = 0.9226776361465454, MSE = 0.019666263833642006, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016881301417015493, Lv_loss = 0.0, Circular Tuning Loss = 1.2677829265594482\n",
      "3969) Lyapunov Risk = 0.9226065278053284, MSE = 0.01965043880045414, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001687046606093645, Lv_loss = 0.0, Circular Tuning Loss = 1.2676550149917603\n",
      "3970) Lyapunov Risk = 0.9225353598594666, MSE = 0.0196661576628685, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016861823678482324, Lv_loss = 0.0, Circular Tuning Loss = 1.2675269842147827\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.7902322683924323, 1.7965039530622136]\n",
      "x2 : [0.86940831551797171, 0.8727912272515046]\n",
      "==============================\n",
      "3971) Lyapunov Risk = 0.9245787858963013, MSE = 0.019655592739582062, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001681834110058844, Lv_loss = 0.0, Circular Tuning Loss = 1.2709366083145142\n",
      "3972) Lyapunov Risk = 0.9245075583457947, MSE = 0.019656598567962646, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016812645480968058, Lv_loss = 0.0, Circular Tuning Loss = 1.2708079814910889\n",
      "3973) Lyapunov Risk = 0.9244365692138672, MSE = 0.01966014876961708, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016807868087198585, Lv_loss = 0.0, Circular Tuning Loss = 1.2706793546676636\n",
      "3974) Lyapunov Risk = 0.9243659973144531, MSE = 0.019633300602436066, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.000167999038239941, Lv_loss = 0.0, Circular Tuning Loss = 1.2705506086349487\n",
      "3975) Lyapunov Risk = 0.9242953062057495, MSE = 0.019663861021399498, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016786466585472226, Lv_loss = 0.0, Circular Tuning Loss = 1.2704213857650757\n",
      "3976) Lyapunov Risk = 0.9242246150970459, MSE = 0.019618364050984383, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001676769315963611, Lv_loss = 0.0, Circular Tuning Loss = 1.2702921628952026\n",
      "3977) Lyapunov Risk = 0.9241538643836975, MSE = 0.019671844318509102, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001674487575655803, Lv_loss = 0.0, Circular Tuning Loss = 1.27016282081604\n",
      "3978) Lyapunov Risk = 0.9240826368331909, MSE = 0.019614780321717262, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016717806283850223, Lv_loss = 0.0, Circular Tuning Loss = 1.2700334787368774\n",
      "3979) Lyapunov Risk = 0.9240113496780396, MSE = 0.01966661773622036, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016687592142261565, Lv_loss = 0.0, Circular Tuning Loss = 1.2699038982391357\n",
      "3980) Lyapunov Risk = 0.9239403605461121, MSE = 0.019622527062892914, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016654808132443577, Lv_loss = 0.0, Circular Tuning Loss = 1.2697739601135254\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.2441406250000004, -1.2421875000000004]\n",
      "x2 : [-0.067658234670659276, -0.065966778803892789]\n",
      "==============================\n",
      "3981) Lyapunov Risk = 0.9239513874053955, MSE = 0.019646715372800827, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016589894948992878, Lv_loss = 0.0, Circular Tuning Loss = 1.2686909437179565\n",
      "3982) Lyapunov Risk = 0.9238814115524292, MSE = 0.01965513452887535, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001655997766647488, Lv_loss = 0.0, Circular Tuning Loss = 1.2685599327087402\n",
      "3983) Lyapunov Risk = 0.9238121509552002, MSE = 0.019634123891592026, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016535115719307214, Lv_loss = 0.0, Circular Tuning Loss = 1.268428087234497\n",
      "3984) Lyapunov Risk = 0.9237423539161682, MSE = 0.019677309319376945, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016514708113390952, Lv_loss = 0.0, Circular Tuning Loss = 1.2682958841323853\n",
      "3985) Lyapunov Risk = 0.9236721992492676, MSE = 0.019635111093521118, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001649885525694117, Lv_loss = 0.0, Circular Tuning Loss = 1.2681633234024048\n",
      "3986) Lyapunov Risk = 0.9236021041870117, MSE = 0.019661566242575645, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016487120592501014, Lv_loss = 0.0, Circular Tuning Loss = 1.2680306434631348\n",
      "3987) Lyapunov Risk = 0.9235320091247559, MSE = 0.01964336261153221, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016479272744618356, Lv_loss = 0.0, Circular Tuning Loss = 1.2678974866867065\n",
      "3988) Lyapunov Risk = 0.9234625697135925, MSE = 0.019638897851109505, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016475075972266495, Lv_loss = 0.0, Circular Tuning Loss = 1.2677644491195679\n",
      "3989) Lyapunov Risk = 0.9233933091163635, MSE = 0.019652487710118294, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016473974392283708, Lv_loss = 0.0, Circular Tuning Loss = 1.2676312923431396\n",
      "3990) Lyapunov Risk = 0.9233237504959106, MSE = 0.019633699208498, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016475867596454918, Lv_loss = 0.0, Circular Tuning Loss = 1.2674977779388428\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0389017926884687, 1.0489017926884685]\n",
      "x2 : [-0.92015199152096616, -0.91338616805390016]\n",
      "==============================\n",
      "3991) Lyapunov Risk = 0.9238225221633911, MSE = 0.019648322835564613, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016447539383079857, Lv_loss = 0.0, Circular Tuning Loss = 1.2686721086502075\n",
      "3992) Lyapunov Risk = 0.9237531423568726, MSE = 0.01963127590715885, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016450845578219742, Lv_loss = 0.0, Circular Tuning Loss = 1.268538236618042\n",
      "3993) Lyapunov Risk = 0.9236838817596436, MSE = 0.01963784545660019, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016453010903205723, Lv_loss = 0.0, Circular Tuning Loss = 1.2684037685394287\n",
      "3994) Lyapunov Risk = 0.9236149787902832, MSE = 0.01963821053504944, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016452671843580902, Lv_loss = 0.0, Circular Tuning Loss = 1.2682691812515259\n",
      "3995) Lyapunov Risk = 0.9235460758209229, MSE = 0.01963072083890438, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016450499242637306, Lv_loss = 0.0, Circular Tuning Loss = 1.2681341171264648\n",
      "3996) Lyapunov Risk = 0.9234775304794312, MSE = 0.01964227855205536, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016445601067971438, Lv_loss = 0.0, Circular Tuning Loss = 1.2679988145828247\n",
      "3997) Lyapunov Risk = 0.9234088063240051, MSE = 0.01962721161544323, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001643746072659269, Lv_loss = 0.0, Circular Tuning Loss = 1.267863392829895\n",
      "3998) Lyapunov Risk = 0.9233403205871582, MSE = 0.019634762778878212, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016426747606601566, Lv_loss = 0.0, Circular Tuning Loss = 1.2677277326583862\n",
      "3999) Lyapunov Risk = 0.9232719540596008, MSE = 0.01962103508412838, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001641245762584731, Lv_loss = 0.0, Circular Tuning Loss = 1.2675920724868774\n",
      "4000) Lyapunov Risk = 0.9232039451599121, MSE = 0.01964004896581173, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016396137652918696, Lv_loss = 0.0, Circular Tuning Loss = 1.267456293106079\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0389017926884687, 1.0489017926884685]\n",
      "x2 : [-0.92015199152096616, -0.91338616805390016]\n",
      "==============================\n",
      "4001) Lyapunov Risk = 0.9237037897109985, MSE = 0.01960146427154541, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016343759489245713, Lv_loss = 0.0, Circular Tuning Loss = 1.2686233520507812\n",
      "4002) Lyapunov Risk = 0.9236369729042053, MSE = 0.019652506336569786, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016319521819241345, Lv_loss = 0.0, Circular Tuning Loss = 1.2684868574142456\n",
      "4003) Lyapunov Risk = 0.9235715270042419, MSE = 0.01956988498568535, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016288695042021573, Lv_loss = 0.0, Circular Tuning Loss = 1.2683496475219727\n",
      "4004) Lyapunov Risk = 0.9235070943832397, MSE = 0.019680427387356758, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016253576905000955, Lv_loss = 0.0, Circular Tuning Loss = 1.268211841583252\n",
      "4005) Lyapunov Risk = 0.9234415888786316, MSE = 0.019542142748832703, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016212486661970615, Lv_loss = 0.0, Circular Tuning Loss = 1.268073320388794\n",
      "4006) Lyapunov Risk = 0.9233765602111816, MSE = 0.019705800339579582, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016168723232112825, Lv_loss = 0.0, Circular Tuning Loss = 1.2679344415664673\n",
      "4007) Lyapunov Risk = 0.9233081936836243, MSE = 0.01953294686973095, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016120194050017744, Lv_loss = 0.0, Circular Tuning Loss = 1.2677950859069824\n",
      "4008) Lyapunov Risk = 0.9232409000396729, MSE = 0.01971050351858139, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016070192214101553, Lv_loss = 0.0, Circular Tuning Loss = 1.2676557302474976\n",
      "4009) Lyapunov Risk = 0.923171877861023, MSE = 0.01952851004898548, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00016015901928767562, Lv_loss = 0.0, Circular Tuning Loss = 1.2675158977508545\n",
      "4010) Lyapunov Risk = 0.9231045246124268, MSE = 0.019706018269062042, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015961306053213775, Lv_loss = 0.0, Circular Tuning Loss = 1.2673759460449219\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.2519531250000004, -1.2500000000000004]\n",
      "x2 : [-0.067658234670659276, -0.065966778803892789]\n",
      "==============================\n",
      "4011) Lyapunov Risk = 0.9231244325637817, MSE = 0.019526571035385132, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015872229414526373, Lv_loss = 0.0, Circular Tuning Loss = 1.2663052082061768\n",
      "4012) Lyapunov Risk = 0.9230579137802124, MSE = 0.01971212774515152, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001581231044838205, Lv_loss = 0.0, Circular Tuning Loss = 1.266164779663086\n",
      "4013) Lyapunov Risk = 0.9229904413223267, MSE = 0.01954503171145916, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015748840814922005, Lv_loss = 0.0, Circular Tuning Loss = 1.2660239934921265\n",
      "4014) Lyapunov Risk = 0.922924280166626, MSE = 0.019706401973962784, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015682782395742834, Lv_loss = 0.0, Circular Tuning Loss = 1.2658827304840088\n",
      "4015) Lyapunov Risk = 0.9228595495223999, MSE = 0.019565042108297348, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001561359385959804, Lv_loss = 0.0, Circular Tuning Loss = 1.2657413482666016\n",
      "4016) Lyapunov Risk = 0.922796368598938, MSE = 0.01968313753604889, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001554208720335737, Lv_loss = 0.0, Circular Tuning Loss = 1.2655996084213257\n",
      "4017) Lyapunov Risk = 0.9227344393730164, MSE = 0.019575420767068863, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015468636411242187, Lv_loss = 0.0, Circular Tuning Loss = 1.2654577493667603\n",
      "4018) Lyapunov Risk = 0.9226732850074768, MSE = 0.019673995673656464, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001539375225547701, Lv_loss = 0.0, Circular Tuning Loss = 1.2653158903121948\n",
      "4019) Lyapunov Risk = 0.9226125478744507, MSE = 0.019576331600546837, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015318304940592498, Lv_loss = 0.0, Circular Tuning Loss = 1.265174150466919\n",
      "4020) Lyapunov Risk = 0.9225518703460693, MSE = 0.01969231106340885, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015242422523442656, Lv_loss = 0.0, Circular Tuning Loss = 1.265032172203064\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.2441406250000004, -1.2421875000000004]\n",
      "x2 : [-0.067658234670659276, -0.065966778803892789]\n",
      "==============================\n",
      "4021) Lyapunov Risk = 0.9225732088088989, MSE = 0.0195524450391531, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015136755246203393, Lv_loss = 0.0, Circular Tuning Loss = 1.263941764831543\n",
      "4022) Lyapunov Risk = 0.922518789768219, MSE = 0.019759435206651688, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00015061300655361265, Lv_loss = 0.0, Circular Tuning Loss = 1.263800024986267\n",
      "4023) Lyapunov Risk = 0.9224693775177002, MSE = 0.01951667293906212, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00014986195310484618, Lv_loss = 0.0, Circular Tuning Loss = 1.2636587619781494\n",
      "4024) Lyapunov Risk = 0.9224253296852112, MSE = 0.019848115742206573, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00014911277685314417, Lv_loss = 0.0, Circular Tuning Loss = 1.2635176181793213\n",
      "4025) Lyapunov Risk = 0.9223862886428833, MSE = 0.01948074996471405, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001483720843680203, Lv_loss = 0.0, Circular Tuning Loss = 1.2633769512176514\n",
      "4026) Lyapunov Risk = 0.9223537445068359, MSE = 0.019913170486688614, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00014763200306333601, Lv_loss = 0.0, Circular Tuning Loss = 1.2632362842559814\n",
      "4027) Lyapunov Risk = 0.9223297238349915, MSE = 0.01944226771593094, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00014689656381960958, Lv_loss = 0.0, Circular Tuning Loss = 1.2630963325500488\n",
      "4028) Lyapunov Risk = 0.9223147630691528, MSE = 0.019988244399428368, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00014616423868574202, Lv_loss = 0.0, Circular Tuning Loss = 1.2629562616348267\n",
      "4029) Lyapunov Risk = 0.9223096370697021, MSE = 0.019419800490140915, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001454437879147008, Lv_loss = 0.0, Circular Tuning Loss = 1.2628166675567627\n",
      "4030) Lyapunov Risk = 0.9223143458366394, MSE = 0.02010003663599491, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00014474168710876256, Lv_loss = 0.0, Circular Tuning Loss = 1.2626773118972778\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.2363281250000004, -1.2343750000000004]\n",
      "x2 : [-0.02706329386826371, -0.025371838001497227]\n",
      "==============================\n",
      "4031) Lyapunov Risk = 0.9223808646202087, MSE = 0.01940300129354, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00014376446779351681, Lv_loss = 0.0, Circular Tuning Loss = 1.261554479598999\n",
      "4032) Lyapunov Risk = 0.9224050641059875, MSE = 0.02026432938873768, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00014310510596260428, Lv_loss = 0.0, Circular Tuning Loss = 1.261415958404541\n",
      "4033) Lyapunov Risk = 0.9224079847335815, MSE = 0.019376229494810104, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001424593065166846, Lv_loss = 0.0, Circular Tuning Loss = 1.2612786293029785\n",
      "4034) Lyapunov Risk = 0.9223935604095459, MSE = 0.020403215661644936, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00014185676991473883, Lv_loss = 0.0, Circular Tuning Loss = 1.2611415386199951\n",
      "4035) Lyapunov Risk = 0.9223101735115051, MSE = 0.01933232694864273, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001412695273756981, Lv_loss = 0.0, Circular Tuning Loss = 1.2610054016113281\n",
      "4036) Lyapunov Risk = 0.9221746921539307, MSE = 0.020368874073028564, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00014071838813833892, Lv_loss = 0.0, Circular Tuning Loss = 1.2608696222305298\n",
      "4037) Lyapunov Risk = 0.9220002293586731, MSE = 0.0192796029150486, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00014014318003319204, Lv_loss = 0.0, Circular Tuning Loss = 1.2607342004776\n",
      "4038) Lyapunov Risk = 0.9218308925628662, MSE = 0.020255565643310547, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00013962425873614848, Lv_loss = 0.0, Circular Tuning Loss = 1.2605993747711182\n",
      "4039) Lyapunov Risk = 0.921683132648468, MSE = 0.019260700792074203, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001390761899529025, Lv_loss = 0.0, Circular Tuning Loss = 1.2604644298553467\n",
      "4040) Lyapunov Risk = 0.9215967059135437, MSE = 0.02015737257897854, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00013858517922926694, Lv_loss = 0.0, Circular Tuning Loss = 1.2603304386138916\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0138150540093438, 1.0238150540093436]\n",
      "x2 : [-0.92015199152096616, -0.91338616805390016]\n",
      "==============================\n",
      "4041) Lyapunov Risk = 0.9220836162567139, MSE = 0.019342999905347824, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00013777779531665146, Lv_loss = 0.0, Circular Tuning Loss = 1.2614057064056396\n",
      "4042) Lyapunov Risk = 0.9220951795578003, MSE = 0.020118236541748047, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00013727278565056622, Lv_loss = 0.0, Circular Tuning Loss = 1.2612718343734741\n",
      "4043) Lyapunov Risk = 0.9221089482307434, MSE = 0.019477462396025658, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00013670852058567107, Lv_loss = 0.0, Circular Tuning Loss = 1.2611370086669922\n",
      "4044) Lyapunov Risk = 0.9220892786979675, MSE = 0.020074428990483284, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00013618162483908236, Lv_loss = 0.0, Circular Tuning Loss = 1.261003017425537\n",
      "4045) Lyapunov Risk = 0.92201167345047, MSE = 0.0195581316947937, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001356019638478756, Lv_loss = 0.0, Circular Tuning Loss = 1.2608678340911865\n",
      "4046) Lyapunov Risk = 0.9218790531158447, MSE = 0.019985459744930267, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00013507722178474069, Lv_loss = 0.0, Circular Tuning Loss = 1.2607340812683105\n",
      "4047) Lyapunov Risk = 0.921700656414032, MSE = 0.019532300531864166, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001345032505923882, Lv_loss = 0.0, Circular Tuning Loss = 1.260599136352539\n",
      "4048) Lyapunov Risk = 0.9215225577354431, MSE = 0.019898302853107452, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00013398434384725988, Lv_loss = 0.0, Circular Tuning Loss = 1.2604655027389526\n",
      "4049) Lyapunov Risk = 0.921362042427063, MSE = 0.019461628049612045, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001334204716840759, Lv_loss = 0.0, Circular Tuning Loss = 1.2603312730789185\n",
      "4050) Lyapunov Risk = 0.9212315678596497, MSE = 0.019842350855469704, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00013286128523759544, Lv_loss = 0.0, Circular Tuning Loss = 1.2601975202560425\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0138150540093438, 1.0238150540093436]\n",
      "x2 : [-0.92015199152096616, -0.91338616805390016]\n",
      "==============================\n",
      "4051) Lyapunov Risk = 0.9216602444648743, MSE = 0.019484173506498337, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.000132010318338871, Lv_loss = 0.0, Circular Tuning Loss = 1.2612806558609009\n",
      "4052) Lyapunov Risk = 0.9216111898422241, MSE = 0.019741348922252655, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00013137007772456855, Lv_loss = 0.0, Circular Tuning Loss = 1.261147141456604\n",
      "4053) Lyapunov Risk = 0.921585738658905, MSE = 0.01959727331995964, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00013067912368569523, Lv_loss = 0.0, Circular Tuning Loss = 1.2610130310058594\n",
      "4054) Lyapunov Risk = 0.9215555191040039, MSE = 0.019658932462334633, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00012994397548027337, Lv_loss = 0.0, Circular Tuning Loss = 1.2608784437179565\n",
      "4055) Lyapunov Risk = 0.9214988350868225, MSE = 0.019683100283145905, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00012918896391056478, Lv_loss = 0.0, Circular Tuning Loss = 1.2607437372207642\n",
      "4056) Lyapunov Risk = 0.9214081764221191, MSE = 0.019602391868829727, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00012843008153140545, Lv_loss = 0.0, Circular Tuning Loss = 1.260608434677124\n",
      "4057) Lyapunov Risk = 0.9212995767593384, MSE = 0.01968061737716198, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.000127678838907741, Lv_loss = 0.0, Circular Tuning Loss = 1.260473370552063\n",
      "4058) Lyapunov Risk = 0.9211909174919128, MSE = 0.0195931326597929, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001269278727704659, Lv_loss = 0.0, Circular Tuning Loss = 1.2603378295898438\n",
      "4059) Lyapunov Risk = 0.9211035370826721, MSE = 0.019636133685708046, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00012618718028534204, Lv_loss = 0.0, Circular Tuning Loss = 1.260202407836914\n",
      "4060) Lyapunov Risk = 0.921039342880249, MSE = 0.01961250975728035, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00012545361823868006, Lv_loss = 0.0, Circular Tuning Loss = 1.2600666284561157\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0012716846697813, 1.0112716846697811]\n",
      "x2 : [-0.91338616805390016, -0.90662034458683427]\n",
      "==============================\n",
      "4061) Lyapunov Risk = 0.9214667677879333, MSE = 0.019612843170762062, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00012448358756955713, Lv_loss = 0.0, Circular Tuning Loss = 1.261055827140808\n",
      "4062) Lyapunov Risk = 0.9214251041412354, MSE = 0.01963549479842186, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.000123753838124685, Lv_loss = 0.0, Circular Tuning Loss = 1.260919451713562\n",
      "4063) Lyapunov Risk = 0.921375036239624, MSE = 0.01960580423474312, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00012300974049139768, Lv_loss = 0.0, Circular Tuning Loss = 1.2607825994491577\n",
      "4064) Lyapunov Risk = 0.9213126301765442, MSE = 0.019630875438451767, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00012224758393131196, Lv_loss = 0.0, Circular Tuning Loss = 1.2606455087661743\n",
      "4065) Lyapunov Risk = 0.9212349653244019, MSE = 0.0196166280657053, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00012146578956162557, Lv_loss = 0.0, Circular Tuning Loss = 1.2605081796646118\n",
      "4066) Lyapunov Risk = 0.9211523532867432, MSE = 0.019598374143242836, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00012068193609593436, Lv_loss = 0.0, Circular Tuning Loss = 1.2603709697723389\n",
      "4067) Lyapunov Risk = 0.9210705757141113, MSE = 0.019640998914837837, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00011989071208517998, Lv_loss = 0.0, Circular Tuning Loss = 1.2602336406707764\n",
      "4068) Lyapunov Risk = 0.9209962487220764, MSE = 0.019559239968657494, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00011910616012755781, Lv_loss = 0.0, Circular Tuning Loss = 1.260096549987793\n",
      "4069) Lyapunov Risk = 0.9209303259849548, MSE = 0.019664449617266655, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00011834059841930866, Lv_loss = 0.0, Circular Tuning Loss = 1.2599595785140991\n",
      "4070) Lyapunov Risk = 0.9208692908287048, MSE = 0.01954401656985283, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00011759786866605282, Lv_loss = 0.0, Circular Tuning Loss = 1.2598235607147217\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0012716846697813, 1.0112716846697811]\n",
      "x2 : [-0.92015199152096616, -0.91338616805390016]\n",
      "==============================\n",
      "4071) Lyapunov Risk = 0.921298086643219, MSE = 0.019648855552077293, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00011666365753626451, Lv_loss = 0.0, Circular Tuning Loss = 1.2608426809310913\n",
      "4072) Lyapunov Risk = 0.9212354421615601, MSE = 0.019561590626835823, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001159986641141586, Lv_loss = 0.0, Circular Tuning Loss = 1.2607085704803467\n",
      "4073) Lyapunov Risk = 0.9211704134941101, MSE = 0.01960696466267109, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00011535617522895336, Lv_loss = 0.0, Circular Tuning Loss = 1.2605750560760498\n",
      "4074) Lyapunov Risk = 0.9211034178733826, MSE = 0.019605902954936028, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00011474141501821578, Lv_loss = 0.0, Circular Tuning Loss = 1.260442852973938\n",
      "4075) Lyapunov Risk = 0.9210366606712341, MSE = 0.019553357735276222, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001141568718594499, Lv_loss = 0.0, Circular Tuning Loss = 1.2603118419647217\n",
      "4076) Lyapunov Risk = 0.9209716320037842, MSE = 0.019660500809550285, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00011360777716618031, Lv_loss = 0.0, Circular Tuning Loss = 1.2601823806762695\n",
      "4077) Lyapunov Risk = 0.9209078550338745, MSE = 0.019513839855790138, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00011309567344142124, Lv_loss = 0.0, Circular Tuning Loss = 1.260054588317871\n",
      "4078) Lyapunov Risk = 0.920844316482544, MSE = 0.019686859101057053, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00011260998871875927, Lv_loss = 0.0, Circular Tuning Loss = 1.2599282264709473\n",
      "4079) Lyapunov Risk = 0.920779287815094, MSE = 0.019501101225614548, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00011215553968213499, Lv_loss = 0.0, Circular Tuning Loss = 1.2598035335540771\n",
      "4080) Lyapunov Risk = 0.9207128286361694, MSE = 0.019672691822052002, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001117290448746644, Lv_loss = 0.0, Circular Tuning Loss = 1.2596807479858398\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0012716846697813, 1.0112716846697811]\n",
      "x2 : [-0.92691781498803205, -0.92015199152096616]\n",
      "==============================\n",
      "4081) Lyapunov Risk = 0.9211448431015015, MSE = 0.019519217312335968, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00011111542698927224, Lv_loss = 0.0, Circular Tuning Loss = 1.2607359886169434\n",
      "4082) Lyapunov Risk = 0.9210770726203918, MSE = 0.019624652341008186, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00011072610504925251, Lv_loss = 0.0, Circular Tuning Loss = 1.2606154680252075\n",
      "4083) Lyapunov Risk = 0.9210106730461121, MSE = 0.019560953602194786, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00011034507042495534, Lv_loss = 0.0, Circular Tuning Loss = 1.2604957818984985\n",
      "4084) Lyapunov Risk = 0.9209460616111755, MSE = 0.019572975113987923, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00010997433128068224, Lv_loss = 0.0, Circular Tuning Loss = 1.2603769302368164\n",
      "4085) Lyapunov Risk = 0.9208829402923584, MSE = 0.019607573747634888, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00010961325460812077, Lv_loss = 0.0, Circular Tuning Loss = 1.2602585554122925\n",
      "4086) Lyapunov Risk = 0.9208205938339233, MSE = 0.019534016028046608, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00010926096729235724, Lv_loss = 0.0, Circular Tuning Loss = 1.260141134262085\n",
      "4087) Lyapunov Risk = 0.9207584261894226, MSE = 0.01964038982987404, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00010891640704357997, Lv_loss = 0.0, Circular Tuning Loss = 1.260024070739746\n",
      "4088) Lyapunov Risk = 0.9206972718238831, MSE = 0.019503887742757797, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00010857600864255801, Lv_loss = 0.0, Circular Tuning Loss = 1.2599072456359863\n",
      "4089) Lyapunov Risk = 0.9206358790397644, MSE = 0.019665967673063278, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00010824411583598703, Lv_loss = 0.0, Circular Tuning Loss = 1.2597908973693848\n",
      "4090) Lyapunov Risk = 0.9205827116966248, MSE = 0.019455891102552414, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00010789971565827727, Lv_loss = 0.0, Circular Tuning Loss = 1.2596744298934937\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [0.49218750000000011, 0.50000000000000011]\n",
      "x2 : [-1.0000000000000002, -0.99218750000000022]\n",
      "==============================\n",
      "4091) Lyapunov Risk = 0.9204949736595154, MSE = 0.01973775215446949, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00010734387615229934, Lv_loss = 0.0, Circular Tuning Loss = 1.2595150470733643\n",
      "4092) Lyapunov Risk = 0.9204651713371277, MSE = 0.01936839334666729, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00010698899131966755, Lv_loss = 0.0, Circular Tuning Loss = 1.259398341178894\n",
      "4093) Lyapunov Risk = 0.9204551577568054, MSE = 0.01989104598760605, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00010665252921171486, Lv_loss = 0.0, Circular Tuning Loss = 1.2592816352844238\n",
      "4094) Lyapunov Risk = 0.9205097556114197, MSE = 0.01923317275941372, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00010629287862684578, Lv_loss = 0.0, Circular Tuning Loss = 1.2591636180877686\n",
      "4095) Lyapunov Risk = 0.920648992061615, MSE = 0.02025042474269867, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00010596408537821844, Lv_loss = 0.0, Circular Tuning Loss = 1.2590460777282715\n",
      "4096) Lyapunov Risk = 0.9208884835243225, MSE = 0.019087808206677437, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001056186156347394, Lv_loss = 0.0, Circular Tuning Loss = 1.2589272260665894\n",
      "4097) Lyapunov Risk = 0.9212925434112549, MSE = 0.020864328369498253, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00010531196312513202, Lv_loss = 0.0, Circular Tuning Loss = 1.258809208869934\n",
      "4098) Lyapunov Risk = 0.9217829704284668, MSE = 0.01901960000395775, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001049912316375412, Lv_loss = 0.0, Circular Tuning Loss = 1.2586904764175415\n",
      "4099) Lyapunov Risk = 0.9222326278686523, MSE = 0.021556079387664795, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00010468759865034372, Lv_loss = 0.0, Circular Tuning Loss = 1.2585713863372803\n",
      "4100) Lyapunov Risk = 0.9224354028701782, MSE = 0.019042573869228363, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00010438179015181959, Lv_loss = 6.483248398581054e-06, Circular Tuning Loss = 1.2584521770477295\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [0.49609375000000011, 0.50000000000000011]\n",
      "x2 : [-0.75000000000000022, -0.74218750000000022]\n",
      "==============================\n",
      "4101) Lyapunov Risk = 0.9217336773872375, MSE = 0.021625524386763573, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00010388329974375665, Lv_loss = 0.0, Circular Tuning Loss = 1.2574372291564941\n",
      "4102) Lyapunov Risk = 0.9210890531539917, MSE = 0.0190241951495409, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00010360663873143494, Lv_loss = 0.0, Circular Tuning Loss = 1.257317304611206\n",
      "4103) Lyapunov Risk = 0.920234203338623, MSE = 0.020719151943922043, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00010337133426219225, Lv_loss = 0.0, Circular Tuning Loss = 1.2571970224380493\n",
      "4104) Lyapunov Risk = 0.9194939732551575, MSE = 0.019179796800017357, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00010313142411177978, Lv_loss = 0.0, Circular Tuning Loss = 1.2570760250091553\n",
      "4105) Lyapunov Risk = 0.9191017746925354, MSE = 0.0196889229118824, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00010292364459019154, Lv_loss = 0.0, Circular Tuning Loss = 1.2569550275802612\n",
      "4106) Lyapunov Risk = 0.9190719723701477, MSE = 0.019751952961087227, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00010270916391164064, Lv_loss = 0.0, Circular Tuning Loss = 1.2568333148956299\n",
      "4107) Lyapunov Risk = 0.9193034172058105, MSE = 0.019187642261385918, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.000102479629276786, Lv_loss = 0.0, Circular Tuning Loss = 1.2567105293273926\n",
      "4108) Lyapunov Risk = 0.9196151494979858, MSE = 0.020473476499319077, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00010227441816823557, Lv_loss = 0.0, Circular Tuning Loss = 1.2565884590148926\n",
      "4109) Lyapunov Risk = 0.9197767972946167, MSE = 0.019045108929276466, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00010206009028479457, Lv_loss = 0.0, Circular Tuning Loss = 1.2564656734466553\n",
      "4110) Lyapunov Risk = 0.919754147529602, MSE = 0.020682141184806824, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00010188433952862397, Lv_loss = 0.0, Circular Tuning Loss = 1.2563436031341553\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.26562500000000011, -0.26464843750000011]\n",
      "x2 : [1.2636718750000004, 1.2656250000000004]\n",
      "==============================\n",
      "4111) Lyapunov Risk = 0.91957026720047, MSE = 0.019077593460679054, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00010150102025363594, Lv_loss = 0.0, Circular Tuning Loss = 1.2555804252624512\n",
      "4112) Lyapunov Risk = 0.91929692029953, MSE = 0.020292025059461594, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00010136010678252205, Lv_loss = 0.0, Circular Tuning Loss = 1.2554588317871094\n",
      "4113) Lyapunov Risk = 0.9190433025360107, MSE = 0.019330039620399475, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00010121248487848788, Lv_loss = 0.0, Circular Tuning Loss = 1.2553367614746094\n",
      "4114) Lyapunov Risk = 0.9189196825027466, MSE = 0.019784405827522278, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00010110598668688908, Lv_loss = 0.0, Circular Tuning Loss = 1.2552158832550049\n",
      "4115) Lyapunov Risk = 0.9188193082809448, MSE = 0.019639214500784874, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00010098588245455176, Lv_loss = 0.0, Circular Tuning Loss = 1.2550939321517944\n",
      "4116) Lyapunov Risk = 0.9186897873878479, MSE = 0.019483886659145355, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00010088151611853391, Lv_loss = 0.0, Circular Tuning Loss = 1.2549725770950317\n",
      "4117) Lyapunov Risk = 0.9185429811477661, MSE = 0.01975421980023384, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00010077324986923486, Lv_loss = 0.0, Circular Tuning Loss = 1.2548506259918213\n",
      "4118) Lyapunov Risk = 0.9184377789497375, MSE = 0.019329193979501724, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00010065561218652874, Lv_loss = 0.0, Circular Tuning Loss = 1.2547281980514526\n",
      "4119) Lyapunov Risk = 0.9184096455574036, MSE = 0.019842572510242462, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00010055400343844667, Lv_loss = 0.0, Circular Tuning Loss = 1.2546062469482422\n",
      "4120) Lyapunov Risk = 0.9184560775756836, MSE = 0.019330544397234917, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0001004306977847591, Lv_loss = 0.0, Circular Tuning Loss = 1.2544832229614258\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0514451620280312, 1.061445162028031]\n",
      "x2 : [-0.9742785792574935, -0.96751275579042761]\n",
      "==============================\n",
      "4121) Lyapunov Risk = 0.9192097187042236, MSE = 0.019946176558732986, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.00010012809070758522, Lv_loss = 0.0, Circular Tuning Loss = 1.2559128999710083\n",
      "4122) Lyapunov Risk = 0.9191972017288208, MSE = 0.019388142973184586, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.997612505685538e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2557885646820068\n",
      "4123) Lyapunov Risk = 0.919117271900177, MSE = 0.019926348701119423, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.982266055885702e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.255664348602295\n",
      "4124) Lyapunov Risk = 0.9189459681510925, MSE = 0.01937244087457657, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.963056072592735e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2555385828018188\n",
      "4125) Lyapunov Risk = 0.9187649488449097, MSE = 0.01979292370378971, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.943415352609009e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2554126977920532\n",
      "4126) Lyapunov Risk = 0.9186160564422607, MSE = 0.019358111545443535, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.920007869368419e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2552850246429443\n",
      "4127) Lyapunov Risk = 0.9185329675674438, MSE = 0.019707875326275826, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.89629261312075e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2551575899124146\n",
      "4128) Lyapunov Risk = 0.918482780456543, MSE = 0.019398754462599754, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.869616769719869e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2550289630889893\n",
      "4129) Lyapunov Risk = 0.9184421896934509, MSE = 0.019676240161061287, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.842388681136072e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2548999786376953\n",
      "4130) Lyapunov Risk = 0.9183790683746338, MSE = 0.019456014037132263, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.81292178039439e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2547699213027954\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0012716846697813, 1.0112716846697811]\n",
      "x2 : [-0.93368363845509794, -0.92691781498803205]\n",
      "==============================\n",
      "4131) Lyapunov Risk = 0.9188074469566345, MSE = 0.019602734595537186, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.762846457306296e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2558355331420898\n",
      "4132) Lyapunov Risk = 0.9187172055244446, MSE = 0.0195010956376791, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.728485747473314e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2557039260864258\n",
      "4133) Lyapunov Risk = 0.9186372756958008, MSE = 0.01950572244822979, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.691202285466716e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2555711269378662\n",
      "4134) Lyapunov Risk = 0.9185765981674194, MSE = 0.019546346738934517, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.651126310927793e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2554373741149902\n",
      "4135) Lyapunov Risk = 0.9185299873352051, MSE = 0.019455034285783768, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.608607069822028e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2553025484085083\n",
      "4136) Lyapunov Risk = 0.9184852838516235, MSE = 0.01959315501153469, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.564074571244419e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2551668882369995\n",
      "4137) Lyapunov Risk = 0.9184306859970093, MSE = 0.019451230764389038, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.518005390418693e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.255030870437622\n",
      "4138) Lyapunov Risk = 0.9183633923530579, MSE = 0.01959848962724209, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.470742952544242e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2548941373825073\n",
      "4139) Lyapunov Risk = 0.9182881712913513, MSE = 0.01946510188281536, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.42241313168779e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2547568082809448\n",
      "4140) Lyapunov Risk = 0.9182144403457642, MSE = 0.019552795216441154, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.373228385811672e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2546192407608032\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0012716846697813, 1.0112716846697811]\n",
      "x2 : [-0.94044946192216394, -0.93368363845509794]\n",
      "==============================\n",
      "4141) Lyapunov Risk = 0.9186733961105347, MSE = 0.019498979672789574, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.305132698500529e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2557034492492676\n",
      "4142) Lyapunov Risk = 0.9186166524887085, MSE = 0.01949029602110386, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.252982272300869e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2555644512176514\n",
      "4143) Lyapunov Risk = 0.9185642004013062, MSE = 0.019545141607522964, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.199694613926113e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2554248571395874\n",
      "4144) Lyapunov Risk = 0.9185099601745605, MSE = 0.019451964646577835, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.145846706815064e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2552847862243652\n",
      "4145) Lyapunov Risk = 0.9184498190879822, MSE = 0.019565550610423088, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.09096997929737e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2551441192626953\n",
      "4146) Lyapunov Risk = 0.9183844327926636, MSE = 0.01945195533335209, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.035317634698004e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2550029754638672\n",
      "4147) Lyapunov Risk = 0.9183170199394226, MSE = 0.019549742341041565, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.979016274679452e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.25486159324646\n",
      "4148) Lyapunov Risk = 0.9182514548301697, MSE = 0.019483817741274834, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.922748384065926e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2547203302383423\n",
      "4149) Lyapunov Risk = 0.9181899428367615, MSE = 0.019506720826029778, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.867002179613337e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.254578709602356\n",
      "4150) Lyapunov Risk = 0.9181318879127502, MSE = 0.019522612914443016, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.81194428075105e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2544372081756592\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.7869507063985339, 1.791581610071366]\n",
      "x2 : [0.88293996245210349, 0.88632287418563649]\n",
      "==============================\n",
      "4151) Lyapunov Risk = 0.9200776219367981, MSE = 0.01946677453815937, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.74027464305982e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2576254606246948\n",
      "4152) Lyapunov Risk = 0.9200193285942078, MSE = 0.01953178644180298, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.689986862009391e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.257483959197998\n",
      "4153) Lyapunov Risk = 0.9199586510658264, MSE = 0.019457034766674042, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.643733599456027e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.25734281539917\n",
      "4154) Lyapunov Risk = 0.9198959469795227, MSE = 0.019520515576004982, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.600999717600644e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2572021484375\n",
      "4155) Lyapunov Risk = 0.9198326468467712, MSE = 0.019474254921078682, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.561761933378875e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2570617198944092\n",
      "4156) Lyapunov Risk = 0.9197702407836914, MSE = 0.019500143826007843, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.525454177288339e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2569215297698975\n",
      "4157) Lyapunov Risk = 0.919709324836731, MSE = 0.01949968934059143, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.492069173371419e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2567815780639648\n",
      "4158) Lyapunov Risk = 0.9196497797966003, MSE = 0.01947905868291855, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.461200195597485e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2566423416137695\n",
      "4159) Lyapunov Risk = 0.9195906519889832, MSE = 0.01951497420668602, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.432786853518337e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2565032243728638\n",
      "4160) Lyapunov Risk = 0.9195312857627869, MSE = 0.01946229487657547, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.406654524151236e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2563648223876953\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.7937413706021472, 1.7988988305250753]\n",
      "x2 : [0.86264249205090571, 0.86602540378443871]\n",
      "==============================\n",
      "4161) Lyapunov Risk = 0.9214537739753723, MSE = 0.019516468048095703, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.366425754502416e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2595211267471313\n",
      "4162) Lyapunov Risk = 0.9213922023773193, MSE = 0.01945102959871292, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.348598930751905e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.259382963180542\n",
      "4163) Lyapunov Risk = 0.9213297963142395, MSE = 0.019508128985762596, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.336663449881598e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.25924551486969\n",
      "4164) Lyapunov Risk = 0.9212672114372253, MSE = 0.019457781687378883, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.330152923008427e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2591089010238647\n",
      "4165) Lyapunov Risk = 0.9212047457695007, MSE = 0.019492005929350853, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.328475814778358e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2589727640151978\n",
      "4166) Lyapunov Risk = 0.9211427569389343, MSE = 0.019481442868709564, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.331330172950402e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2588374614715576\n",
      "4167) Lyapunov Risk = 0.9210811853408813, MSE = 0.01947454921901226, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.338285988429561e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2587028741836548\n",
      "4168) Lyapunov Risk = 0.9210199117660522, MSE = 0.01950010657310486, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.349125710083172e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.258569359779358\n",
      "4169) Lyapunov Risk = 0.9209582805633545, MSE = 0.01945793442428112, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.363516099052504e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2584364414215088\n",
      "4170) Lyapunov Risk = 0.9208961129188538, MSE = 0.019501980394124985, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.381138468394056e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.258304238319397\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.7802927923138605, 1.784907897637213]\n",
      "x2 : [0.89647160938623538, 0.89985452111976838]\n",
      "==============================\n",
      "4171) Lyapunov Risk = 0.9228160381317139, MSE = 0.01945289969444275, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.385490218643099e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.261464238166809\n",
      "4172) Lyapunov Risk = 0.9227519035339355, MSE = 0.019488275051116943, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.412977331317961e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2613333463668823\n",
      "4173) Lyapunov Risk = 0.9226874709129333, MSE = 0.019461577758193016, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.446689025731757e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2612031698226929\n",
      "4174) Lyapunov Risk = 0.9226227402687073, MSE = 0.019473139196634293, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.486070146318525e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2610735893249512\n",
      "4175) Lyapunov Risk = 0.9225581884384155, MSE = 0.019475460052490234, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.53070305311121e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2609450817108154\n",
      "4176) Lyapunov Risk = 0.9224936366081238, MSE = 0.019463498145341873, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.580095891375095e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.260817527770996\n",
      "4177) Lyapunov Risk = 0.9224290251731873, MSE = 0.019486086443066597, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.633835386717692e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2606909275054932\n",
      "4178) Lyapunov Risk = 0.9223657846450806, MSE = 0.0194525346159935, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.690980030223727e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2605648040771484\n",
      "4179) Lyapunov Risk = 0.9223034977912903, MSE = 0.01949365995824337, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.746197272557765e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2604392766952515\n",
      "4180) Lyapunov Risk = 0.9222415089607239, MSE = 0.019430704414844513, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.79896615515463e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2603139877319336\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0012716846697813, 1.0112716846697811]\n",
      "x2 : [-0.94721528538922983, -0.94044946192216394]\n",
      "==============================\n",
      "4181) Lyapunov Risk = 0.9227072596549988, MSE = 0.01951187662780285, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.832805178826675e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2614150047302246\n",
      "4182) Lyapunov Risk = 0.9226470589637756, MSE = 0.019401349127292633, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.879823872121051e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.261290431022644\n",
      "4183) Lyapunov Risk = 0.9225879907608032, MSE = 0.01953638158738613, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.923835412133485e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.261165976524353\n",
      "4184) Lyapunov Risk = 0.9225274324417114, MSE = 0.01938171125948429, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.964291919255629e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2610414028167725\n",
      "4185) Lyapunov Risk = 0.9224676489830017, MSE = 0.01954582892358303, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.001726721180603e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2609164714813232\n",
      "4186) Lyapunov Risk = 0.9224050641059875, MSE = 0.019378049299120903, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.036401024786755e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.260791540145874\n",
      "4187) Lyapunov Risk = 0.9223424196243286, MSE = 0.019540440291166306, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.068610961548984e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2606664896011353\n",
      "4188) Lyapunov Risk = 0.9222776889801025, MSE = 0.019392943009734154, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.099062299355865e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2605421543121338\n",
      "4189) Lyapunov Risk = 0.9222118258476257, MSE = 0.019506387412548065, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.127554221777245e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2604174613952637\n",
      "4190) Lyapunov Risk = 0.922146737575531, MSE = 0.019428042694926262, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.154322469839826e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2602932453155518\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0012716846697813, 1.0112716846697811]\n",
      "x2 : [-0.94044946192216394, -0.93368363845509794]\n",
      "==============================\n",
      "4191) Lyapunov Risk = 0.9225957989692688, MSE = 0.019453365355730057, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.161559137282893e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2613611221313477\n",
      "4192) Lyapunov Risk = 0.9225344061851501, MSE = 0.01946151815354824, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.18324658414349e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2612366676330566\n",
      "4193) Lyapunov Risk = 0.9224741458892822, MSE = 0.019415950402617455, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.202183719025925e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2611119747161865\n",
      "4194) Lyapunov Risk = 0.9224140048027039, MSE = 0.019486291334033012, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.218558989232406e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2609868049621582\n",
      "4195) Lyapunov Risk = 0.9223530888557434, MSE = 0.019398754462599754, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.232947195414454e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2608613967895508\n",
      "4196) Lyapunov Risk = 0.9222918748855591, MSE = 0.019495747983455658, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.245477122021839e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2607359886169434\n",
      "4197) Lyapunov Risk = 0.9222300052642822, MSE = 0.019397055730223656, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.256033808924258e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.260610580444336\n",
      "4198) Lyapunov Risk = 0.9221675992012024, MSE = 0.019487090408802032, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.263608808396384e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.260485053062439\n",
      "4199) Lyapunov Risk = 0.9221055507659912, MSE = 0.019406000152230263, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.267919085687026e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2603598833084106\n",
      "4200) Lyapunov Risk = 0.9220438003540039, MSE = 0.019464442506432533, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.267724090022966e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2602345943450928\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0012716846697813, 1.0112716846697811]\n",
      "x2 : [-0.94044946192216394, -0.93368363845509794]\n",
      "==============================\n",
      "4201) Lyapunov Risk = 0.9224960803985596, MSE = 0.01942351832985878, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.245026740245521e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2613019943237305\n",
      "4202) Lyapunov Risk = 0.9224356412887573, MSE = 0.01943233609199524, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.234035678673536e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.261176586151123\n",
      "4203) Lyapunov Risk = 0.922375500202179, MSE = 0.019443582743406296, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.217732440447435e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.261050820350647\n",
      "4204) Lyapunov Risk = 0.9223153591156006, MSE = 0.019409174099564552, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.196772589348257e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2609246969223022\n",
      "4205) Lyapunov Risk = 0.9222549796104431, MSE = 0.019456524401903152, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.171645069727674e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2607983350753784\n",
      "4206) Lyapunov Risk = 0.922194242477417, MSE = 0.01940157450735569, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.143083298113197e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.260671615600586\n",
      "4207) Lyapunov Risk = 0.9221329689025879, MSE = 0.019459193572402, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.112054976867512e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2605448961257935\n",
      "4208) Lyapunov Risk = 0.9220713376998901, MSE = 0.01940055936574936, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.07859139260836e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2604180574417114\n",
      "4209) Lyapunov Risk = 0.9220098257064819, MSE = 0.019448114559054375, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.042766032507643e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.260291337966919\n",
      "4210) Lyapunov Risk = 0.9219484329223633, MSE = 0.01940225064754486, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 9.005197352962568e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.260164737701416\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0012716846697813, 1.0112716846697811]\n",
      "x2 : [-0.94044946192216394, -0.93368363845509794]\n",
      "==============================\n",
      "4211) Lyapunov Risk = 0.9224006533622742, MSE = 0.019441213458776474, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.948824688559398e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2612285614013672\n",
      "4212) Lyapunov Risk = 0.9223399758338928, MSE = 0.019396375864744186, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.90690935193561e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.261101245880127\n",
      "4213) Lyapunov Risk = 0.9222797155380249, MSE = 0.01944340206682682, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.862683171173558e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2609734535217285\n",
      "4214) Lyapunov Risk = 0.9222195744514465, MSE = 0.019389908760786057, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.816749323159456e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2608449459075928\n",
      "4215) Lyapunov Risk = 0.9221597909927368, MSE = 0.01944742538034916, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.768651605350897e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2607157230377197\n",
      "4216) Lyapunov Risk = 0.9221003651618958, MSE = 0.019383179023861885, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.718766912352294e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2605857849121094\n",
      "4217) Lyapunov Risk = 0.9220417737960815, MSE = 0.01945989392697811, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.667530346428975e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2604553699493408\n",
      "4218) Lyapunov Risk = 0.921984076499939, MSE = 0.019372161477804184, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.616854756837711e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.260324478149414\n",
      "4219) Lyapunov Risk = 0.9219275116920471, MSE = 0.019481506198644638, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.567109034629539e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.260193109512329\n",
      "4220) Lyapunov Risk = 0.9218723177909851, MSE = 0.019351623952388763, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.518974209437147e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2600610256195068\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0012716846697813, 1.0112716846697811]\n",
      "x2 : [-0.94721528538922983, -0.94044946192216394]\n",
      "==============================\n",
      "4221) Lyapunov Risk = 0.9223440289497375, MSE = 0.019512323662638664, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.456737123196945e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2611380815505981\n",
      "4222) Lyapunov Risk = 0.922295868396759, MSE = 0.01931324228644371, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.4128332673572e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2610048055648804\n",
      "4223) Lyapunov Risk = 0.9222522974014282, MSE = 0.01956675760447979, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.370567229576409e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2608702182769775\n",
      "4224) Lyapunov Risk = 0.9222174286842346, MSE = 0.019267264753580093, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.330185664817691e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.260735034942627\n",
      "4225) Lyapunov Risk = 0.9221926331520081, MSE = 0.019653407856822014, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.291017729789019e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2605985403060913\n",
      "4226) Lyapunov Risk = 0.9221870303153992, MSE = 0.019215591251850128, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 8.253532723756507e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2604620456695557\n",
      "4227) Lyapunov Risk = 0.9222027063369751, MSE = 0.01979471743106842, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 8.215862908400595e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2603243589401245\n",
      "4228) Lyapunov Risk = 0.9222521781921387, MSE = 0.019165562465786934, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 8.178919233614579e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2601869106292725\n",
      "4229) Lyapunov Risk = 0.9223425984382629, MSE = 0.02001373842358589, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 8.140700083458796e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.260048270225525\n",
      "4230) Lyapunov Risk = 0.9224822521209717, MSE = 0.019131503999233246, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 8.10292549431324e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2599104642868042\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0263584233489063, 1.036358423348906]\n",
      "x2 : [-0.9742785792574935, -0.96751275579042761]\n",
      "==============================\n",
      "4231) Lyapunov Risk = 0.923286497592926, MSE = 0.020314451307058334, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 8.046906441450119e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2611829042434692\n",
      "4232) Lyapunov Risk = 0.9234910607337952, MSE = 0.01912112906575203, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 8.004303526831791e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2610441446304321\n",
      "4233) Lyapunov Risk = 0.9236435294151306, MSE = 0.020623836666345596, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 7.958008791320026e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.260903239250183\n",
      "4234) Lyapunov Risk = 0.9237687587738037, MSE = 0.01908833533525467, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 7.910355634521693e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2607624530792236\n",
      "4235) Lyapunov Risk = 0.9236895442008972, MSE = 0.020800409838557243, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 7.859425386413932e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2606207132339478\n",
      "4236) Lyapunov Risk = 0.9235053062438965, MSE = 0.018954342231154442, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 7.805816130712628e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2604783773422241\n",
      "4237) Lyapunov Risk = 0.9231547117233276, MSE = 0.020652294158935547, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 7.750653458060697e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2603352069854736\n",
      "4238) Lyapunov Risk = 0.9229606986045837, MSE = 0.0189131461083889, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 7.695561362197623e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2601923942565918\n",
      "4239) Lyapunov Risk = 0.9230795502662659, MSE = 0.02054608426988125, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 7.640931289643049e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2600504159927368\n",
      "4240) Lyapunov Risk = 0.9235242605209351, MSE = 0.01925577037036419, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 7.584585546283051e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2599081993103027\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0012716846697813, 1.0112716846697811]\n",
      "x2 : [-0.96074693232336172, -0.95398110885629572]\n",
      "==============================\n",
      "4241) Lyapunov Risk = 0.9247325658798218, MSE = 0.020902158692479134, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 7.51590559957549e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2610217332839966\n",
      "4242) Lyapunov Risk = 0.9250679612159729, MSE = 0.01960349641740322, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 7.461675704689696e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2608798742294312\n",
      "4243) Lyapunov Risk = 0.924977719783783, MSE = 0.021100297570228577, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 7.41237890906632e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2607399225234985\n",
      "4244) Lyapunov Risk = 0.9241829514503479, MSE = 0.019243676215410233, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 7.362068572547287e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2605981826782227\n",
      "4245) Lyapunov Risk = 0.9232902526855469, MSE = 0.02059636265039444, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 7.315194670809433e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2604576349258423\n",
      "4246) Lyapunov Risk = 0.9227777123451233, MSE = 0.01892133615911007, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 7.26772123016417e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.260316014289856\n",
      "4247) Lyapunov Risk = 0.922723650932312, MSE = 0.020158935338258743, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 7.219587860163301e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2601733207702637\n",
      "4248) Lyapunov Risk = 0.9227943420410156, MSE = 0.019457288086414337, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 7.172655750764534e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2600314617156982\n",
      "4249) Lyapunov Risk = 0.9226199388504028, MSE = 0.019601641222834587, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 7.126178388716653e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.259889006614685\n",
      "4250) Lyapunov Risk = 0.9222601056098938, MSE = 0.019865496084094048, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 7.07951039657928e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.25974702835083\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-0.28125000000000011, -0.28027343750000011]\n",
      "x2 : [1.3105468750000004, 1.3125000000000004]\n",
      "==============================\n",
      "4251) Lyapunov Risk = 0.9222046732902527, MSE = 0.01903250627219677, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 7.01958269928582e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2591041326522827\n",
      "4252) Lyapunov Risk = 0.9222811460494995, MSE = 0.020078444853425026, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 6.973079143790528e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2589616775512695\n",
      "4253) Lyapunov Risk = 0.9224281311035156, MSE = 0.019124194979667664, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 6.927001231815666e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2588196992874146\n",
      "4254) Lyapunov Risk = 0.9222859740257263, MSE = 0.01991986483335495, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 6.881035369588062e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2586771249771118\n",
      "4255) Lyapunov Risk = 0.9218976497650146, MSE = 0.019342822954058647, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 6.836609827587381e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2585363388061523\n",
      "4256) Lyapunov Risk = 0.9216015338897705, MSE = 0.01929856278002262, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 6.792940985178575e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2583959102630615\n",
      "4257) Lyapunov Risk = 0.9216185808181763, MSE = 0.01970035769045353, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 6.750433385604993e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2582558393478394\n",
      "4258) Lyapunov Risk = 0.9218087196350098, MSE = 0.019127842038869858, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 6.708745786454529e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2581167221069336\n",
      "4259) Lyapunov Risk = 0.9218387007713318, MSE = 0.0199385154992342, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 6.667718116659671e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2579774856567383\n",
      "4260) Lyapunov Risk = 0.9216147661209106, MSE = 0.01917724870145321, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 6.627929542446509e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.257839560508728\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0012716846697813, 1.0112716846697811]\n",
      "x2 : [-0.9742785792574935, -0.96751275579042761]\n",
      "==============================\n",
      "4261) Lyapunov Risk = 0.9219049215316772, MSE = 0.01957411877810955, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 6.576182931894436e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2590121030807495\n",
      "4262) Lyapunov Risk = 0.9217829704284668, MSE = 0.01939236745238304, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 6.539364403579384e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.258874773979187\n",
      "4263) Lyapunov Risk = 0.9218438267707825, MSE = 0.019249185919761658, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 6.504116754513234e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2587372064590454\n",
      "4264) Lyapunov Risk = 0.9219019412994385, MSE = 0.019713308662176132, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 6.469971413025633e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2585991621017456\n",
      "4265) Lyapunov Risk = 0.9218193888664246, MSE = 0.019164465367794037, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 6.43763123662211e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2584619522094727\n",
      "4266) Lyapunov Risk = 0.9216382503509521, MSE = 0.019636837765574455, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 6.406298780348152e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2583239078521729\n",
      "4267) Lyapunov Risk = 0.9215080738067627, MSE = 0.01925850845873356, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 6.375756493071094e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2581865787506104\n",
      "4268) Lyapunov Risk = 0.921474814414978, MSE = 0.019428541883826256, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 6.345709698507562e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2580488920211792\n",
      "4269) Lyapunov Risk = 0.9214737415313721, MSE = 0.019490035250782967, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 6.316164217423648e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2579113245010376\n",
      "4270) Lyapunov Risk = 0.9214146733283997, MSE = 0.0192936472594738, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 6.287585711106658e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2577744722366333\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0012716846697813, 1.0112716846697811]\n",
      "x2 : [-0.98104440272455951, -0.9742785792574935]\n",
      "==============================\n",
      "4271) Lyapunov Risk = 0.9218990206718445, MSE = 0.01953990012407303, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 6.247642158996314e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.258970856666565\n",
      "4272) Lyapunov Risk = 0.9218015074729919, MSE = 0.01924474909901619, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 6.221311923582107e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.258833646774292\n",
      "4273) Lyapunov Risk = 0.9217541813850403, MSE = 0.019468199461698532, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 6.195982859935611e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2586959600448608\n",
      "4274) Lyapunov Risk = 0.9217328429222107, MSE = 0.019336026161909103, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 6.170539563754573e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2585572004318237\n",
      "4275) Lyapunov Risk = 0.9216771721839905, MSE = 0.019414208829402924, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 6.145070801721886e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2584179639816284\n",
      "4276) Lyapunov Risk = 0.9215821623802185, MSE = 0.01938619837164879, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 6.11919240327552e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2582783699035645\n",
      "4277) Lyapunov Risk = 0.9214833974838257, MSE = 0.019363708794116974, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 6.0933551139896736e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.258138656616211\n",
      "4278) Lyapunov Risk = 0.9214214086532593, MSE = 0.019397124648094177, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 6.067594949854538e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.257999062538147\n",
      "4279) Lyapunov Risk = 0.9213928580284119, MSE = 0.019344527274370193, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 6.040952212060802e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.257859230041504\n",
      "4280) Lyapunov Risk = 0.9213576912879944, MSE = 0.019440073519945145, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 6.013698293827474e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2577195167541504\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.1141620087258435, 1.1241620087258433]\n",
      "x2 : [-1.0825317547305484, -1.0757659312634824]\n",
      "==============================\n",
      "4281) Lyapunov Risk = 0.9223074316978455, MSE = 0.019308213144540787, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.973455699859187e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2597638368606567\n",
      "4282) Lyapunov Risk = 0.9222202301025391, MSE = 0.01944737695157528, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.9421588957775384e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2596235275268555\n",
      "4283) Lyapunov Risk = 0.9221431016921997, MSE = 0.01927410066127777, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.908000093768351e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2594820261001587\n",
      "4284) Lyapunov Risk = 0.9220845103263855, MSE = 0.019442211836576462, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.8716017520055175e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.259340524673462\n",
      "4285) Lyapunov Risk = 0.9220340847969055, MSE = 0.01930166594684124, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.833033355884254e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.259198546409607\n",
      "4286) Lyapunov Risk = 0.9219750165939331, MSE = 0.019418660551309586, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.792851516162045e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2590560913085938\n",
      "4287) Lyapunov Risk = 0.9219051599502563, MSE = 0.01935521326959133, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.75125559407752e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2589139938354492\n",
      "4288) Lyapunov Risk = 0.921835720539093, MSE = 0.01934495009481907, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.708157186745666e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2587717771530151\n",
      "4289) Lyapunov Risk = 0.9217768311500549, MSE = 0.01940963789820671, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.663753836415708e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2586297988891602\n",
      "4290) Lyapunov Risk = 0.9217264652252197, MSE = 0.019285956397652626, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.6177490478148684e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.258487582206726\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.7620096310910294, 1.7665927809429935]\n",
      "x2 : [0.92691781498803205, 0.93368363845509794]\n",
      "==============================\n",
      "4291) Lyapunov Risk = 0.9235637187957764, MSE = 0.019458316266536713, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.560326826525852e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2614555358886719\n",
      "4292) Lyapunov Risk = 0.9235095381736755, MSE = 0.0192427821457386, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.516039891517721e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2613130807876587\n",
      "4293) Lyapunov Risk = 0.923448920249939, MSE = 0.019484519958496094, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.4745618399465457e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2611709833145142\n",
      "4294) Lyapunov Risk = 0.9234010577201843, MSE = 0.019206291064620018, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.4352087317965925e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2610290050506592\n",
      "4295) Lyapunov Risk = 0.9233543872833252, MSE = 0.019528668373823166, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.398460780270398e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.260887622833252\n",
      "4296) Lyapunov Risk = 0.9233282804489136, MSE = 0.01916336454451084, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.362481897464022e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.260745644569397\n",
      "4297) Lyapunov Risk = 0.9232907891273499, MSE = 0.01961754448711872, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.328483894118108e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2606042623519897\n",
      "4298) Lyapunov Risk = 0.9232652187347412, MSE = 0.019105754792690277, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.294949369272217e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2604622840881348\n",
      "4299) Lyapunov Risk = 0.9232214689254761, MSE = 0.019700363278388977, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.263102502794936e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.260321021080017\n",
      "4300) Lyapunov Risk = 0.9231875538825989, MSE = 0.019060667604207993, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.231720206211321e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2601791620254517\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.7710625816671555, 1.7751556087352149]\n",
      "x2 : [0.91676907978743316, 0.92015199152096616]\n",
      "==============================\n",
      "4301) Lyapunov Risk = 0.925020158290863, MSE = 0.01974663883447647, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.1920775149483234e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2631419897079468\n",
      "4302) Lyapunov Risk = 0.9249686002731323, MSE = 0.019048240035772324, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.166526170796715e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2630003690719604\n",
      "4303) Lyapunov Risk = 0.9248903393745422, MSE = 0.019734574481844902, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.145849718246609e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2628594636917114\n",
      "4304) Lyapunov Risk = 0.9248174428939819, MSE = 0.019063621759414673, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.1283775974297896e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.262718677520752\n",
      "4305) Lyapunov Risk = 0.9247295260429382, MSE = 0.01968170516192913, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.1149967475794256e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2625788450241089\n",
      "4306) Lyapunov Risk = 0.9246563911437988, MSE = 0.01909458264708519, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.1038299716310576e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.262439250946045\n",
      "4307) Lyapunov Risk = 0.9245778918266296, MSE = 0.01963532716035843, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.095842425362207e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.262300968170166\n",
      "4308) Lyapunov Risk = 0.9245136380195618, MSE = 0.019120724871754646, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.089470505481586e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2621629238128662\n",
      "4309) Lyapunov Risk = 0.9244436621665955, MSE = 0.019617006182670593, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.0853694119723514e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2620254755020142\n",
      "4310) Lyapunov Risk = 0.9243890047073364, MSE = 0.01911839097738266, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.0797025323845446e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2618882656097412\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.7253444322753162, 1.7299275821272802]\n",
      "x2 : [0.97089566752396061, 0.9742785792574935]\n",
      "==============================\n",
      "4311) Lyapunov Risk = 0.9261656403541565, MSE = 0.019635537639260292, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.062741911388002e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2647478580474854\n",
      "4312) Lyapunov Risk = 0.9261255860328674, MSE = 0.019083617255091667, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.056135341874324e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2646114826202393\n",
      "4313) Lyapunov Risk = 0.9260815382003784, MSE = 0.019687017425894737, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.0517974159447476e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2644766569137573\n",
      "4314) Lyapunov Risk = 0.9260438680648804, MSE = 0.019051501527428627, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.0484002713346854e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2643427848815918\n",
      "4315) Lyapunov Risk = 0.925995945930481, MSE = 0.019734283909201622, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.0473405281081796e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2642102241516113\n",
      "4316) Lyapunov Risk = 0.9259493947029114, MSE = 0.019035978242754936, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.047437662142329e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.264078140258789\n",
      "4317) Lyapunov Risk = 0.9258905649185181, MSE = 0.019754493609070778, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.0498074415372685e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2639473676681519\n",
      "4318) Lyapunov Risk = 0.9258366227149963, MSE = 0.01903393305838108, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.0530336011433974e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2638171911239624\n",
      "4319) Lyapunov Risk = 0.9257709383964539, MSE = 0.019755857065320015, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.058171154814772e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2636878490447998\n",
      "4320) Lyapunov Risk = 0.9257121682167053, MSE = 0.0190363060683012, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.0639802793739364e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2635592222213745\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.7285777205276065, 1.7338046676289212]\n",
      "x2 : [0.9911931379251584, 0.99457604965869129]\n",
      "==============================\n",
      "4321) Lyapunov Risk = 0.9275065064430237, MSE = 0.019748210906982422, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.0619961257325485e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2664893865585327\n",
      "4322) Lyapunov Risk = 0.9274459481239319, MSE = 0.01902928203344345, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.073991269455291e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.266361951828003\n",
      "4323) Lyapunov Risk = 0.9273791313171387, MSE = 0.019742658361792564, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.0911010475829244e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2662365436553955\n",
      "4324) Lyapunov Risk = 0.92731773853302, MSE = 0.019023248925805092, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.11169528181199e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2661118507385254\n",
      "4325) Lyapunov Risk = 0.9272535443305969, MSE = 0.01974673941731453, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.136609615874477e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.265988826751709\n",
      "4326) Lyapunov Risk = 0.9271903038024902, MSE = 0.019025811925530434, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.164457979844883e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2658665180206299\n",
      "4327) Lyapunov Risk = 0.9271261096000671, MSE = 0.0197508055716753, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.195924677536823e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2657458782196045\n",
      "4328) Lyapunov Risk = 0.9270612001419067, MSE = 0.01902751810848713, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.229777525528334e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2656259536743164\n",
      "4329) Lyapunov Risk = 0.9269947409629822, MSE = 0.019743524491786957, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.266072184895165e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2655068635940552\n",
      "4330) Lyapunov Risk = 0.9269261360168457, MSE = 0.019029298797249794, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.303407306200825e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.265387773513794\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0012716846697813, 1.0112716846697811]\n",
      "x2 : [-0.99457604965869129, -0.9878102261916254]\n",
      "==============================\n",
      "4331) Lyapunov Risk = 0.927461564540863, MSE = 0.019723491743206978, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.3321080486057326e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2666237354278564\n",
      "4332) Lyapunov Risk = 0.9273908138275146, MSE = 0.019033845514059067, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.372238592826761e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2665047645568848\n",
      "4333) Lyapunov Risk = 0.9273162484169006, MSE = 0.019700640812516212, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.414044426288456e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2663854360580444\n",
      "4334) Lyapunov Risk = 0.9272394180297852, MSE = 0.019043834879994392, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.4578136769123375e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2662652730941772\n",
      "4335) Lyapunov Risk = 0.9271653890609741, MSE = 0.01966951973736286, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.501612031366676e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2661445140838623\n",
      "4336) Lyapunov Risk = 0.9270901679992676, MSE = 0.01905682310461998, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.5450764193665236e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.266022801399231\n",
      "4337) Lyapunov Risk = 0.9270209074020386, MSE = 0.019650332629680634, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.5886343034217134e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2659008502960205\n",
      "4338) Lyapunov Risk = 0.9269505739212036, MSE = 0.01906769536435604, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.631859676213935e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2657783031463623\n",
      "4339) Lyapunov Risk = 0.9268811345100403, MSE = 0.019634762778878212, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.674574276781641e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2656550407409668\n",
      "4340) Lyapunov Risk = 0.9268102049827576, MSE = 0.01907353848218918, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.7166987971868366e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2655309438705444\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.101618639386281, 1.1116186393862808]\n",
      "x2 : [-1.0757659312634824, -1.0690001077964166]\n",
      "==============================\n",
      "4341) Lyapunov Risk = 0.927690327167511, MSE = 0.019610172137618065, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.747281466028653e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2674647569656372\n",
      "4342) Lyapunov Risk = 0.9276230931282043, MSE = 0.019074782729148865, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.7861951063387096e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2673393487930298\n",
      "4343) Lyapunov Risk = 0.927558183670044, MSE = 0.019602075219154358, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.823640094604343e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2672133445739746\n",
      "4344) Lyapunov Risk = 0.9274944067001343, MSE = 0.01907571777701378, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.859844168298878e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2670857906341553\n",
      "4345) Lyapunov Risk = 0.9274352192878723, MSE = 0.01961107738316059, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.8940877352142707e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2669575214385986\n",
      "4346) Lyapunov Risk = 0.9273766875267029, MSE = 0.01906685344874859, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.925309960730374e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.266827940940857\n",
      "4347) Lyapunov Risk = 0.9273235201835632, MSE = 0.019632574170827866, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.9541162045206875e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.266697883605957\n",
      "4348) Lyapunov Risk = 0.9272670745849609, MSE = 0.019051743671298027, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.980728383292444e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2665669918060303\n",
      "4349) Lyapunov Risk = 0.9272154569625854, MSE = 0.019660117104649544, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 6.0052043409086764e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2664356231689453\n",
      "4350) Lyapunov Risk = 0.9271584153175354, MSE = 0.019038628786802292, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 6.027051858836785e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2663036584854126\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.101618639386281, 1.1116186393862808]\n",
      "x2 : [-1.0757659312634824, -1.0690001077964166]\n",
      "==============================\n",
      "4351) Lyapunov Risk = 0.9280533194541931, MSE = 0.019682567566633224, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 6.0351670981617644e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2682188749313354\n",
      "4352) Lyapunov Risk = 0.9279940724372864, MSE = 0.019022760912775993, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 6.050563752069138e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2680851221084595\n",
      "4353) Lyapunov Risk = 0.927939236164093, MSE = 0.019695380702614784, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 6.0622027376666665e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2679505348205566\n",
      "4354) Lyapunov Risk = 0.9278727173805237, MSE = 0.019015762954950333, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 6.070624658605084e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2678146362304688\n",
      "4355) Lyapunov Risk = 0.9278160333633423, MSE = 0.019700881093740463, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 6.076395948184654e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2676783800125122\n",
      "4356) Lyapunov Risk = 0.927746057510376, MSE = 0.01901513896882534, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 6.079595914343372e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2675411701202393\n",
      "4357) Lyapunov Risk = 0.927691638469696, MSE = 0.01970553956925869, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 6.081189349060878e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2674040794372559\n",
      "4358) Lyapunov Risk = 0.9276224970817566, MSE = 0.019010700285434723, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 6.080797902541235e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2672663927078247\n",
      "4359) Lyapunov Risk = 0.9275693893432617, MSE = 0.019712496548891068, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 6.078661681385711e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2671287059783936\n",
      "4360) Lyapunov Risk = 0.9274981617927551, MSE = 0.019008642062544823, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 6.074395059840754e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2669904232025146\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.101618639386281, 1.1116186393862808]\n",
      "x2 : [-1.0757659312634824, -1.0690001077964166]\n",
      "==============================\n",
      "4361) Lyapunov Risk = 0.9283948540687561, MSE = 0.019718501716852188, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 6.057248174329288e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.26889967918396\n",
      "4362) Lyapunov Risk = 0.9283239841461182, MSE = 0.019002964720129967, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 6.048091745469719e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2687597274780273\n",
      "4363) Lyapunov Risk = 0.9282715320587158, MSE = 0.01972094178199768, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 6.036214472260326e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2686190605163574\n",
      "4364) Lyapunov Risk = 0.9281956553459167, MSE = 0.01899871602654457, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 6.0219837905606255e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2684770822525024\n",
      "4365) Lyapunov Risk = 0.9281396865844727, MSE = 0.019715921953320503, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 6.0064012359362096e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2683347463607788\n",
      "4366) Lyapunov Risk = 0.9280591011047363, MSE = 0.019004058092832565, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 5.989104101900011e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2681916952133179\n",
      "4367) Lyapunov Risk = 0.9280017614364624, MSE = 0.01970829628407955, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 5.971139034954831e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2680487632751465\n",
      "4368) Lyapunov Risk = 0.927920401096344, MSE = 0.01901204138994217, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 5.952103674644604e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2679054737091064\n",
      "4369) Lyapunov Risk = 0.9278666377067566, MSE = 0.01969859190285206, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 5.929425242356956e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.267762303352356\n",
      "4370) Lyapunov Risk = 0.9277878403663635, MSE = 0.01901388168334961, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 5.902345583308488e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2676186561584473\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0012716846697813, 1.0112716846697811]\n",
      "x2 : [-0.9878102261916254, -0.98104440272455951]\n",
      "==============================\n",
      "4371) Lyapunov Risk = 0.9283169507980347, MSE = 0.01968843676149845, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 5.860710371052846e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2687889337539673\n",
      "4372) Lyapunov Risk = 0.9282407760620117, MSE = 0.01901259832084179, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 5.826896813232452e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2686442136764526\n",
      "4373) Lyapunov Risk = 0.9281853437423706, MSE = 0.01967930980026722, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 5.790385330328718e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2684990167617798\n",
      "4374) Lyapunov Risk = 0.9281039237976074, MSE = 0.019015509635210037, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 5.7514600484864786e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.268352746963501\n",
      "4375) Lyapunov Risk = 0.9280429482460022, MSE = 0.01965470425784588, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 5.7104480220004916e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.268206000328064\n",
      "4376) Lyapunov Risk = 0.9279596209526062, MSE = 0.019025908783078194, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 5.667482764692977e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2680584192276\n",
      "4377) Lyapunov Risk = 0.9278913736343384, MSE = 0.019623028114438057, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 5.6228702305816114e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2679104804992676\n",
      "4378) Lyapunov Risk = 0.9278050065040588, MSE = 0.01905123144388199, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 5.576723560807295e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2677617073059082\n",
      "4379) Lyapunov Risk = 0.927727460861206, MSE = 0.01957094483077526, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 5.5292213801294565e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2676128149032593\n",
      "4380) Lyapunov Risk = 0.9276397228240967, MSE = 0.019085416570305824, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 5.4805201216368005e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2674630880355835\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0138150540093438, 1.0238150540093436]\n",
      "x2 : [-1.0013418731257573, -0.99457604965869129]\n",
      "==============================\n",
      "4381) Lyapunov Risk = 0.9281807541847229, MSE = 0.019484467804431915, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 5.420375237008557e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2687228918075562\n",
      "4382) Lyapunov Risk = 0.9280959963798523, MSE = 0.019133834168314934, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 5.36833395017311e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.268571138381958\n",
      "4383) Lyapunov Risk = 0.9280165433883667, MSE = 0.019394079223275185, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 5.3150633902987465e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.268418312072754\n",
      "4384) Lyapunov Risk = 0.927941620349884, MSE = 0.019193390384316444, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 5.259801400825381e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2682644128799438\n",
      "4385) Lyapunov Risk = 0.9278720617294312, MSE = 0.019331244751811028, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 5.202732791076414e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2681097984313965\n",
      "4386) Lyapunov Risk = 0.9278050661087036, MSE = 0.01923714205622673, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 5.14349048899021e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2679541110992432\n",
      "4387) Lyapunov Risk = 0.9277397394180298, MSE = 0.019302254542708397, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 5.0826147344196215e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2677977085113525\n",
      "4388) Lyapunov Risk = 0.927675187587738, MSE = 0.019259152933955193, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 5.020313983550295e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2676405906677246\n",
      "4389) Lyapunov Risk = 0.9276109933853149, MSE = 0.019297242164611816, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 4.9579623009776697e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2674832344055176\n",
      "4390) Lyapunov Risk = 0.9275472164154053, MSE = 0.019254183396697044, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 4.894343146588653e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2673258781433105\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0012716846697813, 1.0112716846697811]\n",
      "x2 : [-1.0013418731257573, -0.99457604965869129]\n",
      "==============================\n",
      "4391) Lyapunov Risk = 0.9280980229377747, MSE = 0.019307028502225876, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 4.8207501095021144e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2685275077819824\n",
      "4392) Lyapunov Risk = 0.9280357956886292, MSE = 0.01922181062400341, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 4.756101407110691e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2683689594268799\n",
      "4393) Lyapunov Risk = 0.9279759526252747, MSE = 0.019341791048645973, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 4.691889262176119e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2682100534439087\n",
      "4394) Lyapunov Risk = 0.9279191493988037, MSE = 0.019174983724951744, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 4.627865200745873e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2680503129959106\n",
      "4395) Lyapunov Risk = 0.9278663992881775, MSE = 0.01940549723803997, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 4.566487041302025e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2678906917572021\n",
      "4396) Lyapunov Risk = 0.92781662940979, MSE = 0.019124001264572144, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 4.5072480133967474e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2677310705184937\n",
      "4397) Lyapunov Risk = 0.9277685880661011, MSE = 0.019479306414723396, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 4.449160405783914e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2675719261169434\n",
      "4398) Lyapunov Risk = 0.9277200102806091, MSE = 0.019085494801402092, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 4.392194023239426e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2674131393432617\n",
      "4399) Lyapunov Risk = 0.9276717305183411, MSE = 0.019538946449756622, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 4.336415440775454e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2672547101974487\n",
      "4400) Lyapunov Risk = 0.9276222586631775, MSE = 0.019050579518079758, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 4.281693691154942e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.267096996307373\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0138150540093438, 1.0238150540093436]\n",
      "x2 : [-1.0284051669940211, -1.0216393435269551]\n",
      "==============================\n",
      "4401) Lyapunov Risk = 0.9282671213150024, MSE = 0.01958324946463108, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 4.2197345464956015e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2684482336044312\n",
      "4402) Lyapunov Risk = 0.9282183051109314, MSE = 0.019014764577150345, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 4.1674706153571606e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2682907581329346\n",
      "4403) Lyapunov Risk = 0.9281790852546692, MSE = 0.019638797268271446, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 4.116519266972318e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2681328058242798\n",
      "4404) Lyapunov Risk = 0.9281333088874817, MSE = 0.018984409049153328, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 4.0675400668988004e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.267974853515625\n",
      "4405) Lyapunov Risk = 0.9281079769134521, MSE = 0.019712338224053383, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 4.0201433876063675e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2678170204162598\n",
      "4406) Lyapunov Risk = 0.9280708432197571, MSE = 0.0189505685120821, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 3.9740025385981426e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2676595449447632\n",
      "4407) Lyapunov Risk = 0.9280814528465271, MSE = 0.019827624782919884, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 3.929906233679503e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2675029039382935\n",
      "4408) Lyapunov Risk = 0.9280732870101929, MSE = 0.018904631957411766, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 3.888014180120081e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.267346739768982\n",
      "4409) Lyapunov Risk = 0.9281274080276489, MSE = 0.019993025809526443, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 3.846640174742788e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2671918869018555\n",
      "4410) Lyapunov Risk = 0.9281837344169617, MSE = 0.01884756051003933, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 3.8050086004659534e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2670373916625977\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0012716846697813, 1.0112716846697811]\n",
      "x2 : [-1.0216393435269551, -1.0148735200598891]\n",
      "==============================\n",
      "4411) Lyapunov Risk = 0.9289467930793762, MSE = 0.020221587270498276, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 3.756051592063159e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.268310546875\n",
      "4412) Lyapunov Risk = 0.9290162920951843, MSE = 0.0188058540225029, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 3.714975537150167e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.268156886100769\n",
      "4413) Lyapunov Risk = 0.929114818572998, MSE = 0.020432481542229652, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 3.6740540963364765e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.268003225326538\n",
      "4414) Lyapunov Risk = 0.9290964007377625, MSE = 0.01879563182592392, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 3.6339864891488105e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2678496837615967\n",
      "4415) Lyapunov Risk = 0.9290388822555542, MSE = 0.020464420318603516, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 3.593571818782948e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2676961421966553\n",
      "4416) Lyapunov Risk = 0.9288200736045837, MSE = 0.018809357658028603, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 3.553484202711843e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2675429582595825\n",
      "4417) Lyapunov Risk = 0.9285827875137329, MSE = 0.020225008949637413, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 3.513365300022997e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2673898935317993\n",
      "4418) Lyapunov Risk = 0.9282554388046265, MSE = 0.01886638253927231, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 3.4744840377243236e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2672370672225952\n",
      "4419) Lyapunov Risk = 0.9279851913452148, MSE = 0.01983289048075676, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 3.431756704230793e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2670834064483643\n",
      "4420) Lyapunov Risk = 0.9277347326278687, MSE = 0.018986498937010765, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 3.386686512385495e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2669289112091064\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0514451620280312, 1.061445162028031]\n",
      "x2 : [-1.0825317547305484, -1.0757659312634824]\n",
      "==============================\n",
      "4421) Lyapunov Risk = 0.9283905625343323, MSE = 0.019440289586782455, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 3.332053165649995e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.268628478050232\n",
      "4422) Lyapunov Risk = 0.9282733201980591, MSE = 0.019210169091820717, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 3.280933015048504e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2684725522994995\n",
      "4423) Lyapunov Risk = 0.9282305836677551, MSE = 0.019131893292069435, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 3.2275151170324534e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2683162689208984\n",
      "4424) Lyapunov Risk = 0.9282325506210327, MSE = 0.019485121592879295, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 3.171915886923671e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2681597471237183\n",
      "4425) Lyapunov Risk = 0.9282379746437073, MSE = 0.018987789750099182, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 3.1150939321378246e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.268002986907959\n",
      "4426) Lyapunov Risk = 0.928227961063385, MSE = 0.019657079130411148, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 3.057231879211031e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2678464651107788\n",
      "4427) Lyapunov Risk = 0.9281665682792664, MSE = 0.018958423286676407, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 3.0012924980837852e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2676901817321777\n",
      "4428) Lyapunov Risk = 0.9280756711959839, MSE = 0.019638707861304283, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 2.9456055926857516e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2675341367721558\n",
      "4429) Lyapunov Risk = 0.9279516935348511, MSE = 0.019009968265891075, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 2.889590359700378e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2673791646957397\n",
      "4430) Lyapunov Risk = 0.9278324246406555, MSE = 0.01947035640478134, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 2.8333301088423468e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2672252655029297\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0389017926884687, 1.0489017926884685]\n",
      "x2 : [-1.0825317547305484, -1.0757659312634824]\n",
      "==============================\n",
      "4431) Lyapunov Risk = 0.9285539388656616, MSE = 0.019123747944831848, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 2.7725987820304e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.268870234489441\n",
      "4432) Lyapunov Risk = 0.9284705519676208, MSE = 0.01924632117152214, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 2.7180703909834847e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2687182426452637\n",
      "4433) Lyapunov Risk = 0.9284173250198364, MSE = 0.019302142783999443, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 2.664758540049661e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2685672044754028\n",
      "4434) Lyapunov Risk = 0.9283809065818787, MSE = 0.01908939890563488, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 2.6129051548196003e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2684170007705688\n",
      "4435) Lyapunov Risk = 0.9283432364463806, MSE = 0.019439879804849625, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 2.5624998670537025e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2682675123214722\n",
      "4436) Lyapunov Risk = 0.9282942414283752, MSE = 0.01904093101620674, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 2.514004154363647e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.268118977546692\n",
      "4437) Lyapunov Risk = 0.9282271862030029, MSE = 0.01947133056819439, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 2.466544901835732e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2679709196090698\n",
      "4438) Lyapunov Risk = 0.9281473159790039, MSE = 0.019073152914643288, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 2.4220171326305717e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2678236961364746\n",
      "4439) Lyapunov Risk = 0.9280596971511841, MSE = 0.01938786543905735, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 2.3788139515090734e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2676771879196167\n",
      "4440) Lyapunov Risk = 0.9279762506484985, MSE = 0.019155552610754967, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 2.3367056201095693e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2675317525863647\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0138150540093438, 1.0238150540093436]\n",
      "x2 : [-1.0825317547305484, -1.0757659312634824]\n",
      "==============================\n",
      "4441) Lyapunov Risk = 0.9287226796150208, MSE = 0.019246231764554977, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 2.2910440748091787e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2690980434417725\n",
      "4442) Lyapunov Risk = 0.9286606907844543, MSE = 0.01925228349864483, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 2.2506930690724403e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2689528465270996\n",
      "4443) Lyapunov Risk = 0.9286062121391296, MSE = 0.01914195902645588, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 2.211825267295353e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.268807291984558\n",
      "4444) Lyapunov Risk = 0.9285538196563721, MSE = 0.019338956102728844, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 2.1737088900408708e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2686609029769897\n",
      "4445) Lyapunov Risk = 0.9285009503364563, MSE = 0.01909596100449562, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 2.1358378944569267e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2685141563415527\n",
      "4446) Lyapunov Risk = 0.9284427165985107, MSE = 0.019388962537050247, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 2.0994062651880085e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2683665752410889\n",
      "4447) Lyapunov Risk = 0.9283795952796936, MSE = 0.019094809889793396, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 2.064704312942922e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2682191133499146\n",
      "4448) Lyapunov Risk = 0.9283103942871094, MSE = 0.019376207143068314, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 2.0303925339248963e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2680712938308716\n",
      "4449) Lyapunov Risk = 0.9282395839691162, MSE = 0.01911722682416439, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.9967570551671088e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2679235935211182\n",
      "4450) Lyapunov Risk = 0.928167462348938, MSE = 0.019315481185913086, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.9636470824480057e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2677754163742065\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0012716846697813, 1.0112716846697811]\n",
      "x2 : [-1.0757659312634824, -1.0690001077964166]\n",
      "==============================\n",
      "4451) Lyapunov Risk = 0.9288801550865173, MSE = 0.019154885783791542, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.9270899429102428e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2692482471466064\n",
      "4452) Lyapunov Risk = 0.9288120269775391, MSE = 0.019243095070123672, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.8945343981613405e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2690987586975098\n",
      "4453) Lyapunov Risk = 0.9287474751472473, MSE = 0.019209956750273705, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.8626604287419468e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2689485549926758\n",
      "4454) Lyapunov Risk = 0.9286850094795227, MSE = 0.019190896302461624, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.8308979633729905e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.268797516822815\n",
      "4455) Lyapunov Risk = 0.9286244511604309, MSE = 0.019261909648776054, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.7990729247685522e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2686458826065063\n",
      "4456) Lyapunov Risk = 0.9285646677017212, MSE = 0.019156357273459435, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.766694003890734e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.26849365234375\n",
      "4457) Lyapunov Risk = 0.9285047054290771, MSE = 0.01929366961121559, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.7338501493213698e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2683409452438354\n",
      "4458) Lyapunov Risk = 0.9284443855285645, MSE = 0.01913234405219555, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.700224675005302e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.268187165260315\n",
      "4459) Lyapunov Risk = 0.9283835291862488, MSE = 0.019306670874357224, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.6660147593938746e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2680330276489258\n",
      "4460) Lyapunov Risk = 0.9283220767974854, MSE = 0.01911832205951214, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.6318286725436337e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2678784132003784\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.6729431562898949, 1.6753875152744953]\n",
      "x2 : [1.0885220262907915, 1.091517162070913]\n",
      "==============================\n",
      "4461) Lyapunov Risk = 0.9300028681755066, MSE = 0.01930864341557026, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.5951847672113217e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2705549001693726\n",
      "4462) Lyapunov Risk = 0.9299405217170715, MSE = 0.01911315694451332, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.5636711395927705e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2704006433486938\n",
      "4463) Lyapunov Risk = 0.9298766255378723, MSE = 0.019305195659399033, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.53405089804437e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.270247459411621\n",
      "4464) Lyapunov Risk = 0.9298126697540283, MSE = 0.019119691103696823, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.5072497262735851e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2700963020324707\n",
      "4465) Lyapunov Risk = 0.9297476410865784, MSE = 0.019290877506136894, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.4826972801529337e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.269946575164795\n",
      "4466) Lyapunov Risk = 0.9296823143959045, MSE = 0.019134296104311943, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.460049406887265e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.269798755645752\n",
      "4467) Lyapunov Risk = 0.9296168088912964, MSE = 0.019263317808508873, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.4389005627890583e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2696527242660522\n",
      "4468) Lyapunov Risk = 0.9295520186424255, MSE = 0.019152754917740822, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.4189648027240764e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.269508719444275\n",
      "4469) Lyapunov Risk = 0.9294875860214233, MSE = 0.019232887774705887, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.4008266589371487e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2693663835525513\n",
      "4470) Lyapunov Risk = 0.9294238090515137, MSE = 0.019175956025719643, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.3839284292771481e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.269225835800171\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.6863439484719316, 1.688340414478982]\n",
      "x2 : [1.0690001077964166, 1.072131184271639]\n",
      "==============================\n",
      "4471) Lyapunov Risk = 0.9310984015464783, MSE = 0.019211119040846825, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.3657680938194972e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2719086408615112\n",
      "4472) Lyapunov Risk = 0.9310349225997925, MSE = 0.019189782440662384, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.3535072866943665e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2717732191085815\n",
      "4473) Lyapunov Risk = 0.9309714436531067, MSE = 0.019192490726709366, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.3444130672723986e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2716410160064697\n",
      "4474) Lyapunov Risk = 0.930907666683197, MSE = 0.019197823479771614, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.3380879863689188e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2715117931365967\n",
      "4475) Lyapunov Risk = 0.9308438301086426, MSE = 0.019179491326212883, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.3342788406589534e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2713851928710938\n",
      "4476) Lyapunov Risk = 0.930779755115509, MSE = 0.019208265468478203, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.3326818589121103e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2712607383728027\n",
      "4477) Lyapunov Risk = 0.9307154417037964, MSE = 0.019173862412571907, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.3331577974895481e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2711385488510132\n",
      "4478) Lyapunov Risk = 0.9306508898735046, MSE = 0.01921476423740387, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.33545181597583e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.271018147468567\n",
      "4479) Lyapunov Risk = 0.9305863380432129, MSE = 0.019169064238667488, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.3394492270890623e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2708996534347534\n",
      "4480) Lyapunov Risk = 0.9305214881896973, MSE = 0.01921725459396839, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.3446163393382449e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2707817554473877\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0012716846697813, 1.0112716846697811]\n",
      "x2 : [-1.1028292251317462, -1.0960634016646802]\n",
      "==============================\n",
      "4481) Lyapunov Risk = 0.9312974810600281, MSE = 0.019170043990015984, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.3484911505656783e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2723780870437622\n",
      "4482) Lyapunov Risk = 0.9312324523925781, MSE = 0.019210224971175194, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.3557470083469525e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2722607851028442\n",
      "4483) Lyapunov Risk = 0.9311676025390625, MSE = 0.019173067063093185, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.3637808478961233e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.272142767906189\n",
      "4484) Lyapunov Risk = 0.9311025142669678, MSE = 0.019202111288905144, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.3723858501180075e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2720239162445068\n",
      "4485) Lyapunov Risk = 0.9310374855995178, MSE = 0.019170667976140976, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.3813682926411275e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2719042301177979\n",
      "4486) Lyapunov Risk = 0.9309723377227783, MSE = 0.01920062117278576, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.3905521882406902e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.271783471107483\n",
      "4487) Lyapunov Risk = 0.9309069514274597, MSE = 0.019176030531525612, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.3998559552419465e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2716621160507202\n",
      "4488) Lyapunov Risk = 0.9308416843414307, MSE = 0.019203485921025276, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.4092565834289417e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2715401649475098\n",
      "4489) Lyapunov Risk = 0.9307763576507568, MSE = 0.01917903497815132, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.4184364772518165e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2714178562164307\n",
      "4490) Lyapunov Risk = 0.930711030960083, MSE = 0.019200345501303673, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.4275616194936447e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2712950706481934\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.2019655941027803, 1.21196559410278]\n",
      "x2 : [-1.2702089883413283, -1.2602089883413286]\n",
      "==============================\n",
      "4491) Lyapunov Risk = 0.9321807026863098, MSE = 0.0191765446215868, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.4336120329971891e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2744052410125732\n",
      "4492) Lyapunov Risk = 0.9321153163909912, MSE = 0.019190030172467232, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.4404292414837983e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2742794752120972\n",
      "4493) Lyapunov Risk = 0.9320499897003174, MSE = 0.019179170951247215, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.4456443750532344e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2741516828536987\n",
      "4494) Lyapunov Risk = 0.9319846034049988, MSE = 0.019182471558451653, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.4495243704004679e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2740223407745361\n",
      "4495) Lyapunov Risk = 0.931919276714325, MSE = 0.019181378185749054, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.4522711353492923e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2738919258117676\n",
      "4496) Lyapunov Risk = 0.9318536520004272, MSE = 0.019178200513124466, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.4541483324137516e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.273760437965393\n",
      "4497) Lyapunov Risk = 0.9317882657051086, MSE = 0.019185476005077362, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.4551600543200038e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2736287117004395\n",
      "4498) Lyapunov Risk = 0.9317227005958557, MSE = 0.019178075715899467, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.4555447705788538e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2734966278076172\n",
      "4499) Lyapunov Risk = 0.9316569566726685, MSE = 0.019190631806850433, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.455461733712582e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2733643054962158\n",
      "4500) Lyapunov Risk = 0.9315913915634155, MSE = 0.019170597195625305, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.454977518733358e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.273232102394104\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.2019655941027803, 1.21196559410278]\n",
      "x2 : [-1.2702089883413283, -1.2602089883413286]\n",
      "==============================\n",
      "4501) Lyapunov Risk = 0.9330551028251648, MSE = 0.01919257640838623, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.4514908798446413e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2763205766677856\n",
      "4502) Lyapunov Risk = 0.9329898953437805, MSE = 0.0191497765481472, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.4492179616354406e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2761870622634888\n",
      "4503) Lyapunov Risk = 0.9329249262809753, MSE = 0.019203994423151016, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.4457754332397599e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2760523557662964\n",
      "4504) Lyapunov Risk = 0.932861864566803, MSE = 0.01912061683833599, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.441204767616e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.275916337966919\n",
      "4505) Lyapunov Risk = 0.9328018426895142, MSE = 0.01925438828766346, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.4358638509293087e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2757796049118042\n",
      "4506) Lyapunov Risk = 0.9327495694160461, MSE = 0.019064007326960564, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.4297467714641243e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2756417989730835\n",
      "4507) Lyapunov Risk = 0.932709276676178, MSE = 0.019361160695552826, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.4230035958462395e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.275503396987915\n",
      "4508) Lyapunov Risk = 0.9326907992362976, MSE = 0.018967801705002785, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.4155427379591856e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2753643989562988\n",
      "4509) Lyapunov Risk = 0.9327108263969421, MSE = 0.019560083746910095, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.4075532817514613e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2752248048782349\n",
      "4510) Lyapunov Risk = 0.9328157901763916, MSE = 0.018827905878424644, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.3988256796437781e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2750846147537231\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0012716846697813, 1.0112716846697811]\n",
      "x2 : [-1.0960634016646802, -1.0892975781976144]\n",
      "==============================\n",
      "4511) Lyapunov Risk = 0.9338559508323669, MSE = 0.01998768374323845, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.3869007489120122e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2766138315200806\n",
      "4512) Lyapunov Risk = 0.9343570470809937, MSE = 0.01871321350336075, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.3767599739367142e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2764708995819092\n",
      "4513) Lyapunov Risk = 0.9352861046791077, MSE = 0.0210068691521883, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.3662584933626931e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.276326298713684\n",
      "4514) Lyapunov Risk = 0.9375791549682617, MSE = 0.019002152606844902, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.3523409506888129e-05, Lv_loss = 2.8413134714355692e-05, Circular Tuning Loss = 1.2761770486831665\n",
      "4515) Lyapunov Risk = 0.9414041042327881, MSE = 0.024037504568696022, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.338930451311171e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2760279178619385\n",
      "4516) Lyapunov Risk = 0.9469349384307861, MSE = 0.020846229046583176, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.3206995390646625e-05, Lv_loss = 0.0001482236839365214, Circular Tuning Loss = 1.2758727073669434\n",
      "4517) Lyapunov Risk = 0.9504274129867554, MSE = 0.02786777913570404, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.3046356798440684e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2757197618484497\n",
      "4518) Lyapunov Risk = 0.9455035924911499, MSE = 0.020639069378376007, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.2842598152928986e-05, Lv_loss = 0.00012080556916771457, Circular Tuning Loss = 1.2755612134933472\n",
      "4519) Lyapunov Risk = 0.9361635446548462, MSE = 0.021513022482395172, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.2667656847042963e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2754063606262207\n",
      "4520) Lyapunov Risk = 0.933073878288269, MSE = 0.019686779007315636, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.2451682778191753e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2752461433410645\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.1718750000000004, -1.1708984375000004]\n",
      "x2 : [0.011840191067365374, 0.013531646934131855]\n",
      "==============================\n",
      "4521) Lyapunov Risk = 0.9372947812080383, MSE = 0.01902749016880989, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.2229954336362425e-05, Lv_loss = 3.5402426874497905e-05, Circular Tuning Loss = 1.2739107608795166\n",
      "4522) Lyapunov Risk = 0.9397412538528442, MSE = 0.023506471887230873, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.2037023225275334e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.27375328540802\n",
      "4523) Lyapunov Risk = 0.9360983371734619, MSE = 0.0189952552318573, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.1807614100689534e-05, Lv_loss = 1.0207920240645763e-05, Circular Tuning Loss = 1.273592233657837\n",
      "4524) Lyapunov Risk = 0.9326321482658386, MSE = 0.019278142601251602, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.1594046554819215e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.273433804512024\n",
      "4525) Lyapunov Risk = 0.9347713589668274, MSE = 0.021186048164963722, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.1397328307793941e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2732768058776855\n",
      "4526) Lyapunov Risk = 0.9373422265052795, MSE = 0.019096283242106438, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.1174493010912556e-05, Lv_loss = 4.1824139771051705e-05, Circular Tuning Loss = 1.2731175422668457\n",
      "4527) Lyapunov Risk = 0.9347077012062073, MSE = 0.021099185571074486, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.0963869499391876e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.27295982837677\n",
      "4528) Lyapunov Risk = 0.9324368238449097, MSE = 0.019271885976195335, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.0720656973717269e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2727985382080078\n",
      "4529) Lyapunov Risk = 0.9337221384048462, MSE = 0.018702154979109764, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.04993687273236e-05, Lv_loss = 2.1595219550363254e-06, Circular Tuning Loss = 1.2726402282714844\n",
      "4530) Lyapunov Risk = 0.9345791339874268, MSE = 0.02121959626674652, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.0289598321833182e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.272482991218567\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.2539062500000004, -1.2529296875000004]\n",
      "x2 : [-0.15730539560928281, -0.15561393974251633]\n",
      "==============================\n",
      "4531) Lyapunov Risk = 0.9332797527313232, MSE = 0.01881961151957512, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.0028246833826415e-05, Lv_loss = 0.0, Circular Tuning Loss = 1.2714084386825562\n",
      "4532) Lyapunov Risk = 0.9322769045829773, MSE = 0.01907176524400711, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 9.801792657526676e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2712498903274536\n",
      "4533) Lyapunov Risk = 0.9333059191703796, MSE = 0.020596466958522797, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 9.595337360224221e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2710931301116943\n",
      "4534) Lyapunov Risk = 0.9332615733146667, MSE = 0.018740637227892876, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 9.415135536983144e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2709394693374634\n",
      "4535) Lyapunov Risk = 0.9320411682128906, MSE = 0.019549265503883362, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 9.244425200449768e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.270787000656128\n",
      "4536) Lyapunov Risk = 0.9322784543037415, MSE = 0.019945424050092697, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 9.087530997931026e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2706363201141357\n",
      "4537) Lyapunov Risk = 0.9327995777130127, MSE = 0.018725702539086342, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 8.946618436311837e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2704886198043823\n",
      "4538) Lyapunov Risk = 0.9320089817047119, MSE = 0.019867846742272377, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 8.812920896161813e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2703415155410767\n",
      "4539) Lyapunov Risk = 0.9316479563713074, MSE = 0.01940140500664711, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 8.689588867127895e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2701960802078247\n",
      "4540) Lyapunov Risk = 0.9321597218513489, MSE = 0.018775925040245056, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 8.580528628954198e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2700527906417847\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0138150540093438, 1.0238150540093436]\n",
      "x2 : [-1.1366583424670758, -1.12989251900001]\n",
      "==============================\n",
      "4541) Lyapunov Risk = 0.9328507781028748, MSE = 0.019979607313871384, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 8.459103810309898e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2717880010604858\n",
      "4542) Lyapunov Risk = 0.9322597980499268, MSE = 0.01906084083020687, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 8.360695574083365e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2716450691223145\n",
      "4543) Lyapunov Risk = 0.9324726462364197, MSE = 0.018916066735982895, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 8.272588274849113e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2715022563934326\n",
      "4544) Lyapunov Risk = 0.9326366186141968, MSE = 0.01997252181172371, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 8.19450997369131e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2713590860366821\n",
      "4545) Lyapunov Risk = 0.9321553111076355, MSE = 0.018920419737696648, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 8.123324732878245e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2712165117263794\n",
      "4546) Lyapunov Risk = 0.9319978356361389, MSE = 0.019103771075606346, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 8.059229912760202e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.271073818206787\n",
      "4547) Lyapunov Risk = 0.9322590231895447, MSE = 0.019779903814196587, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 8.002992217370775e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2709312438964844\n",
      "4548) Lyapunov Risk = 0.9320774078369141, MSE = 0.01885630190372467, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 7.94957213656744e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2707890272140503\n",
      "4549) Lyapunov Risk = 0.931725263595581, MSE = 0.019279422238469124, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 7.900462151155807e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.270646572113037\n",
      "4550) Lyapunov Risk = 0.9318237900733948, MSE = 0.019510861486196518, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 7.854749128455296e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2705042362213135\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0012716846697813, 1.0112716846697811]\n",
      "x2 : [-1.12989251900001, -1.123126695532944]\n",
      "==============================\n",
      "4551) Lyapunov Risk = 0.9327841997146606, MSE = 0.018885811790823936, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 7.798700607963838e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2721643447875977\n",
      "4552) Lyapunov Risk = 0.9324870705604553, MSE = 0.019437609240412712, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 7.761729648336768e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2720211744308472\n",
      "4553) Lyapunov Risk = 0.9323693513870239, MSE = 0.019279617816209793, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 7.727712727501057e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2718769311904907\n",
      "4554) Lyapunov Risk = 0.9324821829795837, MSE = 0.018946852535009384, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 7.693873158132192e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2717314958572388\n",
      "4555) Lyapunov Risk = 0.9323551654815674, MSE = 0.019521523267030716, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 7.661585186724551e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2715849876403809\n",
      "4556) Lyapunov Risk = 0.9321317076683044, MSE = 0.019131621345877647, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 7.629557330801617e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2714375257492065\n",
      "4557) Lyapunov Risk = 0.9321447014808655, MSE = 0.019034946337342262, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 7.6006381277693436e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.271289587020874\n",
      "4558) Lyapunov Risk = 0.9321528673171997, MSE = 0.01950198970735073, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 7.572005415568128e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.271140694618225\n",
      "4559) Lyapunov Risk = 0.9319707155227661, MSE = 0.019033940508961678, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 7.538914815086173e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2709912061691284\n",
      "4560) Lyapunov Risk = 0.9318613409996033, MSE = 0.019130097702145576, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 7.50583058106713e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.270841121673584\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0012716846697813, 1.0112716846697811]\n",
      "x2 : [-1.1366583424670758, -1.12989251900001]\n",
      "==============================\n",
      "4561) Lyapunov Risk = 0.932794988155365, MSE = 0.019401442259550095, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 7.4563586167641915e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.272518277168274\n",
      "4562) Lyapunov Risk = 0.9327132105827332, MSE = 0.019015517085790634, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 7.420404926961055e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2723660469055176\n",
      "4563) Lyapunov Risk = 0.9325619339942932, MSE = 0.019229289144277573, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 7.38609878681018e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2722123861312866\n",
      "4564) Lyapunov Risk = 0.9325153231620789, MSE = 0.019292019307613373, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 7.350788109761197e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2720576524734497\n",
      "4565) Lyapunov Risk = 0.9324917793273926, MSE = 0.019021907821297646, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 7.314748472708743e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2719016075134277\n",
      "4566) Lyapunov Risk = 0.9323770999908447, MSE = 0.01928633451461792, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 7.2773773354128934e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2717442512512207\n",
      "4567) Lyapunov Risk = 0.9322741627693176, MSE = 0.01920405775308609, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 7.240005288622342e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2715864181518555\n",
      "4568) Lyapunov Risk = 0.9322398900985718, MSE = 0.019048959016799927, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 7.202159849839518e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2714277505874634\n",
      "4569) Lyapunov Risk = 0.9321743845939636, MSE = 0.01931418851017952, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 7.162613201217027e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.271268367767334\n",
      "4570) Lyapunov Risk = 0.9320656061172485, MSE = 0.019133208319544792, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 7.118715529941255e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.271108627319336\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0012716846697813, 1.0112716846697811]\n",
      "x2 : [-1.1366583424670758, -1.12989251900001]\n",
      "==============================\n",
      "4571) Lyapunov Risk = 0.9328945875167847, MSE = 0.019093669950962067, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 7.058427854644833e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.272775650024414\n",
      "4572) Lyapunov Risk = 0.9328436851501465, MSE = 0.019289176911115646, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 7.0124451667652465e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2726147174835205\n",
      "4573) Lyapunov Risk = 0.9327591061592102, MSE = 0.019092576578259468, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 6.965743978071259e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2724528312683105\n",
      "4574) Lyapunov Risk = 0.932668924331665, MSE = 0.019150421023368835, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 6.917366135894554e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2722901105880737\n",
      "4575) Lyapunov Risk = 0.9326071739196777, MSE = 0.01925644278526306, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 6.865323939564405e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2721270322799683\n",
      "4576) Lyapunov Risk = 0.9325409531593323, MSE = 0.01906963251531124, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 6.806428700656397e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2719630002975464\n",
      "4577) Lyapunov Risk = 0.9324560761451721, MSE = 0.019198419526219368, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 6.727132586092921e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.271797776222229\n",
      "4578) Lyapunov Risk = 0.9323821663856506, MSE = 0.019205108284950256, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 6.625887635891559e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2716315984725952\n",
      "4579) Lyapunov Risk = 0.9323221445083618, MSE = 0.019069993868470192, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 6.50282208880526e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.271464467048645\n",
      "4580) Lyapunov Risk = 0.9322476387023926, MSE = 0.019239669665694237, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 6.365080935211154e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2712970972061157\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0514451620280312, 1.061445162028031]\n",
      "x2 : [-1.1907849302036033, -1.1840191067365373]\n",
      "==============================\n",
      "4581) Lyapunov Risk = 0.9332330226898193, MSE = 0.019147709012031555, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 6.2056778915575705e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.27336585521698\n",
      "4582) Lyapunov Risk = 0.9331661462783813, MSE = 0.019097018986940384, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 6.052143362467177e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2731986045837402\n",
      "4583) Lyapunov Risk = 0.9331008791923523, MSE = 0.019234808161854744, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 5.893613888474647e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2730321884155273\n",
      "4584) Lyapunov Risk = 0.9330236911773682, MSE = 0.019098469987511635, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 5.728490123146912e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2728660106658936\n",
      "4585) Lyapunov Risk = 0.93294757604599, MSE = 0.019143885001540184, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 5.559162673307583e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2727006673812866\n",
      "4586) Lyapunov Risk = 0.9328820109367371, MSE = 0.019211547449231148, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 5.387236797105288e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2725359201431274\n",
      "4587) Lyapunov Risk = 0.9328139424324036, MSE = 0.01908233016729355, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 5.216183126321994e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.272371530532837\n",
      "4588) Lyapunov Risk = 0.9327359795570374, MSE = 0.019189633429050446, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 5.045331363362493e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.272207498550415\n",
      "4589) Lyapunov Risk = 0.9326625466346741, MSE = 0.019164718687534332, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 4.877081209997414e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.27204430103302\n",
      "4590) Lyapunov Risk = 0.9325952529907227, MSE = 0.01910068467259407, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 4.706129402620718e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2718815803527832\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.1768788554236553, 1.1868788554236551]\n",
      "x2 : [-1.2972722822095921, -1.2872722822095923]\n",
      "==============================\n",
      "4591) Lyapunov Risk = 0.9340372681617737, MSE = 0.019204827025532722, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 4.524835730990162e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2749100923538208\n",
      "4592) Lyapunov Risk = 0.9339622855186462, MSE = 0.01911911554634571, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 4.337867721915245e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2747470140457153\n",
      "4593) Lyapunov Risk = 0.9338899850845337, MSE = 0.019132839515805244, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 4.139910288358806e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2745829820632935\n",
      "4594) Lyapunov Risk = 0.9338211417198181, MSE = 0.01918516494333744, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 3.9319752431765664e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2744179964065552\n",
      "4595) Lyapunov Risk = 0.9337500333786011, MSE = 0.019101712852716446, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 3.7137974686629605e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.27425217628479\n",
      "4596) Lyapunov Risk = 0.93367600440979, MSE = 0.019163798540830612, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 3.499013928376371e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2740858793258667\n",
      "4597) Lyapunov Risk = 0.9336041808128357, MSE = 0.01916263997554779, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 3.2789855595183326e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.273918867111206\n",
      "4598) Lyapunov Risk = 0.9335342645645142, MSE = 0.01911124959588051, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 3.0528367460647132e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2737516164779663\n",
      "4599) Lyapunov Risk = 0.9334617257118225, MSE = 0.019177833572030067, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 2.821866928570671e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2735838890075684\n",
      "4600) Lyapunov Risk = 0.9333884119987488, MSE = 0.01913362927734852, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 2.5936890324373962e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2734158039093018\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0138150540093438, 1.0238150540093436]\n",
      "x2 : [-1.1907849302036033, -1.1840191067365373]\n",
      "==============================\n",
      "4601) Lyapunov Risk = 0.9343428611755371, MSE = 0.019130950793623924, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 2.3946217879711185e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2753281593322754\n",
      "4602) Lyapunov Risk = 0.9342707395553589, MSE = 0.019167674705386162, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 2.201552661063033e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2751587629318237\n",
      "4603) Lyapunov Risk = 0.9341973066329956, MSE = 0.019121238961815834, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 2.0310847048676806e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2749886512756348\n",
      "4604) Lyapunov Risk = 0.9341236352920532, MSE = 0.01914406381547451, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 1.8942573660751805e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.274817943572998\n",
      "4605) Lyapunov Risk = 0.9340507388114929, MSE = 0.019151151180267334, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 1.7597938040125882e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2746464014053345\n",
      "4606) Lyapunov Risk = 0.9339777827262878, MSE = 0.019121261313557625, V_0_loss = tensor([[0.0076]], grad_fn=<PowBackward0>), V_pos_loss = 1.6370094044759753e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.274474859237671\n",
      "4607) Lyapunov Risk = 0.933903694152832, MSE = 0.019152721390128136, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.513260940555483e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2743024826049805\n",
      "4608) Lyapunov Risk = 0.9338298439979553, MSE = 0.019142990931868553, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.3887793102185242e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2741299867630005\n",
      "4609) Lyapunov Risk = 0.9337565898895264, MSE = 0.01913057267665863, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.2737802990159253e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2739570140838623\n",
      "4610) Lyapunov Risk = 0.9336828589439392, MSE = 0.019156623631715775, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.1642448498605518e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2737840414047241\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.101618639386281, 1.1116186393862808]\n",
      "x2 : [-1.2702089883413283, -1.2602089883413286]\n",
      "==============================\n",
      "4611) Lyapunov Risk = 0.9348952174186707, MSE = 0.01913101226091385, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.0667662309060688e-06, Lv_loss = 0.0, Circular Tuning Loss = 1.2763524055480957\n",
      "4612) Lyapunov Risk = 0.9348206520080566, MSE = 0.019131360575556755, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 9.721811693452764e-07, Lv_loss = 0.0, Circular Tuning Loss = 1.2761776447296143\n",
      "4613) Lyapunov Risk = 0.9347463846206665, MSE = 0.019148526713252068, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 8.765273378230631e-07, Lv_loss = 0.0, Circular Tuning Loss = 1.2760016918182373\n",
      "4614) Lyapunov Risk = 0.9346717000007629, MSE = 0.01912345550954342, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 7.791289817760116e-07, Lv_loss = 0.0, Circular Tuning Loss = 1.2758243083953857\n",
      "4615) Lyapunov Risk = 0.9345965385437012, MSE = 0.019137945026159286, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 6.820076805524877e-07, Lv_loss = 0.0, Circular Tuning Loss = 1.2756459712982178\n",
      "4616) Lyapunov Risk = 0.934521496295929, MSE = 0.01914169080555439, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.981290200907097e-07, Lv_loss = 0.0, Circular Tuning Loss = 1.2754666805267334\n",
      "4617) Lyapunov Risk = 0.9344467520713806, MSE = 0.019124485552310944, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 5.130148110765731e-07, Lv_loss = 0.0, Circular Tuning Loss = 1.2752866744995117\n",
      "4618) Lyapunov Risk = 0.934371829032898, MSE = 0.01914377324283123, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 4.259504180481599e-07, Lv_loss = 0.0, Circular Tuning Loss = 1.2751057147979736\n",
      "4619) Lyapunov Risk = 0.9342973828315735, MSE = 0.01913580670952797, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 3.4759472100631683e-07, Lv_loss = 0.0, Circular Tuning Loss = 1.274925708770752\n",
      "4620) Lyapunov Risk = 0.934223473072052, MSE = 0.01912643015384674, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 2.845060862455284e-07, Lv_loss = 0.0, Circular Tuning Loss = 1.2747467756271362\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0389017926884687, 1.0489017926884685]\n",
      "x2 : [-1.2431456944730646, -1.2331456944730648]\n",
      "==============================\n",
      "4621) Lyapunov Risk = 0.9353196024894714, MSE = 0.019141342490911484, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 2.320266787592118e-07, Lv_loss = 0.0, Circular Tuning Loss = 1.2769463062286377\n",
      "4622) Lyapunov Risk = 0.935245156288147, MSE = 0.019121291115880013, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.8036492122064374e-07, Lv_loss = 0.0, Circular Tuning Loss = 1.2767689228057861\n",
      "4623) Lyapunov Risk = 0.935170590877533, MSE = 0.01912792958319187, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 1.283339372548653e-07, Lv_loss = 0.0, Circular Tuning Loss = 1.2765915393829346\n",
      "4624) Lyapunov Risk = 0.9350963234901428, MSE = 0.019132666289806366, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 7.578417893228107e-08, Lv_loss = 0.0, Circular Tuning Loss = 1.276414394378662\n",
      "4625) Lyapunov Risk = 0.9350218176841736, MSE = 0.019117673859000206, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 4.509652384854235e-08, Lv_loss = 0.0, Circular Tuning Loss = 1.2762372493743896\n",
      "4626) Lyapunov Risk = 0.9349473118782043, MSE = 0.01913250796496868, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 2.74334883698657e-08, Lv_loss = 0.0, Circular Tuning Loss = 1.2760604619979858\n",
      "4627) Lyapunov Risk = 0.9348728060722351, MSE = 0.0191277414560318, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 9.696341507492434e-09, Lv_loss = 0.0, Circular Tuning Loss = 1.2758842706680298\n",
      "4628) Lyapunov Risk = 0.9347982406616211, MSE = 0.019123101606965065, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.2757080793380737\n",
      "4629) Lyapunov Risk = 0.9347235560417175, MSE = 0.019136102870106697, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.2755321264266968\n",
      "4630) Lyapunov Risk = 0.934648871421814, MSE = 0.019122913479804993, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.275356650352478\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.5989367584109511, 1.6004932510727155]\n",
      "x2 : [1.1993420501552885, 1.2014163485662581]\n",
      "==============================\n",
      "4631) Lyapunov Risk = 0.9361766576766968, MSE = 0.01912720873951912, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.2777421474456787\n",
      "4632) Lyapunov Risk = 0.9361020922660828, MSE = 0.019124986603856087, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.277569055557251\n",
      "4633) Lyapunov Risk = 0.9360273480415344, MSE = 0.019119419157505035, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.2773983478546143\n",
      "4634) Lyapunov Risk = 0.9359524250030518, MSE = 0.019123846665024757, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.2772297859191895\n",
      "4635) Lyapunov Risk = 0.93587726354599, MSE = 0.0191202312707901, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.2770631313323975\n",
      "4636) Lyapunov Risk = 0.9358019828796387, MSE = 0.01912020891904831, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.2768982648849487\n",
      "4637) Lyapunov Risk = 0.935726523399353, MSE = 0.019124584272503853, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.2767348289489746\n",
      "4638) Lyapunov Risk = 0.9356507658958435, MSE = 0.01912127435207367, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.2765727043151855\n",
      "4639) Lyapunov Risk = 0.9355748295783997, MSE = 0.019123798236250877, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.2764116525650024\n",
      "4640) Lyapunov Risk = 0.9354987740516663, MSE = 0.019122738391160965, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.2762516736984253\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.6132537326143888, 1.6148832560991178]\n",
      "x2 : [1.1768785318043773, 1.1783760996944379]\n",
      "==============================\n",
      "4641) Lyapunov Risk = 0.9370107054710388, MSE = 0.019120577722787857, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.2786256074905396\n",
      "4642) Lyapunov Risk = 0.9369338750839233, MSE = 0.01911483146250248, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.2784682512283325\n",
      "4643) Lyapunov Risk = 0.9368563890457153, MSE = 0.01911819726228714, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.2783132791519165\n",
      "4644) Lyapunov Risk = 0.936778724193573, MSE = 0.019111791625618935, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.2781600952148438\n",
      "4645) Lyapunov Risk = 0.9367006421089172, MSE = 0.019113199785351753, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.2780088186264038\n",
      "4646) Lyapunov Risk = 0.9366220831871033, MSE = 0.019116796553134918, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.277858853340149\n",
      "4647) Lyapunov Risk = 0.9365432858467102, MSE = 0.019113315269351006, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.2777103185653687\n",
      "4648) Lyapunov Risk = 0.9364640712738037, MSE = 0.01911863684654236, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.2775629758834839\n",
      "4649) Lyapunov Risk = 0.9363845586776733, MSE = 0.01911831647157669, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.2774163484573364\n",
      "4650) Lyapunov Risk = 0.9363047480583191, MSE = 0.019114719703793526, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.2772704362869263\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.2960242719571651, 1.3060242719571649]\n",
      "x2 : [-1.5035621756847311, -1.4935621756847313]\n",
      "==============================\n",
      "4651) Lyapunov Risk = 0.9384748935699463, MSE = 0.019119562581181526, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.2818012237548828\n",
      "4652) Lyapunov Risk = 0.9383944869041443, MSE = 0.019106920808553696, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.2816542387008667\n",
      "4653) Lyapunov Risk = 0.9383137226104736, MSE = 0.01911267079412937, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.281505823135376\n",
      "4654) Lyapunov Risk = 0.9382327795028687, MSE = 0.019106214866042137, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.2813559770584106\n",
      "4655) Lyapunov Risk = 0.9381515979766846, MSE = 0.01910276897251606, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.2812044620513916\n",
      "4656) Lyapunov Risk = 0.9380700588226318, MSE = 0.019110308960080147, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.2810516357421875\n",
      "4657) Lyapunov Risk = 0.9379881620407104, MSE = 0.01910369098186493, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.2808970212936401\n",
      "4658) Lyapunov Risk = 0.9379067420959473, MSE = 0.019107569009065628, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.280741572380066\n",
      "4659) Lyapunov Risk = 0.9378250241279602, MSE = 0.019107766449451447, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.2805849313735962\n",
      "4660) Lyapunov Risk = 0.9377432465553284, MSE = 0.019097531214356422, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.2804274559020996\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0519505379378422, 1.061950537937842]\n",
      "x2 : [-1.3513988699461195, -1.3413988699461197]\n",
      "==============================\n",
      "4661) Lyapunov Risk = 0.9391518831253052, MSE = 0.019103839993476868, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.2831552028656006\n",
      "4662) Lyapunov Risk = 0.9390698671340942, MSE = 0.01909240335226059, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.2829947471618652\n",
      "4663) Lyapunov Risk = 0.9389874339103699, MSE = 0.01909550465643406, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.2828319072723389\n",
      "4664) Lyapunov Risk = 0.9389051198959351, MSE = 0.019097980111837387, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.2826671600341797\n",
      "4665) Lyapunov Risk = 0.9388225078582764, MSE = 0.01908940076828003, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.2824994325637817\n",
      "4666) Lyapunov Risk = 0.938739538192749, MSE = 0.019100312143564224, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.2823293209075928\n",
      "4667) Lyapunov Risk = 0.9386563301086426, MSE = 0.01909639500081539, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.2821569442749023\n",
      "4668) Lyapunov Risk = 0.9385728240013123, MSE = 0.019094761461019516, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.2819825410842896\n",
      "4669) Lyapunov Risk = 0.9384891390800476, MSE = 0.01910051517188549, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.281806468963623\n",
      "4670) Lyapunov Risk = 0.9384050369262695, MSE = 0.01909068040549755, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.281628966331482\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0356789556698873, 1.0456789556698871]\n",
      "x2 : [-1.3513988699461195, -1.3413988699461197]\n",
      "==============================\n",
      "4671) Lyapunov Risk = 0.9397973418235779, MSE = 0.01909342035651207, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.2842674255371094\n",
      "4672) Lyapunov Risk = 0.9397125840187073, MSE = 0.019088009372353554, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.2840855121612549\n",
      "4673) Lyapunov Risk = 0.9396275877952576, MSE = 0.019089583307504654, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.283901572227478\n",
      "4674) Lyapunov Risk = 0.9395421743392944, MSE = 0.019090302288532257, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.2837156057357788\n",
      "4675) Lyapunov Risk = 0.9394563436508179, MSE = 0.019087737426161766, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.2835277318954468\n",
      "4676) Lyapunov Risk = 0.9393702745437622, MSE = 0.019091179594397545, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 0.0, Circular Tuning Loss = 1.2833383083343506\n",
      "4677) Lyapunov Risk = 0.9392838478088379, MSE = 0.019088037312030792, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 2.103581664414378e-08, Circular Tuning Loss = 1.2831474542617798\n",
      "4678) Lyapunov Risk = 0.9391970634460449, MSE = 0.019089218229055405, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 8.421567798677643e-08, Circular Tuning Loss = 1.2829554080963135\n",
      "4679) Lyapunov Risk = 0.9391099214553833, MSE = 0.01908956468105316, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 1.5100647487997776e-07, Circular Tuning Loss = 1.2827624082565308\n",
      "4680) Lyapunov Risk = 0.939022421836853, MSE = 0.019086724147200584, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 2.2099617069670785e-07, Circular Tuning Loss = 1.2825682163238525\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.0519505379378422, 1.061950537937842]\n",
      "x2 : [-1.4596520454191744, -1.4496520454191746]\n",
      "==============================\n",
      "4681) Lyapunov Risk = 0.940767765045166, MSE = 0.01908780261874199, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 2.9338036711124005e-07, Circular Tuning Loss = 1.2857894897460938\n",
      "4682) Lyapunov Risk = 0.9406794309616089, MSE = 0.019079484045505524, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 3.705485767113714e-07, Circular Tuning Loss = 1.2855924367904663\n",
      "4683) Lyapunov Risk = 0.9405904412269592, MSE = 0.01908491738140583, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 4.51327196060447e-07, Circular Tuning Loss = 1.285393238067627\n",
      "4684) Lyapunov Risk = 0.9405012130737305, MSE = 0.019080746918916702, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 5.362176125345286e-07, Circular Tuning Loss = 1.2851924896240234\n",
      "4685) Lyapunov Risk = 0.9404114484786987, MSE = 0.019081085920333862, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 6.248064892133698e-07, Circular Tuning Loss = 1.2849904298782349\n",
      "4686) Lyapunov Risk = 0.9403213262557983, MSE = 0.019086120650172234, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 7.162308293118258e-07, Circular Tuning Loss = 1.2847871780395508\n",
      "4687) Lyapunov Risk = 0.9402308464050293, MSE = 0.019080759957432747, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 8.102396122922073e-07, Circular Tuning Loss = 1.2845832109451294\n",
      "4688) Lyapunov Risk = 0.9401399493217468, MSE = 0.019083762541413307, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 9.068339750228915e-07, Circular Tuning Loss = 1.2843784093856812\n",
      "4689) Lyapunov Risk = 0.9400485754013062, MSE = 0.019082698971033096, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 1.0057864301415975e-06, Circular Tuning Loss = 1.2841731309890747\n",
      "4690) Lyapunov Risk = 0.9399573802947998, MSE = 0.01907951571047306, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 1.106742161027796e-06, Circular Tuning Loss = 1.2839676141738892\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.177158599510522, 1.1871585995105218]\n",
      "x2 : [-1.5964639606168205, -1.5864639606168207]\n",
      "==============================\n",
      "4691) Lyapunov Risk = 0.942276656627655, MSE = 0.019083203747868538, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 1.2065285091011901e-06, Circular Tuning Loss = 1.2883964776992798\n",
      "4692) Lyapunov Risk = 0.9421843886375427, MSE = 0.019070260226726532, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 1.3106360938763828e-06, Circular Tuning Loss = 1.28818941116333\n",
      "4693) Lyapunov Risk = 0.9420918226242065, MSE = 0.019076470285654068, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 1.4167602557790815e-06, Circular Tuning Loss = 1.2879812717437744\n",
      "4694) Lyapunov Risk = 0.9419986009597778, MSE = 0.019070949405431747, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 1.525614493402827e-06, Circular Tuning Loss = 1.2877721786499023\n",
      "4695) Lyapunov Risk = 0.9419053196907043, MSE = 0.019069353118538857, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 1.6370819366784417e-06, Circular Tuning Loss = 1.2875620126724243\n",
      "4696) Lyapunov Risk = 0.9418119788169861, MSE = 0.019077397882938385, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 1.7519342918603797e-06, Circular Tuning Loss = 1.2873504161834717\n",
      "4697) Lyapunov Risk = 0.9417186975479126, MSE = 0.01906963624060154, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 1.8707729623201885e-06, Circular Tuning Loss = 1.287137508392334\n",
      "4698) Lyapunov Risk = 0.9416255950927734, MSE = 0.0190759114921093, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 1.995519824049552e-06, Circular Tuning Loss = 1.286921501159668\n",
      "4699) Lyapunov Risk = 0.9415323138237, MSE = 0.019073637202382088, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 2.1279788597894367e-06, Circular Tuning Loss = 1.2867023944854736\n",
      "4700) Lyapunov Risk = 0.9414388537406921, MSE = 0.01906936801970005, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 2.3646330191695597e-06, Circular Tuning Loss = 1.2864809036254883\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.1495800315455715, 1.1595800315455713]\n",
      "x2 : [-1.5457667891164677, -1.5357667891164679]\n",
      "==============================\n",
      "4701) Lyapunov Risk = 0.9435309171676636, MSE = 0.019074873998761177, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 2.6123943825950846e-06, Circular Tuning Loss = 1.2904698848724365\n",
      "4702) Lyapunov Risk = 0.9434366226196289, MSE = 0.01906169205904007, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 2.8821661999245407e-06, Circular Tuning Loss = 1.2902398109436035\n",
      "4703) Lyapunov Risk = 0.943342387676239, MSE = 0.019069021567702293, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 3.1678430332249263e-06, Circular Tuning Loss = 1.2900053262710571\n",
      "4704) Lyapunov Risk = 0.9432488083839417, MSE = 0.019059384241700172, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 3.4634879284567432e-06, Circular Tuning Loss = 1.2897683382034302\n",
      "4705) Lyapunov Risk = 0.9431551098823547, MSE = 0.01905781589448452, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 3.7650468129868386e-06, Circular Tuning Loss = 1.2895296812057495\n",
      "4706) Lyapunov Risk = 0.9430608153343201, MSE = 0.019063666462898254, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 4.073012405569898e-06, Circular Tuning Loss = 1.2892892360687256\n",
      "4707) Lyapunov Risk = 0.942966103553772, MSE = 0.019055476412177086, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 4.38658889834187e-06, Circular Tuning Loss = 1.2890475988388062\n",
      "4708) Lyapunov Risk = 0.9428710341453552, MSE = 0.019064290449023247, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 4.7051057663338725e-06, Circular Tuning Loss = 1.2888048887252808\n",
      "4709) Lyapunov Risk = 0.9427756667137146, MSE = 0.01905912160873413, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 5.027578936278587e-06, Circular Tuning Loss = 1.2885613441467285\n",
      "4710) Lyapunov Risk = 0.9426800012588501, MSE = 0.0190585944801569, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 5.353838332666783e-06, Circular Tuning Loss = 1.2883169651031494\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.5716280655178634, 1.5729190160715736]\n",
      "x2 : [1.2352836795167472, 1.2367812474068081]\n",
      "==============================\n",
      "4711) Lyapunov Risk = 0.9440996050834656, MSE = 0.019061146304011345, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 5.673887244483922e-06, Circular Tuning Loss = 1.2904667854309082\n",
      "4712) Lyapunov Risk = 0.9440041780471802, MSE = 0.01904989220201969, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 5.988257726130541e-06, Circular Tuning Loss = 1.290223240852356\n",
      "4713) Lyapunov Risk = 0.9439084529876709, MSE = 0.019060533493757248, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 6.289391421887558e-06, Circular Tuning Loss = 1.2899818420410156\n",
      "4714) Lyapunov Risk = 0.9438122510910034, MSE = 0.019048944115638733, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 6.579031378350919e-06, Circular Tuning Loss = 1.289742112159729\n",
      "4715) Lyapunov Risk = 0.9437171220779419, MSE = 0.019051527604460716, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 6.937389116501436e-06, Circular Tuning Loss = 1.2895044088363647\n",
      "4716) Lyapunov Risk = 0.9436219334602356, MSE = 0.019053881987929344, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 7.83681662142044e-06, Circular Tuning Loss = 1.2892704010009766\n",
      "4717) Lyapunov Risk = 0.9435266256332397, MSE = 0.019044330343604088, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 8.952927601058036e-06, Circular Tuning Loss = 1.2890396118164062\n",
      "4718) Lyapunov Risk = 0.9434309601783752, MSE = 0.019055193290114403, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 9.997592314903159e-06, Circular Tuning Loss = 1.2888119220733643\n",
      "4719) Lyapunov Risk = 0.9433351755142212, MSE = 0.019047001376748085, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 1.0980773367919028e-05, Circular Tuning Loss = 1.2885867357254028\n",
      "4720) Lyapunov Risk = 0.9432390928268433, MSE = 0.019053803756833076, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 1.1911396541108843e-05, Circular Tuning Loss = 1.2883639335632324\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.5787346948859584, 1.5799343491605022]\n",
      "x2 : [1.2262982721763827, 1.2277958400664435]\n",
      "==============================\n",
      "4721) Lyapunov Risk = 0.9446574449539185, MSE = 0.019047480076551437, V_0_loss = tensor([[0.0075]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 1.5710131265223026e-05, Circular Tuning Loss = 1.2905205488204956\n",
      "4722) Lyapunov Risk = 0.9445614814758301, MSE = 0.019044769927859306, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 1.6953639715211466e-05, Circular Tuning Loss = 1.2903043031692505\n",
      "4723) Lyapunov Risk = 0.9444652795791626, MSE = 0.019050879403948784, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 1.7918409866979346e-05, Circular Tuning Loss = 1.2900928258895874\n",
      "4724) Lyapunov Risk = 0.9443690180778503, MSE = 0.0190415158867836, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 1.8609436665428802e-05, Circular Tuning Loss = 1.2898858785629272\n",
      "4725) Lyapunov Risk = 0.9442720413208008, MSE = 0.019051386043429375, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 1.910102400870528e-05, Circular Tuning Loss = 1.289682149887085\n",
      "4726) Lyapunov Risk = 0.9441746473312378, MSE = 0.01904468610882759, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 1.9406676074140705e-05, Circular Tuning Loss = 1.289481520652771\n",
      "4727) Lyapunov Risk = 0.9440770149230957, MSE = 0.019044410437345505, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 1.955468178493902e-05, Circular Tuning Loss = 1.2892835140228271\n",
      "4728) Lyapunov Risk = 0.9439787864685059, MSE = 0.019047286361455917, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 1.9556267943698913e-05, Circular Tuning Loss = 1.2890874147415161\n",
      "4729) Lyapunov Risk = 0.9438802003860474, MSE = 0.019039999693632126, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 1.9413899281062186e-05, Circular Tuning Loss = 1.288893461227417\n",
      "4730) Lyapunov Risk = 0.9437814354896545, MSE = 0.01904737763106823, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 1.9157167116645724e-05, Circular Tuning Loss = 1.2887012958526611\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [1.6047355520828579, 1.6060770655310406]\n",
      "x2 : [1.1918542107049848, 1.1933517785950456]\n",
      "==============================\n",
      "4731) Lyapunov Risk = 0.9451792240142822, MSE = 0.019042793661355972, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 1.8733975593931973e-05, Circular Tuning Loss = 1.2908705472946167\n",
      "4732) Lyapunov Risk = 0.945079505443573, MSE = 0.019036132842302322, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 1.8031194485956803e-05, Circular Tuning Loss = 1.290685772895813\n",
      "4733) Lyapunov Risk = 0.9449793696403503, MSE = 0.019044090062379837, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 1.7042109902831726e-05, Circular Tuning Loss = 1.29050612449646\n",
      "4734) Lyapunov Risk = 0.9448785781860352, MSE = 0.01902962662279606, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 1.57840404426679e-05, Circular Tuning Loss = 1.2903308868408203\n",
      "4735) Lyapunov Risk = 0.9447771310806274, MSE = 0.019042929634451866, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 1.429586518497672e-05, Circular Tuning Loss = 1.2901593446731567\n",
      "4736) Lyapunov Risk = 0.9446753859519958, MSE = 0.019031353294849396, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 1.2605097253981512e-05, Circular Tuning Loss = 1.2899912595748901\n",
      "4737) Lyapunov Risk = 0.9445732831954956, MSE = 0.019041268154978752, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 1.0829874554474372e-05, Circular Tuning Loss = 1.289825439453125\n",
      "4738) Lyapunov Risk = 0.9444705843925476, MSE = 0.019032614305615425, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 9.461536137678195e-06, Circular Tuning Loss = 1.2896614074707031\n",
      "4739) Lyapunov Risk = 0.9443674683570862, MSE = 0.019035805016756058, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 8.41154542285949e-06, Circular Tuning Loss = 1.289499044418335\n",
      "4740) Lyapunov Risk = 0.9442641139030457, MSE = 0.019034964963793755, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 7.965107215568423e-06, Circular Tuning Loss = 1.2893377542495728\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.1778264377299483, -1.1763823838030907]\n",
      "x2 : [-1.6174438126493789, -1.6163613188146888]\n",
      "==============================\n",
      "4741) Lyapunov Risk = 0.9458797574043274, MSE = 0.019032221287488937, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 7.787019967508968e-06, Circular Tuning Loss = 1.2919301986694336\n",
      "4742) Lyapunov Risk = 0.9457756280899048, MSE = 0.019029337912797928, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 7.609456588397734e-06, Circular Tuning Loss = 1.2917711734771729\n",
      "4743) Lyapunov Risk = 0.9456713199615479, MSE = 0.01903044804930687, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 7.420646852551727e-06, Circular Tuning Loss = 1.2916133403778076\n",
      "4744) Lyapunov Risk = 0.9455663561820984, MSE = 0.019024768844246864, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 7.221862233564025e-06, Circular Tuning Loss = 1.2914562225341797\n",
      "4745) Lyapunov Risk = 0.9454610347747803, MSE = 0.019026705995202065, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 7.014886705292156e-06, Circular Tuning Loss = 1.2912999391555786\n",
      "4746) Lyapunov Risk = 0.9453552961349487, MSE = 0.01902857795357704, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 6.8012968768016435e-06, Circular Tuning Loss = 1.2911440134048462\n",
      "4747) Lyapunov Risk = 0.945249080657959, MSE = 0.019028615206480026, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 6.582729838555679e-06, Circular Tuning Loss = 1.2909884452819824\n",
      "4748) Lyapunov Risk = 0.9451426863670349, MSE = 0.019033949822187424, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 6.360189217957668e-06, Circular Tuning Loss = 1.2908326387405396\n",
      "4749) Lyapunov Risk = 0.9450361728668213, MSE = 0.01901979371905327, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 6.135170679044677e-06, Circular Tuning Loss = 1.2906763553619385\n",
      "4750) Lyapunov Risk = 0.9449294209480286, MSE = 0.019044984132051468, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 5.90832269153907e-06, Circular Tuning Loss = 1.2905198335647583\n",
      "===========Verifying==========\n",
      "Not a Lyapunov function. Found counterexample: \n",
      "x1 : [-1.1489453591927914, -1.1475013052659335]\n",
      "x2 : [-1.6380600582435858, -1.6360724599281475]\n",
      "==============================\n",
      "4751) Lyapunov Risk = 0.9465343952178955, MSE = 0.0190206840634346, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 5.6694302656978834e-06, Circular Tuning Loss = 1.2930976152420044\n",
      "4752) Lyapunov Risk = 0.9464263319969177, MSE = 0.01902763731777668, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 5.430794772109948e-06, Circular Tuning Loss = 1.2929413318634033\n",
      "4753) Lyapunov Risk = 0.9463186860084534, MSE = 0.019035445526242256, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 5.182432687433902e-06, Circular Tuning Loss = 1.2927857637405396\n",
      "4754) Lyapunov Risk = 0.9462111592292786, MSE = 0.019007647410035133, V_0_loss = tensor([[0.0074]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 4.92631079396233e-06, Circular Tuning Loss = 1.2926307916641235\n",
      "4755) Lyapunov Risk = 0.9461029767990112, MSE = 0.019035646691918373, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 4.6617519728897605e-06, Circular Tuning Loss = 1.2924764156341553\n",
      "4756) Lyapunov Risk = 0.9459944367408752, MSE = 0.019009286537766457, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 4.389785772218602e-06, Circular Tuning Loss = 1.2923227548599243\n",
      "4757) Lyapunov Risk = 0.9458856582641602, MSE = 0.01902834139764309, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 4.112660008104285e-06, Circular Tuning Loss = 1.2921695709228516\n",
      "4758) Lyapunov Risk = 0.9457765817642212, MSE = 0.0190269872546196, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 3.832352831523167e-06, Circular Tuning Loss = 1.2920160293579102\n",
      "4759) Lyapunov Risk = 0.9456674456596375, MSE = 0.019016548991203308, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 3.5505142932379385e-06, Circular Tuning Loss = 1.2918621301651\n",
      "4760) Lyapunov Risk = 0.945559024810791, MSE = 0.01904258504509926, V_0_loss = tensor([[0.0073]], grad_fn=<PowBackward0>), V_pos_loss = 0.0, Lv_loss = 3.268249884058605e-06, Circular Tuning Loss = 1.2917078733444214\n",
      "===========Verifying==========\n",
      "Satisfy conditions\n",
      "tanh((-0.10851762443780899 - 0.57033085823059082 * tanh((-0.83319848775863647 - 0.026773005723953247 * x1 - 0.012656852602958679 * x2)) + 0.45058655738830566 * tanh((-0.37920704483985901 + 0.66573327779769897 * x1 - 0.75851088762283325 * x2)) + 0.59204500913619995 * tanh((0.052715953439474106 - 0.4724782407283783 * x1 + 0.74365693330764771 * x2)) - 0.31076329946517944 * tanh((0.53846395015716553 + 0.95878970623016357 * x1 + 0.2498060017824173 * x2)) + 0.47323921322822571 * tanh((0.68746316432952881 - 0.05122462660074234 * x1 - 0.28516259789466858 * x2)) - 0.29375234246253967 * tanh((0.78240442276000977 - 0.84357458353042603 * x1 - 0.92243224382400513 * x2))))  is a Lyapunov function.\n",
      "==============================\n",
      "\n",
      "\n",
      "Total time:  1956.5225786449996\n",
      "Verified time:  1036.6342070780033\n"
     ]
    }
   ],
   "source": [
    "out_iters = 0\n",
    "valid = False\n",
    "while out_iters < 2 and not valid: \n",
    "    start = timeit.default_timer()\n",
    "    model_v = Net(D_in,H1, D_out)\n",
    "    L = []\n",
    "    i = 0 \n",
    "    t = 0\n",
    "    max_iters = 5000 # increase number of epoches if cannot find a valid LF\n",
    "    optimizer_v = torch.optim.Adam(model_v.parameters(), lr=learning_rate)\n",
    "\n",
    "    while i < max_iters and not valid: \n",
    "        # Calculate the loss\n",
    "        x = x.float()\n",
    "        x = x\n",
    "        # Value of Lyapunov Model\n",
    "        V_candidate = model_v(x)\n",
    "        X0 = model_v(x_0)\n",
    "        # Value of Function Model\n",
    "        f = model_f(x)\n",
    "        Circle_Tuning = Tune(x)\n",
    "        Circle_Tuning = Circle_Tuning\n",
    "        # Compute lie derivative of V : L_V = ∑∂V/∂xᵢ*fᵢ\n",
    "        L_V = torch.diagonal(torch.mm(torch.mm(torch.mm(dtanh(V_candidate),model_v.layer2.weight)\\\n",
    "                            *dtanh(torch.tanh(torch.mm(x,model_v.layer1.weight.t())+model_v.layer1.bias)),model_v.layer1.weight),f.t()),0)\n",
    "        \n",
    "        dVdx = torch.mm(torch.mm(dtanh(V_candidate),model_v.layer2.weight)\\\n",
    "                            *dtanh(torch.tanh(torch.mm(x,model_v.layer1.weight.t())+model_v.layer1.bias)),model_v.layer1.weight)\n",
    "                \n",
    "        # MSE Loss\n",
    "        L1 = loss_fn(model_f(X_train),y_train)\n",
    "                \n",
    "        # Needs to be tuned\n",
    "        Lyapunov_risk = (F.relu(-V_candidate)+ 1.2*F.relu(L_V+0.2)).mean() +0.5 * ((Circle_Tuning-V_candidate).pow(2)).mean() + 5*(X0).pow(2) + 0.01*torch.norm(dVdx) + 3 * L1\n",
    " \n",
    "        L.append(Lyapunov_risk.item())\n",
    "        optimizer_v.zero_grad()\n",
    "        optimizer_f.zero_grad()\n",
    "        Lyapunov_risk.backward()\n",
    "        optimizer_v.step() \n",
    "        optimizer_f.step() \n",
    "\n",
    "        print(f\"{i}) Lyapunov Risk = {Lyapunov_risk.item()}, MSE = {L1}, V_0_loss = {(X0).pow(2).float()}, V_pos_loss = {F.relu(-V_candidate).mean()}, Lv_loss = {F.relu(L_V).mean()}, Circular Tuning Loss = {((Circle_Tuning-V_candidate).pow(2)).mean()}\")\n",
    "        # Finding the values for the new model function\n",
    "        f_w1 = model_f.layer1.weight.data.cpu().numpy()\n",
    "        f_w2 = model_f.layer2.weight.data.cpu().numpy()\n",
    "        f_b1 = model_f.layer1.bias.data.cpu().numpy()\n",
    "        f_b2 = model_f.layer2.bias.data.cpu().numpy()\n",
    "\n",
    "        f_h1 = []\n",
    "        f_z1 = np.dot(vars_,f_w1.T)+f_b1\n",
    "        for n in range(len(f_z1)):\n",
    "            f_h1.append(tanh(f_z1[n]))\n",
    "        f_learn = np.dot(f_h1,f_w2.T)+f_b2\n",
    "        # save the weights and biases \n",
    "        w1 = model_v.layer1.weight.data.cpu().numpy()\n",
    "        w2 = model_v.layer2.weight.data.cpu().numpy()\n",
    "        b1 = model_v.layer1.bias.data.cpu().numpy()\n",
    "        b2 = model_v.layer2.bias.data.cpu().numpy()\n",
    "        \n",
    "        # Falsification with SMT solver\n",
    "        if i % 10 == 0:\n",
    "                    \n",
    "            # Candidate V\n",
    "            z1 = np.dot(vars_,w1.T)+b1\n",
    "        \n",
    "            a1 = []\n",
    "            for j in range(0,len(z1)):\n",
    "                a1.append(tanh(z1[j]))\n",
    "            z2 = np.dot(a1,w2.T)+b2\n",
    "            V_learn = tanh(z2.item(0))\n",
    "        \n",
    "            print('===========Verifying==========')        \n",
    "            start_ = timeit.default_timer() \n",
    "            #beta = -np.maximum(beta, -0.02) # in case beta is too negative and cannot return any results\n",
    "            result= CheckLyapunov(vars_, f_learn, V_learn, ball_lb, ball_ub, config, beta) # SMT solver\n",
    "            stop_ = timeit.default_timer() \n",
    "        \n",
    "            if (result): \n",
    "                    print(\"Not a Lyapunov function. Found counterexample: \")\n",
    "                    print(result)\n",
    "                    x = x.to('cpu')\n",
    "                    x = AddCounterexamples(x,result,10)\n",
    "            else:  \n",
    "                    # # calculate norm of dVdx with the SMT solver\n",
    "                    # M = 0.05 # lower bound of M\n",
    "                    # dvdx_bound = np.sqrt(M)\n",
    "                    # violation = CheckdVdx(vars_, V_learn, ball_ub, config, M) \n",
    "                    # while violation:\n",
    "                    #     violation = CheckdVdx(vars_, V_learn, ball_ub, config, M)\n",
    "                    #     if not violation:\n",
    "                    #         dvdx_bound = np.sqrt(M)\n",
    "                    #         print(dvdx_bound, \"is the norm of dVdx\")\n",
    "                    #     M += 0.001\n",
    "                    # beta = -dvdx_bound*((Kf+KF)*d+loss) # update beta \n",
    "                    # print(\"Satisfies with a non-strict condition\")\n",
    "                    # result_strict= CheckLyapunov(vars_, f_learn, V_learn, ball_lb, ball_ub, config, beta) # SMT solver\n",
    "                    # beta = beta.detach().numpy()\n",
    "                    # if not result_strict:\n",
    "                    #     valid = True\n",
    "                    #     print(\"Satisfy conditions with beta = \", beta)\n",
    "                    #     print(V_learn, \" is a Lyapunov function.\")\n",
    "                    valid = True\n",
    "                    print(\"Satisfy conditions\")\n",
    "                    print(V_learn, \" is a Lyapunov function.\")\n",
    "            t += (stop_ - start_)\n",
    "            print('==============================') \n",
    "        i += 1\n",
    "\n",
    "    stop = timeit.default_timer()\n",
    "    \n",
    "    np.savetxt(\"w1_vdp.txt\", model_v.layer1.weight.data.cpu(), fmt=\"%s\")\n",
    "    np.savetxt(\"w2_vdp.txt\", model_v.layer2.weight.data.cpu(), fmt=\"%s\")\n",
    "    np.savetxt(\"b1_vdp.txt\", model_v.layer1.bias.data.cpu(), fmt=\"%s\")\n",
    "    np.savetxt(\"b2_vdp.txt\", model_v.layer2.bias.data.cpu(), fmt=\"%s\")\n",
    "\n",
    "    print('\\n')\n",
    "    print(\"Total time: \", stop - start)\n",
    "    print(\"Verified time: \", t)\n",
    "    \n",
    "    out_iters+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3c067bce-f018-49b7-914b-34c9148957bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the Lyapunov Function\n",
    "fig, ax = plt.subplots()\n",
    "# Define grid for plotting\n",
    "len_sample = [256, 256]\n",
    "x = np.linspace(region[0], region[1], len_sample[0])\n",
    "y = np.linspace(region[0], region[1], len_sample[1])\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "# Convert X and Y to torch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "Y_tensor = torch.tensor(Y, dtype=torch.float32)\n",
    "\n",
    "# Concatenate X and Y to create input data tensor\n",
    "input_data = torch.stack((X_tensor, Y_tensor), dim=-1).reshape(-1, 2)\n",
    "unflatten = torch.nn.Unflatten(0, len_sample)\n",
    "\n",
    "# Lyapunov Function\n",
    "with torch.no_grad():\n",
    "    V = model_v(input_data)\n",
    "    cont_out = unflatten(V)\n",
    "    cont_out = cont_out.detach().numpy()\n",
    "# Plot the vector field\n",
    "cp = ax.contourf(X, Y, cont_out[:,:,0])\n",
    "fig.colorbar(cp)\n",
    "plt.grid(True)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Lyapunov Function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bedb33ca-2505-4915-8240-d81b46ce2761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the Lyapunov function in 3D\n",
    "fig = plt.figure(figsize=(10, 8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.plot_surface(X, Y, cont_out[:,:,0], cmap='viridis')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "ax.set_zlabel('Lyapunov Function Value')\n",
    "ax.set_title('Lyapunov Function')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a64187d2-698f-441d-8d7e-126f5e18f23f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots()\n",
    "# Define grid for plotting\n",
    "len_sample = [256, 256]\n",
    "x = np.linspace(region[0], region[1], len_sample[0])\n",
    "y = np.linspace(region[0], region[1], len_sample[1])\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "# Convert X and Y to torch tensors\n",
    "X_tensor = torch.tensor(X, dtype=torch.float32)\n",
    "Y_tensor = torch.tensor(Y, dtype=torch.float32)\n",
    "\n",
    "# Concatenate X and Y to create input data tensor\n",
    "input_data = torch.stack((X_tensor, Y_tensor), dim=-1).reshape(-1, 2)\n",
    "unflatten = torch.nn.Unflatten(0, len_sample)\n",
    "\n",
    "# Vector Field\n",
    "with torch.no_grad():\n",
    "    F = model_f(input_data)\n",
    "    vect_out = unflatten(F)\n",
    "    vect_out = vect_out.detach().numpy()\n",
    "    U = vect_out[:,:, 0]\n",
    "    V = vect_out[:,:,1]\n",
    "ax.streamplot(X, Y, U, V, density=1.4, linewidth=None, color='b')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Vector Field for Neural Network Dynamical System')\n",
    "\n",
    "# Lyapunov Function\n",
    "with torch.no_grad():\n",
    "    V = model_v(input_data)\n",
    "    cont_out = unflatten(V)\n",
    "    cont_out = cont_out.detach().numpy()\n",
    "# Plot the vector field\n",
    "cp = ax.contourf(X, Y, cont_out[:,:,0])\n",
    "fig.colorbar(cp)\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac043fee-52a3-4408-b022-fd2dd3e095b8",
   "metadata": {},
   "source": [
    "## Plot the Training Trajectories and the Output Trajectory taken by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ec111d8-2438-4535-b84a-81c545bdf97e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the Training Data\n",
    "fig, ax = plt.subplots()\n",
    "n = int(X_train.shape[0]/1000)\n",
    "for i in range(5):\n",
    "    ax.plot(X_train[(i-1)*1000+1:i*1000,0], X_train[(i-1)*1000+1:i*1000,1],\"b\")\n",
    "\n",
    "# Plotting the final trajectory\n",
    "n = 1000\n",
    "x = torch.zeros((n, 2))\n",
    "x[0] = torch.tensor([-1.1,-0.05], dtype=torch.float32)\n",
    "for j in range(1, n):\n",
    "    x[j] = x[j-1] + model_f(x[j-1]) * dt\n",
    "x = x.detach().numpy()\n",
    "ax.plot(x[:, 0], x[:, 1],'r')\n",
    "\n",
    "# Plotting the origin\n",
    "#plt.plot(0, 0, 'ro')\n",
    "#plt.text(0.1, 0.1, 'Origin (0, 0)', fontsize=10)\n",
    "\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.title('Trajectories of the Dynamical System')\n",
    "plt.grid(True)\n",
    "plt.axis('equal')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
